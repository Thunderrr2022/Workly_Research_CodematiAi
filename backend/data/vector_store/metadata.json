{
  "documents": {
    "tmpfq1e9t_3_Subhakar_RAMA_TADIMALLA.pdf_3b63db93_d12e23f3": {
      "id": "tmpfq1e9t_3_Subhakar_RAMA_TADIMALLA.pdf_3b63db93_d12e23f3",
      "filename": "Subhakar_RAMA_TADIMALLA.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmpfq1e9t_3_Subhakar_RAMA_TADIMALLA.pdf",
      "text_length": 2763,
      "chunk_count": 4,
      "added_at": "2025-09-20T20:41:31"
    },
    "tmp4mk9_2wh_CodeMate_Hackathon_Guidelines.pdf_64c80de2_6daa17c3": {
      "id": "tmp4mk9_2wh_CodeMate_Hackathon_Guidelines.pdf_64c80de2_6daa17c3",
      "filename": "CodeMate_Hackathon_Guidelines.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmp4mk9_2wh_CodeMate_Hackathon_Guidelines.pdf",
      "text_length": 2853,
      "chunk_count": 4,
      "added_at": "2025-09-20T20:43:29"
    },
    "tmpvrf3z0fe_CodeMate_Hackathon_Problem_Statements.pdf_04fd9f26_d87ac2be": {
      "id": "tmpvrf3z0fe_CodeMate_Hackathon_Problem_Statements.pdf_04fd9f26_d87ac2be",
      "filename": "CodeMate_Hackathon_Problem_Statements.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmpvrf3z0fe_CodeMate_Hackathon_Problem_Statements.pdf",
      "text_length": 5760,
      "chunk_count": 8,
      "added_at": "2025-09-20T21:08:05"
    },
    "tmp9cqjsl65_CodeMate_Hackathon_Guidelines.pdf_64c80de2_a2508099": {
      "id": "tmp9cqjsl65_CodeMate_Hackathon_Guidelines.pdf_64c80de2_a2508099",
      "filename": "CodeMate_Hackathon_Guidelines.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmp9cqjsl65_CodeMate_Hackathon_Guidelines.pdf",
      "text_length": 2853,
      "chunk_count": 4,
      "added_at": "2025-09-20T21:32:23"
    },
    "tmp4cbou3oj_research_report_2025-09-20.pdf_2d559232_65733a86": {
      "id": "tmp4cbou3oj_research_report_2025-09-20.pdf_2d559232_65733a86",
      "filename": "research_report_2025-09-20.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmp4cbou3oj_research_report_2025-09-20.pdf",
      "text_length": 1653,
      "chunk_count": 3,
      "added_at": "2025-09-20T21:32:55"
    },
    "tmp8wi97st1_test_ar_vr_doc.txt_e928ccf9_cb4c86f3": {
      "id": "tmp8wi97st1_test_ar_vr_doc.txt_e928ccf9_cb4c86f3",
      "filename": "test_ar_vr_doc.txt",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmp8wi97st1_test_ar_vr_doc.txt",
      "text_length": 2354,
      "chunk_count": 4,
      "added_at": "2025-09-20T21:43:26"
    },
    "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7": {
      "id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "filename": "UNIT II - GCV.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmpy27f51_d_UNIT II - GCV.pdf",
      "text_length": 29225,
      "chunk_count": 39,
      "added_at": "2025-09-20T21:46:10"
    },
    "tmpfkjb5g09.txt_e928ccf9_dfe95088": {
      "id": "tmpfkjb5g09.txt_e928ccf9_dfe95088",
      "filename": "test_ar_vr_doc.txt",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmpfkjb5g09.txt",
      "text_length": 2354,
      "chunk_count": 4,
      "added_at": "2025-09-20T21:52:12"
    },
    "tmp2ix3axfe.txt_e928ccf9_627b62b9": {
      "id": "tmp2ix3axfe.txt_e928ccf9_627b62b9",
      "filename": "test_ar_vr_doc.txt",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmp2ix3axfe.txt",
      "text_length": 2354,
      "chunk_count": 4,
      "added_at": "2025-09-20T21:53:51"
    },
    "tmpnai1uf_d.txt_e928ccf9_28c09460": {
      "id": "tmpnai1uf_d.txt_e928ccf9_28c09460",
      "filename": "test_ar_vr_doc.txt",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmpnai1uf_d.txt",
      "text_length": 2354,
      "chunk_count": 4,
      "added_at": "2025-09-20T21:54:34"
    },
    "tmp3fipkrrd.txt_e928ccf9_9db2a331": {
      "id": "tmp3fipkrrd.txt_e928ccf9_9db2a331",
      "filename": "test_ar_vr_doc.txt",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmp3fipkrrd.txt",
      "text_length": 2354,
      "chunk_count": 4,
      "added_at": "2025-09-20T21:55:34"
    },
    "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8": {
      "id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "filename": "UNIT I - GCV NOTES.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmpyoc6mhp1_UNIT I - GCV NOTES.pdf",
      "text_length": 35915,
      "chunk_count": 47,
      "added_at": "2025-09-20T21:56:50"
    },
    "tmpex89ia9c.pdf_b9876e2d_1a573e61": {
      "id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "filename": "UNIT I - GCV NOTES.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmpex89ia9c.pdf",
      "text_length": 35915,
      "chunk_count": 47,
      "added_at": "2025-09-20T21:56:58"
    },
    "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99": {
      "id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "filename": "UNIT I - GCV NOTES.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmpf9r6pu7d_UNIT I - GCV NOTES.pdf",
      "text_length": 35915,
      "chunk_count": 47,
      "added_at": "2025-09-20T21:57:17"
    },
    "tmpupqjtq0y.pdf_b9876e2d_41ddd12a": {
      "id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "filename": "UNIT I - GCV NOTES.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmpupqjtq0y.pdf",
      "text_length": 35915,
      "chunk_count": 47,
      "added_at": "2025-09-20T21:57:26"
    },
    "e40f6281-a1f2-458e-a226-c1f49cd8dea3_test_ar_vr_doc.txt_e928ccf9_9a7b0b57": {
      "id": "e40f6281-a1f2-458e-a226-c1f49cd8dea3_test_ar_vr_doc.txt_e928ccf9_9a7b0b57",
      "filename": "test_ar_vr_doc.txt",
      "file_path": "uploads/e40f6281-a1f2-458e-a226-c1f49cd8dea3_test_ar_vr_doc.txt",
      "text_length": 2354,
      "chunk_count": 4,
      "added_at": "2025-09-21T06:43:54"
    },
    "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166": {
      "id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "filename": "UNIT II - GCV.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmprvm4fu_o_UNIT II - GCV.pdf",
      "text_length": 29225,
      "chunk_count": 39,
      "added_at": "2025-09-21T06:45:54"
    },
    "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3": {
      "id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "filename": "UNIT II - GCV.pdf",
      "file_path": "uploads/2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf",
      "text_length": 29225,
      "chunk_count": 39,
      "added_at": "2025-09-21T06:46:01"
    },
    "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3": {
      "id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "filename": "UNIT I - GCV NOTES.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmpfh78omy3_UNIT I - GCV NOTES.pdf",
      "text_length": 34296,
      "chunk_count": 45,
      "added_at": "2025-09-21T07:13:17"
    },
    "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3": {
      "id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "filename": "UNIT I - GCV NOTES.pdf",
      "file_path": "uploads/42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf",
      "text_length": 34296,
      "chunk_count": 45,
      "added_at": "2025-09-21T07:13:26"
    },
    "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513": {
      "id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "filename": "UNIT II - GCV.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmpws6vz554_UNIT II - GCV.pdf",
      "text_length": 28219,
      "chunk_count": 37,
      "added_at": "2025-09-21T07:23:34"
    },
    "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc": {
      "id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "filename": "UNIT II - GCV.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmpq6fgzwr7_UNIT II - GCV.pdf",
      "text_length": 28219,
      "chunk_count": 37,
      "added_at": "2025-09-21T07:30:53"
    },
    "tmp8fzwuted_Restitution Devices in AR.pdf_bb87f86e_fc012117": {
      "id": "tmp8fzwuted_Restitution Devices in AR.pdf_bb87f86e_fc012117",
      "filename": "Restitution Devices in AR.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmp8fzwuted_Restitution Devices in AR.pdf",
      "text_length": 3621,
      "chunk_count": 5,
      "added_at": "2025-09-21T07:35:11"
    },
    "tmp_teku8x2_Tutorial4_Banking_Laws_Comparison.pdf_da86a0f3_13072223": {
      "id": "tmp_teku8x2_Tutorial4_Banking_Laws_Comparison.pdf_da86a0f3_13072223",
      "filename": "Tutorial4_Banking_Laws_Comparison.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmp_teku8x2_Tutorial4_Banking_Laws_Comparison.pdf",
      "text_length": 3487,
      "chunk_count": 5,
      "added_at": "2025-09-21T07:40:59"
    },
    "tmpy_gzq1e__VR-AR for industrial renewal.pdf_8ebec43a_18d419b8": {
      "id": "tmpy_gzq1e__VR-AR for industrial renewal.pdf_8ebec43a_18d419b8",
      "filename": "VR-AR for industrial renewal.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmpy_gzq1e__VR-AR for industrial renewal.pdf",
      "text_length": 4683,
      "chunk_count": 7,
      "added_at": "2025-09-21T07:45:03"
    },
    "e69a2cb3-36e0-44d2-b1ae-2a5b48c16a02_docA.txt_125a1826_d5c09805": {
      "id": "e69a2cb3-36e0-44d2-b1ae-2a5b48c16a02_docA.txt_125a1826_d5c09805",
      "filename": "docA.txt",
      "file_path": "uploads/e69a2cb3-36e0-44d2-b1ae-2a5b48c16a02_docA.txt",
      "text_length": 83,
      "chunk_count": 1,
      "added_at": "2025-09-21T07:50:44"
    },
    "2eb8b721-ddce-4bbd-ac02-4a47277965fe_docB.txt_b3f2c7e0_e19edc39": {
      "id": "2eb8b721-ddce-4bbd-ac02-4a47277965fe_docB.txt_b3f2c7e0_e19edc39",
      "filename": "docB.txt",
      "file_path": "uploads/2eb8b721-ddce-4bbd-ac02-4a47277965fe_docB.txt",
      "text_length": 83,
      "chunk_count": 1,
      "added_at": "2025-09-21T07:50:52"
    },
    "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398": {
      "id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "filename": "UNIT II - GCV.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmpi1f70h19_UNIT II - GCV.pdf",
      "text_length": 28219,
      "chunk_count": 37,
      "added_at": "2025-09-21T07:56:14"
    },
    "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd": {
      "id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "filename": "UNIT II - GCV.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmp9lufgen8_UNIT II - GCV.pdf",
      "text_length": 28219,
      "chunk_count": 37,
      "added_at": "2025-09-21T08:35:45"
    },
    "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865": {
      "id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "filename": "UNIT I - GCV NOTES.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmp_m_71n3r_UNIT I - GCV NOTES.pdf",
      "text_length": 34296,
      "chunk_count": 45,
      "added_at": "2025-09-21T08:36:07"
    },
    "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78": {
      "id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "filename": "UNIT I - GCV NOTES.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmp_d45enbk_UNIT I - GCV NOTES.pdf",
      "text_length": 34296,
      "chunk_count": 45,
      "added_at": "2025-09-21T08:40:26"
    },
    "7983b982-fce7-40aa-9820-783d0b476c8f_test_ai_document.txt_74ec5939_56ed54d4": {
      "id": "7983b982-fce7-40aa-9820-783d0b476c8f_test_ai_document.txt_74ec5939_56ed54d4",
      "filename": "test_ai_document.txt",
      "file_path": "uploads/7983b982-fce7-40aa-9820-783d0b476c8f_test_ai_document.txt",
      "text_length": 492,
      "chunk_count": 1,
      "added_at": "2025-09-21T08:44:07"
    },
    "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f": {
      "id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "filename": "UNIT I - GCV NOTES.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmp6b5qb6dw_UNIT I - GCV NOTES.pdf",
      "text_length": 34296,
      "chunk_count": 45,
      "added_at": "2025-09-21T08:45:41"
    },
    "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82": {
      "id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "filename": "UNIT I - GCV NOTES.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmpm2bra9mn_UNIT I - GCV NOTES.pdf",
      "text_length": 34296,
      "chunk_count": 45,
      "added_at": "2025-09-21T09:06:40"
    },
    "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210": {
      "id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "filename": "UNIT I - GCV NOTES.pdf",
      "file_path": "/var/folders/jv/hgf0qmc91ll4d_r0f3w80ml40000gn/T/tmp37h9epij_UNIT I - GCV NOTES.pdf",
      "text_length": 34296,
      "chunk_count": 45,
      "added_at": "2025-09-21T09:08:05"
    }
  },
  "texts": [
    {
      "doc_id": "tmpfq1e9t_3_Subhakar_RAMA_TADIMALLA.pdf_3b63db93_d12e23f3",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nSubhakar Tadimalla  leetcode.com/u/subhakarxt/ | Tadimallasubhakar@gmail.com | linkedin.com/in/subhakartadimalla/ | github.com/Thunderrr2022 Summary Software Engineer in training with strong foundations in Cloud, AI/ML, Networking, and Database Systems. Skilled in C++, Python, MySQL, and AWS, with experience in CI/CD pipelines, scalable applications, and ML-driven platforms. EDUCATION    SRM Institute of Science and Technology, Kattankulathur                                    Sept. 2022 – May 2026 B. Tech in Computer Science and Engineering CGPA: 8.65 Career Point, Rajahmundry 2022 XII – Board of Intermediate Education Percentage: 96.3% Bhartiya Vidya Bhavans, Andhra Pradesh 2020 X – Central Board of Secondary Education Percentage: 83.4% TECHNICAL SKILLS Languages: C, C++, Java, Python, Shell Scripting, and SQL Frameworks/Tools: React, FastAPI, TensorFlow, Docker, GitHub, LINUX, Terraform, CI/CD, Kubernetes, AWS Cloud/Databases: AWS (EC2, Lambda, S3), MySQL, MongoDB EXP",
      "filename": "Subhakar_RAMA_TADIMALLA.pdf"
    },
    {
      "doc_id": "tmpfq1e9t_3_Subhakar_RAMA_TADIMALLA.pdf_3b63db93_d12e23f3",
      "chunk_index": 1,
      "content": "Java, Python, Shell Scripting, and SQL Frameworks/Tools: React, FastAPI, TensorFlow, Docker, GitHub, LINUX, Terraform, CI/CD, Kubernetes, AWS Cloud/Databases: AWS (EC2, Lambda, S3), MySQL, MongoDB EXPERIENCE National University of Singapore Internship June 2024 NUS  Singapore, Singapore • Designed and deployed a smart waste management system using Python, YOLOv8, and geotagging; rewarded users for identifying scattered waste via a gamified incentive model. • Collaborated with NUS faculty on research of different models for aerial/drone image detection; contributed to dataset preparation, model experimentation, and analysis for smart waste management. PROJECTS Blog deployment platform| Terraform, AWS (ECS, ECR, S3, Code Pipeline, Code Build), Docker, GitHub Actions                GitHub • Built a CI/CD pipeline using Terraform and GitHub Actions to automate deployment of a MERN-based blog platform with zero downtime. Web-based Employee Management System| Node.js, Express.",
      "filename": "Subhakar_RAMA_TADIMALLA.pdf"
    },
    {
      "doc_id": "tmpfq1e9t_3_Subhakar_RAMA_TADIMALLA.pdf_3b63db93_d12e23f3",
      "chunk_index": 2,
      "content": "GitHub • Built a CI/CD pipeline using Terraform and GitHub Actions to automate deployment of a MERN-based blog platform with zero downtime. Web-based Employee Management System| Node.js, Express.js, MySQL, REST APIs, AWS EC2 GitHub • Developed a full-stack employee management system with React frontend, Node.js backend, and MySQL database. AI based SHG platform | React, Node.js, Python, TensorFlow, MySQL, REST APIs.                            GitHub • Built an AI-driven SHG loan tracking & application system with loan eligibility prediction and MySQL for loan management. • Applied software engineering principles (requirement analysis, modular design, testing, version control) POSITION OF RESPONSIBILITY Chief Liaison - Core Team Aug 2024 - Present Society of Women Engineers SRMIST • Facilitating communication and strategic collaboration between university departments, students, and external stakeholders.",
      "filename": "Subhakar_RAMA_TADIMALLA.pdf"
    },
    {
      "doc_id": "tmpfq1e9t_3_Subhakar_RAMA_TADIMALLA.pdf_3b63db93_d12e23f3",
      "chunk_index": 3,
      "content": "f Liaison - Core Team Aug 2024 - Present Society of Women Engineers SRMIST • Facilitating communication and strategic collaboration between university departments, students, and external stakeholders. ACHIEVEMENTS • 2nd Place – Intelligi AI Agent Hackathon (50+ teams) • ODOO Hack’2, Finalists – Participated in OODO office PUNE • Hack Vega Finalist among 10,000+ participants nationwide. • Oracle: MySQL 8.0 Database Developer Oracle Certified Professional",
      "filename": "Subhakar_RAMA_TADIMALLA.pdf"
    },
    {
      "doc_id": "tmp4mk9_2wh_CodeMate_Hackathon_Guidelines.pdf_64c80de2_6daa17c3",
      "chunk_index": 0,
      "content": "--- Page 1 ---\n \nHackathon Guidelines & Information Document  \nEvent Overview  \nA Hackathon will be conducted on 20th September and 21st September . The event is designed to \nassess creativity, technical skills, and problem -solving abilities while providing participants with \npractical exposure to building projects using CodeMate Build  and the CodeMate Extension . \nThe use of these specified AI tools is mandatory . This requirement is intended to evaluate the \nefficiency, adaptability, and understanding of students in applying AI tools during project \ndevelopment.  \nPhases of the Hackathon  \nPhase 1: Problem Statement and Project Development  \n1. At the start of the hackathon, participants will be provided with three problem statements . \n2. Each participant must select one problem statement  to work on.  \n3. All participants are required to:  \no Create an account on CodeMate for Education  via the official platform link: \nhttps://edu.codemate.",
      "filename": "CodeMate_Hackathon_Guidelines.pdf"
    },
    {
      "doc_id": "tmp4mk9_2wh_CodeMate_Hackathon_Guidelines.pdf_64c80de2_6daa17c3",
      "chunk_index": 1,
      "content": "articipant must select one problem statement  to work on.  \n3. All participants are required to:  \no Create an account on CodeMate for Education  via the official platform link: \nhttps://edu.codemate.ai/  \no Join the respective classroom  on CodeMate where the project assignments will be \navailable.  \no Access the chosen project assignment  and begin working on it using CodeMate \nBuild  and the CodeMate Extension . \nSubmission Requirements  \nParticipants must submit the following:  \n• Upload the entire Codebase on CodeMate  IDE ( Excluding node modules  if in the project)  \n• A live working video demonstrating the project  \n• A live hosted URL of the project  \n• A GitHub repository link containing the complete source code  \nPhase 2: Evaluation and Shortlisting  \n1. Submissions will be evaluated based on:  \no Functionality  \no Innovation  \no Code quality  \no Problem -solving approach  \no Effective use of the mandatory AI tools  \n2.",
      "filename": "CodeMate_Hackathon_Guidelines.pdf"
    },
    {
      "doc_id": "tmp4mk9_2wh_CodeMate_Hackathon_Guidelines.pdf_64c80de2_6daa17c3",
      "chunk_index": 2,
      "content": "valuation and Shortlisting  \n1. Submissions will be evaluated based on:  \no Functionality  \no Innovation  \no Code quality  \no Problem -solving approach  \no Effective use of the mandatory AI tools  \n2. Shortlisted participants will be notified and invited for the interview round.  \n\n--- Page 2 ---\n \nPhase 3: Interview and Offers  \n1. Shortlisted students will appear for an interview conducted by the evaluation panel.  \n2. Students who successfully clear the interview round will be issued offer letters . \nImportant Dates  \n• Hackathon Dates: 20th September & 21st September  \n• Submission Deadline:  24 hours . \n• Interview Round: 22nd September.  \nKey Instructions  \n• Registration on CodeMate for Education  is compulsory. Platform Link: \nhttps://edu.codemate.ai/  \n• All submissions must include the required deliverables:  source code , video, hosted URL, and \nGitHub repository.  \n• Projects must demonstrate the use of CodeMate Build  and the CodeMate Extension .",
      "filename": "CodeMate_Hackathon_Guidelines.pdf"
    },
    {
      "doc_id": "tmp4mk9_2wh_CodeMate_Hackathon_Guidelines.pdf_64c80de2_6daa17c3",
      "chunk_index": 3,
      "content": "All submissions must include the required deliverables:  source code , video, hosted URL, and \nGitHub repository.  \n• Projects must demonstrate the use of CodeMate Build  and the CodeMate Extension . \n• Late or incomplete submissions may not be considered for evaluation.  \n• Participants must maintain originality and follow ethical coding practices.  \nOutcome  \nThe hackathon is a platform to showcase coding skills and problem -solving abilities. Students who \nsuccessfully complete all phases and clear the interview will be issued official offer letters  from \nCodeMate.",
      "filename": "CodeMate_Hackathon_Guidelines.pdf"
    },
    {
      "doc_id": "tmpvrf3z0fe_CodeMate_Hackathon_Problem_Statements.pdf_04fd9f26_d87ac2be",
      "chunk_index": 0,
      "content": "--- Page 1 ---\n \nCodeMate Hackathon Problem \nStatements and Submission Guidelines  \nProblem Statements  \nParticipants must select one of the following problem statements to build their project. All projects \nmust be developed using Python  wherever specified. The use of CodeMate Build  and CodeMate \nExtension  is mandatory throughout the development process  to gauge the understanding of AI tools \nand efficiency.  \nProblem Statement 1: Python -Based Command Terminal  \nDescription  \nDevelop a fully functioning command terminal that mimics the behavior of a real system terminal. \nThe backend of this terminal must be built in Python. The terminal should be able to execute \nstandard commands (such as file operations, directory navigation, process checks, etc.) and return \naccurate outputs.  \nChallenge  \nThe key challenge is replicating the low -level behavior of a traditional terminal in a Python \nenvironment while ensuring efficiency, correctness, and extensibility.",
      "filename": "CodeMate_Hackathon_Problem_Statements.pdf"
    },
    {
      "doc_id": "tmpvrf3z0fe_CodeMate_Hackathon_Problem_Statements.pdf_04fd9f26_d87ac2be",
      "chunk_index": 1,
      "content": "accurate outputs.  \nChallenge  \nThe key challenge is replicating the low -level behavior of a traditional terminal in a Python \nenvironment while ensuring efficiency, correctness, and extensibility.  \nMandatory Requirements  \n• A Python backend to process and execute commands  \n• Support for full-fledged  file and directory operations (e.g., ls, cd, pwd, mkdir, rm)  \n• Error handling for invalid commands  \n• Clean and responsive interface (can be CLI or web -based)  \n• Integration with system monitoring tools such as CPU, memory, and processes  \nOptional  Enhancements  \n• AI-driven terminal where users can type natural language queries (e.g., “create a new folder \ncalled test and move file1.txt into it” ) and the system interprets them into actual commands  \n• Command history and auto -completion  \nProblem Statement 2: PR (Pull Request) Review Agent  \nDescription  \nBuild an AI -powered agent capable of reviewing pull requests across any git server (e.g., GitHub, \nGitLab, Bitbucket).",
      "filename": "CodeMate_Hackathon_Problem_Statements.pdf"
    },
    {
      "doc_id": "tmpvrf3z0fe_CodeMate_Hackathon_Problem_Statements.pdf_04fd9f26_d87ac2be",
      "chunk_index": 2,
      "content": "completion  \nProblem Statement 2: PR (Pull Request) Review Agent  \nDescription  \nBuild an AI -powered agent capable of reviewing pull requests across any git server (e.g., GitHub, \nGitLab, Bitbucket). The agent should analyze code changes and provide constructive feedback for \nimprovements.  \nChallenge  \nCreating a general -purpose agent that works with any git server and can understand diverse \ncodebases. The system must evaluate changes for quality, standards, and possible issues.  \nMandatory Requirements  \n\n--- Page 2 ---\n \n• Compatibility with multiple git servers (not restricted to GitHub only)  \n• Feedback generation on code structure, standards, and possible bugs  \n• Written in Python with a modular structure  \nPossible Enhancements  \n• AI-driven feedback with automated suggestions for better readability, performance, or \nsecurity  \n• Inline review comments similar to GitHub or GitLab review systems  \n• Integration with CI/CD pipelines for automated pre -merge reviews  \n• Scorin",
      "filename": "CodeMate_Hackathon_Problem_Statements.pdf"
    },
    {
      "doc_id": "tmpvrf3z0fe_CodeMate_Hackathon_Problem_Statements.pdf_04fd9f26_d87ac2be",
      "chunk_index": 3,
      "content": "for better readability, performance, or \nsecurity  \n• Inline review comments similar to GitHub or GitLab review systems  \n• Integration with CI/CD pipelines for automated pre -merge reviews  \n• Scoring system to grade PRs on code quality  \nProblem Statement 3: Deep Researcher Agent  \nDescription  \nCreate a deep researcher agent that can search, analyze, and synthesize information from large -scale \ndata sources. The solution must not rely on external web search APIs; instead, it should handle local \nembedding generation and reasoning.  \nChallenge  \nBuilding a high -scale system that can effectively gather, process, and retrieve relevant information \nwithout depending on external APIs. The embeddings and retrieval logic must be handled locally.  \nMandatory Requirements  \n• Python -based system for query handling and response generation  \n• Local embedding generation for document indexing and retrieval  \n• Support for multi -step reasoning to break down queries into smaller tasks  \n• Eff",
      "filename": "CodeMate_Hackathon_Problem_Statements.pdf"
    },
    {
      "doc_id": "tmpvrf3z0fe_CodeMate_Hackathon_Problem_Statements.pdf_04fd9f26_d87ac2be",
      "chunk_index": 4,
      "content": "tem for query handling and response generation  \n• Local embedding generation for document indexing and retrieval  \n• Support for multi -step reasoning to break down queries into smaller tasks  \n• Efficient storage and retrieval pipeline  \nPossible Enhancements  \n• Summarization of multiple sources into a coherent research report  \n• Interactive query refinement where the user can ask follow -up questions to dig deeper  \n• AI-powered assistant that explains reasoning steps  \n• Export of research results in structured formats such as PDF or Markdown  \n \n \n \n \n \n\n--- Page 3 ---\n \nSubmission Guidelines  \nAll participants must complete two mandatory modes of submission. Both are compulsory and will \nhave separate evaluation criteria.  \nSubmission on CodeMate for Education  \n1. Create an account on CodeMate for Education  via the platform link: \nhttp://edu.codemate.ai/signup?org_code=e6ccbc16 -5e38 -4042 -b3cf -\n4a558b408ffc&class_code=B4hiap  \n2.",
      "filename": "CodeMate_Hackathon_Problem_Statements.pdf"
    },
    {
      "doc_id": "tmpvrf3z0fe_CodeMate_Hackathon_Problem_Statements.pdf_04fd9f26_d87ac2be",
      "chunk_index": 5,
      "content": "CodeMate for Education  \n1. Create an account on CodeMate for Education  via the platform link: \nhttp://edu.codemate.ai/signup?org_code=e6ccbc16 -5e38 -4042 -b3cf -\n4a558b408ffc&class_code=B4hiap  \n2. In case the above link doesn’t work:  \n• Head to https://edu.codemate.ai/  \n• Create your account using your college official email id’s.  \n• Under the heading of Public Courses – New  \n• Head to the Join a private classroom with a code  \n• Enter the following code in the text box and you should be logged in: B4hiap  \n3. Join the assigned classroom and access your chosen project assignment  \n4. Upload the following deliverables:  \no Source code  on CodeMate  IDE (CodeMate for education, assignment submission)  \no While uploading your files ensure to remove node modules, any venv folder, or \nother system level files , they may negatively impact your evaluation.  \no A live working video demonstrating the project  \no A live hosted URL of the project  \no A GitHub repository link containing th",
      "filename": "CodeMate_Hackathon_Problem_Statements.pdf"
    },
    {
      "doc_id": "tmpvrf3z0fe_CodeMate_Hackathon_Problem_Statements.pdf_04fd9f26_d87ac2be",
      "chunk_index": 6,
      "content": "ther system level files , they may negatively impact your evaluation.  \no A live working video demonstrating the project  \no A live hosted URL of the project  \no A GitHub repository link containing the complete source code  \no Watch the video  for clear steps on uploading your project.  \nSubmission on LinkedIn  \n1. Prepare a LinkedIn post with the following:  \no The working video of your project, with a short verbal or written explanation  \no An explanation of your project’s purpose and features  \n2. Follow CodeMate’s  LinkedIn account  \n3. Tag the official CodeMate LinkedIn account   and SRM University in your post  \n4.  Add the tag of #SRMHacksWithCodemate  \nImportant Notes  \n• Use of CodeMate Build and CodeMate Extension is mandatory  \n• Both submission modes, CodeMate for Education and LinkedIn, must be completed  \n• Failure to complete either submission may result in non-evaluation.  \n• Enhancements are not compulsory but may improve evaluation scores , and act as deciding \nfactor",
      "filename": "CodeMate_Hackathon_Problem_Statements.pdf"
    },
    {
      "doc_id": "tmpvrf3z0fe_CodeMate_Hackathon_Problem_Statements.pdf_04fd9f26_d87ac2be",
      "chunk_index": 7,
      "content": "LinkedIn, must be completed  \n• Failure to complete either submission may result in non-evaluation.  \n• Enhancements are not compulsory but may improve evaluation scores , and act as deciding \nfactors in case of similar scores.",
      "filename": "CodeMate_Hackathon_Problem_Statements.pdf"
    },
    {
      "doc_id": "tmp9cqjsl65_CodeMate_Hackathon_Guidelines.pdf_64c80de2_a2508099",
      "chunk_index": 0,
      "content": "--- Page 1 ---\n \nHackathon Guidelines & Information Document  \nEvent Overview  \nA Hackathon will be conducted on 20th September and 21st September . The event is designed to \nassess creativity, technical skills, and problem -solving abilities while providing participants with \npractical exposure to building projects using CodeMate Build  and the CodeMate Extension . \nThe use of these specified AI tools is mandatory . This requirement is intended to evaluate the \nefficiency, adaptability, and understanding of students in applying AI tools during project \ndevelopment.  \nPhases of the Hackathon  \nPhase 1: Problem Statement and Project Development  \n1. At the start of the hackathon, participants will be provided with three problem statements . \n2. Each participant must select one problem statement  to work on.  \n3. All participants are required to:  \no Create an account on CodeMate for Education  via the official platform link: \nhttps://edu.codemate.",
      "filename": "CodeMate_Hackathon_Guidelines.pdf"
    },
    {
      "doc_id": "tmp9cqjsl65_CodeMate_Hackathon_Guidelines.pdf_64c80de2_a2508099",
      "chunk_index": 1,
      "content": "articipant must select one problem statement  to work on.  \n3. All participants are required to:  \no Create an account on CodeMate for Education  via the official platform link: \nhttps://edu.codemate.ai/  \no Join the respective classroom  on CodeMate where the project assignments will be \navailable.  \no Access the chosen project assignment  and begin working on it using CodeMate \nBuild  and the CodeMate Extension . \nSubmission Requirements  \nParticipants must submit the following:  \n• Upload the entire Codebase on CodeMate  IDE ( Excluding node modules  if in the project)  \n• A live working video demonstrating the project  \n• A live hosted URL of the project  \n• A GitHub repository link containing the complete source code  \nPhase 2: Evaluation and Shortlisting  \n1. Submissions will be evaluated based on:  \no Functionality  \no Innovation  \no Code quality  \no Problem -solving approach  \no Effective use of the mandatory AI tools  \n2.",
      "filename": "CodeMate_Hackathon_Guidelines.pdf"
    },
    {
      "doc_id": "tmp9cqjsl65_CodeMate_Hackathon_Guidelines.pdf_64c80de2_a2508099",
      "chunk_index": 2,
      "content": "valuation and Shortlisting  \n1. Submissions will be evaluated based on:  \no Functionality  \no Innovation  \no Code quality  \no Problem -solving approach  \no Effective use of the mandatory AI tools  \n2. Shortlisted participants will be notified and invited for the interview round.  \n\n--- Page 2 ---\n \nPhase 3: Interview and Offers  \n1. Shortlisted students will appear for an interview conducted by the evaluation panel.  \n2. Students who successfully clear the interview round will be issued offer letters . \nImportant Dates  \n• Hackathon Dates: 20th September & 21st September  \n• Submission Deadline:  24 hours . \n• Interview Round: 22nd September.  \nKey Instructions  \n• Registration on CodeMate for Education  is compulsory. Platform Link: \nhttps://edu.codemate.ai/  \n• All submissions must include the required deliverables:  source code , video, hosted URL, and \nGitHub repository.  \n• Projects must demonstrate the use of CodeMate Build  and the CodeMate Extension .",
      "filename": "CodeMate_Hackathon_Guidelines.pdf"
    },
    {
      "doc_id": "tmp9cqjsl65_CodeMate_Hackathon_Guidelines.pdf_64c80de2_a2508099",
      "chunk_index": 3,
      "content": "All submissions must include the required deliverables:  source code , video, hosted URL, and \nGitHub repository.  \n• Projects must demonstrate the use of CodeMate Build  and the CodeMate Extension . \n• Late or incomplete submissions may not be considered for evaluation.  \n• Participants must maintain originality and follow ethical coding practices.  \nOutcome  \nThe hackathon is a platform to showcase coding skills and problem -solving abilities. Students who \nsuccessfully complete all phases and clear the interview will be issued official offer letters  from \nCodeMate.",
      "filename": "CodeMate_Hackathon_Guidelines.pdf"
    },
    {
      "doc_id": "tmp4cbou3oj_research_report_2025-09-20.pdf_2d559232_65733a86",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nDeep Researcher Agent - Research Report\nGenerated on 2025-09-21 02:11:55\nPage 1\nDeep Researcher Agent\n Research Report\n \nGenerated: 2025-09-21 02:11:55\nQuery: what is this\nResearch Query\nwhat is this\nAnalyzed Documents\nDocument #\nFilename\n1\nSubhakar_RAMA_TADIMALLA.pdf\nResearch Process\nThe following steps were taken to analyze your query:\nStep\nDescription\n1\nQuery received - Processing query: 'what is this'\n2\nQuery decomposition - Broke down query into 1 sub-questions: what is this\n3\nDocument retrieval - Retrieved 0 relevant document sections from 0 sources\n4\nInformation synthesis - Synthesized comprehensive answer from 0 document sections\n5\nGap analysis - Identified 8 knowledge gaps in the research\nSynthesized Answer\nNo relevant documents found for this query. Please upload relevant documents or try a\ndifferent query.\n\n\n--- Page 2 ---\nDeep Researcher Agent - Research Report\nGenerated on 2025-09-21 02:11:55\nPage 2\nKnowledge Gaps\nThe following knowledge gaps were identified",
      "filename": "research_report_2025-09-20.pdf"
    },
    {
      "doc_id": "tmp4cbou3oj_research_report_2025-09-20.pdf_2d559232_65733a86",
      "chunk_index": 1,
      "content": "elevant documents or try a\ndifferent query.\n\n\n--- Page 2 ---\nDeep Researcher Agent - Research Report\nGenerated on 2025-09-21 02:11:55\nPage 2\nKnowledge Gaps\nThe following knowledge gaps were identified during the research:\nGap #\nDescription\n1\nLimited document coverage - only a few sources available for analysis\n2\nNo quantitative data or statistical analysis found in the retrieved documents\n3\nLimited recent information - documents may not reflect current developments\n4\nNo geographic or regional analysis found in the available documents\n5\nNo comparative analysis or benchmarking data found\n6\nLimited implementation details or practical guidance found\n7\nNo cost analysis or economic impact data found\n8\nNo regulatory or compliance information found\n---\nThis report was generated by the Deep Researcher Agent, an AI-powered multi-agent\nresearch system.",
      "filename": "research_report_2025-09-20.pdf"
    },
    {
      "doc_id": "tmp4cbou3oj_research_report_2025-09-20.pdf_2d559232_65733a86",
      "chunk_index": 2,
      "content": "her Agent, an AI-powered multi-agent\nresearch system.",
      "filename": "research_report_2025-09-20.pdf"
    },
    {
      "doc_id": "tmp8wi97st1_test_ar_vr_doc.txt_e928ccf9_cb4c86f3",
      "chunk_index": 0,
      "content": "Augmented Reality (AR) and Virtual Reality (VR) Technology Overview\n\nAugmented Reality (AR) is a technology that overlays digital information and virtual objects onto the real world, enhancing the user's perception of reality. AR applications use cameras, sensors, and displays to blend virtual content with the physical environment in real-time.\n\nKey AR Technologies:\n- Marker-based AR: Uses visual markers to trigger virtual content\n- Markerless AR: Uses GPS, accelerometers, and computer vision\n- Projection-based AR: Projects light onto real-world surfaces\n- Superimposition-based AR: Replaces or enhances real-world objects\n\nPopular AR Applications:\n- Mobile AR apps like Pokemon GO and Snapchat filters\n- Industrial maintenance and training\n- Medical visualization and surgery assistance\n- Retail and e-commerce product visualization\n- Navigation and wayfinding systems\n\nVirtual Reality (VR) is an immersive technology that creates a completely artificial digital environment that users can int",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmp8wi97st1_test_ar_vr_doc.txt_e928ccf9_cb4c86f3",
      "chunk_index": 1,
      "content": "il and e-commerce product visualization\n- Navigation and wayfinding systems\n\nVirtual Reality (VR) is an immersive technology that creates a completely artificial digital environment that users can interact with using specialized headsets and controllers. VR replaces the user's real-world environment with a computer-generated simulation.\n\nKey VR Technologies:\n- Head-mounted displays (HMDs) like Oculus Rift, HTC Vive, PlayStation VR\n- Motion tracking systems for hand and body movement\n- Haptic feedback devices for tactile sensations\n- Spatial audio for immersive sound experiences\n\nPopular VR Applications:\n- Gaming and entertainment\n- Virtual training and education\n- Architectural visualization\n- Therapy and rehabilitation\n- Virtual tourism and exploration\n\nCurrent Market Trends:\nThe AR/VR market is experiencing rapid growth, with projections showing significant expansion in both consumer and enterprise sectors.",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmp8wi97st1_test_ar_vr_doc.txt_e928ccf9_cb4c86f3",
      "chunk_index": 2,
      "content": "itation\n- Virtual tourism and exploration\n\nCurrent Market Trends:\nThe AR/VR market is experiencing rapid growth, with projections showing significant expansion in both consumer and enterprise sectors. Major technology companies like Apple, Google, Microsoft, and Meta are investing heavily in AR/VR development.\n\nFuture Prospects:\n- Mixed Reality (MR) combining AR and VR\n- 5G connectivity enabling cloud-based AR/VR experiences\n- Improved hardware with better resolution and comfort\n- Integration with artificial intelligence and machine learning\n- Expansion into healthcare, education, and remote work applications\n\nChallenges and Limitations:\n- Hardware costs and accessibility\n- Motion sickness and user comfort issues\n- Content creation complexity\n- Privacy and security concerns\n- Battery life and processing power limitations",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmp8wi97st1_test_ar_vr_doc.txt_e928ccf9_cb4c86f3",
      "chunk_index": 3,
      "content": "and processing power limitations",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nUnit II \nCLIP (Contrastive Language –Image Pretraining)  \nCLIP (Contrastive Language –Image Pretraining) learns a joint text –image embedding \nspace by using contrastive learning to bring matching image –text pairs close and push \nnon-matching pairs apart.  \nKey points & justifications:  \n1. Dual encoders (text & image) mapped to a shared space.  \nJustification:  Mapping both modalities into the same vector space makes direct \nsimilarity computations (cosine similarity) possible. This design simplifies \ndownstream tasks (retrieval, zero -shot classification) because the model does \nnot have to learn task -specific cros s-modal projections every time — the shared \nspace is a reusable interface.  \n2. Contrastive (InfoNCE) loss pulls positives and pushes negatives.  \nJustification:  InfoNCE directly optimizes relative similarity: maximizing similarity \nof correct pairs while minimizing similarity of incorrect pairs.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 1,
      "content": "CE) loss pulls positives and pushes negatives.  \nJustification:  InfoNCE directly optimizes relative similarity: maximizing similarity \nof correct pairs while minimizing similarity of incorrect pairs. This encourages \nembeddings to capture semantics that distinguish correct captions from \ndistractors, which is precisely w hat cross -modal tasks require.  \n3. Large batch / many negatives improve representation quality.  \nJustification:  More negatives increase the difficulty of the contrastive task, \nforcing embeddings to capture fine -grained distinctions. Empirically large \neffective batch sizes (or memory banks) create stronger supervision signals, \nproducing richer semantic structure.  \n4. Enables zero -shot transfer and robust retrieval.  \nJustification:  Because CLIP learns general alignment between text concepts and \nvisual features, it can map a new text label into the same space and retrieve \nrelevant images without task -specific retraining — the learned semantic \ngeometry gen",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 2,
      "content": "ignment between text concepts and \nvisual features, it can map a new text label into the same space and retrieve \nrelevant images without task -specific retraining — the learned semantic \ngeometry generalizes.  \nExample:  \nImage: “a red bicycle on a rainy street.” CLIP will place the image embedding near \ncaptions describing bicycles/rain, and far from unrelated captions (e.g., “a dog in a \npark”).  \nApplications & justification:  \n• Zero-shot classification:  No fine-tuning needed because class names can be \nembedded and compared to images.  \nJustification:  The shared semantic space means class semantics are already \nencoded.  \n\n--- Page 2 ---\n• Text-guided retrieval and generation:  CLIP scores can rank generated images or \nguide generative models.  \nJustification:  Direct similarity metrics allow automatic evaluation and steering.  \nText embeddings in multimodal diffusion models  \nText embeddings convert a prompt into a dense vector that conditions diffusion models, \nguiding stocha",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 3,
      "content": "trics allow automatic evaluation and steering.  \nText embeddings in multimodal diffusion models  \nText embeddings convert a prompt into a dense vector that conditions diffusion models, \nguiding stochastic denoising toward images that match the text.  \nKey points & justifications:  \n1. Serve as conditioning signal during denoising.  \nDiffusion models generate by reversing noise; conditioning vectors are injected \n(via concatenation, cross -attention, or FiLM) so each denoising step has \nsemantic context. Without conditioning, the model has no way to steer \ngeneration toward the desired sem antics.  \n2. Capture both object and style attributes.  \nModern text encoders (Transformers) represent not just nouns but adjectives, \nrelations, and style descriptors. Embeddings therefore allow the generator to \nsynthesize content (objects) and aesthetic (style) simultaneously.  \n3. Enable fine controls (compositional prompts, modifiers).",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 4,
      "content": "ns, and style descriptors. Embeddings therefore allow the generator to \nsynthesize content (objects) and aesthetic (style) simultaneously.  \n3. Enable fine controls (compositional prompts, modifiers).  \n Vector arithmetic and attention let the model weight different subcomponents \nof the prompt; e.g., “photorealistic” vs “oil painting” map to different embedding \ndirections, producing controlled stylistic outcomes.  \n4. Facilitate semantic consistency across steps.  \nConditioning every denoising step (rather than only at start) ensures semantic \ninformation persists through the stochastic sampling, preventing drift to \nirrelevant modes.  \nExample:  \nPrompt: “A small wooden cabin at sunset, misty atmosphere.” The embedding encodes \nobject (“cabin”), material (“wooden”), time (“sunset”), and mood (“misty”) so the \ndiffusion model composes these attributes coherently.  \nApplications & justification:  \n• Text-to-image (Stable Diffusion):  Embeddings let a single model produce \ndiverse outp",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 5,
      "content": "mood (“misty”) so the \ndiffusion model composes these attributes coherently.  \nApplications & justification:  \n• Text-to-image (Stable Diffusion):  Embeddings let a single model produce \ndiverse outputs from many prompts.  \nA single learned forward/backward process can be reused with different \ncondition vectors.  \n\n--- Page 3 ---\n• Prompt interpolation and editing:  Embeddings allow latent manipulations \n(e.g., amplify “sunset”) to edit outputs.  \nContinuous embeddings provide smooth control that discrete labels cannot.  \nCritical insight / limitation  \nIf embeddings lack domain knowledge or are ambiguous, generation will be \nsemantically weak. Therefore, high -quality text encoders and, when needed, domain -\nspecific embedding fine -tuning are essential.  \nCommon evaluation metrics for text –image alignment  \nEvaluating multimodal generation requires metrics that measure both visual quality  and \nsemantic alignment  between text and image.  \nMetrics & justifications:  \n1.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 6,
      "content": "etrics for text –image alignment  \nEvaluating multimodal generation requires metrics that measure both visual quality  and \nsemantic alignment  between text and image.  \nMetrics & justifications:  \n1. CLIPScore (cosine similarity of CLIP embeddings).  \nWhat it measures:  Semantic alignment between generated image and \nprompt.  \nCLIP is trained to align modalities; its cosine similarity is a direct proxy for how \nwell image content matches textual semantics. It’s automatic and correlates \nreasonably with human judgments for many prompts.  \n2. FID (Fréchet Inception Distance).  \nWhat it measures:  Distributional similarity between generated images and \nreal images.  \nFID captures both quality and diversity by comparing feature statistics (means, \ncovariances). Lower FID implies generated images occupy similar manifold to \nreal images.  \n3. Inception Score (IS).  \nWhat it measures: Distinctiveness and confidence of generated images (via \nan Inception classifier).",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 7,
      "content": "FID implies generated images occupy similar manifold to \nreal images.  \n3. Inception Score (IS).  \nWhat it measures: Distinctiveness and confidence of generated images (via \nan Inception classifier).  \nIS rewards samples that are recognizable and varied; however it doesn’t \nmeasure prompt alignment.  \n4. Human evaluation (relevance, fidelity, preference).  \nWhat it measures:  Subjective semantic correctness and visual appeal.  \nAutomated metrics are imperfect, so human judgment remains the gold \nstandard, especially for nuanced or creative prompts.  \n5. Task-specific metrics (precision/recall on objects, detection mAP).  \nWhen prompts require specific objects or relations, applying object detectors \nand measuring precision/recall quantifies functional correctness.  \n\n--- Page 4 ---\nCombining metrics — justification:  \nNo single metric captures all aspects. CLIPScore checks alignment but not realism; FID \nchecks realism but not prompt adherence.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 8,
      "content": "nal correctness.  \n\n--- Page 4 ---\nCombining metrics — justification:  \nNo single metric captures all aspects. CLIPScore checks alignment but not realism; FID \nchecks realism but not prompt adherence. Combining metrics plus human checks \nproduces more reliable evaluation.  \nLimitations : \nCLIPScore can be gamed (adversarially optimized); FID is sensitive to dataset choice \nand model used for features. Thus metric selection should align with evaluation goals \nand be interpreted carefully.  \n \nFine-tuning CLIP  \nIntroduction:  \nPretrained CLIP is broad but not deep in domain -specific semantics; fine -tuning adapts \nit to specialized vocabularies, visual cues, and biases of a target domain.  \nKey points & justifications:  \n1. Bridging domain vocabulary gaps.  \nCLIP’s internet training may underrepresent domain terms (medical labels, \nindustrial parts). Fine -tuning with domain captions teaches the text encoder \ndomain semantics and aligns them to visual cues in that field.  \n2.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 9,
      "content": "ing may underrepresent domain terms (medical labels, \nindustrial parts). Fine -tuning with domain captions teaches the text encoder \ndomain semantics and aligns them to visual cues in that field.  \n2. Improving visual feature sensitivity to domain specifics.  \nFine-tuning the image encoder helps it attend to subtle diagnostic visual features \n(e.g., microcalcifications) that general models may deem irrelevant.  \n3. Reducing harmful biases and spurious correlations.  \nDomain curation can balance datasets and remove stereotypes present in \ninternet data, improving fairness and factual accuracy in sensitive contexts.  \n4. Better downstream task performance (retrieval, VQA, diagnostics).  \nFine-tuned embeddings yield higher retrieval precision and more accurate VQA \nanswers because they encode task -relevant features.  \nPractical methods & justifications:  \n• Full fine-tuning: update all weights — best for abundant labels.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 10,
      "content": "trieval precision and more accurate VQA \nanswers because they encode task -relevant features.  \nPractical methods & justifications:  \n• Full fine-tuning: update all weights — best for abundant labels.  \nAllows maximal adaptation but risks catastrophic forgetting and needs data/GPU \nresources.  \n• Adapter modules / LoRA / prompt tuning:  lightweight adjustments.  \n Preserve pretrained knowledge while cheaply adapting to domain; less risk of \nforgetting and cheaper to train.  \n\n--- Page 5 ---\n• Continual learning / regularization:  e.g., Elastic Weight Consolidation to \nprevent forgetting.  \nMaintains general CLIP capabilities while learning domain specifics.  \nExample:  \nFine-tuning CLIP on annotated chest X -rays (labels, radiologist captions) yields \nimproved retrieval and VQA performance for radiology tasks because the model learns \nto associate radiographic patterns with domain terms.  \n \nFine-tuning requires curated, representative, and labeled domain data; otherwise you \nrisk over",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 11,
      "content": "for radiology tasks because the model learns \nto associate radiographic patterns with domain terms.  \n \nFine-tuning requires curated, representative, and labeled domain data; otherwise you \nrisk overfitting or preserving harmful biases. Validation and human oversight are \nessential.  \n \nArchitecture of CLIP and joint learning  \nIntroduction:  \nCLIP uses separate encoders for images and text, projection heads to a common \nembedding space, and contrastive training to jointly learn aligned representations.  \n \nArchitecture components & justifications:  \n1. Image encoder (ViT or ResNet).  \nCNNs (ResNet) capture local textures; ViTs capture long -range interactions. \n\n\n--- Page 6 ---\nChoice depends on tradeoffs (compute vs performance). Both produce rich \nvisual features for projection.  \n2. Text encoder (Transformer).  \n Transformers model sequential and contextual language semantics effectively, \nenabling capture of compositional meaning (modifiers, relations).  \n3.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 12,
      "content": "for projection.  \n2. Text encoder (Transformer).  \n Transformers model sequential and contextual language semantics effectively, \nenabling capture of compositional meaning (modifiers, relations).  \n3. Projection heads (linear layers) mapping to shared space.  \nSeparate high -dim features are projected to a common dimensionality so cosine \nsimilarity is meaningful; projection can also adapt modality -specific statistics.  \n4. Contrastive (InfoNCE) training with large effective batch size.  \nMany negatives help the model learn fine distinctions. Training with symmetric \nloss (image→text and text→image) strengthens bidirectional retrieval capability.  \n5. Temperature scaling in contrastive loss.  \n Temperature controls concentration of similarity distribution; tuning it balances \nsensitivity between positive/negative pairs.  \nWhy this design works ? \n• Separate encoders let each modality use architectures tailored to its inductive \nbiases, yet the projection + contrastive loss forces sema",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 13,
      "content": "between positive/negative pairs.  \nWhy this design works ? \n• Separate encoders let each modality use architectures tailored to its inductive \nbiases, yet the projection + contrastive loss forces semantic alignment without \nmerging architectures (which would be less flexible).  \n• Large paired datasets provide diverse supervision so the embedding geometry \ngeneralizes across many concepts.  \nExample:  \nDuring training a batch of image -caption pairs, each image’s closest embedding should \nbe its caption’s embedding. The symmetric contrastive loss enforces this across all \nbatch pairs, producing a globally consistent embedding geometry.  \nTradeoffs : \n• Heavy compute and data requirements are justified by strong zero -shot \nperformance.  \n• Model complexity makes fine -tuning expensive; adapter techniques can mitigate \ncosts.  \n \nCLIP can be integrated with diffusion models for text -to-image generation  \nIntroduction:  \nCLIP can guide diffusion models either by providing conditioning e",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 14,
      "content": "pter techniques can mitigate \ncosts.  \n \nCLIP can be integrated with diffusion models for text -to-image generation  \nIntroduction:  \nCLIP can guide diffusion models either by providing conditioning embeddings or by \nacting as an external scorer to encourage semantic alignment during sampling.  \n\n--- Page 7 ---\nIntegration mechanisms & justifications:  \n1. Embedding conditioning (direct):  feed CLIP text embeddings into diffusion \nmodel (via cross -attention or concatenation).  \nDirect conditioning uses the semantic vector as part of the generative process, \nenabling the model to learn to map embeddings to visual features during training \n— the cleanest, learned integration.  \n2. CLIP guidance (external scorer / gradient guidance):  compute CLIP similarity \nof intermediate samples to the prompt and backpropagate gradients to \nnudge samples.  \n This allows a pretrained diffusion model (without conditioning) to be steered at \nsampling time; useful when retraining is expensive.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 15,
      "content": "es to the prompt and backpropagate gradients to \nnudge samples.  \n This allows a pretrained diffusion model (without conditioning) to be steered at \nsampling time; useful when retraining is expensive. It leverages CLIP’s semantic \nsignal as an online objective.  \n3. Classifier -free guidance vs CLIP scoring:  classifier -free guidance blends \nunconditional and conditional denoising; CLIP guidance explicitly optimizes \nsemantic similarity.  \nClassifier -free guidance is learned and often efficient; CLIP guidance can \nimprove semantic alignment but is computationally heavier and sometimes \nunstable, so practitioners choose based on constraints.  \n4. Hybrid approaches (fine -tune diffusion with CLIP):  fine-tune a conditional \ndiffusion model where conditioning is CLIP embeddings.  \nThis produces the most coherent integration: the generator learns to use \nembeddings during training, reducing the need for costly gradient -based steering \nat sampling time.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 16,
      "content": "ing is CLIP embeddings.  \nThis produces the most coherent integration: the generator learns to use \nembeddings during training, reducing the need for costly gradient -based steering \nat sampling time.  \nExample workflow (gradient guidance):  \nAt each sampling step, generate image x_t, compute CLIP similarity s = cosine(clip_text, \nclip_image(x_t)), compute ∇_{x_t} s and adjust x_t in direction that increases similarity, \nthen proceed to next denoising step.  \nTradeoffs : \n• Pros: CLIP guidance improves semantic fidelity and allows reusing pretrained \ndiffusion models.  \n• Cons: Extra compute (CLIP forward + gradient) and potential for adversarial \nartifacts if optimized too aggressively — justification for careful step size and \nregularization.  \n \nQ7 — Compare CLIP -guided generation vs GAN -based text -to-image methods  \n \n\n--- Page 8 ---\nComparison points & justifications:  \n1. Semantic alignment:  CLIP-guided diffusion > GANs.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 17,
      "content": "arization.  \n \nQ7 — Compare CLIP -guided generation vs GAN -based text -to-image methods  \n \n\n--- Page 8 ---\nComparison points & justifications:  \n1. Semantic alignment:  CLIP-guided diffusion > GANs.  \nJustification:  CLIP provides explicit semantic supervision via \nembeddings/scores; GANs rely on discriminator signals that emphasize \nrealism rather than semantic correctness.  \n2. Visual sharpness / texture realism:  GANs often produce sharper textures.  \nJustification:  GAN adversarial loss explicitly forces photorealistic textures; \ndiffusion models historically produced blurrier outputs (though modern \ntechniques narrowed the gap).  \n3. Training stability:  Diffusion (with CLIP) tends to be more stable than GAN \ntraining.  \nJustification:  GANs suffer from mode collapse and training instability due to \nadversarial dynamics; diffusion is likelihood -based and often converges \nmore predictably.  \n4.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 18,
      "content": "e than GAN \ntraining.  \nJustification:  GANs suffer from mode collapse and training instability due to \nadversarial dynamics; diffusion is likelihood -based and often converges \nmore predictably.  \n4. Sampling speed / compute:  GANs typically faster at inference; CLIP -guided \ndiffusion is slower.  \nJustification:  GANs generate in one forward pass; diffusion models require \nmany denoising steps; CLIP guidance adds more compute for \nscoring/gradients.  \n5. Controllability & editing:  CLIP-guided diffusion offers finer control (text, \nprompt editing).  \nJustification:  Conditioning and CLIP feedback directly influence semantics \nacross steps; GANs can be controlled via latent manipulations but mapping \nbetween latent and semantics is less direct.  \n6. Robustness to prompts:  CLIP-guided methods generalize better to open -\nended prompts.  \nJustification:  CLIP’s pretraining on broad captions provides strong semantic \ngrounding; GANs trained on limited paired data often struggle with out",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 19,
      "content": "hods generalize better to open -\nended prompts.  \nJustification:  CLIP’s pretraining on broad captions provides strong semantic \ngrounding; GANs trained on limited paired data often struggle with out -of-\ndistribution prompts.  \nUse-case recommendations (justified):  \n• For high-speed production of photoreal textures , GANs may be preferable.  \nJustification:  Fast single -pass generation with high fidelity.  \n• For semantic, creative, and controllable generation , CLIP-guided diffusion is \npreferable despite slower sampling.  \nJustification:  Better alignment to textual intent and flexibility.  \n \n\n--- Page 9 ---\nLimitation of CLIP and a detailed solution (with justifications)  \nLimitation chosen:  Bias and spurious correlations inherited from large web -scale \ntraining data.  \n• CLIP’s embeddings reflect the distribution of its training corpus; societal \nstereotypes and underrepresentation produce associations that can harm \ndownstream use (e.g.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 20,
      "content": "web -scale \ntraining data.  \n• CLIP’s embeddings reflect the distribution of its training corpus; societal \nstereotypes and underrepresentation produce associations that can harm \ndownstream use (e.g., biased retrieval or discriminatory generative outputs). In \ncritical domains (hiring, la w, medicine) these errors are unacceptable.  \nProposed multi -pronged solution : \n1. Domain-aware fine -tuning with curated datasets.  \nCurated, annotated domain data corrects label distributions and teaches the \nmodel correct associations relevant to the domain (e.g., medical labels). It \nreduces reliance on noisy web labels.  \n2. Bias mitigation during training (reweighting / adversarial debiasing).  \nReweighting or adversarial objectives discourage encoding of protected \nattributes (e.g., gender) when they’re not relevant. These methods directly \npenalize the emergence of undesirable correlations.  \n3. Counterfactual data augmentation.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 21,
      "content": "iscourage encoding of protected \nattributes (e.g., gender) when they’re not relevant. These methods directly \npenalize the emergence of undesirable correlations.  \n3. Counterfactual data augmentation.  \nGenerating or collecting balanced examples that swap sensitive attributes (e.g., \nsame profession across genders/ethnicities) reduces statistical shortcuts and \nforces the model to focus on relevant visual cues.  \n4. Evaluation & continuous monitoring (human -in-the-loop).  \nAutomated checks (fairness metrics) plus human audits detect remaining bias. \nContinuous monitoring post -deployment catches distribution shifts and \nemergent problems.  \n5. Model explanations and transparency.  \nSaliency maps or retrieval -based explanations help users understand why the \nmodel associated certain text and images, enabling corrective action.  \nExample application:  \nDeploying an e -commerce visual search: before deployment, augment training with \ndiverse product images across demographics, apply rew",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 22,
      "content": "and images, enabling corrective action.  \nExample application:  \nDeploying an e -commerce visual search: before deployment, augment training with \ndiverse product images across demographics, apply reweighting, and run fairness tests \nto ensure the model does not systematically underrepresent particular groups.  \n \n \n \n\n--- Page 10 ---\n2. CLIP AND JOINT EMBEDDINGS  \nIntroduction  \nGenerative AI has transformed the way text and visual data can be integrated to create \nnew forms of digital content. Among the leading approaches are Contrastive Language –\nImage Pretraining (CLIP)  and diffusion models , which together form a powerful pipeline \nfor text-to-image synthesis.  \nCLIP aligns language and visual modalities through joint embeddings , while diffusion \nmodels use probabilistic denoising processes  to synthesize realistic and semantically \naligned images.  \nThis integration is significant across domains like education, design, healthcare, \nentertainment, and scientific communication ,",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 23,
      "content": "processes  to synthesize realistic and semantically \naligned images.  \nThis integration is significant across domains like education, design, healthcare, \nentertainment, and scientific communication , where the ability to convert descriptions \ninto visuals  saves time, enhances creativity, and improves accessibility. However, \nensuring reliability, accuracy, and fairness requires deeper understanding of the \nmechanisms, limitations, and solutions of such systems.  \n(a) CLIP and Joint Embeddings – Mechanism and Benefits  \n1. Core Concept  \no CLIP consists of two encoders:  \n▪ A Text Encoder  (Transformer -based) processes natural language \nprompts.  \n▪ An Image Encoder  (ResNet or Vision Transformer) processes image \ndata.  \no Both outputs are projected into a shared embedding space , enabling \ncomparisons.  \n2. Contrastive Learning  \no During training, CLIP is presented with a batch of image –text pairs.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 24,
      "content": "s image \ndata.  \no Both outputs are projected into a shared embedding space , enabling \ncomparisons.  \n2. Contrastive Learning  \no During training, CLIP is presented with a batch of image –text pairs.  \no The correct image –caption pair should have a high cosine similarity , while \nincorrect pairs should score low.  \no InfoNCE loss  optimizes this by pulling true pairs closer and pushing false \npairs apart.  \n3. Why This Matters for Generation  \no When combined with diffusion models, the shared space ensures the \ngenerated image faithfully represents the meaning of the text . \n\n--- Page 11 ---\no Unlike traditional vision models limited to classification, CLIP’s \nembeddings generalize across unseen categories and abstract prompts.  \n4. Example  \no Prompt: “A panda wearing sunglasses playing guitar.”  \no CLIP embeddings capture not only the object (“panda”) but also \nattributes (“wearing sunglasses”) and context (“playing guitar”).",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 25,
      "content": ". Example  \no Prompt: “A panda wearing sunglasses playing guitar.”  \no CLIP embeddings capture not only the object (“panda”) but also \nattributes (“wearing sunglasses”) and context (“playing guitar”).  \no The diffusion model uses these embeddings to guide generation, ensuring \nall described elements appear.  \n5. Justification  \no This approach solves the problem of semantic drift , where generated \nimages deviate from text.  \no It also enables zero-shot transfer , where the model works on new \nconcepts without retraining.  \n \n(b) Noise Scheduling and Diffusion Process – Stability and Quality  \n1. Forward Diffusion (Training Stage)  \no The model learns by gradually adding Gaussian noise  to real images over \nmany steps until they become indistinguishable from random noise.  \no This corruption process teaches the system how data can be “destroyed” \nin a controlled manner.  \n2. Backward Diffusion (Generation Stage)  \no The generative model reverses the process, progressively denoising \nra",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 26,
      "content": "on process teaches the system how data can be “destroyed” \nin a controlled manner.  \n2. Backward Diffusion (Generation Stage)  \no The generative model reverses the process, progressively denoising \nrandom noise  step by step to reconstruct a meaningful image.  \no Conditioning on text embeddings ensures that the denoising follows the \nsemantic structure encoded in the prompt.  \n3. Noise Schedulers  \no Decide the rate and distribution  of noise addition/removal across \ntimesteps.  \no Common schedulers: linear, cosine, exponential decay . \no The choice affects image clarity, diversity, and fidelity . \n4. Why It Matters  \n\n--- Page 12 ---\no Too much noise at early steps → unstable generations.  \no Too little → lack of diversity.  \no A well-designed scheduler balances exploration and accuracy, leading to \nimages that are high-quality, sharp, and semantically consistent . \n5. Example  \no A poorly tuned scheduler may generate a “blurred car” for the prompt “a \nred sports car on a racetrack.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 27,
      "content": ", leading to \nimages that are high-quality, sharp, and semantically consistent . \n5. Example  \no A poorly tuned scheduler may generate a “blurred car” for the prompt “a \nred sports car on a racetrack.”  \no With proper scheduling, details like color, motion blur, and track \nbackground  are preserved.  \n6. Justification  \no Diffusion + noise scheduling ensures outputs remain reliable and artifact-\nfree, addressing weaknesses of earlier GAN -based methods which often \nsuffered from mode collapse.  \n(c) Ensuring Accuracy with Fine -Tuning – Overcoming Hallucinations  \n1. The Challenge  \no Generative models, when trained on generic internet data, may produce \nimages that are visually appealing but scientifically or contextually \ninaccurate . \no Risk of “hallucination” (adding irrelevant objects) or oversimplification.  \n2. Role of Fine -Tuning  \no Fine-tuning adapts pretrained models to specific domains  using curated \ndatasets.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 28,
      "content": "ccurate . \no Risk of “hallucination” (adding irrelevant objects) or oversimplification.  \n2. Role of Fine -Tuning  \no Fine-tuning adapts pretrained models to specific domains  using curated \ndatasets.  \no Adjusts weights so the model captures domain -specific semantics and \navoids irrelevant associations.  \n3. Methods  \no Full fine-tuning: Retrain on specialized datasets (e.g., radiology images, \nengineering diagrams).  \no Adapter/LoRA tuning : Lightweight layers added for efficient adaptation.  \no Prompt-tuning: Adding domain -specific tokens or context.  \n4. Example  \no Generic model → “DNA double helix” may produce artistic swirls.  \n\n--- Page 13 ---\no Fine-tuned model on biology diagrams → generates precise base pairs and \nmolecular structure . \n5. Justification  \no Fine-tuning improves factual accuracy . \no Reduces domain mismatch, making outputs trustworthy in professional \nor academic settings.  \no Supports applications where error tolerance is low  (e.g.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 29,
      "content": "o Fine-tuning improves factual accuracy . \no Reduces domain mismatch, making outputs trustworthy in professional \nor academic settings.  \no Supports applications where error tolerance is low  (e.g., medicine, \nengineering, education).  \n(d) Limitations of CLIP and Solutions  \n1. Limitations  \no Bias and Fairness : CLIP inherits social and cultural biases from web data.  \no Ambiguity Handling : Struggles when prompts are vague (“a beautiful \nscene”) or multi -layered.  \no Domain Gaps : Lacks accuracy in highly technical or specialized areas.  \no Computational Cost : Joint text -image training and inference are resource -\nintensive.  \n2. Possible Solutions  \no Bias Mitigation : Curate balanced datasets, use fairness -aware training, \nand adversarial debiasing.  \no Prompt Engineering : Rephrase prompts to be specific, reducing \nambiguity.  \no Domain Adaptation : Use fine -tuning, adapters, or hybrid models for niche \ntasks.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 30,
      "content": "ining, \nand adversarial debiasing.  \no Prompt Engineering : Rephrase prompts to be specific, reducing \nambiguity.  \no Domain Adaptation : Use fine -tuning, adapters, or hybrid models for niche \ntasks.  \no Human-in-the-Loop Evaluation : Incorporate expert feedback to validate \noutputs.  \n3. Example  \no Prompt: “A doctor”  may disproportionately generate male figures due to \nbiased training data.  \no Mitigation: Fine -tuning with balanced datasets ensures diverse \nrepresentations.  \n4. Justification  \n\n--- Page 14 ---\no Without addressing these issues, the trustworthiness and adoption of \nCLIP-based systems may be limited.  \no Solutions ensure outputs remain inclusive, accurate, and ethically \ndeployable . \n \nThe integration of CLIP and diffusion models represents a paradigm shift in multimodal \nAI, enabling systems to understand and generate complex visual representations from \nnatural language.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 31,
      "content": "able . \n \nThe integration of CLIP and diffusion models represents a paradigm shift in multimodal \nAI, enabling systems to understand and generate complex visual representations from \nnatural language.  \nCLIP ensures semantic alignment  through joint embeddings, while diffusion models \nguarantee stability and quality  via noise scheduling and denoising processes.  \nFine-tuning resolves the issue of accuracy and domain specificity , while awareness of \nCLIP’s limitations (biases, ambiguity, domain gaps) and corrective solutions ensures \ntrustworthy deployment . In essence, the synergy between CLIP and diffusion models \nforms a robust, flexible, and scalable framework  for multimodal content creation, \ncapable of serving both general and highly specialized applications.  \n3. CLIP with diffusion mode ls \nIntroduction  \nText-to-image generation has become one of the most exciting advancements in \nartificial intelligence.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 32,
      "content": "oth general and highly specialized applications.  \n3. CLIP with diffusion mode ls \nIntroduction  \nText-to-image generation has become one of the most exciting advancements in \nartificial intelligence. By combining CLIP (Contrastive Language –Image Pretraining)  \nwith diffusion models , systems can generate images that accurately reflect user \ndescriptions. CLIP provides a bridge between language and vision, aligning text prompts \nwith visual features, while diffusion models create high -quality, coherent outputs \nthrough a noise -to-image process. Together, they enable applications ranging from \ncreative design and education to healthcare and entertainment.  \n(a) Architecture of CLIP – Connecting Text and Visuals  \n1. Dual Encoder System  \no CLIP consists of a text encoder  (Transformer -based) and an image \nencoder  (Vision Transformer or CNN).  \no Both map their inputs into feature vectors . \n2.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 33,
      "content": "and Visuals  \n1. Dual Encoder System  \no CLIP consists of a text encoder  (Transformer -based) and an image \nencoder  (Vision Transformer or CNN).  \no Both map their inputs into feature vectors . \n2. Shared Semantic Space  \no Text and image embeddings are projected into a joint latent space  where \nsimilarity is measured.  \no Training uses contrastive learning : matching text –image pairs are pulled \ncloser, mismatched ones pushed apart.  \n\n--- Page 15 ---\n3. Outcome  \no This allows CLIP to capture not just objects but also attributes, context, \nand relationships . \no For example, the phrase “bright red car on a snowy road”  aligns with \nimages showing both the car and the setting.  \n4. Significance  \no These joint embeddings are crucial for guiding generative models so that \noutputs remain semantically aligned  with textual descriptions.  \n(b) Text-Guided Stable Diffusion – The Generation Process  \n1.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 34,
      "content": "ese joint embeddings are crucial for guiding generative models so that \noutputs remain semantically aligned  with textual descriptions.  \n(b) Text-Guided Stable Diffusion – The Generation Process  \n1. Forward Diffusion  \no Real images are progressively noised until they become indistinguishable \nrandom noise.  \n2. Backward Diffusion (Denoising)  \no The model learns to reverse this process: starting from noise, it generates \nan image step by step.  \n3. Conditioning with CLIP  \no The embeddings from CLIP are injected into the backward process as \nguidance signals . \no This ensures that the generated image reflects the semantic meaning of \nthe text prompt . \n4. Noise Scheduling  \no Proper noise scheduling regulates how much detail is added at each step, \npreventing artifacts and improving stability.  \n5. Why It Works  \no Diffusion models combined with CLIP generate stable, realistic, and \nprompt-aligned visuals , outperforming earlier GAN -based approaches \nthat often struggled with fine",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 35,
      "content": "bility.  \n5. Why It Works  \no Diffusion models combined with CLIP generate stable, realistic, and \nprompt-aligned visuals , outperforming earlier GAN -based approaches \nthat often struggled with fine details.  \n (c) Fine-Tuning for Domain -Specific Applications  \n1. Need for Fine -Tuning  \no Base CLIP and diffusion models are trained on broad internet data, which \nmay not cover specialized domains well.  \n\n--- Page 16 ---\n2. Process  \no Fine-tuning involves training or adapting the model with domain-specific \nprompts or datasets . \no Example: In medicine, fine -tuning ensures that a description like “X-ray \nshowing lung opacity”  produces medically accurate images.  \n3. Benefits  \no Enhances accuracy  (outputs match technical details).  \no Improves aesthetic or contextual relevance  (outputs suit the domain \nstyle).  \no Reduces biases and errors  from general -purpose training.  \n4. Justification  \no Without fine -tuning, models may produce outputs that are visually \nplausible but fact",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 36,
      "content": "ts suit the domain \nstyle).  \no Reduces biases and errors  from general -purpose training.  \n4. Justification  \no Without fine -tuning, models may produce outputs that are visually \nplausible but factually incorrect. Domain adaptation ensures trustworthy \nand useful results . \n(d) Evaluation Metrics for Text –Image Alignment  \n1. Quantitative Metrics  \no CLIPScore : Measures similarity between generated image embeddings \nand prompt embeddings.  \no FID (Fréchet Inception Distance) : Evaluates image quality by comparing \ngenerated and real data distributions.  \no IS (Inception Score) : Measures diversity and realism of generated \nimages.  \n2. Qualitative Metrics  \no Human evaluation : Users judge whether images align with descriptions.  \no Task-based evaluation : Checking how well generated outputs support \ndownstream tasks (e.g., retrieval, classification).  \n3. Balanced Evaluation  \no A mix of automated and human assessments ensures both objective \naccuracy  and subjective quality  are",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 37,
      "content": "outputs support \ndownstream tasks (e.g., retrieval, classification).  \n3. Balanced Evaluation  \no A mix of automated and human assessments ensures both objective \naccuracy  and subjective quality  are measured.  \n4. Significance  \n\n--- Page 17 ---\no Robust evaluation is critical to confirm that the system produces outputs \nthat are reliable, meaningful, and user -aligned. \nConclusion  \nBy integrating CLIP embeddings  with diffusion -based generation , AI systems achieve \naccurate text -to-image synthesis. CLIP ensures semantic alignment, diffusion \nguarantees high visual fidelity, fine -tuning adapts models to specialized domains, and \nevaluation metrics confirm performance. This synergy represents a power ful paradigm \nfor multimodal AI, enabling diverse applications where reliable translation of language \ninto images is essential.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpy27f51_d_UNIT II - GCV.pdf_bf6575c5_9fd031e7",
      "chunk_index": 38,
      "content": "ation of language \ninto images is essential.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpfkjb5g09.txt_e928ccf9_dfe95088",
      "chunk_index": 0,
      "content": "Augmented Reality (AR) and Virtual Reality (VR) Technology Overview\n\nAugmented Reality (AR) is a technology that overlays digital information and virtual objects onto the real world, enhancing the user's perception of reality. AR applications use cameras, sensors, and displays to blend virtual content with the physical environment in real-time.\n\nKey AR Technologies:\n- Marker-based AR: Uses visual markers to trigger virtual content\n- Markerless AR: Uses GPS, accelerometers, and computer vision\n- Projection-based AR: Projects light onto real-world surfaces\n- Superimposition-based AR: Replaces or enhances real-world objects\n\nPopular AR Applications:\n- Mobile AR apps like Pokemon GO and Snapchat filters\n- Industrial maintenance and training\n- Medical visualization and surgery assistance\n- Retail and e-commerce product visualization\n- Navigation and wayfinding systems\n\nVirtual Reality (VR) is an immersive technology that creates a completely artificial digital environment that users can int",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmpfkjb5g09.txt_e928ccf9_dfe95088",
      "chunk_index": 1,
      "content": "il and e-commerce product visualization\n- Navigation and wayfinding systems\n\nVirtual Reality (VR) is an immersive technology that creates a completely artificial digital environment that users can interact with using specialized headsets and controllers. VR replaces the user's real-world environment with a computer-generated simulation.\n\nKey VR Technologies:\n- Head-mounted displays (HMDs) like Oculus Rift, HTC Vive, PlayStation VR\n- Motion tracking systems for hand and body movement\n- Haptic feedback devices for tactile sensations\n- Spatial audio for immersive sound experiences\n\nPopular VR Applications:\n- Gaming and entertainment\n- Virtual training and education\n- Architectural visualization\n- Therapy and rehabilitation\n- Virtual tourism and exploration\n\nCurrent Market Trends:\nThe AR/VR market is experiencing rapid growth, with projections showing significant expansion in both consumer and enterprise sectors.",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmpfkjb5g09.txt_e928ccf9_dfe95088",
      "chunk_index": 2,
      "content": "itation\n- Virtual tourism and exploration\n\nCurrent Market Trends:\nThe AR/VR market is experiencing rapid growth, with projections showing significant expansion in both consumer and enterprise sectors. Major technology companies like Apple, Google, Microsoft, and Meta are investing heavily in AR/VR development.\n\nFuture Prospects:\n- Mixed Reality (MR) combining AR and VR\n- 5G connectivity enabling cloud-based AR/VR experiences\n- Improved hardware with better resolution and comfort\n- Integration with artificial intelligence and machine learning\n- Expansion into healthcare, education, and remote work applications\n\nChallenges and Limitations:\n- Hardware costs and accessibility\n- Motion sickness and user comfort issues\n- Content creation complexity\n- Privacy and security concerns\n- Battery life and processing power limitations",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmpfkjb5g09.txt_e928ccf9_dfe95088",
      "chunk_index": 3,
      "content": "and processing power limitations",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmp2ix3axfe.txt_e928ccf9_627b62b9",
      "chunk_index": 0,
      "content": "Augmented Reality (AR) and Virtual Reality (VR) Technology Overview\n\nAugmented Reality (AR) is a technology that overlays digital information and virtual objects onto the real world, enhancing the user's perception of reality. AR applications use cameras, sensors, and displays to blend virtual content with the physical environment in real-time.\n\nKey AR Technologies:\n- Marker-based AR: Uses visual markers to trigger virtual content\n- Markerless AR: Uses GPS, accelerometers, and computer vision\n- Projection-based AR: Projects light onto real-world surfaces\n- Superimposition-based AR: Replaces or enhances real-world objects\n\nPopular AR Applications:\n- Mobile AR apps like Pokemon GO and Snapchat filters\n- Industrial maintenance and training\n- Medical visualization and surgery assistance\n- Retail and e-commerce product visualization\n- Navigation and wayfinding systems\n\nVirtual Reality (VR) is an immersive technology that creates a completely artificial digital environment that users can int",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmp2ix3axfe.txt_e928ccf9_627b62b9",
      "chunk_index": 1,
      "content": "il and e-commerce product visualization\n- Navigation and wayfinding systems\n\nVirtual Reality (VR) is an immersive technology that creates a completely artificial digital environment that users can interact with using specialized headsets and controllers. VR replaces the user's real-world environment with a computer-generated simulation.\n\nKey VR Technologies:\n- Head-mounted displays (HMDs) like Oculus Rift, HTC Vive, PlayStation VR\n- Motion tracking systems for hand and body movement\n- Haptic feedback devices for tactile sensations\n- Spatial audio for immersive sound experiences\n\nPopular VR Applications:\n- Gaming and entertainment\n- Virtual training and education\n- Architectural visualization\n- Therapy and rehabilitation\n- Virtual tourism and exploration\n\nCurrent Market Trends:\nThe AR/VR market is experiencing rapid growth, with projections showing significant expansion in both consumer and enterprise sectors.",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmp2ix3axfe.txt_e928ccf9_627b62b9",
      "chunk_index": 2,
      "content": "itation\n- Virtual tourism and exploration\n\nCurrent Market Trends:\nThe AR/VR market is experiencing rapid growth, with projections showing significant expansion in both consumer and enterprise sectors. Major technology companies like Apple, Google, Microsoft, and Meta are investing heavily in AR/VR development.\n\nFuture Prospects:\n- Mixed Reality (MR) combining AR and VR\n- 5G connectivity enabling cloud-based AR/VR experiences\n- Improved hardware with better resolution and comfort\n- Integration with artificial intelligence and machine learning\n- Expansion into healthcare, education, and remote work applications\n\nChallenges and Limitations:\n- Hardware costs and accessibility\n- Motion sickness and user comfort issues\n- Content creation complexity\n- Privacy and security concerns\n- Battery life and processing power limitations",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmp2ix3axfe.txt_e928ccf9_627b62b9",
      "chunk_index": 3,
      "content": "and processing power limitations",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmpnai1uf_d.txt_e928ccf9_28c09460",
      "chunk_index": 0,
      "content": "Augmented Reality (AR) and Virtual Reality (VR) Technology Overview\n\nAugmented Reality (AR) is a technology that overlays digital information and virtual objects onto the real world, enhancing the user's perception of reality. AR applications use cameras, sensors, and displays to blend virtual content with the physical environment in real-time.\n\nKey AR Technologies:\n- Marker-based AR: Uses visual markers to trigger virtual content\n- Markerless AR: Uses GPS, accelerometers, and computer vision\n- Projection-based AR: Projects light onto real-world surfaces\n- Superimposition-based AR: Replaces or enhances real-world objects\n\nPopular AR Applications:\n- Mobile AR apps like Pokemon GO and Snapchat filters\n- Industrial maintenance and training\n- Medical visualization and surgery assistance\n- Retail and e-commerce product visualization\n- Navigation and wayfinding systems\n\nVirtual Reality (VR) is an immersive technology that creates a completely artificial digital environment that users can int",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmpnai1uf_d.txt_e928ccf9_28c09460",
      "chunk_index": 1,
      "content": "il and e-commerce product visualization\n- Navigation and wayfinding systems\n\nVirtual Reality (VR) is an immersive technology that creates a completely artificial digital environment that users can interact with using specialized headsets and controllers. VR replaces the user's real-world environment with a computer-generated simulation.\n\nKey VR Technologies:\n- Head-mounted displays (HMDs) like Oculus Rift, HTC Vive, PlayStation VR\n- Motion tracking systems for hand and body movement\n- Haptic feedback devices for tactile sensations\n- Spatial audio for immersive sound experiences\n\nPopular VR Applications:\n- Gaming and entertainment\n- Virtual training and education\n- Architectural visualization\n- Therapy and rehabilitation\n- Virtual tourism and exploration\n\nCurrent Market Trends:\nThe AR/VR market is experiencing rapid growth, with projections showing significant expansion in both consumer and enterprise sectors.",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmpnai1uf_d.txt_e928ccf9_28c09460",
      "chunk_index": 2,
      "content": "itation\n- Virtual tourism and exploration\n\nCurrent Market Trends:\nThe AR/VR market is experiencing rapid growth, with projections showing significant expansion in both consumer and enterprise sectors. Major technology companies like Apple, Google, Microsoft, and Meta are investing heavily in AR/VR development.\n\nFuture Prospects:\n- Mixed Reality (MR) combining AR and VR\n- 5G connectivity enabling cloud-based AR/VR experiences\n- Improved hardware with better resolution and comfort\n- Integration with artificial intelligence and machine learning\n- Expansion into healthcare, education, and remote work applications\n\nChallenges and Limitations:\n- Hardware costs and accessibility\n- Motion sickness and user comfort issues\n- Content creation complexity\n- Privacy and security concerns\n- Battery life and processing power limitations",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmpnai1uf_d.txt_e928ccf9_28c09460",
      "chunk_index": 3,
      "content": "and processing power limitations",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmp3fipkrrd.txt_e928ccf9_9db2a331",
      "chunk_index": 0,
      "content": "Augmented Reality (AR) and Virtual Reality (VR) Technology Overview\n\nAugmented Reality (AR) is a technology that overlays digital information and virtual objects onto the real world, enhancing the user's perception of reality. AR applications use cameras, sensors, and displays to blend virtual content with the physical environment in real-time.\n\nKey AR Technologies:\n- Marker-based AR: Uses visual markers to trigger virtual content\n- Markerless AR: Uses GPS, accelerometers, and computer vision\n- Projection-based AR: Projects light onto real-world surfaces\n- Superimposition-based AR: Replaces or enhances real-world objects\n\nPopular AR Applications:\n- Mobile AR apps like Pokemon GO and Snapchat filters\n- Industrial maintenance and training\n- Medical visualization and surgery assistance\n- Retail and e-commerce product visualization\n- Navigation and wayfinding systems\n\nVirtual Reality (VR) is an immersive technology that creates a completely artificial digital environment that users can int",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmp3fipkrrd.txt_e928ccf9_9db2a331",
      "chunk_index": 1,
      "content": "il and e-commerce product visualization\n- Navigation and wayfinding systems\n\nVirtual Reality (VR) is an immersive technology that creates a completely artificial digital environment that users can interact with using specialized headsets and controllers. VR replaces the user's real-world environment with a computer-generated simulation.\n\nKey VR Technologies:\n- Head-mounted displays (HMDs) like Oculus Rift, HTC Vive, PlayStation VR\n- Motion tracking systems for hand and body movement\n- Haptic feedback devices for tactile sensations\n- Spatial audio for immersive sound experiences\n\nPopular VR Applications:\n- Gaming and entertainment\n- Virtual training and education\n- Architectural visualization\n- Therapy and rehabilitation\n- Virtual tourism and exploration\n\nCurrent Market Trends:\nThe AR/VR market is experiencing rapid growth, with projections showing significant expansion in both consumer and enterprise sectors.",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmp3fipkrrd.txt_e928ccf9_9db2a331",
      "chunk_index": 2,
      "content": "itation\n- Virtual tourism and exploration\n\nCurrent Market Trends:\nThe AR/VR market is experiencing rapid growth, with projections showing significant expansion in both consumer and enterprise sectors. Major technology companies like Apple, Google, Microsoft, and Meta are investing heavily in AR/VR development.\n\nFuture Prospects:\n- Mixed Reality (MR) combining AR and VR\n- 5G connectivity enabling cloud-based AR/VR experiences\n- Improved hardware with better resolution and comfort\n- Integration with artificial intelligence and machine learning\n- Expansion into healthcare, education, and remote work applications\n\nChallenges and Limitations:\n- Hardware costs and accessibility\n- Motion sickness and user comfort issues\n- Content creation complexity\n- Privacy and security concerns\n- Battery life and processing power limitations",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmp3fipkrrd.txt_e928ccf9_9db2a331",
      "chunk_index": 3,
      "content": "and processing power limitations",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nDIFFUSION MODELS  \nDiffusion models are a type of generative AI that create new data like images, audio or even \nvideo by starting with random noise and gradually turning it into something meaningful. They \nwork by simulating a diffusion process where data is  slowly corrupted by noise during \ntraining and then learning to reverse this process step by step. By doing so the model learns \nhow to generate high quality samples from scratch.  \nUnderstanding  Diffusion  Models  \n \n \n• Diffusion  models  are generative  models  that learn  to reverse  a diffusion  process  to \ngenerate  data.  The diffusion  process  involves  gradually  adding  noise  to data until it \nbecomes  pure noise.  \n• Through  this process  a simple  distribution  is transformed  into a complex  data distribution  \nin a series  of small incremental  steps.  \n• Essentially  these  models  operate  as a reverse  diffusion  phenomenon  where  noise  is \nintroduced  to the data in a forward  manner  and r",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 1,
      "content": "ribution  \nin a series  of small incremental  steps.  \n• Essentially  these  models  operate  as a reverse  diffusion  phenomenon  where  noise  is \nintroduced  to the data in a forward  manner  and removed  in a reverse  manner  to generate  \nnew data samples.  \n• By learning  to reverse  this process  diffusion  models  start from  noise  and gradually  \ndenoise  it to produce  data that closely  resembles  the training  examples.  \n \nKey Components  \n1. Forward  Diffusion  Process : This process  involves  adding  noise  to the data in a series  of \nsmall  steps.  Each  step slightly  increases  the noise,  making  the data progressively  more  \nrandom  until  it resembles  pure noise.  \n2. Reverse  Diffusion  Process : The model  learns  to reverse  the noise -adding  steps.  Starting  \nfrom  pure noise,  the model  iteratively  removes  the noise,  generating  data that matches  \nthe training  distribution.  \n3.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 2,
      "content": ": The model  learns  to reverse  the noise -adding  steps.  Starting  \nfrom  pure noise,  the model  iteratively  removes  the noise,  generating  data that matches  \nthe training  distribution.  \n3. Score  Function : This function  estimates  the gradient  of the data distribution  concerning  \nthe noise.  It helps  guide  the reverse  diffusion  process  to produce  realistic  samples.  \n \n \n \n \n \n\n\n--- Page 2 ---\nArchitecture  of Diffusion  Models  \nThe architecture  of diffusion  models  typically  involves  two main  components:  \n1. Forward  Diffusion  Process  \n2. Reverse  Diffusion  Process  \n1. Forward  Diffusion  Process  \nIn this process  noise  is incrementally  added  to the data over a series  of steps.  This is akin to \na Markov  chain  where  each step slightly  degrades  the data by adding  Gaussian  noise.  \n \nForward Diffusion P  \nMathematically,  this can be represented  as: \n \nwhere,  \n• xt is the noisy  data at step t \n• αt controls  the amount  of noise  added.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 3,
      "content": "the data by adding  Gaussian  noise.  \n \nForward Diffusion P  \nMathematically,  this can be represented  as: \n \nwhere,  \n• xt is the noisy  data at step t \n• αt controls  the amount  of noise  added.  \n \n2. Reverse  Diffusion  Process  \nThe reverse  process  aims  to reconstruct  the original  data by denoising  the noisy  data in a \nseries  of steps  reversing  the forward  diffusion.  \n \nReverse Diffusion Process  \nThis is typically  modelled  using  a neural  network  that predicts  the noise  added  at each step:  \n \nwhere,  \n• μθ and σθ are learned  parameters.  \n \nWorking  Principle  of Diffusion  Models  \nDuring  training  the model  learns  to predict  the noise  added  at each step of the forward  \nprocess.  This is done  by minimizing  a loss function  that measures  the difference  between  the \npredicted  and actual  noise.  \n \nForward  Process  (Diffusion)  \n• The forward  process  involves  gradually  corrupting  the data x0 with Gaussian  noise  over \na sequence  of tim",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 4,
      "content": "nce  between  the \npredicted  and actual  noise.  \n \nForward  Process  (Diffusion)  \n• The forward  process  involves  gradually  corrupting  the data x0 with Gaussian  noise  over \na sequence  of time steps  \n• Let xt represent  the noisy  data at time step t. The process  is defined  as: \n \n• where  βt is the noise  schedule  that controls  the amount  of noise  added  at each step and ϵ is \nis Gaussian  noise.  \n\n\n--- Page 3 ---\n• As t increases,  xt becomes  more  noisy  until  it approximates  a Gaussian  distribution.  \n \nReverse  Process  (Denoising)  \n• The reverse  process  aims  to reconstruct  the original  data x0x0 from  the noisy  data xT at \nthe final  time step T. \n• This process  is modelled  using  a neural  network  to approximate  the conditional  \nprobability  pθ(xt−1∣xt). \n• The reverse  process  can be formulated  as: \n \n• where  ϵθ is a neural  network  parameterized  by θ that predicts  the noise.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 5,
      "content": "network  to approximate  the conditional  \nprobability  pθ(xt−1∣xt). \n• The reverse  process  can be formulated  as: \n \n• where  ϵθ is a neural  network  parameterized  by θ that predicts  the noise.  \n \nTraining  Diffusion  Models  \n• The training  objective  for diffusion  models  involves  minimizing  the difference  between  \nthe true noise  ϵ added  in the forward  process  and the noise  predicted  by the neural  \nnetwork  ϵθ. \n• The score  function  which  estimates  the gradient  of the data distribution  concerning  the \nnoise  plays  an important  role in guiding  the reverse  process.  \n• The loss function  is typically  the mean  squared  error  (MSE)  between  these  two quantities:  \n \n• This encourages  the model  to accurately  predict  the noise  and, consequently,  to denoise  \neffectively  during  the reverse  process.  \n \nIn diffusion models, both the forward and backward processes are modeled  as a sequence of \nsmall incremental steps rather than a single transfor",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 6,
      "content": "noise  \neffectively  during  the reverse  process.  \n \nIn diffusion models, both the forward and backward processes are modeled  as a sequence of \nsmall incremental steps rather than a single transformation. This sequential approach is \ncrucial because:  \n1. Gradual Learning  – By breaking the process into many steps, the model learns how \nto handle slight changes at each stage, making it e asier to reverse the noise addition. If \nit tried to denoise from a fully noisy image in one step, it would struggle to map the \nrandom noise back to structured data.  \n2. Stability in Training  – Learning through small denoising steps prevents abrupt \ntransitions,  reducing the chances of errors or divergence during training. It ensures \nthat the model refines its predictions slowly, stabilizing gradients and allowing \nconsistent improvements.  \n3. Better Control Over Generation  – The step -wise nature allows the model to b e \nsampled at different stages, offering control over how much noise to re",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 7,
      "content": "nts and allowing \nconsistent improvements.  \n3. Better Control Over Generation  – The step -wise nature allows the model to b e \nsampled at different stages, offering control over how much noise to remove or retain. \nThis is especially useful in VR environments, where designers might want to balance \nrealism with creativity.  \n4. Avoiding Catastrophic Forgetting  – Incremental denoising r einforces the learning at \nevery step, ensuring that earlier patterns are not forgotten as the model progresses \ntoward generating complex outputs.  \n\n\n--- Page 4 ---\nThus, modeling the forward and backward processes as a sequence of steps ensures that \nlearning is smooth, robu st, and interpretable, ultimately allowing the system to produce high -\nquality, stable, and realistic images from rough sketches.  \nNoise plays a central role in the diffusion process, and carefully adjusting it can significantly \ninfluence the outcomes:  \n1.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 8,
      "content": "duce high -\nquality, stable, and realistic images from rough sketches.  \nNoise plays a central role in the diffusion process, and carefully adjusting it can significantly \ninfluence the outcomes:  \n1. Higher Noise Levels  \no Encourages diverse outputs  because the model explores a wider range of \npossibilities when starting from more random data.  \no Useful for generating creative or artistic VR landscapes where uniqueness is \ndesired.  \no However, if the noise is too  high, the generated images may lose structure or \ncoherence, reducing realism.  \n2. Lower Noise Levels  \no Helps maintain realism and fidelity  because the model starts closer to \nstructured patterns, making it easier to produce clear and consistent images.  \no Best suit ed for VR environments where accuracy, recognizable objects, and \nrealistic textures are essential.  \no It may, however, limit creativity and diversity since the outputs are \nconstrained to follow the training data closely.  \n3.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 9,
      "content": "accuracy, recognizable objects, and \nrealistic textures are essential.  \no It may, however, limit creativity and diversity since the outputs are \nconstrained to follow the training data closely.  \n3. Noise Scheduling  \no Adjusting how noise is added or removed across steps (e.g., linear, \nexponential, cosine schedules) allows fine -tuning between exploration and \nrefinement.  \no Designers can control whether the model produces subtle variations or \nradically different landscapes.  \n4. Application in VR Sy stems  \no For immersive experiences, higher noise levels at early steps can generate \nunpredictable and novel environments, while later steps can be fine -tuned with \nlower noise to ensure realistic details.  \no This balance allows users to start with abstract sketch es and transform them \ninto believable virtual worlds that retain creativity without sacrificing \ncoherence.  \n \n \n \n \n \n \n \n \n \n\n--- Page 5 ---\nDENOISING DIFFUSION PROBABILISTIC MODEL (DDPM)  \nWhat are DDPMs?  \nThey are",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 10,
      "content": "m \ninto believable virtual worlds that retain creativity without sacrificing \ncoherence.  \n \n \n \n \n \n \n \n \n \n\n--- Page 5 ---\nDENOISING DIFFUSION PROBABILISTIC MODEL (DDPM)  \nWhat are DDPMs?  \nThey are a class of  generative models  that work by iteratively  adding noise  to an input signal \n(like an image, text, or audio)  and then learning to denoise  from the noisy signal  to generate \nnew samples .  \n \nGenerative models  \nAre a type of model that can generate new data instances.  Previously, machine learning models \nhave done a good job of learning differences in data and then making predictions or \nclassification tasks. For example, a model trained on a digits dataset like  MNIST  can recognize \na 0 from a  1. Generative models, on the other hand, learn the distribution of digits and can create \na “fake digit” which closely resembles a real digit.  \n \nA Denoising Diffusion Probabilistic Model (DDPM)  is a type of gener ative model that \ncreates realistic images by learning how to p",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 11,
      "content": "an create \na “fake digit” which closely resembles a real digit.  \n \nA Denoising Diffusion Probabilistic Model (DDPM)  is a type of gener ative model that \ncreates realistic images by learning how to progressively refine noisy data. It works in two \nphases:  \n1. Forward Process (Noise Addition)  – The model gradually adds random noise to a \nclean image over many steps until the image becomes indistinguishable from noise.  \n2. Backward Process (Denoising)  – The model learns to reverse this process by \npredicting how to remove noise at each step, eventual ly reconstructing a high -quality \nimage from random noise or a rough input.  \nThe model is called probabilistic  because it doesn’t rely on a single deterministic \ntransformation but instead learns the distribution of possible images at each stage of noise \nand denoising. This approach allows it to generate diverse, high -fidelity images by sampling \nfrom the learned distribution.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 12,
      "content": "instead learns the distribution of possible images at each stage of noise \nand denoising. This approach allows it to generate diverse, high -fidelity images by sampling \nfrom the learned distribution.  \n\n\n--- Page 6 ---\nKey Features of DDPM:  \n• Iterative Refinement  – Instead of transforming an image in one step, it uses many \nsmall steps, making it easier to  model complex patterns.  \n• Noise -Based Learning  – By learning how images degrade with noise, the model \nunderstands how to reverse this degradation to recreate details.  \n• Probabilistic Nature  – It generates a range of plausible outputs rather than a single \nfixed result, which is useful in creative tasks like animation.  \n• Flexibility  – DDPMs can be applied to various tasks such as image synthesis, super -\nresolution, and in your case, converting ro ugh sketches into fully rendered scenes.  \nForward and Backward Diffusion Process  \nThe forward diffusion process  is the initial phase in a DDPM where noise is incrementally",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 13,
      "content": "your case, converting ro ugh sketches into fully rendered scenes.  \nForward and Backward Diffusion Process  \nThe forward diffusion process  is the initial phase in a DDPM where noise is incrementally \nadded to clean data over many steps. The purpose is to teach the model how data transitions \nfrom structured and detailed forms into randomness.  \nKey steps involved:  \n1. Starting with clean data  – At the beginning, the model takes real data such as an \nimage or signal that contains structured information like shapes, textures, and \npatterns.  \n2. Adding noise at each step  – Gaussian noise is added to the data in small amounts \nover a sequence of steps. The nois e schedule (linear, cosine, etc.) controls how much \nnoise is added at each step.  \n3. Progressive degradation  – The data becomes increasingly noisy at every step. \nInitially, the patterns are still recognizable, but as the process continues, the structure \ndisapp ears, and the data looks like random noise.  \n4.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 14,
      "content": "The data becomes increasingly noisy at every step. \nInitially, the patterns are still recognizable, but as the process continues, the structure \ndisapp ears, and the data looks like random noise.  \n4. Mathematical formulation  – At step t, the noisy data xt is derived from the previous \nstep xt−1 by sampling from a normal distribution:  \n \nwhere αt controls the amount of retained information and ϵ is sampled fr om a normal \ndistribution.  \nWhy this step is essential:  \n• It exposes the model to how real data deteriorates with noise.  \n• It creates a learning path for the model to understand the inverse operation —\nrecovering the data from noisy versions.  \n• It ensures that the m odel can generalize to varying noise levels and recover details \nfrom incomplete or corrupted data.  \n\n\n--- Page 7 ---\nRole of the Markov Chain in the Forward Diffusion Process of a DDPM  \nIn a Denoising Diffusion Probabilistic Model (DDPM) , the forward diffusion process  \ninvolves gradually adding noise to c",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 15,
      "content": "e 7 ---\nRole of the Markov Chain in the Forward Diffusion Process of a DDPM  \nIn a Denoising Diffusion Probabilistic Model (DDPM) , the forward diffusion process  \ninvolves gradually adding noise to clean data over multiple steps. This process is modeled as \na Markov chain , which plays a crucial role in structuring how noise is added.  \nA Markov chain  is a mathematical system that transitions from one state to another,  where \nthe next state depends only on the current state and not on the entire history of past states. In \nthe context of DDPM’s forward diffusion process, this means:  \n1. Stepwise progression  \no At each time step ttt, noise is added based only on the data at that step \n(xt−1x_{t -1}xt−1), not on earlier steps. This simplifies the process and \nensures that each step depends only on the immediately preceding one.  \n2. Controlled noise addition  \no The amount of noise added at each step is determined by a known noise \nschedule, ensuring that the transition from structu",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 16,
      "content": "nds only on the immediately preceding one.  \n2. Controlled noise addition  \no The amount of noise added at each step is determined by a known noise \nschedule, ensuring that the transition from structured data to noise is smooth \nand gradual.  \n3. Mathematical tractability  \no By assuming that each step depends only on the previous step, the forward \nprocess becomes easier to analyze, simulate, and invert during training.  \n How does it help structure the noise addition steps?  \n1. Simplifies modeling  \no The Markov assumption allows the model to focus on learning local \ntransitions rather than global dependencies, making the noise addition process \ncomputationally feasible.  \n2. Ensures grad ual degradation  \no The structured, stepwise approach ensures that noise is added progressively, \npreserving information early on and fully randomizing the data at later steps.  \n3. Supports efficient training  \no The Markov property allows the use of recursive formulat ions where each \nnoisy sampl",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 17,
      "content": "reserving information early on and fully randomizing the data at later steps.  \n3. Supports efficient training  \no The Markov property allows the use of recursive formulat ions where each \nnoisy sample can be derived from the previous one using simple equations, \nfacilitating optimization and gradient computation.  \n4. Enables inversion during sampling  \no Since each step only depends on the previous one, the backward process \n(denoisin g) can also be structured in the same stepwise manner, allowing the \nmodel to learn how to reverse the process reliably.  \nThe backward diffusion process  is where the model learns to reverse the noise addition and \nreconstruct the original or new data from noisy inputs.  \nKey aspects:  \n1. Predicting the noise  – At each step, the model is trained to estimate the noise that \nwas added in the forward process. It lear ns how the noisy data differs from its clean \nversion and tries to correct it.  \n\n--- Page 8 ---\n2.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 18,
      "content": "ach step, the model is trained to estimate the noise that \nwas added in the forward process. It lear ns how the noisy data differs from its clean \nversion and tries to correct it.  \n\n--- Page 8 ---\n2. Iterative refinement  – Starting from pure noise, the model removes noise \nprogressively by applying its learned knowledge of patterns at each step. Over time, \nthe image or data be comes clearer and more structured.  \n3. Learning objective  – The model is optimized to minimize the difference between the \npredicted noise and the actual noise added during training. This is typically done \nusing a loss function like Mean Squared Error (MSE).  \n4. Sampling during generation  – Once trained, the model can start from random noise \nand iteratively apply the backward process to generate new, realistic data samples.  \nWhy this process is critical:  \n• It allows the model to reconstruct missing or noisy details.  \n• It ensures that the output is consistent with real -world data distributions.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 19,
      "content": "alistic data samples.  \nWhy this process is critical:  \n• It allows the model to reconstruct missing or noisy details.  \n• It ensures that the output is consistent with real -world data distributions.  \n• It provides control over the generation process by using learned probabilities rather \nthan rigid rules.  \nThe probabilistic nature of DDPM plays a central role in its ability to generate both diverse \nand high -quality outputs.  \nWhy probabilistic modeling is useful ? \n1. Learning distributions rather than fixed mappings  \no Instead of learning a direct transformation from input to output, the model \nlearns the underlying distribution of possib le clean data conditioned on noisy \ninputs.  \no This enables the model to handle uncertainty and variations present in real \ndata.  \n2. Sampling from distributions  \no During generation, the model samples noise from a distribution at each step. \nEven with the same input, different random samples produce varied outputs, \npromoting creativity an",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 20,
      "content": "from distributions  \no During generation, the model samples noise from a distribution at each step. \nEven with the same input, different random samples produce varied outputs, \npromoting creativity and diversity.  \n3. Capturing subtle patterns  \no Probabilistic modeling allows the model to learn nuanced relationships in the \ndata such as textures, lighting patterns, or variations in shape th at are hard to \ncapture with deterministic methods.  \n \n4. Balancing realism and exploration  \no By controlling the noise level and how it’s modeled, the system can explore \nnew possibilities while staying within the realm of realistic outputs. This is \ncrucial for app lications like design, simulation, and data augmentation.  \nChallenges:  \n1. High computational cost  \no Because the process involves many steps (often hundreds or thousands), \ngenerating data can be slow and resource -intensive.  \n2. Latency issues in real -time application s \n\n--- Page 9 ---\no The iterative nature makes it difficul",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 21,
      "content": "any steps (often hundreds or thousands), \ngenerating data can be slow and resource -intensive.  \n2. Latency issues in real -time application s \n\n--- Page 9 ---\no The iterative nature makes it difficult to apply DDPMs in interactive or real -\ntime environments where fast feedback is essential.  \n3. Difficulty in controlling outputs  \no Without proper conditioning or guidance, the model might produce outputs \nthat are inconsis tent with user expectations or desired styles.  \n4. Data requirements  \no Training DDPMs effectively requires large and diverse datasets to accurately \nlearn noise patterns and recover fine details.  \n \nENERGY -BASED MODELS(EBMs)  \nEnergy -Based Models (EBMs)  are a class of probabilistic models that define relationships \nbetween variables using an energy function. Rather than explicitly modeling probability \ndistributions, EBMs assign an “energy” value to each possible configuration of variables, \nwhere lower energy indicates more likely or desirable configuration",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 22,
      "content": "her than explicitly modeling probability \ndistributions, EBMs assign an “energy” value to each possible configuration of variables, \nwhere lower energy indicates more likely or desirable configurations, and higher energy \ncorresponds to less likely ones.  \nEBMs are widely used in machine learning for t asks such as representation learning, \nstructured prediction, anomaly detection, and reinforcement learning, where capturing \nrelationships and constraints between variables is more important than explicitly computing \nprobabilities.  \n \n2. The Concept of Energy in EBMs  \n• An energy function  E(x)maps an input  x to a scalar energy value.  \n• The lower the energy, the more plausible or preferred the data point is according to \nthe model.  \n• The probability distribution  p(x)is related to the energy via the Boltzmann \ndistribution:  \n \nwhere  Z is the partition function:  \n \n• The partition function  Z is often intractable, making it difficult to directly compute \nprobabilities, but not",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 23,
      "content": "he energy via the Boltzmann \ndistribution:  \n \nwhere  Z is the partition function:  \n \n• The partition function  Z is often intractable, making it difficult to directly compute \nprobabilities, but not necessary for learning.  \n \n\n\n--- Page 10 ---\n3. Architecture and Working  \nCore Components:  \n1. Energy Function  \no The energy function is typically parameterized by neural networks or other \ndifferentiable models.  \no It scores different data configurations to indicate how well they conform to the \ndesired patterns.  \n2. Learning Objective  \no EBMs learn by comparing the energies of positive (correct) and negative \n(incorrect or unlikely) samples.  \no The goal is to assign lower energy to real data and higher energy to unlikely \ndata.  \n3. Training Approaches  \no Contrastive Divergence (CD)  – Optimizes the model by comparing energy \ndifferences betwe en observed and model -generated samples.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 24,
      "content": "ta and higher energy to unlikely \ndata.  \n3. Training Approaches  \no Contrastive Divergence (CD)  – Optimizes the model by comparing energy \ndifferences betwe en observed and model -generated samples.  \no Score Matching  – Matches the gradient of the energy function rather than the \nenergy itself.  \no Noise Contrastive Estimation (NCE)  – Uses noise samples to help \napproximate the partition function during learning.  \n \n4. Markov Random Fields (MRFs) and Conditional EBMs  \n• EBMs are closely related to Markov Random Fields (MRFs), which model \ndependencies between variables using graph structures.  \n• Conditional EBMs  extend the energy framework to ta sks where the output depends \non input features (e.g., image classification, structured output prediction).  \n \n5. Applications of EBMs  \n1. Unsupervised Learning  \no Modeling complex relationships in high -dimensional data such as im ages, \nspeech, or text.  \n2.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 25,
      "content": "assification, structured output prediction).  \n \n5. Applications of EBMs  \n1. Unsupervised Learning  \no Modeling complex relationships in high -dimensional data such as im ages, \nspeech, or text.  \n2. Anomaly Detection  \no Identifying outliers by assigning higher energy to rare or unlikely \nconfigurations.  \n3. Reinforcement Learning (RL)  \no Estimating value functions where actions with lower energy correspond to \nmore rewarding behaviors.  \n4. Generative Modeling  \no Generating samples by searching for configurations with low energy, often \nusing sampling algorithms like Langevin dynamics.  \n5. Structured Prediction  \no Solving problems like image segmentation or sequence labeling where \nrelationships between output variables are important.  \n\n--- Page 11 ---\n \n6. Advantages of EBMs  \n• Flexibility  – Can model arbitrary dependencies without requiring explicit probability \ndistributions.  \n• Interpretability  – The energy function directly encodes preferenc es or constraints.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 26,
      "content": "BMs  \n• Flexibility  – Can model arbitrary dependencies without requiring explicit probability \ndistributions.  \n• Interpretability  – The energy function directly encodes preferenc es or constraints.  \n• Applicability  – Useful in domains where structured relationships and constraints \ndominate over simple classification.  \n \n7. Challenges and Limitations  \n1. Intractable Partition Function  \no Computing  ZZZ is ofte n impossible in practice, requiring approximation \ntechniques that can be unstable.  \n2. Training Instability  \no Optimization methods like contrastive divergence rely on sampling, which can \nlead to slow convergence or poor performance.  \n3. Sampling Complexity  \no Generatin g samples requires iterative methods such as Markov Chain Monte \nCarlo (MCMC), which can be computationally expensive.  \n4. Scalability Issues  \no Handling high -dimensional data with complex energy landscapes is \nchallenging.  \n \n8.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 27,
      "content": "ods such as Markov Chain Monte \nCarlo (MCMC), which can be computationally expensive.  \n4. Scalability Issues  \no Handling high -dimensional data with complex energy landscapes is \nchallenging.  \n \n8. Recent Advances  \n• Neural EBMs  – Combining deep learning with energy functions to model high -\ndimensional and structured data more effectively.  \n• Score -based Generative Models  – Learning the gradi ent of the energy function to \navoid directly computing the partition function.  \n• Applications in Contrastive Learning  – EBMs form the backbone of contrastive \napproaches where relationships between samples are emphasized.  \n \n \n \n \n \n \n \n \n\n--- Page 12 ---\nCOMPARE EBMS VS VAES  \nAspect  Energy -Based Models (EBMs)  Variational Autoencoders (VAEs)  \n✅ Architecture  - Defined by an energy function \nthat assigns a scalar “energy” to \neach configuration of inputs (and \noptionally outputs).  \n- No explicit probability \ndistribution; the model learns to \nassign lower energy to desired \nsamp",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 28,
      "content": "unction \nthat assigns a scalar “energy” to \neach configuration of inputs (and \noptionally outputs).  \n- No explicit probability \ndistribution; the model learns to \nassign lower energy to desired \nsamples  and higher energy to \nundesired ones.  \n- Often optimized using contrastive \ndivergence or score matching.  \n- The architecture focuses on \nrelationships between data points \nrather than reconstructing or \ngenerating them directly.  - Composed of two main parts: an \nencoder and a decoder.  \n- The encoder maps input data to a \nlatent space distribution (typically \nGaussian).  \n- The decoder reconstructs data \nfrom samples drawn from the latent \nspace.  \n- Uses variational inference to \napproximate intractable posteriors.  \n- The architecture explicitly models \ndata generation.  \n✅ Objective  - Learn an energy landscape where \ncorrect data points are assigned \nlower energy.  \n- Optimization is based on \ndistinguishing good samples from \nbad ones.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 29,
      "content": "tly models \ndata generation.  \n✅ Objective  - Learn an energy landscape where \ncorrect data points are assigned \nlower energy.  \n- Optimization is based on \ndistinguishing good samples from \nbad ones.  - Maximize the Evidence Lower \nBound (ELBO) which balances \nreconstruction accuracy and \nregularization of the latent space.  \n- Encourages latent space structure \nfor efficient sampling and \ninterpolation.  \n✅ Probabilistic \nInterpretation  - Indirect; energy defi nes the \nlikelihood up to a normalization \nconstant (partition function), which \nis often intractable.  \n- Focuses on learning relationships \nand constraints rather than full \ndensity estimation.  - Explicit probabilistic framework \nwith tractable priors and \nappro ximate posteriors.  \n- Can directly sample from the latent \nspace and model uncertainty.  \n✅ Training \nMethods  - Uses sampling -based methods \nlike Markov Chain Monte Carlo \n(MCMC), contrastive divergence, \nor score matching.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 30,
      "content": "directly sample from the latent \nspace and model uncertainty.  \n✅ Training \nMethods  - Uses sampling -based methods \nlike Markov Chain Monte Carlo \n(MCMC), contrastive divergence, \nor score matching.  \n- Training can be unstable due to \nreliance on sampling and gradient \nestimation.  - Uses backpropagation with \nreparameterization trick for efficient \ngradient estimation.  \n- More stable and easier to train \nwith large datasets.  \n✅ Applications  - Modeling complex dependencies \nin structured data.  \n- Used in tasks like anomaly \ndetection, reinforcement learning, \nand unsupervised learning.  \n- Applicable where relationships \nand constraints are more important \nthan explicit reconstruction.  - Image and speech generation, data \ncompression, anomaly detection , \nand semi -supervised learning.  \n- Used where interpretable latent \nrepresentations and smooth \ngeneration paths are required.  \n\n--- Page 13 ---\nAspect  Energy -Based Models (EBMs)  Variational Autoencoders (VAEs)  \n✅ Strengt",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 31,
      "content": "ing.  \n- Used where interpretable latent \nrepresentations and smooth \ngeneration paths are required.  \n\n--- Page 13 ---\nAspect  Energy -Based Models (EBMs)  Variational Autoencoders (VAEs)  \n✅ Strengths  - Flexibility in modeling \nrelationships without requiring \nexplicit likelihood functions.  \n- Can incorporate constraint s and \ndomain knowledge easily.  - Well -suited for generating new \ndata samples.  \n- Provides interpretable latent spaces \nuseful for downstream tasks.  \n✅ Limitations  - Training is computationally \nexpensive and less scalable. - \nNormalization constant estimation  \nis intractable in many cases.  - May suffer from blurry \nreconstructions or mode collapse.  \n- Latent space structure depends \nheavily on choice of priors and \narchitectures.  \n \nINTRODUCTION TO NOISE SCHEDULERS IN DIFFUSION MODELS  \nIn diffusion models, noise plays a central role in transforming structured data into random noise \nduring training and then reconstructing it during sampling.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 32,
      "content": "TO NOISE SCHEDULERS IN DIFFUSION MODELS  \nIn diffusion models, noise plays a central role in transforming structured data into random noise \nduring training and then reconstructing it during sampling. However, how much noise is added \nor removed at each step is not arbitrary —it must be carefully controlled to ensure that the model \nlearns meaningful patterns and can effectively generate high -quality data.  \nThis is where noise schedulers  come into play.  \nA noise scheduler  defines the schedule or strategy by which noise is added to data in the \nforward diffusion process and removed in the backward process. It determines the magnitude \nof noise at each step, shaping how the model degrades and refines information over time.  \nThe design of the noise schedule affects several critical aspects:  \n• Learning efficiency  – Too much noise can obscur e important details, while too little \nmay prevent the model from learning to handle uncertainty.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 33,
      "content": "noise schedule affects several critical aspects:  \n• Learning efficiency  – Too much noise can obscur e important details, while too little \nmay prevent the model from learning to handle uncertainty.  \n• Sample diversity and quality  – The progression of noise influences how creative or \nrealistic the generated outputs are.  \n• Training stability  – Gradual noise addi tion helps avoid erratic learning and ensures \nthat the model can generalize from noisy inputs.  \nCommon schedules include linear, cosine, and exponential noise schedules , each offering \ndifferent trade -offs between smoothness, speed, and complexity.  \nSignifica nce of Noise Schedulers in Diffusion Models  \nIn diffusion models, noise schedulers  determine how noise is added (in the forward process) \nor removed (in the backward process) at each step. They play a critical role in controlling the \nquality, stability, and efficiency of the model during both training and sampling.  \nWhy are noise schedulers important?  \n1.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 34,
      "content": "kward process) at each step. They play a critical role in controlling the \nquality, stability, and efficiency of the model during both training and sampling.  \nWhy are noise schedulers important?  \n1. Control over noise injection  \no A noise scheduler defines how much noise is added at each step, influencing \nhow quickly the data degrades from its original form to pure noise.  \n\n--- Page 14 ---\no A carefully designed schedule ensures that the model learns meaningful \ntransformations at each step rather than abrupt or overly noisy transitions.  \n2. Balance between learning and randomness  \no If noise is added too aggressively, the model may strugg le to learn how to \nrecover the data because too much information is lost early.  \no If noise is too weak, the model may not generalize well and could overfit to \nspecific patterns without learning how to handle uncertainty.  \n3. Smooth transitions  \no Gradual noise addi tion allows the model to capture complex patterns and fine \ndetails at di",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 35,
      "content": "could overfit to \nspecific patterns without learning how to handle uncertainty.  \n3. Smooth transitions  \no Gradual noise addi tion allows the model to capture complex patterns and fine \ndetails at different noise levels, helping the backward process refine the data \neffectively.  \n4. Influences sample quality and diversity  \no The noise schedule affects the kinds of outputs the model generates. For \ninstance, a slower noise increase might produce high -fidelity samples, while a \nfaster schedule might encourage more diverse and creative outputs.  \n5. Stabilizes training  \no Appropriate noise scheduling prevents extreme gradients or erratic learning  \nbehavior, enabling stable and efficient training across large datasets.  \n✅ Example of a commonly used noise scheduler: Linear noise schedule  \nOne widely used noise scheduler is the linear noise schedule , where the noise level increases \nat a constant rate ac ross steps.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 36,
      "content": "✅ Example of a commonly used noise scheduler: Linear noise schedule  \nOne widely used noise scheduler is the linear noise schedule , where the noise level increases \nat a constant rate ac ross steps.  \n• The noise added at each step t is computed as:  \n \nwhere:  \no βstart is the initial noise amount,  \no βend is the final noise amount,  \no T is the total number of steps.  \n \nWhy it's used:  \n• Simplicity – easy to implement and analyze.  \n• Gradual degradation – ensures smooth transitions from structured data to noise.  \n• Works well in practice for a variety of tasks without requiring complex tuning.  \n✅ Other common noise schedules  \n• Cosine schedule  – Uses a cosine curve to control noise increments, adding noise \nmore sm oothly at the beginning and end.  \n\n\n--- Page 15 ---\n• Exponential schedule  – Adds noise in a way that accelerates or decelerates across \nsteps, providing more control over learning phases.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 37,
      "content": "more sm oothly at the beginning and end.  \n\n\n--- Page 15 ---\n• Exponential schedule  – Adds noise in a way that accelerates or decelerates across \nsteps, providing more control over learning phases.  \nComparison between Class -Conditional Diffusion Models and Unconditional Diffusion \nModels  \nAspect  Class -Conditional Diffusion Models  Unconditional Diffusion Models  \n✅ Definition  Diffusion models where the generation \nprocess is guided by class labels or \nadditional conditioning information (e.g., \ntext, attributes). The model learns how the \ndata distribution changes for different \nclasses.  Diffusion models that generate data \npurely based on learned distributions \nwithout any conditioning information. \nThe model only depends on noise and \nthe learned data distribution.  \n✅ \nArchitecture  - Incorporates class labels or auxiliary \ninputs into the noise prediction network.  \n- Conditioning is usually done by \nconcatenating labels or through \nembeddings that influence intermediate",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 38,
      "content": "cture  - Incorporates class labels or auxiliary \ninputs into the noise prediction network.  \n- Conditioning is usually done by \nconcatenating labels or through \nembeddings that influence intermediate \nlayers.  \n- The model learns separate modes of the \ndata distribution for each class o r \ncondition.  - Contains only the noise prediction \nnetwork without any external inputs.  \n- Learns the general structure and \ndistribution of the entire dataset.  \n- Generates samples based on noise \nwithout class -specific guidance.  \n✅ Training \nObjective  - Learn how to denoise while respecting \nclass information.  \n- The model minimizes the reconstruction \nloss while conditioning on the class, \nensuring generated samples match the \ntarget category.  - Learn to denoise without any guidance \nother than the underlying data \ndistribution.  \n- The model focuses on general patterns \nand statistical relationships in the \ndataset.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 39,
      "content": "the \ntarget category.  - Learn to denoise without any guidance \nother than the underlying data \ndistribution.  \n- The model focuses on general patterns \nand statistical relationships in the \ndataset.  \n✅ Sampling  - During generation, class labels guide the \nsampling process, allowing control over \nwhat kind of sample is generated (e.g., a \ncat vs. a dog image ). \n- Can produce targeted, structured outputs.  - Generates samples from noise without \ncontrol over attributes or categories.  \n- Produces diverse outputs but without \nspecific guidance.  \n✅ \nApplications  - Image synthesis conditioned on class \nlabels (e.g., gene rating specific objects or \nfaces).  \n- Text-to-image generation, style transfer, \nor scenarios requiring targeted outputs.  \n- Semi -supervised learning where \nadditional information improves generation \nquality.  - General image, audio, or video \ngeneration where c ontrol is not \nnecessary.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 40,
      "content": "os requiring targeted outputs.  \n- Semi -supervised learning where \nadditional information improves generation \nquality.  - General image, audio, or video \ngeneration where c ontrol is not \nnecessary.  \n- Data augmentation, unsupervised \nlearning, and exploratory creative \ngeneration.  \n✅ \nAdvantages  - Greater control over generated samples.  \n- Can produce outputs tailored to specific \ntasks or user inputs.  \n- More interpretable generati on process.  - Simpler architecture and easier to \nimplement.  \n- Requires less labeled data.  \n\n--- Page 16 ---\nAspect  Class -Conditional Diffusion Models  Unconditional Diffusion Models  \n- Capable of learning diverse patterns \nfrom large, unstructured datasets.  \n✅ \nLimitations  - Requires labeled  data or conditioning \ninputs, which may not always be available.  \n- More complex architecture and higher \ncomputational cost.  - Lacks control over generated content.  \n- May produce irrelevant or ambiguous \noutputs when diverse patterns overlap.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 41,
      "content": "ays be available.  \n- More complex architecture and higher \ncomputational cost.  - Lacks control over generated content.  \n- May produce irrelevant or ambiguous \noutputs when diverse patterns overlap.  \n \nDDIM (DENOISING DIFFUSION IMPLICIT MODELS)  \nDDIM (Denoising Diffusion Implicit Models)  is an improvement over standard diffusion \nmodels like DDPM (Denoising Diffusion Probabilistic Models). It introduces a new sampling \nmethod that allows generating high -quality samples with significantly fewer steps, while still \nretaining diversity and structure in the outputs.  \n✅ Why DDIM was introduced  \n1. Reduce Sampling Time  \no Traditional diffusion models like DDPM require hundreds or thousands of \nsteps during sampling, which makes them computationally expensive and slow \nfor practical applications.  \n2. Maintain Quality and Diversity  \no Simply reducing steps in DDPM leads to degraded or  less diverse outputs.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 42,
      "content": "ling, which makes them computationally expensive and slow \nfor practical applications.  \n2. Maintain Quality and Diversity  \no Simply reducing steps in DDPM leads to degraded or  less diverse outputs.  \no DDIM proposes a deterministic or pseudo -deterministic approach that \nmaintains high sample fidelity even with fewer steps.  \n✅ How DDIM works  \n1. Implicit Sampling  \no Instead of following the stochastic rev erse process of DDPM, DDIM defines a \ndeterministic mapping between noise and data, reducing randomness during \nsampling.  \no The model avoids resampling at each step, making it faster and more stable.  \n2. Non-Markovian Transitions  \no Unlike DDPM where each step depend s only on the previous one (Markov \nproperty), DDIM relaxes this assumption by allowing steps that depend on \nearlier states.  \no This enables more flexible transitions and faster sampling while preserving \nsample quality.  \n3.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 43,
      "content": "(Markov \nproperty), DDIM relaxes this assumption by allowing steps that depend on \nearlier states.  \no This enables more flexible transitions and faster sampling while preserving \nsample quality.  \n3. Controlled Interpolation  \no DDIM allows int erpolation between different noise levels and samples, which \ncan be used for creative applications like style mixing or smooth transitions.  \n \n\n--- Page 17 ---\n✅ Key Differences from DDPM  \nFeature  DDPM  DDIM  \nSampling process  Stochastic, follows Markov chain with \nrandom transitions  Deterministic or pseudo -deterministic, \nwith fewer steps  \nComputational \ncost High due to many sampling steps  Much lower with accelerated sampling  \nDiversity  Can explore a wide range of outputs due \nto randomness  Maintains diversity but with controlled \nnoise patterns  \nUse case  Suitable for tasks needing rich \nexploration  Better for fast generation and interactive \napplications  \n \n✅ Mathematical Insight  \nIn DDPM, the reverse process is modeled as a",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 44,
      "content": "se patterns  \nUse case  Suitable for tasks needing rich \nexploration  Better for fast generation and interactive \napplications  \n \n✅ Mathematical Insight  \nIn DDPM, the reverse process is modeled as a probabilistic sampling from  p(xt−1∣xt), where \nrandomness is inherent at each step.  \nIn DDIM, a deterministic transition is defi ned: \n \nHere:  \n• αt defines how much signal is preserved at each step.  \n• ϵθ(xt,t) is the model’s learned noise prediction.  \nThis formulation allows skipping intermediate steps while still approximating the \nreverse trajectory.  \n \n✅ Applications of DDIM  \n1. Image Generation  \no Produces high -resolution images quickly without compromising on details.  \n2. Video and Audio Synthesis  \no Enables faster generation for time -sensitive applications like animation or \nsound design.  \n3. Style Transfer & Interpolation  \no Smoothly blends between samples by manipulating latent noise patterns \ndeterministically.  \n4.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 45,
      "content": "for time -sensitive applications like animation or \nsound design.  \n3. Style Transfer & Interpolation  \no Smoothly blends between samples by manipulating latent noise patterns \ndeterministically.  \n4. Interactive Tools  \no Supports real -time editing and creative workflows where speed and control are \ncritical.  \n\n\n--- Page 18 ---\n \n✅ Advantages of DDIM  \n✔ Faster sampling with fewer step s \n✔ Stable and high -quality output s \n✔ Supports interpolation and controlled gene ration \n✔ Reduces computational cost without major trade -offs in realism  \n \n✅ Limitations of DDIM  \n❗ May lose some diversity due to reduced randomnes s \n❗ Requires careful tuning of schedules and noise level s \n❗ Still dependent on well -trained models to perform effectively  \n \n✅ Conclusion  \nDDIM is a powerful extension of diffusion models that addresses one of their biggest \nlimitations —slow sampling —by introducing deterministic or semi -deterministic  transitions.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpyoc6mhp1_UNIT I - GCV NOTES.pdf_b9876e2d_a299b4e8",
      "chunk_index": 46,
      "content": "y  \n \n✅ Conclusion  \nDDIM is a powerful extension of diffusion models that addresses one of their biggest \nlimitations —slow sampling —by introducing deterministic or semi -deterministic  transitions. \nIt enables faster generation while maintaining sample fidelity and diversity, making it highly \nsuitable for real -world applications like image synthesis, animation, and interactive creative \ntools.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nDIFFUSION MODELS  \nDiffusion models are a type of generative AI that create new data like images, audio or even \nvideo by starting with random noise and gradually turning it into something meaningful. They \nwork by simulating a diffusion process where data is  slowly corrupted by noise during \ntraining and then learning to reverse this process step by step. By doing so the model learns \nhow to generate high quality samples from scratch.  \nUnderstanding  Diffusion  Models  \n \n \n• Diffusion  models  are generative  models  that learn  to reverse  a diffusion  process  to \ngenerate  data.  The diffusion  process  involves  gradually  adding  noise  to data until it \nbecomes  pure noise.  \n• Through  this process  a simple  distribution  is transformed  into a complex  data distribution  \nin a series  of small incremental  steps.  \n• Essentially  these  models  operate  as a reverse  diffusion  phenomenon  where  noise  is \nintroduced  to the data in a forward  manner  and r",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 1,
      "content": "ribution  \nin a series  of small incremental  steps.  \n• Essentially  these  models  operate  as a reverse  diffusion  phenomenon  where  noise  is \nintroduced  to the data in a forward  manner  and removed  in a reverse  manner  to generate  \nnew data samples.  \n• By learning  to reverse  this process  diffusion  models  start from  noise  and gradually  \ndenoise  it to produce  data that closely  resembles  the training  examples.  \n \nKey Components  \n1. Forward  Diffusion  Process : This process  involves  adding  noise  to the data in a series  of \nsmall  steps.  Each  step slightly  increases  the noise,  making  the data progressively  more  \nrandom  until  it resembles  pure noise.  \n2. Reverse  Diffusion  Process : The model  learns  to reverse  the noise -adding  steps.  Starting  \nfrom  pure noise,  the model  iteratively  removes  the noise,  generating  data that matches  \nthe training  distribution.  \n3.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 2,
      "content": ": The model  learns  to reverse  the noise -adding  steps.  Starting  \nfrom  pure noise,  the model  iteratively  removes  the noise,  generating  data that matches  \nthe training  distribution.  \n3. Score  Function : This function  estimates  the gradient  of the data distribution  concerning  \nthe noise.  It helps  guide  the reverse  diffusion  process  to produce  realistic  samples.  \n \n \n \n \n \n\n\n--- Page 2 ---\nArchitecture  of Diffusion  Models  \nThe architecture  of diffusion  models  typically  involves  two main  components:  \n1. Forward  Diffusion  Process  \n2. Reverse  Diffusion  Process  \n1. Forward  Diffusion  Process  \nIn this process  noise  is incrementally  added  to the data over a series  of steps.  This is akin to \na Markov  chain  where  each step slightly  degrades  the data by adding  Gaussian  noise.  \n \nForward Diffusion P  \nMathematically,  this can be represented  as: \n \nwhere,  \n• xt is the noisy  data at step t \n• αt controls  the amount  of noise  added.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 3,
      "content": "the data by adding  Gaussian  noise.  \n \nForward Diffusion P  \nMathematically,  this can be represented  as: \n \nwhere,  \n• xt is the noisy  data at step t \n• αt controls  the amount  of noise  added.  \n \n2. Reverse  Diffusion  Process  \nThe reverse  process  aims  to reconstruct  the original  data by denoising  the noisy  data in a \nseries  of steps  reversing  the forward  diffusion.  \n \nReverse Diffusion Process  \nThis is typically  modelled  using  a neural  network  that predicts  the noise  added  at each step:  \n \nwhere,  \n• μθ and σθ are learned  parameters.  \n \nWorking  Principle  of Diffusion  Models  \nDuring  training  the model  learns  to predict  the noise  added  at each step of the forward  \nprocess.  This is done  by minimizing  a loss function  that measures  the difference  between  the \npredicted  and actual  noise.  \n \nForward  Process  (Diffusion)  \n• The forward  process  involves  gradually  corrupting  the data x0 with Gaussian  noise  over \na sequence  of tim",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 4,
      "content": "nce  between  the \npredicted  and actual  noise.  \n \nForward  Process  (Diffusion)  \n• The forward  process  involves  gradually  corrupting  the data x0 with Gaussian  noise  over \na sequence  of time steps  \n• Let xt represent  the noisy  data at time step t. The process  is defined  as: \n \n• where  βt is the noise  schedule  that controls  the amount  of noise  added  at each step and ϵ is \nis Gaussian  noise.  \n\n\n--- Page 3 ---\n• As t increases,  xt becomes  more  noisy  until  it approximates  a Gaussian  distribution.  \n \nReverse  Process  (Denoising)  \n• The reverse  process  aims  to reconstruct  the original  data x0x0 from  the noisy  data xT at \nthe final  time step T. \n• This process  is modelled  using  a neural  network  to approximate  the conditional  \nprobability  pθ(xt−1∣xt). \n• The reverse  process  can be formulated  as: \n \n• where  ϵθ is a neural  network  parameterized  by θ that predicts  the noise.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 5,
      "content": "network  to approximate  the conditional  \nprobability  pθ(xt−1∣xt). \n• The reverse  process  can be formulated  as: \n \n• where  ϵθ is a neural  network  parameterized  by θ that predicts  the noise.  \n \nTraining  Diffusion  Models  \n• The training  objective  for diffusion  models  involves  minimizing  the difference  between  \nthe true noise  ϵ added  in the forward  process  and the noise  predicted  by the neural  \nnetwork  ϵθ. \n• The score  function  which  estimates  the gradient  of the data distribution  concerning  the \nnoise  plays  an important  role in guiding  the reverse  process.  \n• The loss function  is typically  the mean  squared  error  (MSE)  between  these  two quantities:  \n \n• This encourages  the model  to accurately  predict  the noise  and, consequently,  to denoise  \neffectively  during  the reverse  process.  \n \nIn diffusion models, both the forward and backward processes are modeled  as a sequence of \nsmall incremental steps rather than a single transfor",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 6,
      "content": "noise  \neffectively  during  the reverse  process.  \n \nIn diffusion models, both the forward and backward processes are modeled  as a sequence of \nsmall incremental steps rather than a single transformation. This sequential approach is \ncrucial because:  \n1. Gradual Learning  – By breaking the process into many steps, the model learns how \nto handle slight changes at each stage, making it e asier to reverse the noise addition. If \nit tried to denoise from a fully noisy image in one step, it would struggle to map the \nrandom noise back to structured data.  \n2. Stability in Training  – Learning through small denoising steps prevents abrupt \ntransitions,  reducing the chances of errors or divergence during training. It ensures \nthat the model refines its predictions slowly, stabilizing gradients and allowing \nconsistent improvements.  \n3. Better Control Over Generation  – The step -wise nature allows the model to b e \nsampled at different stages, offering control over how much noise to re",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 7,
      "content": "nts and allowing \nconsistent improvements.  \n3. Better Control Over Generation  – The step -wise nature allows the model to b e \nsampled at different stages, offering control over how much noise to remove or retain. \nThis is especially useful in VR environments, where designers might want to balance \nrealism with creativity.  \n4. Avoiding Catastrophic Forgetting  – Incremental denoising r einforces the learning at \nevery step, ensuring that earlier patterns are not forgotten as the model progresses \ntoward generating complex outputs.  \n\n\n--- Page 4 ---\nThus, modeling the forward and backward processes as a sequence of steps ensures that \nlearning is smooth, robu st, and interpretable, ultimately allowing the system to produce high -\nquality, stable, and realistic images from rough sketches.  \nNoise plays a central role in the diffusion process, and carefully adjusting it can significantly \ninfluence the outcomes:  \n1.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 8,
      "content": "duce high -\nquality, stable, and realistic images from rough sketches.  \nNoise plays a central role in the diffusion process, and carefully adjusting it can significantly \ninfluence the outcomes:  \n1. Higher Noise Levels  \no Encourages diverse outputs  because the model explores a wider range of \npossibilities when starting from more random data.  \no Useful for generating creative or artistic VR landscapes where uniqueness is \ndesired.  \no However, if the noise is too  high, the generated images may lose structure or \ncoherence, reducing realism.  \n2. Lower Noise Levels  \no Helps maintain realism and fidelity  because the model starts closer to \nstructured patterns, making it easier to produce clear and consistent images.  \no Best suit ed for VR environments where accuracy, recognizable objects, and \nrealistic textures are essential.  \no It may, however, limit creativity and diversity since the outputs are \nconstrained to follow the training data closely.  \n3.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 9,
      "content": "accuracy, recognizable objects, and \nrealistic textures are essential.  \no It may, however, limit creativity and diversity since the outputs are \nconstrained to follow the training data closely.  \n3. Noise Scheduling  \no Adjusting how noise is added or removed across steps (e.g., linear, \nexponential, cosine schedules) allows fine -tuning between exploration and \nrefinement.  \no Designers can control whether the model produces subtle variations or \nradically different landscapes.  \n4. Application in VR Sy stems  \no For immersive experiences, higher noise levels at early steps can generate \nunpredictable and novel environments, while later steps can be fine -tuned with \nlower noise to ensure realistic details.  \no This balance allows users to start with abstract sketch es and transform them \ninto believable virtual worlds that retain creativity without sacrificing \ncoherence.  \n \n \n \n \n \n \n \n \n \n\n--- Page 5 ---\nDENOISING DIFFUSION PROBABILISTIC MODEL (DDPM)  \nWhat are DDPMs?  \nThey are",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 10,
      "content": "m \ninto believable virtual worlds that retain creativity without sacrificing \ncoherence.  \n \n \n \n \n \n \n \n \n \n\n--- Page 5 ---\nDENOISING DIFFUSION PROBABILISTIC MODEL (DDPM)  \nWhat are DDPMs?  \nThey are a class of  generative models  that work by iteratively  adding noise  to an input signal \n(like an image, text, or audio)  and then learning to denoise  from the noisy signal  to generate \nnew samples .  \n \nGenerative models  \nAre a type of model that can generate new data instances.  Previously, machine learning models \nhave done a good job of learning differences in data and then making predictions or \nclassification tasks. For example, a model trained on a digits dataset like  MNIST  can recognize \na 0 from a  1. Generative models, on the other hand, learn the distribution of digits and can create \na “fake digit” which closely resembles a real digit.  \n \nA Denoising Diffusion Probabilistic Model (DDPM)  is a type of gener ative model that \ncreates realistic images by learning how to p",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 11,
      "content": "an create \na “fake digit” which closely resembles a real digit.  \n \nA Denoising Diffusion Probabilistic Model (DDPM)  is a type of gener ative model that \ncreates realistic images by learning how to progressively refine noisy data. It works in two \nphases:  \n1. Forward Process (Noise Addition)  – The model gradually adds random noise to a \nclean image over many steps until the image becomes indistinguishable from noise.  \n2. Backward Process (Denoising)  – The model learns to reverse this process by \npredicting how to remove noise at each step, eventual ly reconstructing a high -quality \nimage from random noise or a rough input.  \nThe model is called probabilistic  because it doesn’t rely on a single deterministic \ntransformation but instead learns the distribution of possible images at each stage of noise \nand denoising. This approach allows it to generate diverse, high -fidelity images by sampling \nfrom the learned distribution.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 12,
      "content": "instead learns the distribution of possible images at each stage of noise \nand denoising. This approach allows it to generate diverse, high -fidelity images by sampling \nfrom the learned distribution.  \n\n\n--- Page 6 ---\nKey Features of DDPM:  \n• Iterative Refinement  – Instead of transforming an image in one step, it uses many \nsmall steps, making it easier to  model complex patterns.  \n• Noise -Based Learning  – By learning how images degrade with noise, the model \nunderstands how to reverse this degradation to recreate details.  \n• Probabilistic Nature  – It generates a range of plausible outputs rather than a single \nfixed result, which is useful in creative tasks like animation.  \n• Flexibility  – DDPMs can be applied to various tasks such as image synthesis, super -\nresolution, and in your case, converting ro ugh sketches into fully rendered scenes.  \nForward and Backward Diffusion Process  \nThe forward diffusion process  is the initial phase in a DDPM where noise is incrementally",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 13,
      "content": "your case, converting ro ugh sketches into fully rendered scenes.  \nForward and Backward Diffusion Process  \nThe forward diffusion process  is the initial phase in a DDPM where noise is incrementally \nadded to clean data over many steps. The purpose is to teach the model how data transitions \nfrom structured and detailed forms into randomness.  \nKey steps involved:  \n1. Starting with clean data  – At the beginning, the model takes real data such as an \nimage or signal that contains structured information like shapes, textures, and \npatterns.  \n2. Adding noise at each step  – Gaussian noise is added to the data in small amounts \nover a sequence of steps. The nois e schedule (linear, cosine, etc.) controls how much \nnoise is added at each step.  \n3. Progressive degradation  – The data becomes increasingly noisy at every step. \nInitially, the patterns are still recognizable, but as the process continues, the structure \ndisapp ears, and the data looks like random noise.  \n4.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 14,
      "content": "The data becomes increasingly noisy at every step. \nInitially, the patterns are still recognizable, but as the process continues, the structure \ndisapp ears, and the data looks like random noise.  \n4. Mathematical formulation  – At step t, the noisy data xt is derived from the previous \nstep xt−1 by sampling from a normal distribution:  \n \nwhere αt controls the amount of retained information and ϵ is sampled fr om a normal \ndistribution.  \nWhy this step is essential:  \n• It exposes the model to how real data deteriorates with noise.  \n• It creates a learning path for the model to understand the inverse operation —\nrecovering the data from noisy versions.  \n• It ensures that the m odel can generalize to varying noise levels and recover details \nfrom incomplete or corrupted data.  \n\n\n--- Page 7 ---\nRole of the Markov Chain in the Forward Diffusion Process of a DDPM  \nIn a Denoising Diffusion Probabilistic Model (DDPM) , the forward diffusion process  \ninvolves gradually adding noise to c",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 15,
      "content": "e 7 ---\nRole of the Markov Chain in the Forward Diffusion Process of a DDPM  \nIn a Denoising Diffusion Probabilistic Model (DDPM) , the forward diffusion process  \ninvolves gradually adding noise to clean data over multiple steps. This process is modeled as \na Markov chain , which plays a crucial role in structuring how noise is added.  \nA Markov chain  is a mathematical system that transitions from one state to another,  where \nthe next state depends only on the current state and not on the entire history of past states. In \nthe context of DDPM’s forward diffusion process, this means:  \n1. Stepwise progression  \no At each time step ttt, noise is added based only on the data at that step \n(xt−1x_{t -1}xt−1), not on earlier steps. This simplifies the process and \nensures that each step depends only on the immediately preceding one.  \n2. Controlled noise addition  \no The amount of noise added at each step is determined by a known noise \nschedule, ensuring that the transition from structu",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 16,
      "content": "nds only on the immediately preceding one.  \n2. Controlled noise addition  \no The amount of noise added at each step is determined by a known noise \nschedule, ensuring that the transition from structured data to noise is smooth \nand gradual.  \n3. Mathematical tractability  \no By assuming that each step depends only on the previous step, the forward \nprocess becomes easier to analyze, simulate, and invert during training.  \n How does it help structure the noise addition steps?  \n1. Simplifies modeling  \no The Markov assumption allows the model to focus on learning local \ntransitions rather than global dependencies, making the noise addition process \ncomputationally feasible.  \n2. Ensures grad ual degradation  \no The structured, stepwise approach ensures that noise is added progressively, \npreserving information early on and fully randomizing the data at later steps.  \n3. Supports efficient training  \no The Markov property allows the use of recursive formulat ions where each \nnoisy sampl",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 17,
      "content": "reserving information early on and fully randomizing the data at later steps.  \n3. Supports efficient training  \no The Markov property allows the use of recursive formulat ions where each \nnoisy sample can be derived from the previous one using simple equations, \nfacilitating optimization and gradient computation.  \n4. Enables inversion during sampling  \no Since each step only depends on the previous one, the backward process \n(denoisin g) can also be structured in the same stepwise manner, allowing the \nmodel to learn how to reverse the process reliably.  \nThe backward diffusion process  is where the model learns to reverse the noise addition and \nreconstruct the original or new data from noisy inputs.  \nKey aspects:  \n1. Predicting the noise  – At each step, the model is trained to estimate the noise that \nwas added in the forward process. It lear ns how the noisy data differs from its clean \nversion and tries to correct it.  \n\n--- Page 8 ---\n2.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 18,
      "content": "ach step, the model is trained to estimate the noise that \nwas added in the forward process. It lear ns how the noisy data differs from its clean \nversion and tries to correct it.  \n\n--- Page 8 ---\n2. Iterative refinement  – Starting from pure noise, the model removes noise \nprogressively by applying its learned knowledge of patterns at each step. Over time, \nthe image or data be comes clearer and more structured.  \n3. Learning objective  – The model is optimized to minimize the difference between the \npredicted noise and the actual noise added during training. This is typically done \nusing a loss function like Mean Squared Error (MSE).  \n4. Sampling during generation  – Once trained, the model can start from random noise \nand iteratively apply the backward process to generate new, realistic data samples.  \nWhy this process is critical:  \n• It allows the model to reconstruct missing or noisy details.  \n• It ensures that the output is consistent with real -world data distributions.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 19,
      "content": "alistic data samples.  \nWhy this process is critical:  \n• It allows the model to reconstruct missing or noisy details.  \n• It ensures that the output is consistent with real -world data distributions.  \n• It provides control over the generation process by using learned probabilities rather \nthan rigid rules.  \nThe probabilistic nature of DDPM plays a central role in its ability to generate both diverse \nand high -quality outputs.  \nWhy probabilistic modeling is useful ? \n1. Learning distributions rather than fixed mappings  \no Instead of learning a direct transformation from input to output, the model \nlearns the underlying distribution of possib le clean data conditioned on noisy \ninputs.  \no This enables the model to handle uncertainty and variations present in real \ndata.  \n2. Sampling from distributions  \no During generation, the model samples noise from a distribution at each step. \nEven with the same input, different random samples produce varied outputs, \npromoting creativity an",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 20,
      "content": "from distributions  \no During generation, the model samples noise from a distribution at each step. \nEven with the same input, different random samples produce varied outputs, \npromoting creativity and diversity.  \n3. Capturing subtle patterns  \no Probabilistic modeling allows the model to learn nuanced relationships in the \ndata such as textures, lighting patterns, or variations in shape th at are hard to \ncapture with deterministic methods.  \n \n4. Balancing realism and exploration  \no By controlling the noise level and how it’s modeled, the system can explore \nnew possibilities while staying within the realm of realistic outputs. This is \ncrucial for app lications like design, simulation, and data augmentation.  \nChallenges:  \n1. High computational cost  \no Because the process involves many steps (often hundreds or thousands), \ngenerating data can be slow and resource -intensive.  \n2. Latency issues in real -time application s \n\n--- Page 9 ---\no The iterative nature makes it difficul",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 21,
      "content": "any steps (often hundreds or thousands), \ngenerating data can be slow and resource -intensive.  \n2. Latency issues in real -time application s \n\n--- Page 9 ---\no The iterative nature makes it difficult to apply DDPMs in interactive or real -\ntime environments where fast feedback is essential.  \n3. Difficulty in controlling outputs  \no Without proper conditioning or guidance, the model might produce outputs \nthat are inconsis tent with user expectations or desired styles.  \n4. Data requirements  \no Training DDPMs effectively requires large and diverse datasets to accurately \nlearn noise patterns and recover fine details.  \n \nENERGY -BASED MODELS(EBMs)  \nEnergy -Based Models (EBMs)  are a class of probabilistic models that define relationships \nbetween variables using an energy function. Rather than explicitly modeling probability \ndistributions, EBMs assign an “energy” value to each possible configuration of variables, \nwhere lower energy indicates more likely or desirable configuration",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 22,
      "content": "her than explicitly modeling probability \ndistributions, EBMs assign an “energy” value to each possible configuration of variables, \nwhere lower energy indicates more likely or desirable configurations, and higher energy \ncorresponds to less likely ones.  \nEBMs are widely used in machine learning for t asks such as representation learning, \nstructured prediction, anomaly detection, and reinforcement learning, where capturing \nrelationships and constraints between variables is more important than explicitly computing \nprobabilities.  \n \n2. The Concept of Energy in EBMs  \n• An energy function  E(x)maps an input  x to a scalar energy value.  \n• The lower the energy, the more plausible or preferred the data point is according to \nthe model.  \n• The probability distribution  p(x)is related to the energy via the Boltzmann \ndistribution:  \n \nwhere  Z is the partition function:  \n \n• The partition function  Z is often intractable, making it difficult to directly compute \nprobabilities, but not",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 23,
      "content": "he energy via the Boltzmann \ndistribution:  \n \nwhere  Z is the partition function:  \n \n• The partition function  Z is often intractable, making it difficult to directly compute \nprobabilities, but not necessary for learning.  \n \n\n\n--- Page 10 ---\n3. Architecture and Working  \nCore Components:  \n1. Energy Function  \no The energy function is typically parameterized by neural networks or other \ndifferentiable models.  \no It scores different data configurations to indicate how well they conform to the \ndesired patterns.  \n2. Learning Objective  \no EBMs learn by comparing the energies of positive (correct) and negative \n(incorrect or unlikely) samples.  \no The goal is to assign lower energy to real data and higher energy to unlikely \ndata.  \n3. Training Approaches  \no Contrastive Divergence (CD)  – Optimizes the model by comparing energy \ndifferences betwe en observed and model -generated samples.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 24,
      "content": "ta and higher energy to unlikely \ndata.  \n3. Training Approaches  \no Contrastive Divergence (CD)  – Optimizes the model by comparing energy \ndifferences betwe en observed and model -generated samples.  \no Score Matching  – Matches the gradient of the energy function rather than the \nenergy itself.  \no Noise Contrastive Estimation (NCE)  – Uses noise samples to help \napproximate the partition function during learning.  \n \n4. Markov Random Fields (MRFs) and Conditional EBMs  \n• EBMs are closely related to Markov Random Fields (MRFs), which model \ndependencies between variables using graph structures.  \n• Conditional EBMs  extend the energy framework to ta sks where the output depends \non input features (e.g., image classification, structured output prediction).  \n \n5. Applications of EBMs  \n1. Unsupervised Learning  \no Modeling complex relationships in high -dimensional data such as im ages, \nspeech, or text.  \n2.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 25,
      "content": "assification, structured output prediction).  \n \n5. Applications of EBMs  \n1. Unsupervised Learning  \no Modeling complex relationships in high -dimensional data such as im ages, \nspeech, or text.  \n2. Anomaly Detection  \no Identifying outliers by assigning higher energy to rare or unlikely \nconfigurations.  \n3. Reinforcement Learning (RL)  \no Estimating value functions where actions with lower energy correspond to \nmore rewarding behaviors.  \n4. Generative Modeling  \no Generating samples by searching for configurations with low energy, often \nusing sampling algorithms like Langevin dynamics.  \n5. Structured Prediction  \no Solving problems like image segmentation or sequence labeling where \nrelationships between output variables are important.  \n\n--- Page 11 ---\n \n6. Advantages of EBMs  \n• Flexibility  – Can model arbitrary dependencies without requiring explicit probability \ndistributions.  \n• Interpretability  – The energy function directly encodes preferenc es or constraints.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 26,
      "content": "BMs  \n• Flexibility  – Can model arbitrary dependencies without requiring explicit probability \ndistributions.  \n• Interpretability  – The energy function directly encodes preferenc es or constraints.  \n• Applicability  – Useful in domains where structured relationships and constraints \ndominate over simple classification.  \n \n7. Challenges and Limitations  \n1. Intractable Partition Function  \no Computing  ZZZ is ofte n impossible in practice, requiring approximation \ntechniques that can be unstable.  \n2. Training Instability  \no Optimization methods like contrastive divergence rely on sampling, which can \nlead to slow convergence or poor performance.  \n3. Sampling Complexity  \no Generatin g samples requires iterative methods such as Markov Chain Monte \nCarlo (MCMC), which can be computationally expensive.  \n4. Scalability Issues  \no Handling high -dimensional data with complex energy landscapes is \nchallenging.  \n \n8.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 27,
      "content": "ods such as Markov Chain Monte \nCarlo (MCMC), which can be computationally expensive.  \n4. Scalability Issues  \no Handling high -dimensional data with complex energy landscapes is \nchallenging.  \n \n8. Recent Advances  \n• Neural EBMs  – Combining deep learning with energy functions to model high -\ndimensional and structured data more effectively.  \n• Score -based Generative Models  – Learning the gradi ent of the energy function to \navoid directly computing the partition function.  \n• Applications in Contrastive Learning  – EBMs form the backbone of contrastive \napproaches where relationships between samples are emphasized.  \n \n \n \n \n \n \n \n \n\n--- Page 12 ---\nCOMPARE EBMS VS VAES  \nAspect  Energy -Based Models (EBMs)  Variational Autoencoders (VAEs)  \n✅ Architecture  - Defined by an energy function \nthat assigns a scalar “energy” to \neach configuration of inputs (and \noptionally outputs).  \n- No explicit probability \ndistribution; the model learns to \nassign lower energy to desired \nsamp",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 28,
      "content": "unction \nthat assigns a scalar “energy” to \neach configuration of inputs (and \noptionally outputs).  \n- No explicit probability \ndistribution; the model learns to \nassign lower energy to desired \nsamples  and higher energy to \nundesired ones.  \n- Often optimized using contrastive \ndivergence or score matching.  \n- The architecture focuses on \nrelationships between data points \nrather than reconstructing or \ngenerating them directly.  - Composed of two main parts: an \nencoder and a decoder.  \n- The encoder maps input data to a \nlatent space distribution (typically \nGaussian).  \n- The decoder reconstructs data \nfrom samples drawn from the latent \nspace.  \n- Uses variational inference to \napproximate intractable posteriors.  \n- The architecture explicitly models \ndata generation.  \n✅ Objective  - Learn an energy landscape where \ncorrect data points are assigned \nlower energy.  \n- Optimization is based on \ndistinguishing good samples from \nbad ones.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 29,
      "content": "tly models \ndata generation.  \n✅ Objective  - Learn an energy landscape where \ncorrect data points are assigned \nlower energy.  \n- Optimization is based on \ndistinguishing good samples from \nbad ones.  - Maximize the Evidence Lower \nBound (ELBO) which balances \nreconstruction accuracy and \nregularization of the latent space.  \n- Encourages latent space structure \nfor efficient sampling and \ninterpolation.  \n✅ Probabilistic \nInterpretation  - Indirect; energy defi nes the \nlikelihood up to a normalization \nconstant (partition function), which \nis often intractable.  \n- Focuses on learning relationships \nand constraints rather than full \ndensity estimation.  - Explicit probabilistic framework \nwith tractable priors and \nappro ximate posteriors.  \n- Can directly sample from the latent \nspace and model uncertainty.  \n✅ Training \nMethods  - Uses sampling -based methods \nlike Markov Chain Monte Carlo \n(MCMC), contrastive divergence, \nor score matching.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 30,
      "content": "directly sample from the latent \nspace and model uncertainty.  \n✅ Training \nMethods  - Uses sampling -based methods \nlike Markov Chain Monte Carlo \n(MCMC), contrastive divergence, \nor score matching.  \n- Training can be unstable due to \nreliance on sampling and gradient \nestimation.  - Uses backpropagation with \nreparameterization trick for efficient \ngradient estimation.  \n- More stable and easier to train \nwith large datasets.  \n✅ Applications  - Modeling complex dependencies \nin structured data.  \n- Used in tasks like anomaly \ndetection, reinforcement learning, \nand unsupervised learning.  \n- Applicable where relationships \nand constraints are more important \nthan explicit reconstruction.  - Image and speech generation, data \ncompression, anomaly detection , \nand semi -supervised learning.  \n- Used where interpretable latent \nrepresentations and smooth \ngeneration paths are required.  \n\n--- Page 13 ---\nAspect  Energy -Based Models (EBMs)  Variational Autoencoders (VAEs)  \n✅ Strengt",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 31,
      "content": "ing.  \n- Used where interpretable latent \nrepresentations and smooth \ngeneration paths are required.  \n\n--- Page 13 ---\nAspect  Energy -Based Models (EBMs)  Variational Autoencoders (VAEs)  \n✅ Strengths  - Flexibility in modeling \nrelationships without requiring \nexplicit likelihood functions.  \n- Can incorporate constraint s and \ndomain knowledge easily.  - Well -suited for generating new \ndata samples.  \n- Provides interpretable latent spaces \nuseful for downstream tasks.  \n✅ Limitations  - Training is computationally \nexpensive and less scalable. - \nNormalization constant estimation  \nis intractable in many cases.  - May suffer from blurry \nreconstructions or mode collapse.  \n- Latent space structure depends \nheavily on choice of priors and \narchitectures.  \n \nINTRODUCTION TO NOISE SCHEDULERS IN DIFFUSION MODELS  \nIn diffusion models, noise plays a central role in transforming structured data into random noise \nduring training and then reconstructing it during sampling.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 32,
      "content": "TO NOISE SCHEDULERS IN DIFFUSION MODELS  \nIn diffusion models, noise plays a central role in transforming structured data into random noise \nduring training and then reconstructing it during sampling. However, how much noise is added \nor removed at each step is not arbitrary —it must be carefully controlled to ensure that the model \nlearns meaningful patterns and can effectively generate high -quality data.  \nThis is where noise schedulers  come into play.  \nA noise scheduler  defines the schedule or strategy by which noise is added to data in the \nforward diffusion process and removed in the backward process. It determines the magnitude \nof noise at each step, shaping how the model degrades and refines information over time.  \nThe design of the noise schedule affects several critical aspects:  \n• Learning efficiency  – Too much noise can obscur e important details, while too little \nmay prevent the model from learning to handle uncertainty.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 33,
      "content": "noise schedule affects several critical aspects:  \n• Learning efficiency  – Too much noise can obscur e important details, while too little \nmay prevent the model from learning to handle uncertainty.  \n• Sample diversity and quality  – The progression of noise influences how creative or \nrealistic the generated outputs are.  \n• Training stability  – Gradual noise addi tion helps avoid erratic learning and ensures \nthat the model can generalize from noisy inputs.  \nCommon schedules include linear, cosine, and exponential noise schedules , each offering \ndifferent trade -offs between smoothness, speed, and complexity.  \nSignifica nce of Noise Schedulers in Diffusion Models  \nIn diffusion models, noise schedulers  determine how noise is added (in the forward process) \nor removed (in the backward process) at each step. They play a critical role in controlling the \nquality, stability, and efficiency of the model during both training and sampling.  \nWhy are noise schedulers important?  \n1.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 34,
      "content": "kward process) at each step. They play a critical role in controlling the \nquality, stability, and efficiency of the model during both training and sampling.  \nWhy are noise schedulers important?  \n1. Control over noise injection  \no A noise scheduler defines how much noise is added at each step, influencing \nhow quickly the data degrades from its original form to pure noise.  \n\n--- Page 14 ---\no A carefully designed schedule ensures that the model learns meaningful \ntransformations at each step rather than abrupt or overly noisy transitions.  \n2. Balance between learning and randomness  \no If noise is added too aggressively, the model may strugg le to learn how to \nrecover the data because too much information is lost early.  \no If noise is too weak, the model may not generalize well and could overfit to \nspecific patterns without learning how to handle uncertainty.  \n3. Smooth transitions  \no Gradual noise addi tion allows the model to capture complex patterns and fine \ndetails at di",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 35,
      "content": "could overfit to \nspecific patterns without learning how to handle uncertainty.  \n3. Smooth transitions  \no Gradual noise addi tion allows the model to capture complex patterns and fine \ndetails at different noise levels, helping the backward process refine the data \neffectively.  \n4. Influences sample quality and diversity  \no The noise schedule affects the kinds of outputs the model generates. For \ninstance, a slower noise increase might produce high -fidelity samples, while a \nfaster schedule might encourage more diverse and creative outputs.  \n5. Stabilizes training  \no Appropriate noise scheduling prevents extreme gradients or erratic learning  \nbehavior, enabling stable and efficient training across large datasets.  \n✅ Example of a commonly used noise scheduler: Linear noise schedule  \nOne widely used noise scheduler is the linear noise schedule , where the noise level increases \nat a constant rate ac ross steps.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 36,
      "content": "✅ Example of a commonly used noise scheduler: Linear noise schedule  \nOne widely used noise scheduler is the linear noise schedule , where the noise level increases \nat a constant rate ac ross steps.  \n• The noise added at each step t is computed as:  \n \nwhere:  \no βstart is the initial noise amount,  \no βend is the final noise amount,  \no T is the total number of steps.  \n \nWhy it's used:  \n• Simplicity – easy to implement and analyze.  \n• Gradual degradation – ensures smooth transitions from structured data to noise.  \n• Works well in practice for a variety of tasks without requiring complex tuning.  \n✅ Other common noise schedules  \n• Cosine schedule  – Uses a cosine curve to control noise increments, adding noise \nmore sm oothly at the beginning and end.  \n\n\n--- Page 15 ---\n• Exponential schedule  – Adds noise in a way that accelerates or decelerates across \nsteps, providing more control over learning phases.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 37,
      "content": "more sm oothly at the beginning and end.  \n\n\n--- Page 15 ---\n• Exponential schedule  – Adds noise in a way that accelerates or decelerates across \nsteps, providing more control over learning phases.  \nComparison between Class -Conditional Diffusion Models and Unconditional Diffusion \nModels  \nAspect  Class -Conditional Diffusion Models  Unconditional Diffusion Models  \n✅ Definition  Diffusion models where the generation \nprocess is guided by class labels or \nadditional conditioning information (e.g., \ntext, attributes). The model learns how the \ndata distribution changes for different \nclasses.  Diffusion models that generate data \npurely based on learned distributions \nwithout any conditioning information. \nThe model only depends on noise and \nthe learned data distribution.  \n✅ \nArchitecture  - Incorporates class labels or auxiliary \ninputs into the noise prediction network.  \n- Conditioning is usually done by \nconcatenating labels or through \nembeddings that influence intermediate",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 38,
      "content": "cture  - Incorporates class labels or auxiliary \ninputs into the noise prediction network.  \n- Conditioning is usually done by \nconcatenating labels or through \nembeddings that influence intermediate \nlayers.  \n- The model learns separate modes of the \ndata distribution for each class o r \ncondition.  - Contains only the noise prediction \nnetwork without any external inputs.  \n- Learns the general structure and \ndistribution of the entire dataset.  \n- Generates samples based on noise \nwithout class -specific guidance.  \n✅ Training \nObjective  - Learn how to denoise while respecting \nclass information.  \n- The model minimizes the reconstruction \nloss while conditioning on the class, \nensuring generated samples match the \ntarget category.  - Learn to denoise without any guidance \nother than the underlying data \ndistribution.  \n- The model focuses on general patterns \nand statistical relationships in the \ndataset.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 39,
      "content": "the \ntarget category.  - Learn to denoise without any guidance \nother than the underlying data \ndistribution.  \n- The model focuses on general patterns \nand statistical relationships in the \ndataset.  \n✅ Sampling  - During generation, class labels guide the \nsampling process, allowing control over \nwhat kind of sample is generated (e.g., a \ncat vs. a dog image ). \n- Can produce targeted, structured outputs.  - Generates samples from noise without \ncontrol over attributes or categories.  \n- Produces diverse outputs but without \nspecific guidance.  \n✅ \nApplications  - Image synthesis conditioned on class \nlabels (e.g., gene rating specific objects or \nfaces).  \n- Text-to-image generation, style transfer, \nor scenarios requiring targeted outputs.  \n- Semi -supervised learning where \nadditional information improves generation \nquality.  - General image, audio, or video \ngeneration where c ontrol is not \nnecessary.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 40,
      "content": "os requiring targeted outputs.  \n- Semi -supervised learning where \nadditional information improves generation \nquality.  - General image, audio, or video \ngeneration where c ontrol is not \nnecessary.  \n- Data augmentation, unsupervised \nlearning, and exploratory creative \ngeneration.  \n✅ \nAdvantages  - Greater control over generated samples.  \n- Can produce outputs tailored to specific \ntasks or user inputs.  \n- More interpretable generati on process.  - Simpler architecture and easier to \nimplement.  \n- Requires less labeled data.  \n\n--- Page 16 ---\nAspect  Class -Conditional Diffusion Models  Unconditional Diffusion Models  \n- Capable of learning diverse patterns \nfrom large, unstructured datasets.  \n✅ \nLimitations  - Requires labeled  data or conditioning \ninputs, which may not always be available.  \n- More complex architecture and higher \ncomputational cost.  - Lacks control over generated content.  \n- May produce irrelevant or ambiguous \noutputs when diverse patterns overlap.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 41,
      "content": "ays be available.  \n- More complex architecture and higher \ncomputational cost.  - Lacks control over generated content.  \n- May produce irrelevant or ambiguous \noutputs when diverse patterns overlap.  \n \nDDIM (DENOISING DIFFUSION IMPLICIT MODELS)  \nDDIM (Denoising Diffusion Implicit Models)  is an improvement over standard diffusion \nmodels like DDPM (Denoising Diffusion Probabilistic Models). It introduces a new sampling \nmethod that allows generating high -quality samples with significantly fewer steps, while still \nretaining diversity and structure in the outputs.  \n✅ Why DDIM was introduced  \n1. Reduce Sampling Time  \no Traditional diffusion models like DDPM require hundreds or thousands of \nsteps during sampling, which makes them computationally expensive and slow \nfor practical applications.  \n2. Maintain Quality and Diversity  \no Simply reducing steps in DDPM leads to degraded or  less diverse outputs.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 42,
      "content": "ling, which makes them computationally expensive and slow \nfor practical applications.  \n2. Maintain Quality and Diversity  \no Simply reducing steps in DDPM leads to degraded or  less diverse outputs.  \no DDIM proposes a deterministic or pseudo -deterministic approach that \nmaintains high sample fidelity even with fewer steps.  \n✅ How DDIM works  \n1. Implicit Sampling  \no Instead of following the stochastic rev erse process of DDPM, DDIM defines a \ndeterministic mapping between noise and data, reducing randomness during \nsampling.  \no The model avoids resampling at each step, making it faster and more stable.  \n2. Non-Markovian Transitions  \no Unlike DDPM where each step depend s only on the previous one (Markov \nproperty), DDIM relaxes this assumption by allowing steps that depend on \nearlier states.  \no This enables more flexible transitions and faster sampling while preserving \nsample quality.  \n3.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 43,
      "content": "(Markov \nproperty), DDIM relaxes this assumption by allowing steps that depend on \nearlier states.  \no This enables more flexible transitions and faster sampling while preserving \nsample quality.  \n3. Controlled Interpolation  \no DDIM allows int erpolation between different noise levels and samples, which \ncan be used for creative applications like style mixing or smooth transitions.  \n \n\n--- Page 17 ---\n✅ Key Differences from DDPM  \nFeature  DDPM  DDIM  \nSampling process  Stochastic, follows Markov chain with \nrandom transitions  Deterministic or pseudo -deterministic, \nwith fewer steps  \nComputational \ncost High due to many sampling steps  Much lower with accelerated sampling  \nDiversity  Can explore a wide range of outputs due \nto randomness  Maintains diversity but with controlled \nnoise patterns  \nUse case  Suitable for tasks needing rich \nexploration  Better for fast generation and interactive \napplications  \n \n✅ Mathematical Insight  \nIn DDPM, the reverse process is modeled as a",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 44,
      "content": "se patterns  \nUse case  Suitable for tasks needing rich \nexploration  Better for fast generation and interactive \napplications  \n \n✅ Mathematical Insight  \nIn DDPM, the reverse process is modeled as a probabilistic sampling from  p(xt−1∣xt), where \nrandomness is inherent at each step.  \nIn DDIM, a deterministic transition is defi ned: \n \nHere:  \n• αt defines how much signal is preserved at each step.  \n• ϵθ(xt,t) is the model’s learned noise prediction.  \nThis formulation allows skipping intermediate steps while still approximating the \nreverse trajectory.  \n \n✅ Applications of DDIM  \n1. Image Generation  \no Produces high -resolution images quickly without compromising on details.  \n2. Video and Audio Synthesis  \no Enables faster generation for time -sensitive applications like animation or \nsound design.  \n3. Style Transfer & Interpolation  \no Smoothly blends between samples by manipulating latent noise patterns \ndeterministically.  \n4.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 45,
      "content": "for time -sensitive applications like animation or \nsound design.  \n3. Style Transfer & Interpolation  \no Smoothly blends between samples by manipulating latent noise patterns \ndeterministically.  \n4. Interactive Tools  \no Supports real -time editing and creative workflows where speed and control are \ncritical.  \n\n\n--- Page 18 ---\n \n✅ Advantages of DDIM  \n✔ Faster sampling with fewer step s \n✔ Stable and high -quality output s \n✔ Supports interpolation and controlled gene ration \n✔ Reduces computational cost without major trade -offs in realism  \n \n✅ Limitations of DDIM  \n❗ May lose some diversity due to reduced randomnes s \n❗ Requires careful tuning of schedules and noise level s \n❗ Still dependent on well -trained models to perform effectively  \n \n✅ Conclusion  \nDDIM is a powerful extension of diffusion models that addresses one of their biggest \nlimitations —slow sampling —by introducing deterministic or semi -deterministic  transitions.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpex89ia9c.pdf_b9876e2d_1a573e61",
      "chunk_index": 46,
      "content": "y  \n \n✅ Conclusion  \nDDIM is a powerful extension of diffusion models that addresses one of their biggest \nlimitations —slow sampling —by introducing deterministic or semi -deterministic  transitions. \nIt enables faster generation while maintaining sample fidelity and diversity, making it highly \nsuitable for real -world applications like image synthesis, animation, and interactive creative \ntools.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nDIFFUSION MODELS  \nDiffusion models are a type of generative AI that create new data like images, audio or even \nvideo by starting with random noise and gradually turning it into something meaningful. They \nwork by simulating a diffusion process where data is  slowly corrupted by noise during \ntraining and then learning to reverse this process step by step. By doing so the model learns \nhow to generate high quality samples from scratch.  \nUnderstanding  Diffusion  Models  \n \n \n• Diffusion  models  are generative  models  that learn  to reverse  a diffusion  process  to \ngenerate  data.  The diffusion  process  involves  gradually  adding  noise  to data until it \nbecomes  pure noise.  \n• Through  this process  a simple  distribution  is transformed  into a complex  data distribution  \nin a series  of small incremental  steps.  \n• Essentially  these  models  operate  as a reverse  diffusion  phenomenon  where  noise  is \nintroduced  to the data in a forward  manner  and r",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 1,
      "content": "ribution  \nin a series  of small incremental  steps.  \n• Essentially  these  models  operate  as a reverse  diffusion  phenomenon  where  noise  is \nintroduced  to the data in a forward  manner  and removed  in a reverse  manner  to generate  \nnew data samples.  \n• By learning  to reverse  this process  diffusion  models  start from  noise  and gradually  \ndenoise  it to produce  data that closely  resembles  the training  examples.  \n \nKey Components  \n1. Forward  Diffusion  Process : This process  involves  adding  noise  to the data in a series  of \nsmall  steps.  Each  step slightly  increases  the noise,  making  the data progressively  more  \nrandom  until  it resembles  pure noise.  \n2. Reverse  Diffusion  Process : The model  learns  to reverse  the noise -adding  steps.  Starting  \nfrom  pure noise,  the model  iteratively  removes  the noise,  generating  data that matches  \nthe training  distribution.  \n3.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 2,
      "content": ": The model  learns  to reverse  the noise -adding  steps.  Starting  \nfrom  pure noise,  the model  iteratively  removes  the noise,  generating  data that matches  \nthe training  distribution.  \n3. Score  Function : This function  estimates  the gradient  of the data distribution  concerning  \nthe noise.  It helps  guide  the reverse  diffusion  process  to produce  realistic  samples.  \n \n \n \n \n \n\n\n--- Page 2 ---\nArchitecture  of Diffusion  Models  \nThe architecture  of diffusion  models  typically  involves  two main  components:  \n1. Forward  Diffusion  Process  \n2. Reverse  Diffusion  Process  \n1. Forward  Diffusion  Process  \nIn this process  noise  is incrementally  added  to the data over a series  of steps.  This is akin to \na Markov  chain  where  each step slightly  degrades  the data by adding  Gaussian  noise.  \n \nForward Diffusion P  \nMathematically,  this can be represented  as: \n \nwhere,  \n• xt is the noisy  data at step t \n• αt controls  the amount  of noise  added.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 3,
      "content": "the data by adding  Gaussian  noise.  \n \nForward Diffusion P  \nMathematically,  this can be represented  as: \n \nwhere,  \n• xt is the noisy  data at step t \n• αt controls  the amount  of noise  added.  \n \n2. Reverse  Diffusion  Process  \nThe reverse  process  aims  to reconstruct  the original  data by denoising  the noisy  data in a \nseries  of steps  reversing  the forward  diffusion.  \n \nReverse Diffusion Process  \nThis is typically  modelled  using  a neural  network  that predicts  the noise  added  at each step:  \n \nwhere,  \n• μθ and σθ are learned  parameters.  \n \nWorking  Principle  of Diffusion  Models  \nDuring  training  the model  learns  to predict  the noise  added  at each step of the forward  \nprocess.  This is done  by minimizing  a loss function  that measures  the difference  between  the \npredicted  and actual  noise.  \n \nForward  Process  (Diffusion)  \n• The forward  process  involves  gradually  corrupting  the data x0 with Gaussian  noise  over \na sequence  of tim",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 4,
      "content": "nce  between  the \npredicted  and actual  noise.  \n \nForward  Process  (Diffusion)  \n• The forward  process  involves  gradually  corrupting  the data x0 with Gaussian  noise  over \na sequence  of time steps  \n• Let xt represent  the noisy  data at time step t. The process  is defined  as: \n \n• where  βt is the noise  schedule  that controls  the amount  of noise  added  at each step and ϵ is \nis Gaussian  noise.  \n\n\n--- Page 3 ---\n• As t increases,  xt becomes  more  noisy  until  it approximates  a Gaussian  distribution.  \n \nReverse  Process  (Denoising)  \n• The reverse  process  aims  to reconstruct  the original  data x0x0 from  the noisy  data xT at \nthe final  time step T. \n• This process  is modelled  using  a neural  network  to approximate  the conditional  \nprobability  pθ(xt−1∣xt). \n• The reverse  process  can be formulated  as: \n \n• where  ϵθ is a neural  network  parameterized  by θ that predicts  the noise.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 5,
      "content": "network  to approximate  the conditional  \nprobability  pθ(xt−1∣xt). \n• The reverse  process  can be formulated  as: \n \n• where  ϵθ is a neural  network  parameterized  by θ that predicts  the noise.  \n \nTraining  Diffusion  Models  \n• The training  objective  for diffusion  models  involves  minimizing  the difference  between  \nthe true noise  ϵ added  in the forward  process  and the noise  predicted  by the neural  \nnetwork  ϵθ. \n• The score  function  which  estimates  the gradient  of the data distribution  concerning  the \nnoise  plays  an important  role in guiding  the reverse  process.  \n• The loss function  is typically  the mean  squared  error  (MSE)  between  these  two quantities:  \n \n• This encourages  the model  to accurately  predict  the noise  and, consequently,  to denoise  \neffectively  during  the reverse  process.  \n \nIn diffusion models, both the forward and backward processes are modeled  as a sequence of \nsmall incremental steps rather than a single transfor",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 6,
      "content": "noise  \neffectively  during  the reverse  process.  \n \nIn diffusion models, both the forward and backward processes are modeled  as a sequence of \nsmall incremental steps rather than a single transformation. This sequential approach is \ncrucial because:  \n1. Gradual Learning  – By breaking the process into many steps, the model learns how \nto handle slight changes at each stage, making it e asier to reverse the noise addition. If \nit tried to denoise from a fully noisy image in one step, it would struggle to map the \nrandom noise back to structured data.  \n2. Stability in Training  – Learning through small denoising steps prevents abrupt \ntransitions,  reducing the chances of errors or divergence during training. It ensures \nthat the model refines its predictions slowly, stabilizing gradients and allowing \nconsistent improvements.  \n3. Better Control Over Generation  – The step -wise nature allows the model to b e \nsampled at different stages, offering control over how much noise to re",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 7,
      "content": "nts and allowing \nconsistent improvements.  \n3. Better Control Over Generation  – The step -wise nature allows the model to b e \nsampled at different stages, offering control over how much noise to remove or retain. \nThis is especially useful in VR environments, where designers might want to balance \nrealism with creativity.  \n4. Avoiding Catastrophic Forgetting  – Incremental denoising r einforces the learning at \nevery step, ensuring that earlier patterns are not forgotten as the model progresses \ntoward generating complex outputs.  \n\n\n--- Page 4 ---\nThus, modeling the forward and backward processes as a sequence of steps ensures that \nlearning is smooth, robu st, and interpretable, ultimately allowing the system to produce high -\nquality, stable, and realistic images from rough sketches.  \nNoise plays a central role in the diffusion process, and carefully adjusting it can significantly \ninfluence the outcomes:  \n1.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 8,
      "content": "duce high -\nquality, stable, and realistic images from rough sketches.  \nNoise plays a central role in the diffusion process, and carefully adjusting it can significantly \ninfluence the outcomes:  \n1. Higher Noise Levels  \no Encourages diverse outputs  because the model explores a wider range of \npossibilities when starting from more random data.  \no Useful for generating creative or artistic VR landscapes where uniqueness is \ndesired.  \no However, if the noise is too  high, the generated images may lose structure or \ncoherence, reducing realism.  \n2. Lower Noise Levels  \no Helps maintain realism and fidelity  because the model starts closer to \nstructured patterns, making it easier to produce clear and consistent images.  \no Best suit ed for VR environments where accuracy, recognizable objects, and \nrealistic textures are essential.  \no It may, however, limit creativity and diversity since the outputs are \nconstrained to follow the training data closely.  \n3.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 9,
      "content": "accuracy, recognizable objects, and \nrealistic textures are essential.  \no It may, however, limit creativity and diversity since the outputs are \nconstrained to follow the training data closely.  \n3. Noise Scheduling  \no Adjusting how noise is added or removed across steps (e.g., linear, \nexponential, cosine schedules) allows fine -tuning between exploration and \nrefinement.  \no Designers can control whether the model produces subtle variations or \nradically different landscapes.  \n4. Application in VR Sy stems  \no For immersive experiences, higher noise levels at early steps can generate \nunpredictable and novel environments, while later steps can be fine -tuned with \nlower noise to ensure realistic details.  \no This balance allows users to start with abstract sketch es and transform them \ninto believable virtual worlds that retain creativity without sacrificing \ncoherence.  \n \n \n \n \n \n \n \n \n \n\n--- Page 5 ---\nDENOISING DIFFUSION PROBABILISTIC MODEL (DDPM)  \nWhat are DDPMs?  \nThey are",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 10,
      "content": "m \ninto believable virtual worlds that retain creativity without sacrificing \ncoherence.  \n \n \n \n \n \n \n \n \n \n\n--- Page 5 ---\nDENOISING DIFFUSION PROBABILISTIC MODEL (DDPM)  \nWhat are DDPMs?  \nThey are a class of  generative models  that work by iteratively  adding noise  to an input signal \n(like an image, text, or audio)  and then learning to denoise  from the noisy signal  to generate \nnew samples .  \n \nGenerative models  \nAre a type of model that can generate new data instances.  Previously, machine learning models \nhave done a good job of learning differences in data and then making predictions or \nclassification tasks. For example, a model trained on a digits dataset like  MNIST  can recognize \na 0 from a  1. Generative models, on the other hand, learn the distribution of digits and can create \na “fake digit” which closely resembles a real digit.  \n \nA Denoising Diffusion Probabilistic Model (DDPM)  is a type of gener ative model that \ncreates realistic images by learning how to p",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 11,
      "content": "an create \na “fake digit” which closely resembles a real digit.  \n \nA Denoising Diffusion Probabilistic Model (DDPM)  is a type of gener ative model that \ncreates realistic images by learning how to progressively refine noisy data. It works in two \nphases:  \n1. Forward Process (Noise Addition)  – The model gradually adds random noise to a \nclean image over many steps until the image becomes indistinguishable from noise.  \n2. Backward Process (Denoising)  – The model learns to reverse this process by \npredicting how to remove noise at each step, eventual ly reconstructing a high -quality \nimage from random noise or a rough input.  \nThe model is called probabilistic  because it doesn’t rely on a single deterministic \ntransformation but instead learns the distribution of possible images at each stage of noise \nand denoising. This approach allows it to generate diverse, high -fidelity images by sampling \nfrom the learned distribution.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 12,
      "content": "instead learns the distribution of possible images at each stage of noise \nand denoising. This approach allows it to generate diverse, high -fidelity images by sampling \nfrom the learned distribution.  \n\n\n--- Page 6 ---\nKey Features of DDPM:  \n• Iterative Refinement  – Instead of transforming an image in one step, it uses many \nsmall steps, making it easier to  model complex patterns.  \n• Noise -Based Learning  – By learning how images degrade with noise, the model \nunderstands how to reverse this degradation to recreate details.  \n• Probabilistic Nature  – It generates a range of plausible outputs rather than a single \nfixed result, which is useful in creative tasks like animation.  \n• Flexibility  – DDPMs can be applied to various tasks such as image synthesis, super -\nresolution, and in your case, converting ro ugh sketches into fully rendered scenes.  \nForward and Backward Diffusion Process  \nThe forward diffusion process  is the initial phase in a DDPM where noise is incrementally",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 13,
      "content": "your case, converting ro ugh sketches into fully rendered scenes.  \nForward and Backward Diffusion Process  \nThe forward diffusion process  is the initial phase in a DDPM where noise is incrementally \nadded to clean data over many steps. The purpose is to teach the model how data transitions \nfrom structured and detailed forms into randomness.  \nKey steps involved:  \n1. Starting with clean data  – At the beginning, the model takes real data such as an \nimage or signal that contains structured information like shapes, textures, and \npatterns.  \n2. Adding noise at each step  – Gaussian noise is added to the data in small amounts \nover a sequence of steps. The nois e schedule (linear, cosine, etc.) controls how much \nnoise is added at each step.  \n3. Progressive degradation  – The data becomes increasingly noisy at every step. \nInitially, the patterns are still recognizable, but as the process continues, the structure \ndisapp ears, and the data looks like random noise.  \n4.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 14,
      "content": "The data becomes increasingly noisy at every step. \nInitially, the patterns are still recognizable, but as the process continues, the structure \ndisapp ears, and the data looks like random noise.  \n4. Mathematical formulation  – At step t, the noisy data xt is derived from the previous \nstep xt−1 by sampling from a normal distribution:  \n \nwhere αt controls the amount of retained information and ϵ is sampled fr om a normal \ndistribution.  \nWhy this step is essential:  \n• It exposes the model to how real data deteriorates with noise.  \n• It creates a learning path for the model to understand the inverse operation —\nrecovering the data from noisy versions.  \n• It ensures that the m odel can generalize to varying noise levels and recover details \nfrom incomplete or corrupted data.  \n\n\n--- Page 7 ---\nRole of the Markov Chain in the Forward Diffusion Process of a DDPM  \nIn a Denoising Diffusion Probabilistic Model (DDPM) , the forward diffusion process  \ninvolves gradually adding noise to c",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 15,
      "content": "e 7 ---\nRole of the Markov Chain in the Forward Diffusion Process of a DDPM  \nIn a Denoising Diffusion Probabilistic Model (DDPM) , the forward diffusion process  \ninvolves gradually adding noise to clean data over multiple steps. This process is modeled as \na Markov chain , which plays a crucial role in structuring how noise is added.  \nA Markov chain  is a mathematical system that transitions from one state to another,  where \nthe next state depends only on the current state and not on the entire history of past states. In \nthe context of DDPM’s forward diffusion process, this means:  \n1. Stepwise progression  \no At each time step ttt, noise is added based only on the data at that step \n(xt−1x_{t -1}xt−1), not on earlier steps. This simplifies the process and \nensures that each step depends only on the immediately preceding one.  \n2. Controlled noise addition  \no The amount of noise added at each step is determined by a known noise \nschedule, ensuring that the transition from structu",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 16,
      "content": "nds only on the immediately preceding one.  \n2. Controlled noise addition  \no The amount of noise added at each step is determined by a known noise \nschedule, ensuring that the transition from structured data to noise is smooth \nand gradual.  \n3. Mathematical tractability  \no By assuming that each step depends only on the previous step, the forward \nprocess becomes easier to analyze, simulate, and invert during training.  \n How does it help structure the noise addition steps?  \n1. Simplifies modeling  \no The Markov assumption allows the model to focus on learning local \ntransitions rather than global dependencies, making the noise addition process \ncomputationally feasible.  \n2. Ensures grad ual degradation  \no The structured, stepwise approach ensures that noise is added progressively, \npreserving information early on and fully randomizing the data at later steps.  \n3. Supports efficient training  \no The Markov property allows the use of recursive formulat ions where each \nnoisy sampl",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 17,
      "content": "reserving information early on and fully randomizing the data at later steps.  \n3. Supports efficient training  \no The Markov property allows the use of recursive formulat ions where each \nnoisy sample can be derived from the previous one using simple equations, \nfacilitating optimization and gradient computation.  \n4. Enables inversion during sampling  \no Since each step only depends on the previous one, the backward process \n(denoisin g) can also be structured in the same stepwise manner, allowing the \nmodel to learn how to reverse the process reliably.  \nThe backward diffusion process  is where the model learns to reverse the noise addition and \nreconstruct the original or new data from noisy inputs.  \nKey aspects:  \n1. Predicting the noise  – At each step, the model is trained to estimate the noise that \nwas added in the forward process. It lear ns how the noisy data differs from its clean \nversion and tries to correct it.  \n\n--- Page 8 ---\n2.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 18,
      "content": "ach step, the model is trained to estimate the noise that \nwas added in the forward process. It lear ns how the noisy data differs from its clean \nversion and tries to correct it.  \n\n--- Page 8 ---\n2. Iterative refinement  – Starting from pure noise, the model removes noise \nprogressively by applying its learned knowledge of patterns at each step. Over time, \nthe image or data be comes clearer and more structured.  \n3. Learning objective  – The model is optimized to minimize the difference between the \npredicted noise and the actual noise added during training. This is typically done \nusing a loss function like Mean Squared Error (MSE).  \n4. Sampling during generation  – Once trained, the model can start from random noise \nand iteratively apply the backward process to generate new, realistic data samples.  \nWhy this process is critical:  \n• It allows the model to reconstruct missing or noisy details.  \n• It ensures that the output is consistent with real -world data distributions.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 19,
      "content": "alistic data samples.  \nWhy this process is critical:  \n• It allows the model to reconstruct missing or noisy details.  \n• It ensures that the output is consistent with real -world data distributions.  \n• It provides control over the generation process by using learned probabilities rather \nthan rigid rules.  \nThe probabilistic nature of DDPM plays a central role in its ability to generate both diverse \nand high -quality outputs.  \nWhy probabilistic modeling is useful ? \n1. Learning distributions rather than fixed mappings  \no Instead of learning a direct transformation from input to output, the model \nlearns the underlying distribution of possib le clean data conditioned on noisy \ninputs.  \no This enables the model to handle uncertainty and variations present in real \ndata.  \n2. Sampling from distributions  \no During generation, the model samples noise from a distribution at each step. \nEven with the same input, different random samples produce varied outputs, \npromoting creativity an",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 20,
      "content": "from distributions  \no During generation, the model samples noise from a distribution at each step. \nEven with the same input, different random samples produce varied outputs, \npromoting creativity and diversity.  \n3. Capturing subtle patterns  \no Probabilistic modeling allows the model to learn nuanced relationships in the \ndata such as textures, lighting patterns, or variations in shape th at are hard to \ncapture with deterministic methods.  \n \n4. Balancing realism and exploration  \no By controlling the noise level and how it’s modeled, the system can explore \nnew possibilities while staying within the realm of realistic outputs. This is \ncrucial for app lications like design, simulation, and data augmentation.  \nChallenges:  \n1. High computational cost  \no Because the process involves many steps (often hundreds or thousands), \ngenerating data can be slow and resource -intensive.  \n2. Latency issues in real -time application s \n\n--- Page 9 ---\no The iterative nature makes it difficul",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 21,
      "content": "any steps (often hundreds or thousands), \ngenerating data can be slow and resource -intensive.  \n2. Latency issues in real -time application s \n\n--- Page 9 ---\no The iterative nature makes it difficult to apply DDPMs in interactive or real -\ntime environments where fast feedback is essential.  \n3. Difficulty in controlling outputs  \no Without proper conditioning or guidance, the model might produce outputs \nthat are inconsis tent with user expectations or desired styles.  \n4. Data requirements  \no Training DDPMs effectively requires large and diverse datasets to accurately \nlearn noise patterns and recover fine details.  \n \nENERGY -BASED MODELS(EBMs)  \nEnergy -Based Models (EBMs)  are a class of probabilistic models that define relationships \nbetween variables using an energy function. Rather than explicitly modeling probability \ndistributions, EBMs assign an “energy” value to each possible configuration of variables, \nwhere lower energy indicates more likely or desirable configuration",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 22,
      "content": "her than explicitly modeling probability \ndistributions, EBMs assign an “energy” value to each possible configuration of variables, \nwhere lower energy indicates more likely or desirable configurations, and higher energy \ncorresponds to less likely ones.  \nEBMs are widely used in machine learning for t asks such as representation learning, \nstructured prediction, anomaly detection, and reinforcement learning, where capturing \nrelationships and constraints between variables is more important than explicitly computing \nprobabilities.  \n \n2. The Concept of Energy in EBMs  \n• An energy function  E(x)maps an input  x to a scalar energy value.  \n• The lower the energy, the more plausible or preferred the data point is according to \nthe model.  \n• The probability distribution  p(x)is related to the energy via the Boltzmann \ndistribution:  \n \nwhere  Z is the partition function:  \n \n• The partition function  Z is often intractable, making it difficult to directly compute \nprobabilities, but not",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 23,
      "content": "he energy via the Boltzmann \ndistribution:  \n \nwhere  Z is the partition function:  \n \n• The partition function  Z is often intractable, making it difficult to directly compute \nprobabilities, but not necessary for learning.  \n \n\n\n--- Page 10 ---\n3. Architecture and Working  \nCore Components:  \n1. Energy Function  \no The energy function is typically parameterized by neural networks or other \ndifferentiable models.  \no It scores different data configurations to indicate how well they conform to the \ndesired patterns.  \n2. Learning Objective  \no EBMs learn by comparing the energies of positive (correct) and negative \n(incorrect or unlikely) samples.  \no The goal is to assign lower energy to real data and higher energy to unlikely \ndata.  \n3. Training Approaches  \no Contrastive Divergence (CD)  – Optimizes the model by comparing energy \ndifferences betwe en observed and model -generated samples.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 24,
      "content": "ta and higher energy to unlikely \ndata.  \n3. Training Approaches  \no Contrastive Divergence (CD)  – Optimizes the model by comparing energy \ndifferences betwe en observed and model -generated samples.  \no Score Matching  – Matches the gradient of the energy function rather than the \nenergy itself.  \no Noise Contrastive Estimation (NCE)  – Uses noise samples to help \napproximate the partition function during learning.  \n \n4. Markov Random Fields (MRFs) and Conditional EBMs  \n• EBMs are closely related to Markov Random Fields (MRFs), which model \ndependencies between variables using graph structures.  \n• Conditional EBMs  extend the energy framework to ta sks where the output depends \non input features (e.g., image classification, structured output prediction).  \n \n5. Applications of EBMs  \n1. Unsupervised Learning  \no Modeling complex relationships in high -dimensional data such as im ages, \nspeech, or text.  \n2.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 25,
      "content": "assification, structured output prediction).  \n \n5. Applications of EBMs  \n1. Unsupervised Learning  \no Modeling complex relationships in high -dimensional data such as im ages, \nspeech, or text.  \n2. Anomaly Detection  \no Identifying outliers by assigning higher energy to rare or unlikely \nconfigurations.  \n3. Reinforcement Learning (RL)  \no Estimating value functions where actions with lower energy correspond to \nmore rewarding behaviors.  \n4. Generative Modeling  \no Generating samples by searching for configurations with low energy, often \nusing sampling algorithms like Langevin dynamics.  \n5. Structured Prediction  \no Solving problems like image segmentation or sequence labeling where \nrelationships between output variables are important.  \n\n--- Page 11 ---\n \n6. Advantages of EBMs  \n• Flexibility  – Can model arbitrary dependencies without requiring explicit probability \ndistributions.  \n• Interpretability  – The energy function directly encodes preferenc es or constraints.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 26,
      "content": "BMs  \n• Flexibility  – Can model arbitrary dependencies without requiring explicit probability \ndistributions.  \n• Interpretability  – The energy function directly encodes preferenc es or constraints.  \n• Applicability  – Useful in domains where structured relationships and constraints \ndominate over simple classification.  \n \n7. Challenges and Limitations  \n1. Intractable Partition Function  \no Computing  ZZZ is ofte n impossible in practice, requiring approximation \ntechniques that can be unstable.  \n2. Training Instability  \no Optimization methods like contrastive divergence rely on sampling, which can \nlead to slow convergence or poor performance.  \n3. Sampling Complexity  \no Generatin g samples requires iterative methods such as Markov Chain Monte \nCarlo (MCMC), which can be computationally expensive.  \n4. Scalability Issues  \no Handling high -dimensional data with complex energy landscapes is \nchallenging.  \n \n8.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 27,
      "content": "ods such as Markov Chain Monte \nCarlo (MCMC), which can be computationally expensive.  \n4. Scalability Issues  \no Handling high -dimensional data with complex energy landscapes is \nchallenging.  \n \n8. Recent Advances  \n• Neural EBMs  – Combining deep learning with energy functions to model high -\ndimensional and structured data more effectively.  \n• Score -based Generative Models  – Learning the gradi ent of the energy function to \navoid directly computing the partition function.  \n• Applications in Contrastive Learning  – EBMs form the backbone of contrastive \napproaches where relationships between samples are emphasized.  \n \n \n \n \n \n \n \n \n\n--- Page 12 ---\nCOMPARE EBMS VS VAES  \nAspect  Energy -Based Models (EBMs)  Variational Autoencoders (VAEs)  \n✅ Architecture  - Defined by an energy function \nthat assigns a scalar “energy” to \neach configuration of inputs (and \noptionally outputs).  \n- No explicit probability \ndistribution; the model learns to \nassign lower energy to desired \nsamp",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 28,
      "content": "unction \nthat assigns a scalar “energy” to \neach configuration of inputs (and \noptionally outputs).  \n- No explicit probability \ndistribution; the model learns to \nassign lower energy to desired \nsamples  and higher energy to \nundesired ones.  \n- Often optimized using contrastive \ndivergence or score matching.  \n- The architecture focuses on \nrelationships between data points \nrather than reconstructing or \ngenerating them directly.  - Composed of two main parts: an \nencoder and a decoder.  \n- The encoder maps input data to a \nlatent space distribution (typically \nGaussian).  \n- The decoder reconstructs data \nfrom samples drawn from the latent \nspace.  \n- Uses variational inference to \napproximate intractable posteriors.  \n- The architecture explicitly models \ndata generation.  \n✅ Objective  - Learn an energy landscape where \ncorrect data points are assigned \nlower energy.  \n- Optimization is based on \ndistinguishing good samples from \nbad ones.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 29,
      "content": "tly models \ndata generation.  \n✅ Objective  - Learn an energy landscape where \ncorrect data points are assigned \nlower energy.  \n- Optimization is based on \ndistinguishing good samples from \nbad ones.  - Maximize the Evidence Lower \nBound (ELBO) which balances \nreconstruction accuracy and \nregularization of the latent space.  \n- Encourages latent space structure \nfor efficient sampling and \ninterpolation.  \n✅ Probabilistic \nInterpretation  - Indirect; energy defi nes the \nlikelihood up to a normalization \nconstant (partition function), which \nis often intractable.  \n- Focuses on learning relationships \nand constraints rather than full \ndensity estimation.  - Explicit probabilistic framework \nwith tractable priors and \nappro ximate posteriors.  \n- Can directly sample from the latent \nspace and model uncertainty.  \n✅ Training \nMethods  - Uses sampling -based methods \nlike Markov Chain Monte Carlo \n(MCMC), contrastive divergence, \nor score matching.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 30,
      "content": "directly sample from the latent \nspace and model uncertainty.  \n✅ Training \nMethods  - Uses sampling -based methods \nlike Markov Chain Monte Carlo \n(MCMC), contrastive divergence, \nor score matching.  \n- Training can be unstable due to \nreliance on sampling and gradient \nestimation.  - Uses backpropagation with \nreparameterization trick for efficient \ngradient estimation.  \n- More stable and easier to train \nwith large datasets.  \n✅ Applications  - Modeling complex dependencies \nin structured data.  \n- Used in tasks like anomaly \ndetection, reinforcement learning, \nand unsupervised learning.  \n- Applicable where relationships \nand constraints are more important \nthan explicit reconstruction.  - Image and speech generation, data \ncompression, anomaly detection , \nand semi -supervised learning.  \n- Used where interpretable latent \nrepresentations and smooth \ngeneration paths are required.  \n\n--- Page 13 ---\nAspect  Energy -Based Models (EBMs)  Variational Autoencoders (VAEs)  \n✅ Strengt",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 31,
      "content": "ing.  \n- Used where interpretable latent \nrepresentations and smooth \ngeneration paths are required.  \n\n--- Page 13 ---\nAspect  Energy -Based Models (EBMs)  Variational Autoencoders (VAEs)  \n✅ Strengths  - Flexibility in modeling \nrelationships without requiring \nexplicit likelihood functions.  \n- Can incorporate constraint s and \ndomain knowledge easily.  - Well -suited for generating new \ndata samples.  \n- Provides interpretable latent spaces \nuseful for downstream tasks.  \n✅ Limitations  - Training is computationally \nexpensive and less scalable. - \nNormalization constant estimation  \nis intractable in many cases.  - May suffer from blurry \nreconstructions or mode collapse.  \n- Latent space structure depends \nheavily on choice of priors and \narchitectures.  \n \nINTRODUCTION TO NOISE SCHEDULERS IN DIFFUSION MODELS  \nIn diffusion models, noise plays a central role in transforming structured data into random noise \nduring training and then reconstructing it during sampling.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 32,
      "content": "TO NOISE SCHEDULERS IN DIFFUSION MODELS  \nIn diffusion models, noise plays a central role in transforming structured data into random noise \nduring training and then reconstructing it during sampling. However, how much noise is added \nor removed at each step is not arbitrary —it must be carefully controlled to ensure that the model \nlearns meaningful patterns and can effectively generate high -quality data.  \nThis is where noise schedulers  come into play.  \nA noise scheduler  defines the schedule or strategy by which noise is added to data in the \nforward diffusion process and removed in the backward process. It determines the magnitude \nof noise at each step, shaping how the model degrades and refines information over time.  \nThe design of the noise schedule affects several critical aspects:  \n• Learning efficiency  – Too much noise can obscur e important details, while too little \nmay prevent the model from learning to handle uncertainty.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 33,
      "content": "noise schedule affects several critical aspects:  \n• Learning efficiency  – Too much noise can obscur e important details, while too little \nmay prevent the model from learning to handle uncertainty.  \n• Sample diversity and quality  – The progression of noise influences how creative or \nrealistic the generated outputs are.  \n• Training stability  – Gradual noise addi tion helps avoid erratic learning and ensures \nthat the model can generalize from noisy inputs.  \nCommon schedules include linear, cosine, and exponential noise schedules , each offering \ndifferent trade -offs between smoothness, speed, and complexity.  \nSignifica nce of Noise Schedulers in Diffusion Models  \nIn diffusion models, noise schedulers  determine how noise is added (in the forward process) \nor removed (in the backward process) at each step. They play a critical role in controlling the \nquality, stability, and efficiency of the model during both training and sampling.  \nWhy are noise schedulers important?  \n1.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 34,
      "content": "kward process) at each step. They play a critical role in controlling the \nquality, stability, and efficiency of the model during both training and sampling.  \nWhy are noise schedulers important?  \n1. Control over noise injection  \no A noise scheduler defines how much noise is added at each step, influencing \nhow quickly the data degrades from its original form to pure noise.  \n\n--- Page 14 ---\no A carefully designed schedule ensures that the model learns meaningful \ntransformations at each step rather than abrupt or overly noisy transitions.  \n2. Balance between learning and randomness  \no If noise is added too aggressively, the model may strugg le to learn how to \nrecover the data because too much information is lost early.  \no If noise is too weak, the model may not generalize well and could overfit to \nspecific patterns without learning how to handle uncertainty.  \n3. Smooth transitions  \no Gradual noise addi tion allows the model to capture complex patterns and fine \ndetails at di",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 35,
      "content": "could overfit to \nspecific patterns without learning how to handle uncertainty.  \n3. Smooth transitions  \no Gradual noise addi tion allows the model to capture complex patterns and fine \ndetails at different noise levels, helping the backward process refine the data \neffectively.  \n4. Influences sample quality and diversity  \no The noise schedule affects the kinds of outputs the model generates. For \ninstance, a slower noise increase might produce high -fidelity samples, while a \nfaster schedule might encourage more diverse and creative outputs.  \n5. Stabilizes training  \no Appropriate noise scheduling prevents extreme gradients or erratic learning  \nbehavior, enabling stable and efficient training across large datasets.  \n✅ Example of a commonly used noise scheduler: Linear noise schedule  \nOne widely used noise scheduler is the linear noise schedule , where the noise level increases \nat a constant rate ac ross steps.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 36,
      "content": "✅ Example of a commonly used noise scheduler: Linear noise schedule  \nOne widely used noise scheduler is the linear noise schedule , where the noise level increases \nat a constant rate ac ross steps.  \n• The noise added at each step t is computed as:  \n \nwhere:  \no βstart is the initial noise amount,  \no βend is the final noise amount,  \no T is the total number of steps.  \n \nWhy it's used:  \n• Simplicity – easy to implement and analyze.  \n• Gradual degradation – ensures smooth transitions from structured data to noise.  \n• Works well in practice for a variety of tasks without requiring complex tuning.  \n✅ Other common noise schedules  \n• Cosine schedule  – Uses a cosine curve to control noise increments, adding noise \nmore sm oothly at the beginning and end.  \n\n\n--- Page 15 ---\n• Exponential schedule  – Adds noise in a way that accelerates or decelerates across \nsteps, providing more control over learning phases.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 37,
      "content": "more sm oothly at the beginning and end.  \n\n\n--- Page 15 ---\n• Exponential schedule  – Adds noise in a way that accelerates or decelerates across \nsteps, providing more control over learning phases.  \nComparison between Class -Conditional Diffusion Models and Unconditional Diffusion \nModels  \nAspect  Class -Conditional Diffusion Models  Unconditional Diffusion Models  \n✅ Definition  Diffusion models where the generation \nprocess is guided by class labels or \nadditional conditioning information (e.g., \ntext, attributes). The model learns how the \ndata distribution changes for different \nclasses.  Diffusion models that generate data \npurely based on learned distributions \nwithout any conditioning information. \nThe model only depends on noise and \nthe learned data distribution.  \n✅ \nArchitecture  - Incorporates class labels or auxiliary \ninputs into the noise prediction network.  \n- Conditioning is usually done by \nconcatenating labels or through \nembeddings that influence intermediate",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 38,
      "content": "cture  - Incorporates class labels or auxiliary \ninputs into the noise prediction network.  \n- Conditioning is usually done by \nconcatenating labels or through \nembeddings that influence intermediate \nlayers.  \n- The model learns separate modes of the \ndata distribution for each class o r \ncondition.  - Contains only the noise prediction \nnetwork without any external inputs.  \n- Learns the general structure and \ndistribution of the entire dataset.  \n- Generates samples based on noise \nwithout class -specific guidance.  \n✅ Training \nObjective  - Learn how to denoise while respecting \nclass information.  \n- The model minimizes the reconstruction \nloss while conditioning on the class, \nensuring generated samples match the \ntarget category.  - Learn to denoise without any guidance \nother than the underlying data \ndistribution.  \n- The model focuses on general patterns \nand statistical relationships in the \ndataset.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 39,
      "content": "the \ntarget category.  - Learn to denoise without any guidance \nother than the underlying data \ndistribution.  \n- The model focuses on general patterns \nand statistical relationships in the \ndataset.  \n✅ Sampling  - During generation, class labels guide the \nsampling process, allowing control over \nwhat kind of sample is generated (e.g., a \ncat vs. a dog image ). \n- Can produce targeted, structured outputs.  - Generates samples from noise without \ncontrol over attributes or categories.  \n- Produces diverse outputs but without \nspecific guidance.  \n✅ \nApplications  - Image synthesis conditioned on class \nlabels (e.g., gene rating specific objects or \nfaces).  \n- Text-to-image generation, style transfer, \nor scenarios requiring targeted outputs.  \n- Semi -supervised learning where \nadditional information improves generation \nquality.  - General image, audio, or video \ngeneration where c ontrol is not \nnecessary.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 40,
      "content": "os requiring targeted outputs.  \n- Semi -supervised learning where \nadditional information improves generation \nquality.  - General image, audio, or video \ngeneration where c ontrol is not \nnecessary.  \n- Data augmentation, unsupervised \nlearning, and exploratory creative \ngeneration.  \n✅ \nAdvantages  - Greater control over generated samples.  \n- Can produce outputs tailored to specific \ntasks or user inputs.  \n- More interpretable generati on process.  - Simpler architecture and easier to \nimplement.  \n- Requires less labeled data.  \n\n--- Page 16 ---\nAspect  Class -Conditional Diffusion Models  Unconditional Diffusion Models  \n- Capable of learning diverse patterns \nfrom large, unstructured datasets.  \n✅ \nLimitations  - Requires labeled  data or conditioning \ninputs, which may not always be available.  \n- More complex architecture and higher \ncomputational cost.  - Lacks control over generated content.  \n- May produce irrelevant or ambiguous \noutputs when diverse patterns overlap.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 41,
      "content": "ays be available.  \n- More complex architecture and higher \ncomputational cost.  - Lacks control over generated content.  \n- May produce irrelevant or ambiguous \noutputs when diverse patterns overlap.  \n \nDDIM (DENOISING DIFFUSION IMPLICIT MODELS)  \nDDIM (Denoising Diffusion Implicit Models)  is an improvement over standard diffusion \nmodels like DDPM (Denoising Diffusion Probabilistic Models). It introduces a new sampling \nmethod that allows generating high -quality samples with significantly fewer steps, while still \nretaining diversity and structure in the outputs.  \n✅ Why DDIM was introduced  \n1. Reduce Sampling Time  \no Traditional diffusion models like DDPM require hundreds or thousands of \nsteps during sampling, which makes them computationally expensive and slow \nfor practical applications.  \n2. Maintain Quality and Diversity  \no Simply reducing steps in DDPM leads to degraded or  less diverse outputs.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 42,
      "content": "ling, which makes them computationally expensive and slow \nfor practical applications.  \n2. Maintain Quality and Diversity  \no Simply reducing steps in DDPM leads to degraded or  less diverse outputs.  \no DDIM proposes a deterministic or pseudo -deterministic approach that \nmaintains high sample fidelity even with fewer steps.  \n✅ How DDIM works  \n1. Implicit Sampling  \no Instead of following the stochastic rev erse process of DDPM, DDIM defines a \ndeterministic mapping between noise and data, reducing randomness during \nsampling.  \no The model avoids resampling at each step, making it faster and more stable.  \n2. Non-Markovian Transitions  \no Unlike DDPM where each step depend s only on the previous one (Markov \nproperty), DDIM relaxes this assumption by allowing steps that depend on \nearlier states.  \no This enables more flexible transitions and faster sampling while preserving \nsample quality.  \n3.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 43,
      "content": "(Markov \nproperty), DDIM relaxes this assumption by allowing steps that depend on \nearlier states.  \no This enables more flexible transitions and faster sampling while preserving \nsample quality.  \n3. Controlled Interpolation  \no DDIM allows int erpolation between different noise levels and samples, which \ncan be used for creative applications like style mixing or smooth transitions.  \n \n\n--- Page 17 ---\n✅ Key Differences from DDPM  \nFeature  DDPM  DDIM  \nSampling process  Stochastic, follows Markov chain with \nrandom transitions  Deterministic or pseudo -deterministic, \nwith fewer steps  \nComputational \ncost High due to many sampling steps  Much lower with accelerated sampling  \nDiversity  Can explore a wide range of outputs due \nto randomness  Maintains diversity but with controlled \nnoise patterns  \nUse case  Suitable for tasks needing rich \nexploration  Better for fast generation and interactive \napplications  \n \n✅ Mathematical Insight  \nIn DDPM, the reverse process is modeled as a",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 44,
      "content": "se patterns  \nUse case  Suitable for tasks needing rich \nexploration  Better for fast generation and interactive \napplications  \n \n✅ Mathematical Insight  \nIn DDPM, the reverse process is modeled as a probabilistic sampling from  p(xt−1∣xt), where \nrandomness is inherent at each step.  \nIn DDIM, a deterministic transition is defi ned: \n \nHere:  \n• αt defines how much signal is preserved at each step.  \n• ϵθ(xt,t) is the model’s learned noise prediction.  \nThis formulation allows skipping intermediate steps while still approximating the \nreverse trajectory.  \n \n✅ Applications of DDIM  \n1. Image Generation  \no Produces high -resolution images quickly without compromising on details.  \n2. Video and Audio Synthesis  \no Enables faster generation for time -sensitive applications like animation or \nsound design.  \n3. Style Transfer & Interpolation  \no Smoothly blends between samples by manipulating latent noise patterns \ndeterministically.  \n4.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 45,
      "content": "for time -sensitive applications like animation or \nsound design.  \n3. Style Transfer & Interpolation  \no Smoothly blends between samples by manipulating latent noise patterns \ndeterministically.  \n4. Interactive Tools  \no Supports real -time editing and creative workflows where speed and control are \ncritical.  \n\n\n--- Page 18 ---\n \n✅ Advantages of DDIM  \n✔ Faster sampling with fewer step s \n✔ Stable and high -quality output s \n✔ Supports interpolation and controlled gene ration \n✔ Reduces computational cost without major trade -offs in realism  \n \n✅ Limitations of DDIM  \n❗ May lose some diversity due to reduced randomnes s \n❗ Requires careful tuning of schedules and noise level s \n❗ Still dependent on well -trained models to perform effectively  \n \n✅ Conclusion  \nDDIM is a powerful extension of diffusion models that addresses one of their biggest \nlimitations —slow sampling —by introducing deterministic or semi -deterministic  transitions.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpf9r6pu7d_UNIT I - GCV NOTES.pdf_b9876e2d_ff594a99",
      "chunk_index": 46,
      "content": "y  \n \n✅ Conclusion  \nDDIM is a powerful extension of diffusion models that addresses one of their biggest \nlimitations —slow sampling —by introducing deterministic or semi -deterministic  transitions. \nIt enables faster generation while maintaining sample fidelity and diversity, making it highly \nsuitable for real -world applications like image synthesis, animation, and interactive creative \ntools.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nDIFFUSION MODELS  \nDiffusion models are a type of generative AI that create new data like images, audio or even \nvideo by starting with random noise and gradually turning it into something meaningful. They \nwork by simulating a diffusion process where data is  slowly corrupted by noise during \ntraining and then learning to reverse this process step by step. By doing so the model learns \nhow to generate high quality samples from scratch.  \nUnderstanding  Diffusion  Models  \n \n \n• Diffusion  models  are generative  models  that learn  to reverse  a diffusion  process  to \ngenerate  data.  The diffusion  process  involves  gradually  adding  noise  to data until it \nbecomes  pure noise.  \n• Through  this process  a simple  distribution  is transformed  into a complex  data distribution  \nin a series  of small incremental  steps.  \n• Essentially  these  models  operate  as a reverse  diffusion  phenomenon  where  noise  is \nintroduced  to the data in a forward  manner  and r",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 1,
      "content": "ribution  \nin a series  of small incremental  steps.  \n• Essentially  these  models  operate  as a reverse  diffusion  phenomenon  where  noise  is \nintroduced  to the data in a forward  manner  and removed  in a reverse  manner  to generate  \nnew data samples.  \n• By learning  to reverse  this process  diffusion  models  start from  noise  and gradually  \ndenoise  it to produce  data that closely  resembles  the training  examples.  \n \nKey Components  \n1. Forward  Diffusion  Process : This process  involves  adding  noise  to the data in a series  of \nsmall  steps.  Each  step slightly  increases  the noise,  making  the data progressively  more  \nrandom  until  it resembles  pure noise.  \n2. Reverse  Diffusion  Process : The model  learns  to reverse  the noise -adding  steps.  Starting  \nfrom  pure noise,  the model  iteratively  removes  the noise,  generating  data that matches  \nthe training  distribution.  \n3.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 2,
      "content": ": The model  learns  to reverse  the noise -adding  steps.  Starting  \nfrom  pure noise,  the model  iteratively  removes  the noise,  generating  data that matches  \nthe training  distribution.  \n3. Score  Function : This function  estimates  the gradient  of the data distribution  concerning  \nthe noise.  It helps  guide  the reverse  diffusion  process  to produce  realistic  samples.  \n \n \n \n \n \n\n\n--- Page 2 ---\nArchitecture  of Diffusion  Models  \nThe architecture  of diffusion  models  typically  involves  two main  components:  \n1. Forward  Diffusion  Process  \n2. Reverse  Diffusion  Process  \n1. Forward  Diffusion  Process  \nIn this process  noise  is incrementally  added  to the data over a series  of steps.  This is akin to \na Markov  chain  where  each step slightly  degrades  the data by adding  Gaussian  noise.  \n \nForward Diffusion P  \nMathematically,  this can be represented  as: \n \nwhere,  \n• xt is the noisy  data at step t \n• αt controls  the amount  of noise  added.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 3,
      "content": "the data by adding  Gaussian  noise.  \n \nForward Diffusion P  \nMathematically,  this can be represented  as: \n \nwhere,  \n• xt is the noisy  data at step t \n• αt controls  the amount  of noise  added.  \n \n2. Reverse  Diffusion  Process  \nThe reverse  process  aims  to reconstruct  the original  data by denoising  the noisy  data in a \nseries  of steps  reversing  the forward  diffusion.  \n \nReverse Diffusion Process  \nThis is typically  modelled  using  a neural  network  that predicts  the noise  added  at each step:  \n \nwhere,  \n• μθ and σθ are learned  parameters.  \n \nWorking  Principle  of Diffusion  Models  \nDuring  training  the model  learns  to predict  the noise  added  at each step of the forward  \nprocess.  This is done  by minimizing  a loss function  that measures  the difference  between  the \npredicted  and actual  noise.  \n \nForward  Process  (Diffusion)  \n• The forward  process  involves  gradually  corrupting  the data x0 with Gaussian  noise  over \na sequence  of tim",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 4,
      "content": "nce  between  the \npredicted  and actual  noise.  \n \nForward  Process  (Diffusion)  \n• The forward  process  involves  gradually  corrupting  the data x0 with Gaussian  noise  over \na sequence  of time steps  \n• Let xt represent  the noisy  data at time step t. The process  is defined  as: \n \n• where  βt is the noise  schedule  that controls  the amount  of noise  added  at each step and ϵ is \nis Gaussian  noise.  \n\n\n--- Page 3 ---\n• As t increases,  xt becomes  more  noisy  until  it approximates  a Gaussian  distribution.  \n \nReverse  Process  (Denoising)  \n• The reverse  process  aims  to reconstruct  the original  data x0x0 from  the noisy  data xT at \nthe final  time step T. \n• This process  is modelled  using  a neural  network  to approximate  the conditional  \nprobability  pθ(xt−1∣xt). \n• The reverse  process  can be formulated  as: \n \n• where  ϵθ is a neural  network  parameterized  by θ that predicts  the noise.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 5,
      "content": "network  to approximate  the conditional  \nprobability  pθ(xt−1∣xt). \n• The reverse  process  can be formulated  as: \n \n• where  ϵθ is a neural  network  parameterized  by θ that predicts  the noise.  \n \nTraining  Diffusion  Models  \n• The training  objective  for diffusion  models  involves  minimizing  the difference  between  \nthe true noise  ϵ added  in the forward  process  and the noise  predicted  by the neural  \nnetwork  ϵθ. \n• The score  function  which  estimates  the gradient  of the data distribution  concerning  the \nnoise  plays  an important  role in guiding  the reverse  process.  \n• The loss function  is typically  the mean  squared  error  (MSE)  between  these  two quantities:  \n \n• This encourages  the model  to accurately  predict  the noise  and, consequently,  to denoise  \neffectively  during  the reverse  process.  \n \nIn diffusion models, both the forward and backward processes are modeled  as a sequence of \nsmall incremental steps rather than a single transfor",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 6,
      "content": "noise  \neffectively  during  the reverse  process.  \n \nIn diffusion models, both the forward and backward processes are modeled  as a sequence of \nsmall incremental steps rather than a single transformation. This sequential approach is \ncrucial because:  \n1. Gradual Learning  – By breaking the process into many steps, the model learns how \nto handle slight changes at each stage, making it e asier to reverse the noise addition. If \nit tried to denoise from a fully noisy image in one step, it would struggle to map the \nrandom noise back to structured data.  \n2. Stability in Training  – Learning through small denoising steps prevents abrupt \ntransitions,  reducing the chances of errors or divergence during training. It ensures \nthat the model refines its predictions slowly, stabilizing gradients and allowing \nconsistent improvements.  \n3. Better Control Over Generation  – The step -wise nature allows the model to b e \nsampled at different stages, offering control over how much noise to re",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 7,
      "content": "nts and allowing \nconsistent improvements.  \n3. Better Control Over Generation  – The step -wise nature allows the model to b e \nsampled at different stages, offering control over how much noise to remove or retain. \nThis is especially useful in VR environments, where designers might want to balance \nrealism with creativity.  \n4. Avoiding Catastrophic Forgetting  – Incremental denoising r einforces the learning at \nevery step, ensuring that earlier patterns are not forgotten as the model progresses \ntoward generating complex outputs.  \n\n\n--- Page 4 ---\nThus, modeling the forward and backward processes as a sequence of steps ensures that \nlearning is smooth, robu st, and interpretable, ultimately allowing the system to produce high -\nquality, stable, and realistic images from rough sketches.  \nNoise plays a central role in the diffusion process, and carefully adjusting it can significantly \ninfluence the outcomes:  \n1.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 8,
      "content": "duce high -\nquality, stable, and realistic images from rough sketches.  \nNoise plays a central role in the diffusion process, and carefully adjusting it can significantly \ninfluence the outcomes:  \n1. Higher Noise Levels  \no Encourages diverse outputs  because the model explores a wider range of \npossibilities when starting from more random data.  \no Useful for generating creative or artistic VR landscapes where uniqueness is \ndesired.  \no However, if the noise is too  high, the generated images may lose structure or \ncoherence, reducing realism.  \n2. Lower Noise Levels  \no Helps maintain realism and fidelity  because the model starts closer to \nstructured patterns, making it easier to produce clear and consistent images.  \no Best suit ed for VR environments where accuracy, recognizable objects, and \nrealistic textures are essential.  \no It may, however, limit creativity and diversity since the outputs are \nconstrained to follow the training data closely.  \n3.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 9,
      "content": "accuracy, recognizable objects, and \nrealistic textures are essential.  \no It may, however, limit creativity and diversity since the outputs are \nconstrained to follow the training data closely.  \n3. Noise Scheduling  \no Adjusting how noise is added or removed across steps (e.g., linear, \nexponential, cosine schedules) allows fine -tuning between exploration and \nrefinement.  \no Designers can control whether the model produces subtle variations or \nradically different landscapes.  \n4. Application in VR Sy stems  \no For immersive experiences, higher noise levels at early steps can generate \nunpredictable and novel environments, while later steps can be fine -tuned with \nlower noise to ensure realistic details.  \no This balance allows users to start with abstract sketch es and transform them \ninto believable virtual worlds that retain creativity without sacrificing \ncoherence.  \n \n \n \n \n \n \n \n \n \n\n--- Page 5 ---\nDENOISING DIFFUSION PROBABILISTIC MODEL (DDPM)  \nWhat are DDPMs?  \nThey are",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 10,
      "content": "m \ninto believable virtual worlds that retain creativity without sacrificing \ncoherence.  \n \n \n \n \n \n \n \n \n \n\n--- Page 5 ---\nDENOISING DIFFUSION PROBABILISTIC MODEL (DDPM)  \nWhat are DDPMs?  \nThey are a class of  generative models  that work by iteratively  adding noise  to an input signal \n(like an image, text, or audio)  and then learning to denoise  from the noisy signal  to generate \nnew samples .  \n \nGenerative models  \nAre a type of model that can generate new data instances.  Previously, machine learning models \nhave done a good job of learning differences in data and then making predictions or \nclassification tasks. For example, a model trained on a digits dataset like  MNIST  can recognize \na 0 from a  1. Generative models, on the other hand, learn the distribution of digits and can create \na “fake digit” which closely resembles a real digit.  \n \nA Denoising Diffusion Probabilistic Model (DDPM)  is a type of gener ative model that \ncreates realistic images by learning how to p",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 11,
      "content": "an create \na “fake digit” which closely resembles a real digit.  \n \nA Denoising Diffusion Probabilistic Model (DDPM)  is a type of gener ative model that \ncreates realistic images by learning how to progressively refine noisy data. It works in two \nphases:  \n1. Forward Process (Noise Addition)  – The model gradually adds random noise to a \nclean image over many steps until the image becomes indistinguishable from noise.  \n2. Backward Process (Denoising)  – The model learns to reverse this process by \npredicting how to remove noise at each step, eventual ly reconstructing a high -quality \nimage from random noise or a rough input.  \nThe model is called probabilistic  because it doesn’t rely on a single deterministic \ntransformation but instead learns the distribution of possible images at each stage of noise \nand denoising. This approach allows it to generate diverse, high -fidelity images by sampling \nfrom the learned distribution.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 12,
      "content": "instead learns the distribution of possible images at each stage of noise \nand denoising. This approach allows it to generate diverse, high -fidelity images by sampling \nfrom the learned distribution.  \n\n\n--- Page 6 ---\nKey Features of DDPM:  \n• Iterative Refinement  – Instead of transforming an image in one step, it uses many \nsmall steps, making it easier to  model complex patterns.  \n• Noise -Based Learning  – By learning how images degrade with noise, the model \nunderstands how to reverse this degradation to recreate details.  \n• Probabilistic Nature  – It generates a range of plausible outputs rather than a single \nfixed result, which is useful in creative tasks like animation.  \n• Flexibility  – DDPMs can be applied to various tasks such as image synthesis, super -\nresolution, and in your case, converting ro ugh sketches into fully rendered scenes.  \nForward and Backward Diffusion Process  \nThe forward diffusion process  is the initial phase in a DDPM where noise is incrementally",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 13,
      "content": "your case, converting ro ugh sketches into fully rendered scenes.  \nForward and Backward Diffusion Process  \nThe forward diffusion process  is the initial phase in a DDPM where noise is incrementally \nadded to clean data over many steps. The purpose is to teach the model how data transitions \nfrom structured and detailed forms into randomness.  \nKey steps involved:  \n1. Starting with clean data  – At the beginning, the model takes real data such as an \nimage or signal that contains structured information like shapes, textures, and \npatterns.  \n2. Adding noise at each step  – Gaussian noise is added to the data in small amounts \nover a sequence of steps. The nois e schedule (linear, cosine, etc.) controls how much \nnoise is added at each step.  \n3. Progressive degradation  – The data becomes increasingly noisy at every step. \nInitially, the patterns are still recognizable, but as the process continues, the structure \ndisapp ears, and the data looks like random noise.  \n4.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 14,
      "content": "The data becomes increasingly noisy at every step. \nInitially, the patterns are still recognizable, but as the process continues, the structure \ndisapp ears, and the data looks like random noise.  \n4. Mathematical formulation  – At step t, the noisy data xt is derived from the previous \nstep xt−1 by sampling from a normal distribution:  \n \nwhere αt controls the amount of retained information and ϵ is sampled fr om a normal \ndistribution.  \nWhy this step is essential:  \n• It exposes the model to how real data deteriorates with noise.  \n• It creates a learning path for the model to understand the inverse operation —\nrecovering the data from noisy versions.  \n• It ensures that the m odel can generalize to varying noise levels and recover details \nfrom incomplete or corrupted data.  \n\n\n--- Page 7 ---\nRole of the Markov Chain in the Forward Diffusion Process of a DDPM  \nIn a Denoising Diffusion Probabilistic Model (DDPM) , the forward diffusion process  \ninvolves gradually adding noise to c",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 15,
      "content": "e 7 ---\nRole of the Markov Chain in the Forward Diffusion Process of a DDPM  \nIn a Denoising Diffusion Probabilistic Model (DDPM) , the forward diffusion process  \ninvolves gradually adding noise to clean data over multiple steps. This process is modeled as \na Markov chain , which plays a crucial role in structuring how noise is added.  \nA Markov chain  is a mathematical system that transitions from one state to another,  where \nthe next state depends only on the current state and not on the entire history of past states. In \nthe context of DDPM’s forward diffusion process, this means:  \n1. Stepwise progression  \no At each time step ttt, noise is added based only on the data at that step \n(xt−1x_{t -1}xt−1), not on earlier steps. This simplifies the process and \nensures that each step depends only on the immediately preceding one.  \n2. Controlled noise addition  \no The amount of noise added at each step is determined by a known noise \nschedule, ensuring that the transition from structu",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 16,
      "content": "nds only on the immediately preceding one.  \n2. Controlled noise addition  \no The amount of noise added at each step is determined by a known noise \nschedule, ensuring that the transition from structured data to noise is smooth \nand gradual.  \n3. Mathematical tractability  \no By assuming that each step depends only on the previous step, the forward \nprocess becomes easier to analyze, simulate, and invert during training.  \n How does it help structure the noise addition steps?  \n1. Simplifies modeling  \no The Markov assumption allows the model to focus on learning local \ntransitions rather than global dependencies, making the noise addition process \ncomputationally feasible.  \n2. Ensures grad ual degradation  \no The structured, stepwise approach ensures that noise is added progressively, \npreserving information early on and fully randomizing the data at later steps.  \n3. Supports efficient training  \no The Markov property allows the use of recursive formulat ions where each \nnoisy sampl",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 17,
      "content": "reserving information early on and fully randomizing the data at later steps.  \n3. Supports efficient training  \no The Markov property allows the use of recursive formulat ions where each \nnoisy sample can be derived from the previous one using simple equations, \nfacilitating optimization and gradient computation.  \n4. Enables inversion during sampling  \no Since each step only depends on the previous one, the backward process \n(denoisin g) can also be structured in the same stepwise manner, allowing the \nmodel to learn how to reverse the process reliably.  \nThe backward diffusion process  is where the model learns to reverse the noise addition and \nreconstruct the original or new data from noisy inputs.  \nKey aspects:  \n1. Predicting the noise  – At each step, the model is trained to estimate the noise that \nwas added in the forward process. It lear ns how the noisy data differs from its clean \nversion and tries to correct it.  \n\n--- Page 8 ---\n2.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 18,
      "content": "ach step, the model is trained to estimate the noise that \nwas added in the forward process. It lear ns how the noisy data differs from its clean \nversion and tries to correct it.  \n\n--- Page 8 ---\n2. Iterative refinement  – Starting from pure noise, the model removes noise \nprogressively by applying its learned knowledge of patterns at each step. Over time, \nthe image or data be comes clearer and more structured.  \n3. Learning objective  – The model is optimized to minimize the difference between the \npredicted noise and the actual noise added during training. This is typically done \nusing a loss function like Mean Squared Error (MSE).  \n4. Sampling during generation  – Once trained, the model can start from random noise \nand iteratively apply the backward process to generate new, realistic data samples.  \nWhy this process is critical:  \n• It allows the model to reconstruct missing or noisy details.  \n• It ensures that the output is consistent with real -world data distributions.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 19,
      "content": "alistic data samples.  \nWhy this process is critical:  \n• It allows the model to reconstruct missing or noisy details.  \n• It ensures that the output is consistent with real -world data distributions.  \n• It provides control over the generation process by using learned probabilities rather \nthan rigid rules.  \nThe probabilistic nature of DDPM plays a central role in its ability to generate both diverse \nand high -quality outputs.  \nWhy probabilistic modeling is useful ? \n1. Learning distributions rather than fixed mappings  \no Instead of learning a direct transformation from input to output, the model \nlearns the underlying distribution of possib le clean data conditioned on noisy \ninputs.  \no This enables the model to handle uncertainty and variations present in real \ndata.  \n2. Sampling from distributions  \no During generation, the model samples noise from a distribution at each step. \nEven with the same input, different random samples produce varied outputs, \npromoting creativity an",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 20,
      "content": "from distributions  \no During generation, the model samples noise from a distribution at each step. \nEven with the same input, different random samples produce varied outputs, \npromoting creativity and diversity.  \n3. Capturing subtle patterns  \no Probabilistic modeling allows the model to learn nuanced relationships in the \ndata such as textures, lighting patterns, or variations in shape th at are hard to \ncapture with deterministic methods.  \n \n4. Balancing realism and exploration  \no By controlling the noise level and how it’s modeled, the system can explore \nnew possibilities while staying within the realm of realistic outputs. This is \ncrucial for app lications like design, simulation, and data augmentation.  \nChallenges:  \n1. High computational cost  \no Because the process involves many steps (often hundreds or thousands), \ngenerating data can be slow and resource -intensive.  \n2. Latency issues in real -time application s \n\n--- Page 9 ---\no The iterative nature makes it difficul",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 21,
      "content": "any steps (often hundreds or thousands), \ngenerating data can be slow and resource -intensive.  \n2. Latency issues in real -time application s \n\n--- Page 9 ---\no The iterative nature makes it difficult to apply DDPMs in interactive or real -\ntime environments where fast feedback is essential.  \n3. Difficulty in controlling outputs  \no Without proper conditioning or guidance, the model might produce outputs \nthat are inconsis tent with user expectations or desired styles.  \n4. Data requirements  \no Training DDPMs effectively requires large and diverse datasets to accurately \nlearn noise patterns and recover fine details.  \n \nENERGY -BASED MODELS(EBMs)  \nEnergy -Based Models (EBMs)  are a class of probabilistic models that define relationships \nbetween variables using an energy function. Rather than explicitly modeling probability \ndistributions, EBMs assign an “energy” value to each possible configuration of variables, \nwhere lower energy indicates more likely or desirable configuration",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 22,
      "content": "her than explicitly modeling probability \ndistributions, EBMs assign an “energy” value to each possible configuration of variables, \nwhere lower energy indicates more likely or desirable configurations, and higher energy \ncorresponds to less likely ones.  \nEBMs are widely used in machine learning for t asks such as representation learning, \nstructured prediction, anomaly detection, and reinforcement learning, where capturing \nrelationships and constraints between variables is more important than explicitly computing \nprobabilities.  \n \n2. The Concept of Energy in EBMs  \n• An energy function  E(x)maps an input  x to a scalar energy value.  \n• The lower the energy, the more plausible or preferred the data point is according to \nthe model.  \n• The probability distribution  p(x)is related to the energy via the Boltzmann \ndistribution:  \n \nwhere  Z is the partition function:  \n \n• The partition function  Z is often intractable, making it difficult to directly compute \nprobabilities, but not",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 23,
      "content": "he energy via the Boltzmann \ndistribution:  \n \nwhere  Z is the partition function:  \n \n• The partition function  Z is often intractable, making it difficult to directly compute \nprobabilities, but not necessary for learning.  \n \n\n\n--- Page 10 ---\n3. Architecture and Working  \nCore Components:  \n1. Energy Function  \no The energy function is typically parameterized by neural networks or other \ndifferentiable models.  \no It scores different data configurations to indicate how well they conform to the \ndesired patterns.  \n2. Learning Objective  \no EBMs learn by comparing the energies of positive (correct) and negative \n(incorrect or unlikely) samples.  \no The goal is to assign lower energy to real data and higher energy to unlikely \ndata.  \n3. Training Approaches  \no Contrastive Divergence (CD)  – Optimizes the model by comparing energy \ndifferences betwe en observed and model -generated samples.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 24,
      "content": "ta and higher energy to unlikely \ndata.  \n3. Training Approaches  \no Contrastive Divergence (CD)  – Optimizes the model by comparing energy \ndifferences betwe en observed and model -generated samples.  \no Score Matching  – Matches the gradient of the energy function rather than the \nenergy itself.  \no Noise Contrastive Estimation (NCE)  – Uses noise samples to help \napproximate the partition function during learning.  \n \n4. Markov Random Fields (MRFs) and Conditional EBMs  \n• EBMs are closely related to Markov Random Fields (MRFs), which model \ndependencies between variables using graph structures.  \n• Conditional EBMs  extend the energy framework to ta sks where the output depends \non input features (e.g., image classification, structured output prediction).  \n \n5. Applications of EBMs  \n1. Unsupervised Learning  \no Modeling complex relationships in high -dimensional data such as im ages, \nspeech, or text.  \n2.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 25,
      "content": "assification, structured output prediction).  \n \n5. Applications of EBMs  \n1. Unsupervised Learning  \no Modeling complex relationships in high -dimensional data such as im ages, \nspeech, or text.  \n2. Anomaly Detection  \no Identifying outliers by assigning higher energy to rare or unlikely \nconfigurations.  \n3. Reinforcement Learning (RL)  \no Estimating value functions where actions with lower energy correspond to \nmore rewarding behaviors.  \n4. Generative Modeling  \no Generating samples by searching for configurations with low energy, often \nusing sampling algorithms like Langevin dynamics.  \n5. Structured Prediction  \no Solving problems like image segmentation or sequence labeling where \nrelationships between output variables are important.  \n\n--- Page 11 ---\n \n6. Advantages of EBMs  \n• Flexibility  – Can model arbitrary dependencies without requiring explicit probability \ndistributions.  \n• Interpretability  – The energy function directly encodes preferenc es or constraints.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 26,
      "content": "BMs  \n• Flexibility  – Can model arbitrary dependencies without requiring explicit probability \ndistributions.  \n• Interpretability  – The energy function directly encodes preferenc es or constraints.  \n• Applicability  – Useful in domains where structured relationships and constraints \ndominate over simple classification.  \n \n7. Challenges and Limitations  \n1. Intractable Partition Function  \no Computing  ZZZ is ofte n impossible in practice, requiring approximation \ntechniques that can be unstable.  \n2. Training Instability  \no Optimization methods like contrastive divergence rely on sampling, which can \nlead to slow convergence or poor performance.  \n3. Sampling Complexity  \no Generatin g samples requires iterative methods such as Markov Chain Monte \nCarlo (MCMC), which can be computationally expensive.  \n4. Scalability Issues  \no Handling high -dimensional data with complex energy landscapes is \nchallenging.  \n \n8.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 27,
      "content": "ods such as Markov Chain Monte \nCarlo (MCMC), which can be computationally expensive.  \n4. Scalability Issues  \no Handling high -dimensional data with complex energy landscapes is \nchallenging.  \n \n8. Recent Advances  \n• Neural EBMs  – Combining deep learning with energy functions to model high -\ndimensional and structured data more effectively.  \n• Score -based Generative Models  – Learning the gradi ent of the energy function to \navoid directly computing the partition function.  \n• Applications in Contrastive Learning  – EBMs form the backbone of contrastive \napproaches where relationships between samples are emphasized.  \n \n \n \n \n \n \n \n \n\n--- Page 12 ---\nCOMPARE EBMS VS VAES  \nAspect  Energy -Based Models (EBMs)  Variational Autoencoders (VAEs)  \n✅ Architecture  - Defined by an energy function \nthat assigns a scalar “energy” to \neach configuration of inputs (and \noptionally outputs).  \n- No explicit probability \ndistribution; the model learns to \nassign lower energy to desired \nsamp",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 28,
      "content": "unction \nthat assigns a scalar “energy” to \neach configuration of inputs (and \noptionally outputs).  \n- No explicit probability \ndistribution; the model learns to \nassign lower energy to desired \nsamples  and higher energy to \nundesired ones.  \n- Often optimized using contrastive \ndivergence or score matching.  \n- The architecture focuses on \nrelationships between data points \nrather than reconstructing or \ngenerating them directly.  - Composed of two main parts: an \nencoder and a decoder.  \n- The encoder maps input data to a \nlatent space distribution (typically \nGaussian).  \n- The decoder reconstructs data \nfrom samples drawn from the latent \nspace.  \n- Uses variational inference to \napproximate intractable posteriors.  \n- The architecture explicitly models \ndata generation.  \n✅ Objective  - Learn an energy landscape where \ncorrect data points are assigned \nlower energy.  \n- Optimization is based on \ndistinguishing good samples from \nbad ones.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 29,
      "content": "tly models \ndata generation.  \n✅ Objective  - Learn an energy landscape where \ncorrect data points are assigned \nlower energy.  \n- Optimization is based on \ndistinguishing good samples from \nbad ones.  - Maximize the Evidence Lower \nBound (ELBO) which balances \nreconstruction accuracy and \nregularization of the latent space.  \n- Encourages latent space structure \nfor efficient sampling and \ninterpolation.  \n✅ Probabilistic \nInterpretation  - Indirect; energy defi nes the \nlikelihood up to a normalization \nconstant (partition function), which \nis often intractable.  \n- Focuses on learning relationships \nand constraints rather than full \ndensity estimation.  - Explicit probabilistic framework \nwith tractable priors and \nappro ximate posteriors.  \n- Can directly sample from the latent \nspace and model uncertainty.  \n✅ Training \nMethods  - Uses sampling -based methods \nlike Markov Chain Monte Carlo \n(MCMC), contrastive divergence, \nor score matching.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 30,
      "content": "directly sample from the latent \nspace and model uncertainty.  \n✅ Training \nMethods  - Uses sampling -based methods \nlike Markov Chain Monte Carlo \n(MCMC), contrastive divergence, \nor score matching.  \n- Training can be unstable due to \nreliance on sampling and gradient \nestimation.  - Uses backpropagation with \nreparameterization trick for efficient \ngradient estimation.  \n- More stable and easier to train \nwith large datasets.  \n✅ Applications  - Modeling complex dependencies \nin structured data.  \n- Used in tasks like anomaly \ndetection, reinforcement learning, \nand unsupervised learning.  \n- Applicable where relationships \nand constraints are more important \nthan explicit reconstruction.  - Image and speech generation, data \ncompression, anomaly detection , \nand semi -supervised learning.  \n- Used where interpretable latent \nrepresentations and smooth \ngeneration paths are required.  \n\n--- Page 13 ---\nAspect  Energy -Based Models (EBMs)  Variational Autoencoders (VAEs)  \n✅ Strengt",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 31,
      "content": "ing.  \n- Used where interpretable latent \nrepresentations and smooth \ngeneration paths are required.  \n\n--- Page 13 ---\nAspect  Energy -Based Models (EBMs)  Variational Autoencoders (VAEs)  \n✅ Strengths  - Flexibility in modeling \nrelationships without requiring \nexplicit likelihood functions.  \n- Can incorporate constraint s and \ndomain knowledge easily.  - Well -suited for generating new \ndata samples.  \n- Provides interpretable latent spaces \nuseful for downstream tasks.  \n✅ Limitations  - Training is computationally \nexpensive and less scalable. - \nNormalization constant estimation  \nis intractable in many cases.  - May suffer from blurry \nreconstructions or mode collapse.  \n- Latent space structure depends \nheavily on choice of priors and \narchitectures.  \n \nINTRODUCTION TO NOISE SCHEDULERS IN DIFFUSION MODELS  \nIn diffusion models, noise plays a central role in transforming structured data into random noise \nduring training and then reconstructing it during sampling.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 32,
      "content": "TO NOISE SCHEDULERS IN DIFFUSION MODELS  \nIn diffusion models, noise plays a central role in transforming structured data into random noise \nduring training and then reconstructing it during sampling. However, how much noise is added \nor removed at each step is not arbitrary —it must be carefully controlled to ensure that the model \nlearns meaningful patterns and can effectively generate high -quality data.  \nThis is where noise schedulers  come into play.  \nA noise scheduler  defines the schedule or strategy by which noise is added to data in the \nforward diffusion process and removed in the backward process. It determines the magnitude \nof noise at each step, shaping how the model degrades and refines information over time.  \nThe design of the noise schedule affects several critical aspects:  \n• Learning efficiency  – Too much noise can obscur e important details, while too little \nmay prevent the model from learning to handle uncertainty.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 33,
      "content": "noise schedule affects several critical aspects:  \n• Learning efficiency  – Too much noise can obscur e important details, while too little \nmay prevent the model from learning to handle uncertainty.  \n• Sample diversity and quality  – The progression of noise influences how creative or \nrealistic the generated outputs are.  \n• Training stability  – Gradual noise addi tion helps avoid erratic learning and ensures \nthat the model can generalize from noisy inputs.  \nCommon schedules include linear, cosine, and exponential noise schedules , each offering \ndifferent trade -offs between smoothness, speed, and complexity.  \nSignifica nce of Noise Schedulers in Diffusion Models  \nIn diffusion models, noise schedulers  determine how noise is added (in the forward process) \nor removed (in the backward process) at each step. They play a critical role in controlling the \nquality, stability, and efficiency of the model during both training and sampling.  \nWhy are noise schedulers important?  \n1.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 34,
      "content": "kward process) at each step. They play a critical role in controlling the \nquality, stability, and efficiency of the model during both training and sampling.  \nWhy are noise schedulers important?  \n1. Control over noise injection  \no A noise scheduler defines how much noise is added at each step, influencing \nhow quickly the data degrades from its original form to pure noise.  \n\n--- Page 14 ---\no A carefully designed schedule ensures that the model learns meaningful \ntransformations at each step rather than abrupt or overly noisy transitions.  \n2. Balance between learning and randomness  \no If noise is added too aggressively, the model may strugg le to learn how to \nrecover the data because too much information is lost early.  \no If noise is too weak, the model may not generalize well and could overfit to \nspecific patterns without learning how to handle uncertainty.  \n3. Smooth transitions  \no Gradual noise addi tion allows the model to capture complex patterns and fine \ndetails at di",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 35,
      "content": "could overfit to \nspecific patterns without learning how to handle uncertainty.  \n3. Smooth transitions  \no Gradual noise addi tion allows the model to capture complex patterns and fine \ndetails at different noise levels, helping the backward process refine the data \neffectively.  \n4. Influences sample quality and diversity  \no The noise schedule affects the kinds of outputs the model generates. For \ninstance, a slower noise increase might produce high -fidelity samples, while a \nfaster schedule might encourage more diverse and creative outputs.  \n5. Stabilizes training  \no Appropriate noise scheduling prevents extreme gradients or erratic learning  \nbehavior, enabling stable and efficient training across large datasets.  \n✅ Example of a commonly used noise scheduler: Linear noise schedule  \nOne widely used noise scheduler is the linear noise schedule , where the noise level increases \nat a constant rate ac ross steps.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 36,
      "content": "✅ Example of a commonly used noise scheduler: Linear noise schedule  \nOne widely used noise scheduler is the linear noise schedule , where the noise level increases \nat a constant rate ac ross steps.  \n• The noise added at each step t is computed as:  \n \nwhere:  \no βstart is the initial noise amount,  \no βend is the final noise amount,  \no T is the total number of steps.  \n \nWhy it's used:  \n• Simplicity – easy to implement and analyze.  \n• Gradual degradation – ensures smooth transitions from structured data to noise.  \n• Works well in practice for a variety of tasks without requiring complex tuning.  \n✅ Other common noise schedules  \n• Cosine schedule  – Uses a cosine curve to control noise increments, adding noise \nmore sm oothly at the beginning and end.  \n\n\n--- Page 15 ---\n• Exponential schedule  – Adds noise in a way that accelerates or decelerates across \nsteps, providing more control over learning phases.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 37,
      "content": "more sm oothly at the beginning and end.  \n\n\n--- Page 15 ---\n• Exponential schedule  – Adds noise in a way that accelerates or decelerates across \nsteps, providing more control over learning phases.  \nComparison between Class -Conditional Diffusion Models and Unconditional Diffusion \nModels  \nAspect  Class -Conditional Diffusion Models  Unconditional Diffusion Models  \n✅ Definition  Diffusion models where the generation \nprocess is guided by class labels or \nadditional conditioning information (e.g., \ntext, attributes). The model learns how the \ndata distribution changes for different \nclasses.  Diffusion models that generate data \npurely based on learned distributions \nwithout any conditioning information. \nThe model only depends on noise and \nthe learned data distribution.  \n✅ \nArchitecture  - Incorporates class labels or auxiliary \ninputs into the noise prediction network.  \n- Conditioning is usually done by \nconcatenating labels or through \nembeddings that influence intermediate",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 38,
      "content": "cture  - Incorporates class labels or auxiliary \ninputs into the noise prediction network.  \n- Conditioning is usually done by \nconcatenating labels or through \nembeddings that influence intermediate \nlayers.  \n- The model learns separate modes of the \ndata distribution for each class o r \ncondition.  - Contains only the noise prediction \nnetwork without any external inputs.  \n- Learns the general structure and \ndistribution of the entire dataset.  \n- Generates samples based on noise \nwithout class -specific guidance.  \n✅ Training \nObjective  - Learn how to denoise while respecting \nclass information.  \n- The model minimizes the reconstruction \nloss while conditioning on the class, \nensuring generated samples match the \ntarget category.  - Learn to denoise without any guidance \nother than the underlying data \ndistribution.  \n- The model focuses on general patterns \nand statistical relationships in the \ndataset.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 39,
      "content": "the \ntarget category.  - Learn to denoise without any guidance \nother than the underlying data \ndistribution.  \n- The model focuses on general patterns \nand statistical relationships in the \ndataset.  \n✅ Sampling  - During generation, class labels guide the \nsampling process, allowing control over \nwhat kind of sample is generated (e.g., a \ncat vs. a dog image ). \n- Can produce targeted, structured outputs.  - Generates samples from noise without \ncontrol over attributes or categories.  \n- Produces diverse outputs but without \nspecific guidance.  \n✅ \nApplications  - Image synthesis conditioned on class \nlabels (e.g., gene rating specific objects or \nfaces).  \n- Text-to-image generation, style transfer, \nor scenarios requiring targeted outputs.  \n- Semi -supervised learning where \nadditional information improves generation \nquality.  - General image, audio, or video \ngeneration where c ontrol is not \nnecessary.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 40,
      "content": "os requiring targeted outputs.  \n- Semi -supervised learning where \nadditional information improves generation \nquality.  - General image, audio, or video \ngeneration where c ontrol is not \nnecessary.  \n- Data augmentation, unsupervised \nlearning, and exploratory creative \ngeneration.  \n✅ \nAdvantages  - Greater control over generated samples.  \n- Can produce outputs tailored to specific \ntasks or user inputs.  \n- More interpretable generati on process.  - Simpler architecture and easier to \nimplement.  \n- Requires less labeled data.  \n\n--- Page 16 ---\nAspect  Class -Conditional Diffusion Models  Unconditional Diffusion Models  \n- Capable of learning diverse patterns \nfrom large, unstructured datasets.  \n✅ \nLimitations  - Requires labeled  data or conditioning \ninputs, which may not always be available.  \n- More complex architecture and higher \ncomputational cost.  - Lacks control over generated content.  \n- May produce irrelevant or ambiguous \noutputs when diverse patterns overlap.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 41,
      "content": "ays be available.  \n- More complex architecture and higher \ncomputational cost.  - Lacks control over generated content.  \n- May produce irrelevant or ambiguous \noutputs when diverse patterns overlap.  \n \nDDIM (DENOISING DIFFUSION IMPLICIT MODELS)  \nDDIM (Denoising Diffusion Implicit Models)  is an improvement over standard diffusion \nmodels like DDPM (Denoising Diffusion Probabilistic Models). It introduces a new sampling \nmethod that allows generating high -quality samples with significantly fewer steps, while still \nretaining diversity and structure in the outputs.  \n✅ Why DDIM was introduced  \n1. Reduce Sampling Time  \no Traditional diffusion models like DDPM require hundreds or thousands of \nsteps during sampling, which makes them computationally expensive and slow \nfor practical applications.  \n2. Maintain Quality and Diversity  \no Simply reducing steps in DDPM leads to degraded or  less diverse outputs.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 42,
      "content": "ling, which makes them computationally expensive and slow \nfor practical applications.  \n2. Maintain Quality and Diversity  \no Simply reducing steps in DDPM leads to degraded or  less diverse outputs.  \no DDIM proposes a deterministic or pseudo -deterministic approach that \nmaintains high sample fidelity even with fewer steps.  \n✅ How DDIM works  \n1. Implicit Sampling  \no Instead of following the stochastic rev erse process of DDPM, DDIM defines a \ndeterministic mapping between noise and data, reducing randomness during \nsampling.  \no The model avoids resampling at each step, making it faster and more stable.  \n2. Non-Markovian Transitions  \no Unlike DDPM where each step depend s only on the previous one (Markov \nproperty), DDIM relaxes this assumption by allowing steps that depend on \nearlier states.  \no This enables more flexible transitions and faster sampling while preserving \nsample quality.  \n3.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 43,
      "content": "(Markov \nproperty), DDIM relaxes this assumption by allowing steps that depend on \nearlier states.  \no This enables more flexible transitions and faster sampling while preserving \nsample quality.  \n3. Controlled Interpolation  \no DDIM allows int erpolation between different noise levels and samples, which \ncan be used for creative applications like style mixing or smooth transitions.  \n \n\n--- Page 17 ---\n✅ Key Differences from DDPM  \nFeature  DDPM  DDIM  \nSampling process  Stochastic, follows Markov chain with \nrandom transitions  Deterministic or pseudo -deterministic, \nwith fewer steps  \nComputational \ncost High due to many sampling steps  Much lower with accelerated sampling  \nDiversity  Can explore a wide range of outputs due \nto randomness  Maintains diversity but with controlled \nnoise patterns  \nUse case  Suitable for tasks needing rich \nexploration  Better for fast generation and interactive \napplications  \n \n✅ Mathematical Insight  \nIn DDPM, the reverse process is modeled as a",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 44,
      "content": "se patterns  \nUse case  Suitable for tasks needing rich \nexploration  Better for fast generation and interactive \napplications  \n \n✅ Mathematical Insight  \nIn DDPM, the reverse process is modeled as a probabilistic sampling from  p(xt−1∣xt), where \nrandomness is inherent at each step.  \nIn DDIM, a deterministic transition is defi ned: \n \nHere:  \n• αt defines how much signal is preserved at each step.  \n• ϵθ(xt,t) is the model’s learned noise prediction.  \nThis formulation allows skipping intermediate steps while still approximating the \nreverse trajectory.  \n \n✅ Applications of DDIM  \n1. Image Generation  \no Produces high -resolution images quickly without compromising on details.  \n2. Video and Audio Synthesis  \no Enables faster generation for time -sensitive applications like animation or \nsound design.  \n3. Style Transfer & Interpolation  \no Smoothly blends between samples by manipulating latent noise patterns \ndeterministically.  \n4.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 45,
      "content": "for time -sensitive applications like animation or \nsound design.  \n3. Style Transfer & Interpolation  \no Smoothly blends between samples by manipulating latent noise patterns \ndeterministically.  \n4. Interactive Tools  \no Supports real -time editing and creative workflows where speed and control are \ncritical.  \n\n\n--- Page 18 ---\n \n✅ Advantages of DDIM  \n✔ Faster sampling with fewer step s \n✔ Stable and high -quality output s \n✔ Supports interpolation and controlled gene ration \n✔ Reduces computational cost without major trade -offs in realism  \n \n✅ Limitations of DDIM  \n❗ May lose some diversity due to reduced randomnes s \n❗ Requires careful tuning of schedules and noise level s \n❗ Still dependent on well -trained models to perform effectively  \n \n✅ Conclusion  \nDDIM is a powerful extension of diffusion models that addresses one of their biggest \nlimitations —slow sampling —by introducing deterministic or semi -deterministic  transitions.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpupqjtq0y.pdf_b9876e2d_41ddd12a",
      "chunk_index": 46,
      "content": "y  \n \n✅ Conclusion  \nDDIM is a powerful extension of diffusion models that addresses one of their biggest \nlimitations —slow sampling —by introducing deterministic or semi -deterministic  transitions. \nIt enables faster generation while maintaining sample fidelity and diversity, making it highly \nsuitable for real -world applications like image synthesis, animation, and interactive creative \ntools.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "e40f6281-a1f2-458e-a226-c1f49cd8dea3_test_ar_vr_doc.txt_e928ccf9_9a7b0b57",
      "chunk_index": 0,
      "content": "Augmented Reality (AR) and Virtual Reality (VR) Technology Overview\n\nAugmented Reality (AR) is a technology that overlays digital information and virtual objects onto the real world, enhancing the user's perception of reality. AR applications use cameras, sensors, and displays to blend virtual content with the physical environment in real-time.\n\nKey AR Technologies:\n- Marker-based AR: Uses visual markers to trigger virtual content\n- Markerless AR: Uses GPS, accelerometers, and computer vision\n- Projection-based AR: Projects light onto real-world surfaces\n- Superimposition-based AR: Replaces or enhances real-world objects\n\nPopular AR Applications:\n- Mobile AR apps like Pokemon GO and Snapchat filters\n- Industrial maintenance and training\n- Medical visualization and surgery assistance\n- Retail and e-commerce product visualization\n- Navigation and wayfinding systems\n\nVirtual Reality (VR) is an immersive technology that creates a completely artificial digital environment that users can int",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "e40f6281-a1f2-458e-a226-c1f49cd8dea3_test_ar_vr_doc.txt_e928ccf9_9a7b0b57",
      "chunk_index": 1,
      "content": "il and e-commerce product visualization\n- Navigation and wayfinding systems\n\nVirtual Reality (VR) is an immersive technology that creates a completely artificial digital environment that users can interact with using specialized headsets and controllers. VR replaces the user's real-world environment with a computer-generated simulation.\n\nKey VR Technologies:\n- Head-mounted displays (HMDs) like Oculus Rift, HTC Vive, PlayStation VR\n- Motion tracking systems for hand and body movement\n- Haptic feedback devices for tactile sensations\n- Spatial audio for immersive sound experiences\n\nPopular VR Applications:\n- Gaming and entertainment\n- Virtual training and education\n- Architectural visualization\n- Therapy and rehabilitation\n- Virtual tourism and exploration\n\nCurrent Market Trends:\nThe AR/VR market is experiencing rapid growth, with projections showing significant expansion in both consumer and enterprise sectors.",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "e40f6281-a1f2-458e-a226-c1f49cd8dea3_test_ar_vr_doc.txt_e928ccf9_9a7b0b57",
      "chunk_index": 2,
      "content": "itation\n- Virtual tourism and exploration\n\nCurrent Market Trends:\nThe AR/VR market is experiencing rapid growth, with projections showing significant expansion in both consumer and enterprise sectors. Major technology companies like Apple, Google, Microsoft, and Meta are investing heavily in AR/VR development.\n\nFuture Prospects:\n- Mixed Reality (MR) combining AR and VR\n- 5G connectivity enabling cloud-based AR/VR experiences\n- Improved hardware with better resolution and comfort\n- Integration with artificial intelligence and machine learning\n- Expansion into healthcare, education, and remote work applications\n\nChallenges and Limitations:\n- Hardware costs and accessibility\n- Motion sickness and user comfort issues\n- Content creation complexity\n- Privacy and security concerns\n- Battery life and processing power limitations",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "e40f6281-a1f2-458e-a226-c1f49cd8dea3_test_ar_vr_doc.txt_e928ccf9_9a7b0b57",
      "chunk_index": 3,
      "content": "and processing power limitations",
      "filename": "test_ar_vr_doc.txt"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nUnit II \nCLIP (Contrastive Language –Image Pretraining)  \nCLIP (Contrastive Language –Image Pretraining) learns a joint text –image embedding \nspace by using contrastive learning to bring matching image –text pairs close and push \nnon-matching pairs apart.  \nKey points & justifications:  \n1. Dual encoders (text & image) mapped to a shared space.  \nJustification:  Mapping both modalities into the same vector space makes direct \nsimilarity computations (cosine similarity) possible. This design simplifies \ndownstream tasks (retrieval, zero -shot classification) because the model does \nnot have to learn task -specific cros s-modal projections every time — the shared \nspace is a reusable interface.  \n2. Contrastive (InfoNCE) loss pulls positives and pushes negatives.  \nJustification:  InfoNCE directly optimizes relative similarity: maximizing similarity \nof correct pairs while minimizing similarity of incorrect pairs.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 1,
      "content": "CE) loss pulls positives and pushes negatives.  \nJustification:  InfoNCE directly optimizes relative similarity: maximizing similarity \nof correct pairs while minimizing similarity of incorrect pairs. This encourages \nembeddings to capture semantics that distinguish correct captions from \ndistractors, which is precisely w hat cross -modal tasks require.  \n3. Large batch / many negatives improve representation quality.  \nJustification:  More negatives increase the difficulty of the contrastive task, \nforcing embeddings to capture fine -grained distinctions. Empirically large \neffective batch sizes (or memory banks) create stronger supervision signals, \nproducing richer semantic structure.  \n4. Enables zero -shot transfer and robust retrieval.  \nJustification:  Because CLIP learns general alignment between text concepts and \nvisual features, it can map a new text label into the same space and retrieve \nrelevant images without task -specific retraining — the learned semantic \ngeometry gen",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 2,
      "content": "ignment between text concepts and \nvisual features, it can map a new text label into the same space and retrieve \nrelevant images without task -specific retraining — the learned semantic \ngeometry generalizes.  \nExample:  \nImage: “a red bicycle on a rainy street.” CLIP will place the image embedding near \ncaptions describing bicycles/rain, and far from unrelated captions (e.g., “a dog in a \npark”).  \nApplications & justification:  \n• Zero-shot classification:  No fine-tuning needed because class names can be \nembedded and compared to images.  \nJustification:  The shared semantic space means class semantics are already \nencoded.  \n\n--- Page 2 ---\n• Text-guided retrieval and generation:  CLIP scores can rank generated images or \nguide generative models.  \nJustification:  Direct similarity metrics allow automatic evaluation and steering.  \nText embeddings in multimodal diffusion models  \nText embeddings convert a prompt into a dense vector that conditions diffusion models, \nguiding stocha",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 3,
      "content": "trics allow automatic evaluation and steering.  \nText embeddings in multimodal diffusion models  \nText embeddings convert a prompt into a dense vector that conditions diffusion models, \nguiding stochastic denoising toward images that match the text.  \nKey points & justifications:  \n1. Serve as conditioning signal during denoising.  \nDiffusion models generate by reversing noise; conditioning vectors are injected \n(via concatenation, cross -attention, or FiLM) so each denoising step has \nsemantic context. Without conditioning, the model has no way to steer \ngeneration toward the desired sem antics.  \n2. Capture both object and style attributes.  \nModern text encoders (Transformers) represent not just nouns but adjectives, \nrelations, and style descriptors. Embeddings therefore allow the generator to \nsynthesize content (objects) and aesthetic (style) simultaneously.  \n3. Enable fine controls (compositional prompts, modifiers).",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 4,
      "content": "ns, and style descriptors. Embeddings therefore allow the generator to \nsynthesize content (objects) and aesthetic (style) simultaneously.  \n3. Enable fine controls (compositional prompts, modifiers).  \n Vector arithmetic and attention let the model weight different subcomponents \nof the prompt; e.g., “photorealistic” vs “oil painting” map to different embedding \ndirections, producing controlled stylistic outcomes.  \n4. Facilitate semantic consistency across steps.  \nConditioning every denoising step (rather than only at start) ensures semantic \ninformation persists through the stochastic sampling, preventing drift to \nirrelevant modes.  \nExample:  \nPrompt: “A small wooden cabin at sunset, misty atmosphere.” The embedding encodes \nobject (“cabin”), material (“wooden”), time (“sunset”), and mood (“misty”) so the \ndiffusion model composes these attributes coherently.  \nApplications & justification:  \n• Text-to-image (Stable Diffusion):  Embeddings let a single model produce \ndiverse outp",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 5,
      "content": "mood (“misty”) so the \ndiffusion model composes these attributes coherently.  \nApplications & justification:  \n• Text-to-image (Stable Diffusion):  Embeddings let a single model produce \ndiverse outputs from many prompts.  \nA single learned forward/backward process can be reused with different \ncondition vectors.  \n\n--- Page 3 ---\n• Prompt interpolation and editing:  Embeddings allow latent manipulations \n(e.g., amplify “sunset”) to edit outputs.  \nContinuous embeddings provide smooth control that discrete labels cannot.  \nCritical insight / limitation  \nIf embeddings lack domain knowledge or are ambiguous, generation will be \nsemantically weak. Therefore, high -quality text encoders and, when needed, domain -\nspecific embedding fine -tuning are essential.  \nCommon evaluation metrics for text –image alignment  \nEvaluating multimodal generation requires metrics that measure both visual quality  and \nsemantic alignment  between text and image.  \nMetrics & justifications:  \n1.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 6,
      "content": "etrics for text –image alignment  \nEvaluating multimodal generation requires metrics that measure both visual quality  and \nsemantic alignment  between text and image.  \nMetrics & justifications:  \n1. CLIPScore (cosine similarity of CLIP embeddings).  \nWhat it measures:  Semantic alignment between generated image and \nprompt.  \nCLIP is trained to align modalities; its cosine similarity is a direct proxy for how \nwell image content matches textual semantics. It’s automatic and correlates \nreasonably with human judgments for many prompts.  \n2. FID (Fréchet Inception Distance).  \nWhat it measures:  Distributional similarity between generated images and \nreal images.  \nFID captures both quality and diversity by comparing feature statistics (means, \ncovariances). Lower FID implies generated images occupy similar manifold to \nreal images.  \n3. Inception Score (IS).  \nWhat it measures: Distinctiveness and confidence of generated images (via \nan Inception classifier).",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 7,
      "content": "FID implies generated images occupy similar manifold to \nreal images.  \n3. Inception Score (IS).  \nWhat it measures: Distinctiveness and confidence of generated images (via \nan Inception classifier).  \nIS rewards samples that are recognizable and varied; however it doesn’t \nmeasure prompt alignment.  \n4. Human evaluation (relevance, fidelity, preference).  \nWhat it measures:  Subjective semantic correctness and visual appeal.  \nAutomated metrics are imperfect, so human judgment remains the gold \nstandard, especially for nuanced or creative prompts.  \n5. Task-specific metrics (precision/recall on objects, detection mAP).  \nWhen prompts require specific objects or relations, applying object detectors \nand measuring precision/recall quantifies functional correctness.  \n\n--- Page 4 ---\nCombining metrics — justification:  \nNo single metric captures all aspects. CLIPScore checks alignment but not realism; FID \nchecks realism but not prompt adherence.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 8,
      "content": "nal correctness.  \n\n--- Page 4 ---\nCombining metrics — justification:  \nNo single metric captures all aspects. CLIPScore checks alignment but not realism; FID \nchecks realism but not prompt adherence. Combining metrics plus human checks \nproduces more reliable evaluation.  \nLimitations : \nCLIPScore can be gamed (adversarially optimized); FID is sensitive to dataset choice \nand model used for features. Thus metric selection should align with evaluation goals \nand be interpreted carefully.  \n \nFine-tuning CLIP  \nIntroduction:  \nPretrained CLIP is broad but not deep in domain -specific semantics; fine -tuning adapts \nit to specialized vocabularies, visual cues, and biases of a target domain.  \nKey points & justifications:  \n1. Bridging domain vocabulary gaps.  \nCLIP’s internet training may underrepresent domain terms (medical labels, \nindustrial parts). Fine -tuning with domain captions teaches the text encoder \ndomain semantics and aligns them to visual cues in that field.  \n2.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 9,
      "content": "ing may underrepresent domain terms (medical labels, \nindustrial parts). Fine -tuning with domain captions teaches the text encoder \ndomain semantics and aligns them to visual cues in that field.  \n2. Improving visual feature sensitivity to domain specifics.  \nFine-tuning the image encoder helps it attend to subtle diagnostic visual features \n(e.g., microcalcifications) that general models may deem irrelevant.  \n3. Reducing harmful biases and spurious correlations.  \nDomain curation can balance datasets and remove stereotypes present in \ninternet data, improving fairness and factual accuracy in sensitive contexts.  \n4. Better downstream task performance (retrieval, VQA, diagnostics).  \nFine-tuned embeddings yield higher retrieval precision and more accurate VQA \nanswers because they encode task -relevant features.  \nPractical methods & justifications:  \n• Full fine-tuning: update all weights — best for abundant labels.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 10,
      "content": "trieval precision and more accurate VQA \nanswers because they encode task -relevant features.  \nPractical methods & justifications:  \n• Full fine-tuning: update all weights — best for abundant labels.  \nAllows maximal adaptation but risks catastrophic forgetting and needs data/GPU \nresources.  \n• Adapter modules / LoRA / prompt tuning:  lightweight adjustments.  \n Preserve pretrained knowledge while cheaply adapting to domain; less risk of \nforgetting and cheaper to train.  \n\n--- Page 5 ---\n• Continual learning / regularization:  e.g., Elastic Weight Consolidation to \nprevent forgetting.  \nMaintains general CLIP capabilities while learning domain specifics.  \nExample:  \nFine-tuning CLIP on annotated chest X -rays (labels, radiologist captions) yields \nimproved retrieval and VQA performance for radiology tasks because the model learns \nto associate radiographic patterns with domain terms.  \n \nFine-tuning requires curated, representative, and labeled domain data; otherwise you \nrisk over",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 11,
      "content": "for radiology tasks because the model learns \nto associate radiographic patterns with domain terms.  \n \nFine-tuning requires curated, representative, and labeled domain data; otherwise you \nrisk overfitting or preserving harmful biases. Validation and human oversight are \nessential.  \n \nArchitecture of CLIP and joint learning  \nIntroduction:  \nCLIP uses separate encoders for images and text, projection heads to a common \nembedding space, and contrastive training to jointly learn aligned representations.  \n \nArchitecture components & justifications:  \n1. Image encoder (ViT or ResNet).  \nCNNs (ResNet) capture local textures; ViTs capture long -range interactions. \n\n\n--- Page 6 ---\nChoice depends on tradeoffs (compute vs performance). Both produce rich \nvisual features for projection.  \n2. Text encoder (Transformer).  \n Transformers model sequential and contextual language semantics effectively, \nenabling capture of compositional meaning (modifiers, relations).  \n3.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 12,
      "content": "for projection.  \n2. Text encoder (Transformer).  \n Transformers model sequential and contextual language semantics effectively, \nenabling capture of compositional meaning (modifiers, relations).  \n3. Projection heads (linear layers) mapping to shared space.  \nSeparate high -dim features are projected to a common dimensionality so cosine \nsimilarity is meaningful; projection can also adapt modality -specific statistics.  \n4. Contrastive (InfoNCE) training with large effective batch size.  \nMany negatives help the model learn fine distinctions. Training with symmetric \nloss (image→text and text→image) strengthens bidirectional retrieval capability.  \n5. Temperature scaling in contrastive loss.  \n Temperature controls concentration of similarity distribution; tuning it balances \nsensitivity between positive/negative pairs.  \nWhy this design works ? \n• Separate encoders let each modality use architectures tailored to its inductive \nbiases, yet the projection + contrastive loss forces sema",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 13,
      "content": "between positive/negative pairs.  \nWhy this design works ? \n• Separate encoders let each modality use architectures tailored to its inductive \nbiases, yet the projection + contrastive loss forces semantic alignment without \nmerging architectures (which would be less flexible).  \n• Large paired datasets provide diverse supervision so the embedding geometry \ngeneralizes across many concepts.  \nExample:  \nDuring training a batch of image -caption pairs, each image’s closest embedding should \nbe its caption’s embedding. The symmetric contrastive loss enforces this across all \nbatch pairs, producing a globally consistent embedding geometry.  \nTradeoffs : \n• Heavy compute and data requirements are justified by strong zero -shot \nperformance.  \n• Model complexity makes fine -tuning expensive; adapter techniques can mitigate \ncosts.  \n \nCLIP can be integrated with diffusion models for text -to-image generation  \nIntroduction:  \nCLIP can guide diffusion models either by providing conditioning e",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 14,
      "content": "pter techniques can mitigate \ncosts.  \n \nCLIP can be integrated with diffusion models for text -to-image generation  \nIntroduction:  \nCLIP can guide diffusion models either by providing conditioning embeddings or by \nacting as an external scorer to encourage semantic alignment during sampling.  \n\n--- Page 7 ---\nIntegration mechanisms & justifications:  \n1. Embedding conditioning (direct):  feed CLIP text embeddings into diffusion \nmodel (via cross -attention or concatenation).  \nDirect conditioning uses the semantic vector as part of the generative process, \nenabling the model to learn to map embeddings to visual features during training \n— the cleanest, learned integration.  \n2. CLIP guidance (external scorer / gradient guidance):  compute CLIP similarity \nof intermediate samples to the prompt and backpropagate gradients to \nnudge samples.  \n This allows a pretrained diffusion model (without conditioning) to be steered at \nsampling time; useful when retraining is expensive.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 15,
      "content": "es to the prompt and backpropagate gradients to \nnudge samples.  \n This allows a pretrained diffusion model (without conditioning) to be steered at \nsampling time; useful when retraining is expensive. It leverages CLIP’s semantic \nsignal as an online objective.  \n3. Classifier -free guidance vs CLIP scoring:  classifier -free guidance blends \nunconditional and conditional denoising; CLIP guidance explicitly optimizes \nsemantic similarity.  \nClassifier -free guidance is learned and often efficient; CLIP guidance can \nimprove semantic alignment but is computationally heavier and sometimes \nunstable, so practitioners choose based on constraints.  \n4. Hybrid approaches (fine -tune diffusion with CLIP):  fine-tune a conditional \ndiffusion model where conditioning is CLIP embeddings.  \nThis produces the most coherent integration: the generator learns to use \nembeddings during training, reducing the need for costly gradient -based steering \nat sampling time.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 16,
      "content": "ing is CLIP embeddings.  \nThis produces the most coherent integration: the generator learns to use \nembeddings during training, reducing the need for costly gradient -based steering \nat sampling time.  \nExample workflow (gradient guidance):  \nAt each sampling step, generate image x_t, compute CLIP similarity s = cosine(clip_text, \nclip_image(x_t)), compute ∇_{x_t} s and adjust x_t in direction that increases similarity, \nthen proceed to next denoising step.  \nTradeoffs : \n• Pros: CLIP guidance improves semantic fidelity and allows reusing pretrained \ndiffusion models.  \n• Cons: Extra compute (CLIP forward + gradient) and potential for adversarial \nartifacts if optimized too aggressively — justification for careful step size and \nregularization.  \n \nQ7 — Compare CLIP -guided generation vs GAN -based text -to-image methods  \n \n\n--- Page 8 ---\nComparison points & justifications:  \n1. Semantic alignment:  CLIP-guided diffusion > GANs.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 17,
      "content": "arization.  \n \nQ7 — Compare CLIP -guided generation vs GAN -based text -to-image methods  \n \n\n--- Page 8 ---\nComparison points & justifications:  \n1. Semantic alignment:  CLIP-guided diffusion > GANs.  \nJustification:  CLIP provides explicit semantic supervision via \nembeddings/scores; GANs rely on discriminator signals that emphasize \nrealism rather than semantic correctness.  \n2. Visual sharpness / texture realism:  GANs often produce sharper textures.  \nJustification:  GAN adversarial loss explicitly forces photorealistic textures; \ndiffusion models historically produced blurrier outputs (though modern \ntechniques narrowed the gap).  \n3. Training stability:  Diffusion (with CLIP) tends to be more stable than GAN \ntraining.  \nJustification:  GANs suffer from mode collapse and training instability due to \nadversarial dynamics; diffusion is likelihood -based and often converges \nmore predictably.  \n4.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 18,
      "content": "e than GAN \ntraining.  \nJustification:  GANs suffer from mode collapse and training instability due to \nadversarial dynamics; diffusion is likelihood -based and often converges \nmore predictably.  \n4. Sampling speed / compute:  GANs typically faster at inference; CLIP -guided \ndiffusion is slower.  \nJustification:  GANs generate in one forward pass; diffusion models require \nmany denoising steps; CLIP guidance adds more compute for \nscoring/gradients.  \n5. Controllability & editing:  CLIP-guided diffusion offers finer control (text, \nprompt editing).  \nJustification:  Conditioning and CLIP feedback directly influence semantics \nacross steps; GANs can be controlled via latent manipulations but mapping \nbetween latent and semantics is less direct.  \n6. Robustness to prompts:  CLIP-guided methods generalize better to open -\nended prompts.  \nJustification:  CLIP’s pretraining on broad captions provides strong semantic \ngrounding; GANs trained on limited paired data often struggle with out",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 19,
      "content": "hods generalize better to open -\nended prompts.  \nJustification:  CLIP’s pretraining on broad captions provides strong semantic \ngrounding; GANs trained on limited paired data often struggle with out -of-\ndistribution prompts.  \nUse-case recommendations (justified):  \n• For high-speed production of photoreal textures , GANs may be preferable.  \nJustification:  Fast single -pass generation with high fidelity.  \n• For semantic, creative, and controllable generation , CLIP-guided diffusion is \npreferable despite slower sampling.  \nJustification:  Better alignment to textual intent and flexibility.  \n \n\n--- Page 9 ---\nLimitation of CLIP and a detailed solution (with justifications)  \nLimitation chosen:  Bias and spurious correlations inherited from large web -scale \ntraining data.  \n• CLIP’s embeddings reflect the distribution of its training corpus; societal \nstereotypes and underrepresentation produce associations that can harm \ndownstream use (e.g.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 20,
      "content": "web -scale \ntraining data.  \n• CLIP’s embeddings reflect the distribution of its training corpus; societal \nstereotypes and underrepresentation produce associations that can harm \ndownstream use (e.g., biased retrieval or discriminatory generative outputs). In \ncritical domains (hiring, la w, medicine) these errors are unacceptable.  \nProposed multi -pronged solution : \n1. Domain-aware fine -tuning with curated datasets.  \nCurated, annotated domain data corrects label distributions and teaches the \nmodel correct associations relevant to the domain (e.g., medical labels). It \nreduces reliance on noisy web labels.  \n2. Bias mitigation during training (reweighting / adversarial debiasing).  \nReweighting or adversarial objectives discourage encoding of protected \nattributes (e.g., gender) when they’re not relevant. These methods directly \npenalize the emergence of undesirable correlations.  \n3. Counterfactual data augmentation.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 21,
      "content": "iscourage encoding of protected \nattributes (e.g., gender) when they’re not relevant. These methods directly \npenalize the emergence of undesirable correlations.  \n3. Counterfactual data augmentation.  \nGenerating or collecting balanced examples that swap sensitive attributes (e.g., \nsame profession across genders/ethnicities) reduces statistical shortcuts and \nforces the model to focus on relevant visual cues.  \n4. Evaluation & continuous monitoring (human -in-the-loop).  \nAutomated checks (fairness metrics) plus human audits detect remaining bias. \nContinuous monitoring post -deployment catches distribution shifts and \nemergent problems.  \n5. Model explanations and transparency.  \nSaliency maps or retrieval -based explanations help users understand why the \nmodel associated certain text and images, enabling corrective action.  \nExample application:  \nDeploying an e -commerce visual search: before deployment, augment training with \ndiverse product images across demographics, apply rew",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 22,
      "content": "and images, enabling corrective action.  \nExample application:  \nDeploying an e -commerce visual search: before deployment, augment training with \ndiverse product images across demographics, apply reweighting, and run fairness tests \nto ensure the model does not systematically underrepresent particular groups.  \n \n \n \n\n--- Page 10 ---\n2. CLIP AND JOINT EMBEDDINGS  \nIntroduction  \nGenerative AI has transformed the way text and visual data can be integrated to create \nnew forms of digital content. Among the leading approaches are Contrastive Language –\nImage Pretraining (CLIP)  and diffusion models , which together form a powerful pipeline \nfor text-to-image synthesis.  \nCLIP aligns language and visual modalities through joint embeddings , while diffusion \nmodels use probabilistic denoising processes  to synthesize realistic and semantically \naligned images.  \nThis integration is significant across domains like education, design, healthcare, \nentertainment, and scientific communication ,",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 23,
      "content": "processes  to synthesize realistic and semantically \naligned images.  \nThis integration is significant across domains like education, design, healthcare, \nentertainment, and scientific communication , where the ability to convert descriptions \ninto visuals  saves time, enhances creativity, and improves accessibility. However, \nensuring reliability, accuracy, and fairness requires deeper understanding of the \nmechanisms, limitations, and solutions of such systems.  \n(a) CLIP and Joint Embeddings – Mechanism and Benefits  \n1. Core Concept  \no CLIP consists of two encoders:  \n▪ A Text Encoder  (Transformer -based) processes natural language \nprompts.  \n▪ An Image Encoder  (ResNet or Vision Transformer) processes image \ndata.  \no Both outputs are projected into a shared embedding space , enabling \ncomparisons.  \n2. Contrastive Learning  \no During training, CLIP is presented with a batch of image –text pairs.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 24,
      "content": "s image \ndata.  \no Both outputs are projected into a shared embedding space , enabling \ncomparisons.  \n2. Contrastive Learning  \no During training, CLIP is presented with a batch of image –text pairs.  \no The correct image –caption pair should have a high cosine similarity , while \nincorrect pairs should score low.  \no InfoNCE loss  optimizes this by pulling true pairs closer and pushing false \npairs apart.  \n3. Why This Matters for Generation  \no When combined with diffusion models, the shared space ensures the \ngenerated image faithfully represents the meaning of the text . \n\n--- Page 11 ---\no Unlike traditional vision models limited to classification, CLIP’s \nembeddings generalize across unseen categories and abstract prompts.  \n4. Example  \no Prompt: “A panda wearing sunglasses playing guitar.”  \no CLIP embeddings capture not only the object (“panda”) but also \nattributes (“wearing sunglasses”) and context (“playing guitar”).",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 25,
      "content": ". Example  \no Prompt: “A panda wearing sunglasses playing guitar.”  \no CLIP embeddings capture not only the object (“panda”) but also \nattributes (“wearing sunglasses”) and context (“playing guitar”).  \no The diffusion model uses these embeddings to guide generation, ensuring \nall described elements appear.  \n5. Justification  \no This approach solves the problem of semantic drift , where generated \nimages deviate from text.  \no It also enables zero-shot transfer , where the model works on new \nconcepts without retraining.  \n \n(b) Noise Scheduling and Diffusion Process – Stability and Quality  \n1. Forward Diffusion (Training Stage)  \no The model learns by gradually adding Gaussian noise  to real images over \nmany steps until they become indistinguishable from random noise.  \no This corruption process teaches the system how data can be “destroyed” \nin a controlled manner.  \n2. Backward Diffusion (Generation Stage)  \no The generative model reverses the process, progressively denoising \nra",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 26,
      "content": "on process teaches the system how data can be “destroyed” \nin a controlled manner.  \n2. Backward Diffusion (Generation Stage)  \no The generative model reverses the process, progressively denoising \nrandom noise  step by step to reconstruct a meaningful image.  \no Conditioning on text embeddings ensures that the denoising follows the \nsemantic structure encoded in the prompt.  \n3. Noise Schedulers  \no Decide the rate and distribution  of noise addition/removal across \ntimesteps.  \no Common schedulers: linear, cosine, exponential decay . \no The choice affects image clarity, diversity, and fidelity . \n4. Why It Matters  \n\n--- Page 12 ---\no Too much noise at early steps → unstable generations.  \no Too little → lack of diversity.  \no A well-designed scheduler balances exploration and accuracy, leading to \nimages that are high-quality, sharp, and semantically consistent . \n5. Example  \no A poorly tuned scheduler may generate a “blurred car” for the prompt “a \nred sports car on a racetrack.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 27,
      "content": ", leading to \nimages that are high-quality, sharp, and semantically consistent . \n5. Example  \no A poorly tuned scheduler may generate a “blurred car” for the prompt “a \nred sports car on a racetrack.”  \no With proper scheduling, details like color, motion blur, and track \nbackground  are preserved.  \n6. Justification  \no Diffusion + noise scheduling ensures outputs remain reliable and artifact-\nfree, addressing weaknesses of earlier GAN -based methods which often \nsuffered from mode collapse.  \n(c) Ensuring Accuracy with Fine -Tuning – Overcoming Hallucinations  \n1. The Challenge  \no Generative models, when trained on generic internet data, may produce \nimages that are visually appealing but scientifically or contextually \ninaccurate . \no Risk of “hallucination” (adding irrelevant objects) or oversimplification.  \n2. Role of Fine -Tuning  \no Fine-tuning adapts pretrained models to specific domains  using curated \ndatasets.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 28,
      "content": "ccurate . \no Risk of “hallucination” (adding irrelevant objects) or oversimplification.  \n2. Role of Fine -Tuning  \no Fine-tuning adapts pretrained models to specific domains  using curated \ndatasets.  \no Adjusts weights so the model captures domain -specific semantics and \navoids irrelevant associations.  \n3. Methods  \no Full fine-tuning: Retrain on specialized datasets (e.g., radiology images, \nengineering diagrams).  \no Adapter/LoRA tuning : Lightweight layers added for efficient adaptation.  \no Prompt-tuning: Adding domain -specific tokens or context.  \n4. Example  \no Generic model → “DNA double helix” may produce artistic swirls.  \n\n--- Page 13 ---\no Fine-tuned model on biology diagrams → generates precise base pairs and \nmolecular structure . \n5. Justification  \no Fine-tuning improves factual accuracy . \no Reduces domain mismatch, making outputs trustworthy in professional \nor academic settings.  \no Supports applications where error tolerance is low  (e.g.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 29,
      "content": "o Fine-tuning improves factual accuracy . \no Reduces domain mismatch, making outputs trustworthy in professional \nor academic settings.  \no Supports applications where error tolerance is low  (e.g., medicine, \nengineering, education).  \n(d) Limitations of CLIP and Solutions  \n1. Limitations  \no Bias and Fairness : CLIP inherits social and cultural biases from web data.  \no Ambiguity Handling : Struggles when prompts are vague (“a beautiful \nscene”) or multi -layered.  \no Domain Gaps : Lacks accuracy in highly technical or specialized areas.  \no Computational Cost : Joint text -image training and inference are resource -\nintensive.  \n2. Possible Solutions  \no Bias Mitigation : Curate balanced datasets, use fairness -aware training, \nand adversarial debiasing.  \no Prompt Engineering : Rephrase prompts to be specific, reducing \nambiguity.  \no Domain Adaptation : Use fine -tuning, adapters, or hybrid models for niche \ntasks.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 30,
      "content": "ining, \nand adversarial debiasing.  \no Prompt Engineering : Rephrase prompts to be specific, reducing \nambiguity.  \no Domain Adaptation : Use fine -tuning, adapters, or hybrid models for niche \ntasks.  \no Human-in-the-Loop Evaluation : Incorporate expert feedback to validate \noutputs.  \n3. Example  \no Prompt: “A doctor”  may disproportionately generate male figures due to \nbiased training data.  \no Mitigation: Fine -tuning with balanced datasets ensures diverse \nrepresentations.  \n4. Justification  \n\n--- Page 14 ---\no Without addressing these issues, the trustworthiness and adoption of \nCLIP-based systems may be limited.  \no Solutions ensure outputs remain inclusive, accurate, and ethically \ndeployable . \n \nThe integration of CLIP and diffusion models represents a paradigm shift in multimodal \nAI, enabling systems to understand and generate complex visual representations from \nnatural language.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 31,
      "content": "able . \n \nThe integration of CLIP and diffusion models represents a paradigm shift in multimodal \nAI, enabling systems to understand and generate complex visual representations from \nnatural language.  \nCLIP ensures semantic alignment  through joint embeddings, while diffusion models \nguarantee stability and quality  via noise scheduling and denoising processes.  \nFine-tuning resolves the issue of accuracy and domain specificity , while awareness of \nCLIP’s limitations (biases, ambiguity, domain gaps) and corrective solutions ensures \ntrustworthy deployment . In essence, the synergy between CLIP and diffusion models \nforms a robust, flexible, and scalable framework  for multimodal content creation, \ncapable of serving both general and highly specialized applications.  \n3. CLIP with diffusion mode ls \nIntroduction  \nText-to-image generation has become one of the most exciting advancements in \nartificial intelligence.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 32,
      "content": "oth general and highly specialized applications.  \n3. CLIP with diffusion mode ls \nIntroduction  \nText-to-image generation has become one of the most exciting advancements in \nartificial intelligence. By combining CLIP (Contrastive Language –Image Pretraining)  \nwith diffusion models , systems can generate images that accurately reflect user \ndescriptions. CLIP provides a bridge between language and vision, aligning text prompts \nwith visual features, while diffusion models create high -quality, coherent outputs \nthrough a noise -to-image process. Together, they enable applications ranging from \ncreative design and education to healthcare and entertainment.  \n(a) Architecture of CLIP – Connecting Text and Visuals  \n1. Dual Encoder System  \no CLIP consists of a text encoder  (Transformer -based) and an image \nencoder  (Vision Transformer or CNN).  \no Both map their inputs into feature vectors . \n2.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 33,
      "content": "and Visuals  \n1. Dual Encoder System  \no CLIP consists of a text encoder  (Transformer -based) and an image \nencoder  (Vision Transformer or CNN).  \no Both map their inputs into feature vectors . \n2. Shared Semantic Space  \no Text and image embeddings are projected into a joint latent space  where \nsimilarity is measured.  \no Training uses contrastive learning : matching text –image pairs are pulled \ncloser, mismatched ones pushed apart.  \n\n--- Page 15 ---\n3. Outcome  \no This allows CLIP to capture not just objects but also attributes, context, \nand relationships . \no For example, the phrase “bright red car on a snowy road”  aligns with \nimages showing both the car and the setting.  \n4. Significance  \no These joint embeddings are crucial for guiding generative models so that \noutputs remain semantically aligned  with textual descriptions.  \n(b) Text-Guided Stable Diffusion – The Generation Process  \n1.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 34,
      "content": "ese joint embeddings are crucial for guiding generative models so that \noutputs remain semantically aligned  with textual descriptions.  \n(b) Text-Guided Stable Diffusion – The Generation Process  \n1. Forward Diffusion  \no Real images are progressively noised until they become indistinguishable \nrandom noise.  \n2. Backward Diffusion (Denoising)  \no The model learns to reverse this process: starting from noise, it generates \nan image step by step.  \n3. Conditioning with CLIP  \no The embeddings from CLIP are injected into the backward process as \nguidance signals . \no This ensures that the generated image reflects the semantic meaning of \nthe text prompt . \n4. Noise Scheduling  \no Proper noise scheduling regulates how much detail is added at each step, \npreventing artifacts and improving stability.  \n5. Why It Works  \no Diffusion models combined with CLIP generate stable, realistic, and \nprompt-aligned visuals , outperforming earlier GAN -based approaches \nthat often struggled with fine",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 35,
      "content": "bility.  \n5. Why It Works  \no Diffusion models combined with CLIP generate stable, realistic, and \nprompt-aligned visuals , outperforming earlier GAN -based approaches \nthat often struggled with fine details.  \n (c) Fine-Tuning for Domain -Specific Applications  \n1. Need for Fine -Tuning  \no Base CLIP and diffusion models are trained on broad internet data, which \nmay not cover specialized domains well.  \n\n--- Page 16 ---\n2. Process  \no Fine-tuning involves training or adapting the model with domain-specific \nprompts or datasets . \no Example: In medicine, fine -tuning ensures that a description like “X-ray \nshowing lung opacity”  produces medically accurate images.  \n3. Benefits  \no Enhances accuracy  (outputs match technical details).  \no Improves aesthetic or contextual relevance  (outputs suit the domain \nstyle).  \no Reduces biases and errors  from general -purpose training.  \n4. Justification  \no Without fine -tuning, models may produce outputs that are visually \nplausible but fact",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 36,
      "content": "ts suit the domain \nstyle).  \no Reduces biases and errors  from general -purpose training.  \n4. Justification  \no Without fine -tuning, models may produce outputs that are visually \nplausible but factually incorrect. Domain adaptation ensures trustworthy \nand useful results . \n(d) Evaluation Metrics for Text –Image Alignment  \n1. Quantitative Metrics  \no CLIPScore : Measures similarity between generated image embeddings \nand prompt embeddings.  \no FID (Fréchet Inception Distance) : Evaluates image quality by comparing \ngenerated and real data distributions.  \no IS (Inception Score) : Measures diversity and realism of generated \nimages.  \n2. Qualitative Metrics  \no Human evaluation : Users judge whether images align with descriptions.  \no Task-based evaluation : Checking how well generated outputs support \ndownstream tasks (e.g., retrieval, classification).  \n3. Balanced Evaluation  \no A mix of automated and human assessments ensures both objective \naccuracy  and subjective quality  are",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 37,
      "content": "outputs support \ndownstream tasks (e.g., retrieval, classification).  \n3. Balanced Evaluation  \no A mix of automated and human assessments ensures both objective \naccuracy  and subjective quality  are measured.  \n4. Significance  \n\n--- Page 17 ---\no Robust evaluation is critical to confirm that the system produces outputs \nthat are reliable, meaningful, and user -aligned. \nConclusion  \nBy integrating CLIP embeddings  with diffusion -based generation , AI systems achieve \naccurate text -to-image synthesis. CLIP ensures semantic alignment, diffusion \nguarantees high visual fidelity, fine -tuning adapts models to specialized domains, and \nevaluation metrics confirm performance. This synergy represents a power ful paradigm \nfor multimodal AI, enabling diverse applications where reliable translation of language \ninto images is essential.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmprvm4fu_o_UNIT II - GCV.pdf_bf6575c5_b24ae166",
      "chunk_index": 38,
      "content": "ation of language \ninto images is essential.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nUnit II \nCLIP (Contrastive Language –Image Pretraining)  \nCLIP (Contrastive Language –Image Pretraining) learns a joint text –image embedding \nspace by using contrastive learning to bring matching image –text pairs close and push \nnon-matching pairs apart.  \nKey points & justifications:  \n1. Dual encoders (text & image) mapped to a shared space.  \nJustification:  Mapping both modalities into the same vector space makes direct \nsimilarity computations (cosine similarity) possible. This design simplifies \ndownstream tasks (retrieval, zero -shot classification) because the model does \nnot have to learn task -specific cros s-modal projections every time — the shared \nspace is a reusable interface.  \n2. Contrastive (InfoNCE) loss pulls positives and pushes negatives.  \nJustification:  InfoNCE directly optimizes relative similarity: maximizing similarity \nof correct pairs while minimizing similarity of incorrect pairs.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 1,
      "content": "CE) loss pulls positives and pushes negatives.  \nJustification:  InfoNCE directly optimizes relative similarity: maximizing similarity \nof correct pairs while minimizing similarity of incorrect pairs. This encourages \nembeddings to capture semantics that distinguish correct captions from \ndistractors, which is precisely w hat cross -modal tasks require.  \n3. Large batch / many negatives improve representation quality.  \nJustification:  More negatives increase the difficulty of the contrastive task, \nforcing embeddings to capture fine -grained distinctions. Empirically large \neffective batch sizes (or memory banks) create stronger supervision signals, \nproducing richer semantic structure.  \n4. Enables zero -shot transfer and robust retrieval.  \nJustification:  Because CLIP learns general alignment between text concepts and \nvisual features, it can map a new text label into the same space and retrieve \nrelevant images without task -specific retraining — the learned semantic \ngeometry gen",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 2,
      "content": "ignment between text concepts and \nvisual features, it can map a new text label into the same space and retrieve \nrelevant images without task -specific retraining — the learned semantic \ngeometry generalizes.  \nExample:  \nImage: “a red bicycle on a rainy street.” CLIP will place the image embedding near \ncaptions describing bicycles/rain, and far from unrelated captions (e.g., “a dog in a \npark”).  \nApplications & justification:  \n• Zero-shot classification:  No fine-tuning needed because class names can be \nembedded and compared to images.  \nJustification:  The shared semantic space means class semantics are already \nencoded.  \n\n--- Page 2 ---\n• Text-guided retrieval and generation:  CLIP scores can rank generated images or \nguide generative models.  \nJustification:  Direct similarity metrics allow automatic evaluation and steering.  \nText embeddings in multimodal diffusion models  \nText embeddings convert a prompt into a dense vector that conditions diffusion models, \nguiding stocha",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 3,
      "content": "trics allow automatic evaluation and steering.  \nText embeddings in multimodal diffusion models  \nText embeddings convert a prompt into a dense vector that conditions diffusion models, \nguiding stochastic denoising toward images that match the text.  \nKey points & justifications:  \n1. Serve as conditioning signal during denoising.  \nDiffusion models generate by reversing noise; conditioning vectors are injected \n(via concatenation, cross -attention, or FiLM) so each denoising step has \nsemantic context. Without conditioning, the model has no way to steer \ngeneration toward the desired sem antics.  \n2. Capture both object and style attributes.  \nModern text encoders (Transformers) represent not just nouns but adjectives, \nrelations, and style descriptors. Embeddings therefore allow the generator to \nsynthesize content (objects) and aesthetic (style) simultaneously.  \n3. Enable fine controls (compositional prompts, modifiers).",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 4,
      "content": "ns, and style descriptors. Embeddings therefore allow the generator to \nsynthesize content (objects) and aesthetic (style) simultaneously.  \n3. Enable fine controls (compositional prompts, modifiers).  \n Vector arithmetic and attention let the model weight different subcomponents \nof the prompt; e.g., “photorealistic” vs “oil painting” map to different embedding \ndirections, producing controlled stylistic outcomes.  \n4. Facilitate semantic consistency across steps.  \nConditioning every denoising step (rather than only at start) ensures semantic \ninformation persists through the stochastic sampling, preventing drift to \nirrelevant modes.  \nExample:  \nPrompt: “A small wooden cabin at sunset, misty atmosphere.” The embedding encodes \nobject (“cabin”), material (“wooden”), time (“sunset”), and mood (“misty”) so the \ndiffusion model composes these attributes coherently.  \nApplications & justification:  \n• Text-to-image (Stable Diffusion):  Embeddings let a single model produce \ndiverse outp",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 5,
      "content": "mood (“misty”) so the \ndiffusion model composes these attributes coherently.  \nApplications & justification:  \n• Text-to-image (Stable Diffusion):  Embeddings let a single model produce \ndiverse outputs from many prompts.  \nA single learned forward/backward process can be reused with different \ncondition vectors.  \n\n--- Page 3 ---\n• Prompt interpolation and editing:  Embeddings allow latent manipulations \n(e.g., amplify “sunset”) to edit outputs.  \nContinuous embeddings provide smooth control that discrete labels cannot.  \nCritical insight / limitation  \nIf embeddings lack domain knowledge or are ambiguous, generation will be \nsemantically weak. Therefore, high -quality text encoders and, when needed, domain -\nspecific embedding fine -tuning are essential.  \nCommon evaluation metrics for text –image alignment  \nEvaluating multimodal generation requires metrics that measure both visual quality  and \nsemantic alignment  between text and image.  \nMetrics & justifications:  \n1.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 6,
      "content": "etrics for text –image alignment  \nEvaluating multimodal generation requires metrics that measure both visual quality  and \nsemantic alignment  between text and image.  \nMetrics & justifications:  \n1. CLIPScore (cosine similarity of CLIP embeddings).  \nWhat it measures:  Semantic alignment between generated image and \nprompt.  \nCLIP is trained to align modalities; its cosine similarity is a direct proxy for how \nwell image content matches textual semantics. It’s automatic and correlates \nreasonably with human judgments for many prompts.  \n2. FID (Fréchet Inception Distance).  \nWhat it measures:  Distributional similarity between generated images and \nreal images.  \nFID captures both quality and diversity by comparing feature statistics (means, \ncovariances). Lower FID implies generated images occupy similar manifold to \nreal images.  \n3. Inception Score (IS).  \nWhat it measures: Distinctiveness and confidence of generated images (via \nan Inception classifier).",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 7,
      "content": "FID implies generated images occupy similar manifold to \nreal images.  \n3. Inception Score (IS).  \nWhat it measures: Distinctiveness and confidence of generated images (via \nan Inception classifier).  \nIS rewards samples that are recognizable and varied; however it doesn’t \nmeasure prompt alignment.  \n4. Human evaluation (relevance, fidelity, preference).  \nWhat it measures:  Subjective semantic correctness and visual appeal.  \nAutomated metrics are imperfect, so human judgment remains the gold \nstandard, especially for nuanced or creative prompts.  \n5. Task-specific metrics (precision/recall on objects, detection mAP).  \nWhen prompts require specific objects or relations, applying object detectors \nand measuring precision/recall quantifies functional correctness.  \n\n--- Page 4 ---\nCombining metrics — justification:  \nNo single metric captures all aspects. CLIPScore checks alignment but not realism; FID \nchecks realism but not prompt adherence.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 8,
      "content": "nal correctness.  \n\n--- Page 4 ---\nCombining metrics — justification:  \nNo single metric captures all aspects. CLIPScore checks alignment but not realism; FID \nchecks realism but not prompt adherence. Combining metrics plus human checks \nproduces more reliable evaluation.  \nLimitations : \nCLIPScore can be gamed (adversarially optimized); FID is sensitive to dataset choice \nand model used for features. Thus metric selection should align with evaluation goals \nand be interpreted carefully.  \n \nFine-tuning CLIP  \nIntroduction:  \nPretrained CLIP is broad but not deep in domain -specific semantics; fine -tuning adapts \nit to specialized vocabularies, visual cues, and biases of a target domain.  \nKey points & justifications:  \n1. Bridging domain vocabulary gaps.  \nCLIP’s internet training may underrepresent domain terms (medical labels, \nindustrial parts). Fine -tuning with domain captions teaches the text encoder \ndomain semantics and aligns them to visual cues in that field.  \n2.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 9,
      "content": "ing may underrepresent domain terms (medical labels, \nindustrial parts). Fine -tuning with domain captions teaches the text encoder \ndomain semantics and aligns them to visual cues in that field.  \n2. Improving visual feature sensitivity to domain specifics.  \nFine-tuning the image encoder helps it attend to subtle diagnostic visual features \n(e.g., microcalcifications) that general models may deem irrelevant.  \n3. Reducing harmful biases and spurious correlations.  \nDomain curation can balance datasets and remove stereotypes present in \ninternet data, improving fairness and factual accuracy in sensitive contexts.  \n4. Better downstream task performance (retrieval, VQA, diagnostics).  \nFine-tuned embeddings yield higher retrieval precision and more accurate VQA \nanswers because they encode task -relevant features.  \nPractical methods & justifications:  \n• Full fine-tuning: update all weights — best for abundant labels.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 10,
      "content": "trieval precision and more accurate VQA \nanswers because they encode task -relevant features.  \nPractical methods & justifications:  \n• Full fine-tuning: update all weights — best for abundant labels.  \nAllows maximal adaptation but risks catastrophic forgetting and needs data/GPU \nresources.  \n• Adapter modules / LoRA / prompt tuning:  lightweight adjustments.  \n Preserve pretrained knowledge while cheaply adapting to domain; less risk of \nforgetting and cheaper to train.  \n\n--- Page 5 ---\n• Continual learning / regularization:  e.g., Elastic Weight Consolidation to \nprevent forgetting.  \nMaintains general CLIP capabilities while learning domain specifics.  \nExample:  \nFine-tuning CLIP on annotated chest X -rays (labels, radiologist captions) yields \nimproved retrieval and VQA performance for radiology tasks because the model learns \nto associate radiographic patterns with domain terms.  \n \nFine-tuning requires curated, representative, and labeled domain data; otherwise you \nrisk over",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 11,
      "content": "for radiology tasks because the model learns \nto associate radiographic patterns with domain terms.  \n \nFine-tuning requires curated, representative, and labeled domain data; otherwise you \nrisk overfitting or preserving harmful biases. Validation and human oversight are \nessential.  \n \nArchitecture of CLIP and joint learning  \nIntroduction:  \nCLIP uses separate encoders for images and text, projection heads to a common \nembedding space, and contrastive training to jointly learn aligned representations.  \n \nArchitecture components & justifications:  \n1. Image encoder (ViT or ResNet).  \nCNNs (ResNet) capture local textures; ViTs capture long -range interactions. \n\n\n--- Page 6 ---\nChoice depends on tradeoffs (compute vs performance). Both produce rich \nvisual features for projection.  \n2. Text encoder (Transformer).  \n Transformers model sequential and contextual language semantics effectively, \nenabling capture of compositional meaning (modifiers, relations).  \n3.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 12,
      "content": "for projection.  \n2. Text encoder (Transformer).  \n Transformers model sequential and contextual language semantics effectively, \nenabling capture of compositional meaning (modifiers, relations).  \n3. Projection heads (linear layers) mapping to shared space.  \nSeparate high -dim features are projected to a common dimensionality so cosine \nsimilarity is meaningful; projection can also adapt modality -specific statistics.  \n4. Contrastive (InfoNCE) training with large effective batch size.  \nMany negatives help the model learn fine distinctions. Training with symmetric \nloss (image→text and text→image) strengthens bidirectional retrieval capability.  \n5. Temperature scaling in contrastive loss.  \n Temperature controls concentration of similarity distribution; tuning it balances \nsensitivity between positive/negative pairs.  \nWhy this design works ? \n• Separate encoders let each modality use architectures tailored to its inductive \nbiases, yet the projection + contrastive loss forces sema",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 13,
      "content": "between positive/negative pairs.  \nWhy this design works ? \n• Separate encoders let each modality use architectures tailored to its inductive \nbiases, yet the projection + contrastive loss forces semantic alignment without \nmerging architectures (which would be less flexible).  \n• Large paired datasets provide diverse supervision so the embedding geometry \ngeneralizes across many concepts.  \nExample:  \nDuring training a batch of image -caption pairs, each image’s closest embedding should \nbe its caption’s embedding. The symmetric contrastive loss enforces this across all \nbatch pairs, producing a globally consistent embedding geometry.  \nTradeoffs : \n• Heavy compute and data requirements are justified by strong zero -shot \nperformance.  \n• Model complexity makes fine -tuning expensive; adapter techniques can mitigate \ncosts.  \n \nCLIP can be integrated with diffusion models for text -to-image generation  \nIntroduction:  \nCLIP can guide diffusion models either by providing conditioning e",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 14,
      "content": "pter techniques can mitigate \ncosts.  \n \nCLIP can be integrated with diffusion models for text -to-image generation  \nIntroduction:  \nCLIP can guide diffusion models either by providing conditioning embeddings or by \nacting as an external scorer to encourage semantic alignment during sampling.  \n\n--- Page 7 ---\nIntegration mechanisms & justifications:  \n1. Embedding conditioning (direct):  feed CLIP text embeddings into diffusion \nmodel (via cross -attention or concatenation).  \nDirect conditioning uses the semantic vector as part of the generative process, \nenabling the model to learn to map embeddings to visual features during training \n— the cleanest, learned integration.  \n2. CLIP guidance (external scorer / gradient guidance):  compute CLIP similarity \nof intermediate samples to the prompt and backpropagate gradients to \nnudge samples.  \n This allows a pretrained diffusion model (without conditioning) to be steered at \nsampling time; useful when retraining is expensive.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 15,
      "content": "es to the prompt and backpropagate gradients to \nnudge samples.  \n This allows a pretrained diffusion model (without conditioning) to be steered at \nsampling time; useful when retraining is expensive. It leverages CLIP’s semantic \nsignal as an online objective.  \n3. Classifier -free guidance vs CLIP scoring:  classifier -free guidance blends \nunconditional and conditional denoising; CLIP guidance explicitly optimizes \nsemantic similarity.  \nClassifier -free guidance is learned and often efficient; CLIP guidance can \nimprove semantic alignment but is computationally heavier and sometimes \nunstable, so practitioners choose based on constraints.  \n4. Hybrid approaches (fine -tune diffusion with CLIP):  fine-tune a conditional \ndiffusion model where conditioning is CLIP embeddings.  \nThis produces the most coherent integration: the generator learns to use \nembeddings during training, reducing the need for costly gradient -based steering \nat sampling time.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 16,
      "content": "ing is CLIP embeddings.  \nThis produces the most coherent integration: the generator learns to use \nembeddings during training, reducing the need for costly gradient -based steering \nat sampling time.  \nExample workflow (gradient guidance):  \nAt each sampling step, generate image x_t, compute CLIP similarity s = cosine(clip_text, \nclip_image(x_t)), compute ∇_{x_t} s and adjust x_t in direction that increases similarity, \nthen proceed to next denoising step.  \nTradeoffs : \n• Pros: CLIP guidance improves semantic fidelity and allows reusing pretrained \ndiffusion models.  \n• Cons: Extra compute (CLIP forward + gradient) and potential for adversarial \nartifacts if optimized too aggressively — justification for careful step size and \nregularization.  \n \nQ7 — Compare CLIP -guided generation vs GAN -based text -to-image methods  \n \n\n--- Page 8 ---\nComparison points & justifications:  \n1. Semantic alignment:  CLIP-guided diffusion > GANs.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 17,
      "content": "arization.  \n \nQ7 — Compare CLIP -guided generation vs GAN -based text -to-image methods  \n \n\n--- Page 8 ---\nComparison points & justifications:  \n1. Semantic alignment:  CLIP-guided diffusion > GANs.  \nJustification:  CLIP provides explicit semantic supervision via \nembeddings/scores; GANs rely on discriminator signals that emphasize \nrealism rather than semantic correctness.  \n2. Visual sharpness / texture realism:  GANs often produce sharper textures.  \nJustification:  GAN adversarial loss explicitly forces photorealistic textures; \ndiffusion models historically produced blurrier outputs (though modern \ntechniques narrowed the gap).  \n3. Training stability:  Diffusion (with CLIP) tends to be more stable than GAN \ntraining.  \nJustification:  GANs suffer from mode collapse and training instability due to \nadversarial dynamics; diffusion is likelihood -based and often converges \nmore predictably.  \n4.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 18,
      "content": "e than GAN \ntraining.  \nJustification:  GANs suffer from mode collapse and training instability due to \nadversarial dynamics; diffusion is likelihood -based and often converges \nmore predictably.  \n4. Sampling speed / compute:  GANs typically faster at inference; CLIP -guided \ndiffusion is slower.  \nJustification:  GANs generate in one forward pass; diffusion models require \nmany denoising steps; CLIP guidance adds more compute for \nscoring/gradients.  \n5. Controllability & editing:  CLIP-guided diffusion offers finer control (text, \nprompt editing).  \nJustification:  Conditioning and CLIP feedback directly influence semantics \nacross steps; GANs can be controlled via latent manipulations but mapping \nbetween latent and semantics is less direct.  \n6. Robustness to prompts:  CLIP-guided methods generalize better to open -\nended prompts.  \nJustification:  CLIP’s pretraining on broad captions provides strong semantic \ngrounding; GANs trained on limited paired data often struggle with out",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 19,
      "content": "hods generalize better to open -\nended prompts.  \nJustification:  CLIP’s pretraining on broad captions provides strong semantic \ngrounding; GANs trained on limited paired data often struggle with out -of-\ndistribution prompts.  \nUse-case recommendations (justified):  \n• For high-speed production of photoreal textures , GANs may be preferable.  \nJustification:  Fast single -pass generation with high fidelity.  \n• For semantic, creative, and controllable generation , CLIP-guided diffusion is \npreferable despite slower sampling.  \nJustification:  Better alignment to textual intent and flexibility.  \n \n\n--- Page 9 ---\nLimitation of CLIP and a detailed solution (with justifications)  \nLimitation chosen:  Bias and spurious correlations inherited from large web -scale \ntraining data.  \n• CLIP’s embeddings reflect the distribution of its training corpus; societal \nstereotypes and underrepresentation produce associations that can harm \ndownstream use (e.g.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 20,
      "content": "web -scale \ntraining data.  \n• CLIP’s embeddings reflect the distribution of its training corpus; societal \nstereotypes and underrepresentation produce associations that can harm \ndownstream use (e.g., biased retrieval or discriminatory generative outputs). In \ncritical domains (hiring, la w, medicine) these errors are unacceptable.  \nProposed multi -pronged solution : \n1. Domain-aware fine -tuning with curated datasets.  \nCurated, annotated domain data corrects label distributions and teaches the \nmodel correct associations relevant to the domain (e.g., medical labels). It \nreduces reliance on noisy web labels.  \n2. Bias mitigation during training (reweighting / adversarial debiasing).  \nReweighting or adversarial objectives discourage encoding of protected \nattributes (e.g., gender) when they’re not relevant. These methods directly \npenalize the emergence of undesirable correlations.  \n3. Counterfactual data augmentation.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 21,
      "content": "iscourage encoding of protected \nattributes (e.g., gender) when they’re not relevant. These methods directly \npenalize the emergence of undesirable correlations.  \n3. Counterfactual data augmentation.  \nGenerating or collecting balanced examples that swap sensitive attributes (e.g., \nsame profession across genders/ethnicities) reduces statistical shortcuts and \nforces the model to focus on relevant visual cues.  \n4. Evaluation & continuous monitoring (human -in-the-loop).  \nAutomated checks (fairness metrics) plus human audits detect remaining bias. \nContinuous monitoring post -deployment catches distribution shifts and \nemergent problems.  \n5. Model explanations and transparency.  \nSaliency maps or retrieval -based explanations help users understand why the \nmodel associated certain text and images, enabling corrective action.  \nExample application:  \nDeploying an e -commerce visual search: before deployment, augment training with \ndiverse product images across demographics, apply rew",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 22,
      "content": "and images, enabling corrective action.  \nExample application:  \nDeploying an e -commerce visual search: before deployment, augment training with \ndiverse product images across demographics, apply reweighting, and run fairness tests \nto ensure the model does not systematically underrepresent particular groups.  \n \n \n \n\n--- Page 10 ---\n2. CLIP AND JOINT EMBEDDINGS  \nIntroduction  \nGenerative AI has transformed the way text and visual data can be integrated to create \nnew forms of digital content. Among the leading approaches are Contrastive Language –\nImage Pretraining (CLIP)  and diffusion models , which together form a powerful pipeline \nfor text-to-image synthesis.  \nCLIP aligns language and visual modalities through joint embeddings , while diffusion \nmodels use probabilistic denoising processes  to synthesize realistic and semantically \naligned images.  \nThis integration is significant across domains like education, design, healthcare, \nentertainment, and scientific communication ,",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 23,
      "content": "processes  to synthesize realistic and semantically \naligned images.  \nThis integration is significant across domains like education, design, healthcare, \nentertainment, and scientific communication , where the ability to convert descriptions \ninto visuals  saves time, enhances creativity, and improves accessibility. However, \nensuring reliability, accuracy, and fairness requires deeper understanding of the \nmechanisms, limitations, and solutions of such systems.  \n(a) CLIP and Joint Embeddings – Mechanism and Benefits  \n1. Core Concept  \no CLIP consists of two encoders:  \n▪ A Text Encoder  (Transformer -based) processes natural language \nprompts.  \n▪ An Image Encoder  (ResNet or Vision Transformer) processes image \ndata.  \no Both outputs are projected into a shared embedding space , enabling \ncomparisons.  \n2. Contrastive Learning  \no During training, CLIP is presented with a batch of image –text pairs.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 24,
      "content": "s image \ndata.  \no Both outputs are projected into a shared embedding space , enabling \ncomparisons.  \n2. Contrastive Learning  \no During training, CLIP is presented with a batch of image –text pairs.  \no The correct image –caption pair should have a high cosine similarity , while \nincorrect pairs should score low.  \no InfoNCE loss  optimizes this by pulling true pairs closer and pushing false \npairs apart.  \n3. Why This Matters for Generation  \no When combined with diffusion models, the shared space ensures the \ngenerated image faithfully represents the meaning of the text . \n\n--- Page 11 ---\no Unlike traditional vision models limited to classification, CLIP’s \nembeddings generalize across unseen categories and abstract prompts.  \n4. Example  \no Prompt: “A panda wearing sunglasses playing guitar.”  \no CLIP embeddings capture not only the object (“panda”) but also \nattributes (“wearing sunglasses”) and context (“playing guitar”).",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 25,
      "content": ". Example  \no Prompt: “A panda wearing sunglasses playing guitar.”  \no CLIP embeddings capture not only the object (“panda”) but also \nattributes (“wearing sunglasses”) and context (“playing guitar”).  \no The diffusion model uses these embeddings to guide generation, ensuring \nall described elements appear.  \n5. Justification  \no This approach solves the problem of semantic drift , where generated \nimages deviate from text.  \no It also enables zero-shot transfer , where the model works on new \nconcepts without retraining.  \n \n(b) Noise Scheduling and Diffusion Process – Stability and Quality  \n1. Forward Diffusion (Training Stage)  \no The model learns by gradually adding Gaussian noise  to real images over \nmany steps until they become indistinguishable from random noise.  \no This corruption process teaches the system how data can be “destroyed” \nin a controlled manner.  \n2. Backward Diffusion (Generation Stage)  \no The generative model reverses the process, progressively denoising \nra",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 26,
      "content": "on process teaches the system how data can be “destroyed” \nin a controlled manner.  \n2. Backward Diffusion (Generation Stage)  \no The generative model reverses the process, progressively denoising \nrandom noise  step by step to reconstruct a meaningful image.  \no Conditioning on text embeddings ensures that the denoising follows the \nsemantic structure encoded in the prompt.  \n3. Noise Schedulers  \no Decide the rate and distribution  of noise addition/removal across \ntimesteps.  \no Common schedulers: linear, cosine, exponential decay . \no The choice affects image clarity, diversity, and fidelity . \n4. Why It Matters  \n\n--- Page 12 ---\no Too much noise at early steps → unstable generations.  \no Too little → lack of diversity.  \no A well-designed scheduler balances exploration and accuracy, leading to \nimages that are high-quality, sharp, and semantically consistent . \n5. Example  \no A poorly tuned scheduler may generate a “blurred car” for the prompt “a \nred sports car on a racetrack.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 27,
      "content": ", leading to \nimages that are high-quality, sharp, and semantically consistent . \n5. Example  \no A poorly tuned scheduler may generate a “blurred car” for the prompt “a \nred sports car on a racetrack.”  \no With proper scheduling, details like color, motion blur, and track \nbackground  are preserved.  \n6. Justification  \no Diffusion + noise scheduling ensures outputs remain reliable and artifact-\nfree, addressing weaknesses of earlier GAN -based methods which often \nsuffered from mode collapse.  \n(c) Ensuring Accuracy with Fine -Tuning – Overcoming Hallucinations  \n1. The Challenge  \no Generative models, when trained on generic internet data, may produce \nimages that are visually appealing but scientifically or contextually \ninaccurate . \no Risk of “hallucination” (adding irrelevant objects) or oversimplification.  \n2. Role of Fine -Tuning  \no Fine-tuning adapts pretrained models to specific domains  using curated \ndatasets.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 28,
      "content": "ccurate . \no Risk of “hallucination” (adding irrelevant objects) or oversimplification.  \n2. Role of Fine -Tuning  \no Fine-tuning adapts pretrained models to specific domains  using curated \ndatasets.  \no Adjusts weights so the model captures domain -specific semantics and \navoids irrelevant associations.  \n3. Methods  \no Full fine-tuning: Retrain on specialized datasets (e.g., radiology images, \nengineering diagrams).  \no Adapter/LoRA tuning : Lightweight layers added for efficient adaptation.  \no Prompt-tuning: Adding domain -specific tokens or context.  \n4. Example  \no Generic model → “DNA double helix” may produce artistic swirls.  \n\n--- Page 13 ---\no Fine-tuned model on biology diagrams → generates precise base pairs and \nmolecular structure . \n5. Justification  \no Fine-tuning improves factual accuracy . \no Reduces domain mismatch, making outputs trustworthy in professional \nor academic settings.  \no Supports applications where error tolerance is low  (e.g.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 29,
      "content": "o Fine-tuning improves factual accuracy . \no Reduces domain mismatch, making outputs trustworthy in professional \nor academic settings.  \no Supports applications where error tolerance is low  (e.g., medicine, \nengineering, education).  \n(d) Limitations of CLIP and Solutions  \n1. Limitations  \no Bias and Fairness : CLIP inherits social and cultural biases from web data.  \no Ambiguity Handling : Struggles when prompts are vague (“a beautiful \nscene”) or multi -layered.  \no Domain Gaps : Lacks accuracy in highly technical or specialized areas.  \no Computational Cost : Joint text -image training and inference are resource -\nintensive.  \n2. Possible Solutions  \no Bias Mitigation : Curate balanced datasets, use fairness -aware training, \nand adversarial debiasing.  \no Prompt Engineering : Rephrase prompts to be specific, reducing \nambiguity.  \no Domain Adaptation : Use fine -tuning, adapters, or hybrid models for niche \ntasks.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 30,
      "content": "ining, \nand adversarial debiasing.  \no Prompt Engineering : Rephrase prompts to be specific, reducing \nambiguity.  \no Domain Adaptation : Use fine -tuning, adapters, or hybrid models for niche \ntasks.  \no Human-in-the-Loop Evaluation : Incorporate expert feedback to validate \noutputs.  \n3. Example  \no Prompt: “A doctor”  may disproportionately generate male figures due to \nbiased training data.  \no Mitigation: Fine -tuning with balanced datasets ensures diverse \nrepresentations.  \n4. Justification  \n\n--- Page 14 ---\no Without addressing these issues, the trustworthiness and adoption of \nCLIP-based systems may be limited.  \no Solutions ensure outputs remain inclusive, accurate, and ethically \ndeployable . \n \nThe integration of CLIP and diffusion models represents a paradigm shift in multimodal \nAI, enabling systems to understand and generate complex visual representations from \nnatural language.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 31,
      "content": "able . \n \nThe integration of CLIP and diffusion models represents a paradigm shift in multimodal \nAI, enabling systems to understand and generate complex visual representations from \nnatural language.  \nCLIP ensures semantic alignment  through joint embeddings, while diffusion models \nguarantee stability and quality  via noise scheduling and denoising processes.  \nFine-tuning resolves the issue of accuracy and domain specificity , while awareness of \nCLIP’s limitations (biases, ambiguity, domain gaps) and corrective solutions ensures \ntrustworthy deployment . In essence, the synergy between CLIP and diffusion models \nforms a robust, flexible, and scalable framework  for multimodal content creation, \ncapable of serving both general and highly specialized applications.  \n3. CLIP with diffusion mode ls \nIntroduction  \nText-to-image generation has become one of the most exciting advancements in \nartificial intelligence.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 32,
      "content": "oth general and highly specialized applications.  \n3. CLIP with diffusion mode ls \nIntroduction  \nText-to-image generation has become one of the most exciting advancements in \nartificial intelligence. By combining CLIP (Contrastive Language –Image Pretraining)  \nwith diffusion models , systems can generate images that accurately reflect user \ndescriptions. CLIP provides a bridge between language and vision, aligning text prompts \nwith visual features, while diffusion models create high -quality, coherent outputs \nthrough a noise -to-image process. Together, they enable applications ranging from \ncreative design and education to healthcare and entertainment.  \n(a) Architecture of CLIP – Connecting Text and Visuals  \n1. Dual Encoder System  \no CLIP consists of a text encoder  (Transformer -based) and an image \nencoder  (Vision Transformer or CNN).  \no Both map their inputs into feature vectors . \n2.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 33,
      "content": "and Visuals  \n1. Dual Encoder System  \no CLIP consists of a text encoder  (Transformer -based) and an image \nencoder  (Vision Transformer or CNN).  \no Both map their inputs into feature vectors . \n2. Shared Semantic Space  \no Text and image embeddings are projected into a joint latent space  where \nsimilarity is measured.  \no Training uses contrastive learning : matching text –image pairs are pulled \ncloser, mismatched ones pushed apart.  \n\n--- Page 15 ---\n3. Outcome  \no This allows CLIP to capture not just objects but also attributes, context, \nand relationships . \no For example, the phrase “bright red car on a snowy road”  aligns with \nimages showing both the car and the setting.  \n4. Significance  \no These joint embeddings are crucial for guiding generative models so that \noutputs remain semantically aligned  with textual descriptions.  \n(b) Text-Guided Stable Diffusion – The Generation Process  \n1.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 34,
      "content": "ese joint embeddings are crucial for guiding generative models so that \noutputs remain semantically aligned  with textual descriptions.  \n(b) Text-Guided Stable Diffusion – The Generation Process  \n1. Forward Diffusion  \no Real images are progressively noised until they become indistinguishable \nrandom noise.  \n2. Backward Diffusion (Denoising)  \no The model learns to reverse this process: starting from noise, it generates \nan image step by step.  \n3. Conditioning with CLIP  \no The embeddings from CLIP are injected into the backward process as \nguidance signals . \no This ensures that the generated image reflects the semantic meaning of \nthe text prompt . \n4. Noise Scheduling  \no Proper noise scheduling regulates how much detail is added at each step, \npreventing artifacts and improving stability.  \n5. Why It Works  \no Diffusion models combined with CLIP generate stable, realistic, and \nprompt-aligned visuals , outperforming earlier GAN -based approaches \nthat often struggled with fine",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 35,
      "content": "bility.  \n5. Why It Works  \no Diffusion models combined with CLIP generate stable, realistic, and \nprompt-aligned visuals , outperforming earlier GAN -based approaches \nthat often struggled with fine details.  \n (c) Fine-Tuning for Domain -Specific Applications  \n1. Need for Fine -Tuning  \no Base CLIP and diffusion models are trained on broad internet data, which \nmay not cover specialized domains well.  \n\n--- Page 16 ---\n2. Process  \no Fine-tuning involves training or adapting the model with domain-specific \nprompts or datasets . \no Example: In medicine, fine -tuning ensures that a description like “X-ray \nshowing lung opacity”  produces medically accurate images.  \n3. Benefits  \no Enhances accuracy  (outputs match technical details).  \no Improves aesthetic or contextual relevance  (outputs suit the domain \nstyle).  \no Reduces biases and errors  from general -purpose training.  \n4. Justification  \no Without fine -tuning, models may produce outputs that are visually \nplausible but fact",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 36,
      "content": "ts suit the domain \nstyle).  \no Reduces biases and errors  from general -purpose training.  \n4. Justification  \no Without fine -tuning, models may produce outputs that are visually \nplausible but factually incorrect. Domain adaptation ensures trustworthy \nand useful results . \n(d) Evaluation Metrics for Text –Image Alignment  \n1. Quantitative Metrics  \no CLIPScore : Measures similarity between generated image embeddings \nand prompt embeddings.  \no FID (Fréchet Inception Distance) : Evaluates image quality by comparing \ngenerated and real data distributions.  \no IS (Inception Score) : Measures diversity and realism of generated \nimages.  \n2. Qualitative Metrics  \no Human evaluation : Users judge whether images align with descriptions.  \no Task-based evaluation : Checking how well generated outputs support \ndownstream tasks (e.g., retrieval, classification).  \n3. Balanced Evaluation  \no A mix of automated and human assessments ensures both objective \naccuracy  and subjective quality  are",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 37,
      "content": "outputs support \ndownstream tasks (e.g., retrieval, classification).  \n3. Balanced Evaluation  \no A mix of automated and human assessments ensures both objective \naccuracy  and subjective quality  are measured.  \n4. Significance  \n\n--- Page 17 ---\no Robust evaluation is critical to confirm that the system produces outputs \nthat are reliable, meaningful, and user -aligned. \nConclusion  \nBy integrating CLIP embeddings  with diffusion -based generation , AI systems achieve \naccurate text -to-image synthesis. CLIP ensures semantic alignment, diffusion \nguarantees high visual fidelity, fine -tuning adapts models to specialized domains, and \nevaluation metrics confirm performance. This synergy represents a power ful paradigm \nfor multimodal AI, enabling diverse applications where reliable translation of language \ninto images is essential.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "2be86d49-dfeb-4446-866c-a5d0faba5317_UNIT II - GCV.pdf_bf6575c5_a254fdc3",
      "chunk_index": 38,
      "content": "ation of language \ninto images is essential.",
      "filename": "UNIT II - GCV.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nDIFFUSION MODELS\nDiffusion models are a type of generative AI that create new data like images, audio or even\nvideo by starting with random noise and gradually turning it into something meaningful. They\nwork by simulating a diffusion process where data is slowly corrupted by noise during\ntraining and then learning to reverse this process step by step. By doing so the model learns\nhow to generate high quality samples from scratch.\nUnderstanding Diffusion Models\n• Diffusion models are generative models that learn to reverse a diffusion process to\ngenerate data. The diffusion process involves gradually adding noise to data until it\nbecomes pure noise.\n• Through this process a simple distribution is transformed into a complex data distribution\nin a series of small incremental steps.\n• Essentially these models operate as a reverse diffusion phenomenon where noise is\nintroduced to the data in a forward manner and removed in a reverse manner to generate\nnew data samples.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 1,
      "content": "ntal steps.\n• Essentially these models operate as a reverse diffusion phenomenon where noise is\nintroduced to the data in a forward manner and removed in a reverse manner to generate\nnew data samples.\n• By learning to reverse this process diffusion models start from noise and gradually\ndenoise it to produce data that closely resembles the training examples.\nKey Components\n1. Forward Diffusion Process: This process involves adding noise to the data in a series of\nsmall steps. Each step slightly increases the noise, making the data progressively more\nrandom until it resembles pure noise.\n2. Reverse Diffusion Process: The model learns to reverse the noise-adding steps. Starting\nfrom pure noise, the model iteratively removes the noise, generating data that matches\nthe training distribution.\n3. Score Function: This function estimates the gradient of the data distribution concerning\nthe noise. It helps guide the reverse diffusion process to produce realistic samples.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 2,
      "content": "training distribution.\n3. Score Function: This function estimates the gradient of the data distribution concerning\nthe noise. It helps guide the reverse diffusion process to produce realistic samples.\n\n--- Page 2 ---\nArchitecture of Diffusion Models\nThe architecture of diffusion models typically involves two main components:\n1. Forward Diffusion Process\n2. Reverse Diffusion Process\n1. Forward Diffusion Process\nIn this process noise is incrementally added to the data over a series of steps. This is akin to\na Markov chain where each step slightly degrades the data by adding Gaussian noise.\nForward Diffusion P\nMathematically, this can be represented as:\nwhere,\n• xt is the noisy data at step t\n• αt controls the amount of noise added.\n2. Reverse Diffusion Process\nThe reverse process aims to reconstruct the original data by denoising the noisy data in a\nseries of steps reversing the forward diffusion.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 3,
      "content": "rols the amount of noise added.\n2. Reverse Diffusion Process\nThe reverse process aims to reconstruct the original data by denoising the noisy data in a\nseries of steps reversing the forward diffusion.\nReverse Diffusion Process\nThis is typically modelled using a neural network that predicts the noise added at each step:\nwhere,\n• μθ and σθ are learned parameters.\nWorking Principle of Diffusion Models\nDuring training the model learns to predict the noise added at each step of the forward\nprocess. This is done by minimizing a loss function that measures the difference between the\npredicted and actual noise.\nForward Process (Diffusion)\n• The forward process involves gradually corrupting the data x0 with Gaussian noise over\na sequence of time steps\n• Let xt represent the noisy data at time step t. The process is defined as:\n• where βt is the noise schedule that controls the amount of noise added at each step and ϵ is\nis Gaussian noise.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 4,
      "content": "ime steps\n• Let xt represent the noisy data at time step t. The process is defined as:\n• where βt is the noise schedule that controls the amount of noise added at each step and ϵ is\nis Gaussian noise.\n\n--- Page 3 ---\n• As t increases, xt becomes more noisy until it approximates a Gaussian distribution.\nReverse Process (Denoising)\n• The reverse process aims to reconstruct the original data x0x0 from the noisy data xT at\nthe final time step T.\n• This process is modelled using a neural network to approximate the conditional\nprobability pθ(xt−1∣xt).\n• The reverse process can be formulated as:\n• where ϵθ is a neural network parameterized by θ that predicts the noise.\nTraining Diffusion Models\n• The training objective for diffusion models involves minimizing the difference between\nthe true noise ϵ added in the forward process and the noise predicted by the neural\nnetwork ϵθ.\n• The score function which estimates the gradient of the data distribution concerning the\nnoise plays an important rol",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 5,
      "content": "ϵ added in the forward process and the noise predicted by the neural\nnetwork ϵθ.\n• The score function which estimates the gradient of the data distribution concerning the\nnoise plays an important role in guiding the reverse process.\n• The loss function is typically the mean squared error (MSE) between these two quantities:\n• This encourages the model to accurately predict the noise and, consequently, to denoise\neffectively during the reverse process.\nIn diffusion models, both the forward and backward processes are modeled as a sequence of\nsmall incremental steps rather than a single transformation. This sequential approach is\ncrucial because:\n1. Gradual Learning – By breaking the process into many steps, the model learns how\nto handle slight changes at each stage, making it easier to reverse the noise addition. If\nit tried to denoise from a fully noisy image in one step, it would struggle to map the\nrandom noise back to structured data.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 6,
      "content": "hanges at each stage, making it easier to reverse the noise addition. If\nit tried to denoise from a fully noisy image in one step, it would struggle to map the\nrandom noise back to structured data.\n2. Stability in Training – Learning through small denoising steps prevents abrupt\ntransitions, reducing the chances of errors or divergence during training. It ensures\nthat the model refines its predictions slowly, stabilizing gradients and allowing\nconsistent improvements.\n3. Better Control Over Generation – The step-wise nature allows the model to be\nsampled at different stages, offering control over how much noise to remove or retain.\nThis is especially useful in VR environments, where designers might want to balance\nrealism with creativity.\n4. Avoiding Catastrophic Forgetting – Incremental denoising reinforces the learning at\nevery step, ensuring that earlier patterns are not forgotten as the model progresses\ntoward generating complex outputs.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 7,
      "content": "iding Catastrophic Forgetting – Incremental denoising reinforces the learning at\nevery step, ensuring that earlier patterns are not forgotten as the model progresses\ntoward generating complex outputs.\n\n--- Page 4 ---\nThus, modeling the forward and backward processes as a sequence of steps ensures that\nlearning is smooth, robust, and interpretable, ultimately allowing the system to produce high-\nquality, stable, and realistic images from rough sketches.\nNoise plays a central role in the diffusion process, and carefully adjusting it can significantly\ninfluence the outcomes:\n1. Higher Noise Levels\no Encourages diverse outputs because the model explores a wider range of\npossibilities when starting from more random data.\no Useful for generating creative or artistic VR landscapes where uniqueness is\ndesired.\no However, if the noise is too high, the generated images may lose structure or\ncoherence, reducing realism.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 8,
      "content": "o Useful for generating creative or artistic VR landscapes where uniqueness is\ndesired.\no However, if the noise is too high, the generated images may lose structure or\ncoherence, reducing realism.\n2. Lower Noise Levels\no Helps maintain realism and fidelity because the model starts closer to\nstructured patterns, making it easier to produce clear and consistent images.\no Best suited for VR environments where accuracy, recognizable objects, and\nrealistic textures are essential.\no It may, however, limit creativity and diversity since the outputs are\nconstrained to follow the training data closely.\n3. Noise Scheduling\no Adjusting how noise is added or removed across steps (e.g., linear,\nexponential, cosine schedules) allows fine-tuning between exploration and\nrefinement.\no Designers can control whether the model produces subtle variations or\nradically different landscapes.\n4. Application in VR Systems\no For immersive experiences, higher noise levels at early steps can generate\nunpredictabl",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 9,
      "content": "l whether the model produces subtle variations or\nradically different landscapes.\n4. Application in VR Systems\no For immersive experiences, higher noise levels at early steps can generate\nunpredictable and novel environments, while later steps can be fine-tuned with\nlower noise to ensure realistic details.\no This balance allows users to start with abstract sketches and transform them\ninto believable virtual worlds that retain creativity without sacrificing\ncoherence.\n\n--- Page 5 ---\nDENOISING DIFFUSION PROBABILISTIC MODEL (DDPM)\nWhat are DDPMs?\nThey are a class of generative models that work by iteratively adding noise to an input signal\n(like an image, text, or audio) and then learning to denoise from the noisy signal to generate\nnew samples.\nGenerative models\nAre a type of model that can generate new data instances. Previously, machine learning models\nhave done a good job of learning differences in data and then making predictions or\nclassification tasks.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 10,
      "content": "Are a type of model that can generate new data instances. Previously, machine learning models\nhave done a good job of learning differences in data and then making predictions or\nclassification tasks. For example, a model trained on a digits dataset like MNIST can recognize\na 0 from a 1. Generative models, on the other hand, learn the distribution of digits and can create\na “fake digit” which closely resembles a real digit.\nA Denoising Diffusion Probabilistic Model (DDPM) is a type of generative model that\ncreates realistic images by learning how to progressively refine noisy data. It works in two\nphases:\n1. Forward Process (Noise Addition) – The model gradually adds random noise to a\nclean image over many steps until the image becomes indistinguishable from noise.\n2. Backward Process (Denoising) – The model learns to reverse this process by\npredicting how to remove noise at each step, eventually reconstructing a high-quality\nimage from random noise or a rough input.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 11,
      "content": "ckward Process (Denoising) – The model learns to reverse this process by\npredicting how to remove noise at each step, eventually reconstructing a high-quality\nimage from random noise or a rough input.\nThe model is called probabilistic because it doesn’t rely on a single deterministic\ntransformation but instead learns the distribution of possible images at each stage of noise\nand denoising. This approach allows it to generate diverse, high-fidelity images by sampling\nfrom the learned distribution.\n\n--- Page 6 ---\nKey Features of DDPM:\n• Iterative Refinement – Instead of transforming an image in one step, it uses many\nsmall steps, making it easier to model complex patterns.\n• Noise-Based Learning – By learning how images degrade with noise, the model\nunderstands how to reverse this degradation to recreate details.\n• Probabilistic Nature – It generates a range of plausible outputs rather than a single\nfixed result, which is useful in creative tasks like animation.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 12,
      "content": "to reverse this degradation to recreate details.\n• Probabilistic Nature – It generates a range of plausible outputs rather than a single\nfixed result, which is useful in creative tasks like animation.\n• Flexibility – DDPMs can be applied to various tasks such as image synthesis, super-\nresolution, and in your case, converting rough sketches into fully rendered scenes.\nForward and Backward Diffusion Process\nThe forward diffusion process is the initial phase in a DDPM where noise is incrementally\nadded to clean data over many steps. The purpose is to teach the model how data transitions\nfrom structured and detailed forms into randomness.\nKey steps involved:\n1. Starting with clean data – At the beginning, the model takes real data such as an\nimage or signal that contains structured information like shapes, textures, and\npatterns.\n2. Adding noise at each step – Gaussian noise is added to the data in small amounts\nover a sequence of steps. The noise schedule (linear, cosine, etc.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 13,
      "content": "information like shapes, textures, and\npatterns.\n2. Adding noise at each step – Gaussian noise is added to the data in small amounts\nover a sequence of steps. The noise schedule (linear, cosine, etc.) controls how much\nnoise is added at each step.\n3. Progressive degradation – The data becomes increasingly noisy at every step.\nInitially, the patterns are still recognizable, but as the process continues, the structure\ndisappears, and the data looks like random noise.\n4. Mathematical formulation – At step t, the noisy data x is derived from the previous\nt\nstep x by sampling from a normal distribution:\nt−1\nwhere α controls the amount of retained information and ϵ is sampled from a normal\nt\ndistribution.\nWhy this step is essential:\n• It exposes the model to how real data deteriorates with noise.\n• It creates a learning path for the model to understand the inverse operation—\nrecovering the data from noisy versions.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 14,
      "content": "is essential:\n• It exposes the model to how real data deteriorates with noise.\n• It creates a learning path for the model to understand the inverse operation—\nrecovering the data from noisy versions.\n• It ensures that the model can generalize to varying noise levels and recover details\nfrom incomplete or corrupted data.\n\n--- Page 7 ---\nRole of the Markov Chain in the Forward Diffusion Process of a DDPM\nIn a Denoising Diffusion Probabilistic Model (DDPM), the forward diffusion process\ninvolves gradually adding noise to clean data over multiple steps. This process is modeled as\na Markov chain, which plays a crucial role in structuring how noise is added.\nA Markov chain is a mathematical system that transitions from one state to another, where\nthe next state depends only on the current state and not on the entire history of past states. In\nthe context of DDPM’s forward diffusion process, this means:\n1.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 15,
      "content": "tions from one state to another, where\nthe next state depends only on the current state and not on the entire history of past states. In\nthe context of DDPM’s forward diffusion process, this means:\n1. Stepwise progression\no At each time step ttt, noise is added based only on the data at that step\n(xt−1x_{t-1}xt−1), not on earlier steps. This simplifies the process and\nensures that each step depends only on the immediately preceding one.\n2. Controlled noise addition\no The amount of noise added at each step is determined by a known noise\nschedule, ensuring that the transition from structured data to noise is smooth\nand gradual.\n3. Mathematical tractability\no By assuming that each step depends only on the previous step, the forward\nprocess becomes easier to analyze, simulate, and invert during training.\nHow does it help structure the noise addition steps?\n1. Simplifies modeling\no The Markov assumption allows the model to focus on learning local\ntransitions rather than global dependencies,",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 16,
      "content": "g training.\nHow does it help structure the noise addition steps?\n1. Simplifies modeling\no The Markov assumption allows the model to focus on learning local\ntransitions rather than global dependencies, making the noise addition process\ncomputationally feasible.\n2. Ensures gradual degradation\no The structured, stepwise approach ensures that noise is added progressively,\npreserving information early on and fully randomizing the data at later steps.\n3. Supports efficient training\no The Markov property allows the use of recursive formulations where each\nnoisy sample can be derived from the previous one using simple equations,\nfacilitating optimization and gradient computation.\n4. Enables inversion during sampling\no Since each step only depends on the previous one, the backward process\n(denoising) can also be structured in the same stepwise manner, allowing the\nmodel to learn how to reverse the process reliably.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 17,
      "content": "Since each step only depends on the previous one, the backward process\n(denoising) can also be structured in the same stepwise manner, allowing the\nmodel to learn how to reverse the process reliably.\nThe backward diffusion process is where the model learns to reverse the noise addition and\nreconstruct the original or new data from noisy inputs.\nKey aspects:\n1. Predicting the noise – At each step, the model is trained to estimate the noise that\nwas added in the forward process. It learns how the noisy data differs from its clean\nversion and tries to correct it.\n\n--- Page 8 ---\n2. Iterative refinement – Starting from pure noise, the model removes noise\nprogressively by applying its learned knowledge of patterns at each step. Over time,\nthe image or data becomes clearer and more structured.\n3. Learning objective – The model is optimized to minimize the difference between the\npredicted noise and the actual noise added during training.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 18,
      "content": "the image or data becomes clearer and more structured.\n3. Learning objective – The model is optimized to minimize the difference between the\npredicted noise and the actual noise added during training. This is typically done\nusing a loss function like Mean Squared Error (MSE).\n4. Sampling during generation – Once trained, the model can start from random noise\nand iteratively apply the backward process to generate new, realistic data samples.\nWhy this process is critical:\n• It allows the model to reconstruct missing or noisy details.\n• It ensures that the output is consistent with real-world data distributions.\n• It provides control over the generation process by using learned probabilities rather\nthan rigid rules.\nThe probabilistic nature of DDPM plays a central role in its ability to generate both diverse\nand high-quality outputs.\nWhy probabilistic modeling is useful?\n1. Learning distributions rather than fixed mappings\no Instead of learning a direct transformation from input to output",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 19,
      "content": "ate both diverse\nand high-quality outputs.\nWhy probabilistic modeling is useful?\n1. Learning distributions rather than fixed mappings\no Instead of learning a direct transformation from input to output, the model\nlearns the underlying distribution of possible clean data conditioned on noisy\ninputs.\no This enables the model to handle uncertainty and variations present in real\ndata.\n2. Sampling from distributions\no During generation, the model samples noise from a distribution at each step.\nEven with the same input, different random samples produce varied outputs,\npromoting creativity and diversity.\n3. Capturing subtle patterns\no Probabilistic modeling allows the model to learn nuanced relationships in the\ndata such as textures, lighting patterns, or variations in shape that are hard to\ncapture with deterministic methods.\n4. Balancing realism and exploration\no By controlling the noise level and how it’s modeled, the system can explore\nnew possibilities while staying within the realm of re",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 20,
      "content": "re with deterministic methods.\n4. Balancing realism and exploration\no By controlling the noise level and how it’s modeled, the system can explore\nnew possibilities while staying within the realm of realistic outputs. This is\ncrucial for applications like design, simulation, and data augmentation.\nChallenges:\n1. High computational cost\no Because the process involves many steps (often hundreds or thousands),\ngenerating data can be slow and resource-intensive.\n2. Latency issues in real-time applications\n\n--- Page 9 ---\no The iterative nature makes it difficult to apply DDPMs in interactive or real-\ntime environments where fast feedback is essential.\n3. Difficulty in controlling outputs\no Without proper conditioning or guidance, the model might produce outputs\nthat are inconsistent with user expectations or desired styles.\n4. Data requirements\no Training DDPMs effectively requires large and diverse datasets to accurately\nlearn noise patterns and recover fine details.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 21,
      "content": "nconsistent with user expectations or desired styles.\n4. Data requirements\no Training DDPMs effectively requires large and diverse datasets to accurately\nlearn noise patterns and recover fine details.\nENERGY-BASED MODELS(EBMs)\nEnergy-Based Models (EBMs) are a class of probabilistic models that define relationships\nbetween variables using an energy function. Rather than explicitly modeling probability\ndistributions, EBMs assign an “energy” value to each possible configuration of variables,\nwhere lower energy indicates more likely or desirable configurations, and higher energy\ncorresponds to less likely ones.\nEBMs are widely used in machine learning for tasks such as representation learning,\nstructured prediction, anomaly detection, and reinforcement learning, where capturing\nrelationships and constraints between variables is more important than explicitly computing\nprobabilities.\n2. The Concept of Energy in EBMs\n• An energy function E(x)maps an input x to a scalar energy value.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 22,
      "content": "onships and constraints between variables is more important than explicitly computing\nprobabilities.\n2. The Concept of Energy in EBMs\n• An energy function E(x)maps an input x to a scalar energy value.\n• The lower the energy, the more plausible or preferred the data point is according to\nthe model.\n• The probability distribution p(x)is related to the energy via the Boltzmann\ndistribution:\nwhere Z is the partition function:\n• The partition function Z is often intractable, making it difficult to directly compute\nprobabilities, but not necessary for learning.\n\n--- Page 10 ---\n3. Architecture and Working\nCore Components:\n1. Energy Function\no The energy function is typically parameterized by neural networks or other\ndifferentiable models.\no It scores different data configurations to indicate how well they conform to the\ndesired patterns.\n2. Learning Objective\no EBMs learn by comparing the energies of positive (correct) and negative\n(incorrect or unlikely) samples.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 23,
      "content": "nfigurations to indicate how well they conform to the\ndesired patterns.\n2. Learning Objective\no EBMs learn by comparing the energies of positive (correct) and negative\n(incorrect or unlikely) samples.\no The goal is to assign lower energy to real data and higher energy to unlikely\ndata.\n3. Training Approaches\no Contrastive Divergence (CD) – Optimizes the model by comparing energy\ndifferences between observed and model-generated samples.\no Score Matching – Matches the gradient of the energy function rather than the\nenergy itself.\no Noise Contrastive Estimation (NCE) – Uses noise samples to help\napproximate the partition function during learning.\n4. Markov Random Fields (MRFs) and Conditional EBMs\n• EBMs are closely related to Markov Random Fields (MRFs), which model\ndependencies between variables using graph structures.\n• Conditional EBMs extend the energy framework to tasks where the output depends\non input features (e.g., image classification, structured output prediction).\n5.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 24,
      "content": "ween variables using graph structures.\n• Conditional EBMs extend the energy framework to tasks where the output depends\non input features (e.g., image classification, structured output prediction).\n5. Applications of EBMs\n1. Unsupervised Learning\no Modeling complex relationships in high-dimensional data such as images,\nspeech, or text.\n2. Anomaly Detection\no Identifying outliers by assigning higher energy to rare or unlikely\nconfigurations.\n3. Reinforcement Learning (RL)\no Estimating value functions where actions with lower energy correspond to\nmore rewarding behaviors.\n4. Generative Modeling\no Generating samples by searching for configurations with low energy, often\nusing sampling algorithms like Langevin dynamics.\n5. Structured Prediction\no Solving problems like image segmentation or sequence labeling where\nrelationships between output variables are important.\n\n--- Page 11 ---\n6. Advantages of EBMs\n• Flexibility – Can model arbitrary dependencies without requiring explicit probabilit",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 25,
      "content": "uence labeling where\nrelationships between output variables are important.\n\n--- Page 11 ---\n6. Advantages of EBMs\n• Flexibility – Can model arbitrary dependencies without requiring explicit probability\ndistributions.\n• Interpretability – The energy function directly encodes preferences or constraints.\n• Applicability – Useful in domains where structured relationships and constraints\ndominate over simple classification.\n7. Challenges and Limitations\n1. Intractable Partition Function\no Computing ZZZ is often impossible in practice, requiring approximation\ntechniques that can be unstable.\n2. Training Instability\no Optimization methods like contrastive divergence rely on sampling, which can\nlead to slow convergence or poor performance.\n3. Sampling Complexity\no Generating samples requires iterative methods such as Markov Chain Monte\nCarlo (MCMC), which can be computationally expensive.\n4. Scalability Issues\no Handling high-dimensional data with complex energy landscapes is\nchallenging.\n8.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 26,
      "content": "rative methods such as Markov Chain Monte\nCarlo (MCMC), which can be computationally expensive.\n4. Scalability Issues\no Handling high-dimensional data with complex energy landscapes is\nchallenging.\n8. Recent Advances\n• Neural EBMs – Combining deep learning with energy functions to model high-\ndimensional and structured data more effectively.\n• Score-based Generative Models – Learning the gradient of the energy function to\navoid directly computing the partition function.\n• Applications in Contrastive Learning – EBMs form the backbone of contrastive\napproaches where relationships between samples are emphasized.\n\n--- Page 12 ---\nCOMPARE EBMS VS VAES\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Defined by an energy function\nthat assigns a scalar “energy” to\n- Composed of two main parts: an\neach configuration of inputs (and\nencoder and a decoder.\noptionally outputs).\n- The encoder maps input data to a\n- No explicit probability\nlatent space distribution (typically\ndist",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 27,
      "content": "two main parts: an\neach configuration of inputs (and\nencoder and a decoder.\noptionally outputs).\n- The encoder maps input data to a\n- No explicit probability\nlatent space distribution (typically\ndistribution; the model learns to\nGaussian).\nassign lower energy to desired\n- The decoder reconstructs data\n✅ Architecture samples and higher energy to\nfrom samples drawn from the latent\nundesired ones.\nspace.\n- Often optimized using contrastive\n- Uses variational inference to\ndivergence or score matching.\napproximate intractable posteriors.\n- The architecture focuses on\n- The architecture explicitly models\nrelationships between data points\ndata generation.\nrather than reconstructing or\ngenerating them directly.\n- Maximize the Evidence Lower\n- Learn an energy landscape where\nBound (ELBO) which balances\ncorrect data points are assigned\nreconstruction accuracy and\nlower energy.\n✅ Objective regularization of the latent space.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 28,
      "content": "Evidence Lower\n- Learn an energy landscape where\nBound (ELBO) which balances\ncorrect data points are assigned\nreconstruction accuracy and\nlower energy.\n✅ Objective regularization of the latent space.\n- Optimization is based on\n- Encourages latent space structure\ndistinguishing good samples from\nfor efficient sampling and\nbad ones.\ninterpolation.\n- Indirect; energy defines the\nlikelihood up to a normalization - Explicit probabilistic framework\nconstant (partition function), which with tractable priors and\n✅ Probabilistic\nis often intractable. approximate posteriors.\nInterpretation\n- Focuses on learning relationships - Can directly sample from the latent\nand constraints rather than full space and model uncertainty.\ndensity estimation.\n- Uses sampling-based methods\nlike Markov Chain Monte Carlo - Uses backpropagation with\n(MCMC), contrastive divergence, reparameterization trick for efficient\n✅ Training\nor score matching. gradient estimation.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 29,
      "content": "mpling-based methods\nlike Markov Chain Monte Carlo - Uses backpropagation with\n(MCMC), contrastive divergence, reparameterization trick for efficient\n✅ Training\nor score matching. gradient estimation.\nMethods\n- Training can be unstable due to - More stable and easier to train\nreliance on sampling and gradient with large datasets.\nestimation.\n- Modeling complex dependencies\nin structured data. - Image and speech generation, data\n- Used in tasks like anomaly compression, anomaly detection,\ndetection, reinforcement learning, and semi-supervised learning.\n✅ Applications\nand unsupervised learning. - Used where interpretable latent\n- Applicable where relationships representations and smooth\nand constraints are more important generation paths are required.\nthan explicit reconstruction.\n\n--- Page 13 ---\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Flexibility in modeling\n- Well-suited for generating new\nrelationships without requiring\ndata samples.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 30,
      "content": "onstruction.\n\n--- Page 13 ---\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Flexibility in modeling\n- Well-suited for generating new\nrelationships without requiring\ndata samples.\n✅ Strengths explicit likelihood functions.\n- Provides interpretable latent spaces\n- Can incorporate constraints and\nuseful for downstream tasks.\ndomain knowledge easily.\n- May suffer from blurry\n- Training is computationally\nreconstructions or mode collapse.\nexpensive and less scalable. -\n✅ Limitations - Latent space structure depends\nNormalization constant estimation\nheavily on choice of priors and\nis intractable in many cases.\narchitectures.\nINTRODUCTION TO NOISE SCHEDULERS IN DIFFUSION MODELS\nIn diffusion models, noise plays a central role in transforming structured data into random noise\nduring training and then reconstructing it during sampling. However, how much noise is added\nor removed at each step is not arbitrary—it must be carefully controlled to ensure that the model\nlearns me",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 31,
      "content": "during training and then reconstructing it during sampling. However, how much noise is added\nor removed at each step is not arbitrary—it must be carefully controlled to ensure that the model\nlearns meaningful patterns and can effectively generate high-quality data.\nThis is where noise schedulers come into play.\nA noise scheduler defines the schedule or strategy by which noise is added to data in the\nforward diffusion process and removed in the backward process. It determines the magnitude\nof noise at each step, shaping how the model degrades and refines information over time.\nThe design of the noise schedule affects several critical aspects:\n• Learning efficiency – Too much noise can obscure important details, while too little\nmay prevent the model from learning to handle uncertainty.\n• Sample diversity and quality – The progression of noise influences how creative or\nrealistic the generated outputs are.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 32,
      "content": "s, while too little\nmay prevent the model from learning to handle uncertainty.\n• Sample diversity and quality – The progression of noise influences how creative or\nrealistic the generated outputs are.\n• Training stability – Gradual noise addition helps avoid erratic learning and ensures\nthat the model can generalize from noisy inputs.\nCommon schedules include linear, cosine, and exponential noise schedules, each offering\ndifferent trade-offs between smoothness, speed, and complexity.\nSignificance of Noise Schedulers in Diffusion Models\nIn diffusion models, noise schedulers determine how noise is added (in the forward process)\nor removed (in the backward process) at each step. They play a critical role in controlling the\nquality, stability, and efficiency of the model during both training and sampling.\nWhy are noise schedulers important?\n1. Control over noise injection\no A noise scheduler defines how much noise is added at each step, influencing\nhow quickly the data degrades from its or",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 33,
      "content": "nd sampling.\nWhy are noise schedulers important?\n1. Control over noise injection\no A noise scheduler defines how much noise is added at each step, influencing\nhow quickly the data degrades from its original form to pure noise.\n\n--- Page 14 ---\no A carefully designed schedule ensures that the model learns meaningful\ntransformations at each step rather than abrupt or overly noisy transitions.\n2. Balance between learning and randomness\no If noise is added too aggressively, the model may struggle to learn how to\nrecover the data because too much information is lost early.\no If noise is too weak, the model may not generalize well and could overfit to\nspecific patterns without learning how to handle uncertainty.\n3. Smooth transitions\no Gradual noise addition allows the model to capture complex patterns and fine\ndetails at different noise levels, helping the backward process refine the data\neffectively.\n4.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 34,
      "content": "ty.\n3. Smooth transitions\no Gradual noise addition allows the model to capture complex patterns and fine\ndetails at different noise levels, helping the backward process refine the data\neffectively.\n4. Influences sample quality and diversity\no The noise schedule affects the kinds of outputs the model generates. For\ninstance, a slower noise increase might produce high-fidelity samples, while a\nfaster schedule might encourage more diverse and creative outputs.\n5. Stabilizes training\no Appropriate noise scheduling prevents extreme gradients or erratic learning\nbehavior, enabling stable and efficient training across large datasets.\n✅ Example of a commonly used noise scheduler: Linear noise schedule\nOne widely used noise scheduler is the linear noise schedule, where the noise level increases\nat a constant rate across steps.\n• The noise added at each step t is computed as:\nwhere:\no β start is the initial noise amount,\no β end is the final noise amount,\no T is the total number of steps.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 35,
      "content": "ses\nat a constant rate across steps.\n• The noise added at each step t is computed as:\nwhere:\no β start is the initial noise amount,\no β end is the final noise amount,\no T is the total number of steps.\nWhy it's used:\n• Simplicity – easy to implement and analyze.\n• Gradual degradation – ensures smooth transitions from structured data to noise.\n• Works well in practice for a variety of tasks without requiring complex tuning.\n✅ Other common noise schedules\n• Cosine schedule – Uses a cosine curve to control noise increments, adding noise\nmore smoothly at the beginning and end.\n\n--- Page 15 ---\n• Exponential schedule – Adds noise in a way that accelerates or decelerates across\nsteps, providing more control over learning phases.\nComparison between Class-Conditional Diffusion Models and Unconditional Diffusion\nModels\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\nDiffusion models where the generation\nDiffusion models that generate data\nprocess is guided by class label",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 36,
      "content": "nal Diffusion\nModels\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\nDiffusion models where the generation\nDiffusion models that generate data\nprocess is guided by class labels or\npurely based on learned distributions\nadditional conditioning information (e.g.,\n✅ Definition without any conditioning information.\ntext, attributes). The model learns how the\nThe model only depends on noise and\ndata distribution changes for different\nthe learned data distribution.\nclasses.\n- Incorporates class labels or auxiliary\ninputs into the noise prediction network.\n- Contains only the noise prediction\n- Conditioning is usually done by\nnetwork without any external inputs.\nconcatenating labels or through\n✅ - Learns the general structure and\nembeddings that influence intermediate\nArchitecture distribution of the entire dataset.\nlayers.\n- Generates samples based on noise\n- The model learns separate modes of the\nwithout class-specific guidance.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 37,
      "content": "ddings that influence intermediate\nArchitecture distribution of the entire dataset.\nlayers.\n- Generates samples based on noise\n- The model learns separate modes of the\nwithout class-specific guidance.\ndata distribution for each class or\ncondition.\n- Learn how to denoise while respecting - Learn to denoise without any guidance\nclass information. other than the underlying data\n✅ Training - The model minimizes the reconstruction distribution.\nObjective loss while conditioning on the class, - The model focuses on general patterns\nensuring generated samples match the and statistical relationships in the\ntarget category. dataset.\n- During generation, class labels guide the\n- Generates samples from noise without\nsampling process, allowing control over\ncontrol over attributes or categories.\n✅ Sampling what kind of sample is generated (e.g., a\n- Produces diverse outputs but without\ncat vs. a dog image).\nspecific guidance.\n- Can produce targeted, structured outputs.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 38,
      "content": "tributes or categories.\n✅ Sampling what kind of sample is generated (e.g., a\n- Produces diverse outputs but without\ncat vs. a dog image).\nspecific guidance.\n- Can produce targeted, structured outputs.\n- Image synthesis conditioned on class\nlabels (e.g., generating specific objects or - General image, audio, or video\nfaces). generation where control is not\n✅ - Text-to-image generation, style transfer, necessary.\nApplications or scenarios requiring targeted outputs. - Data augmentation, unsupervised\n- Semi-supervised learning where learning, and exploratory creative\nadditional information improves generation generation.\nquality.\n- Greater control over generated samples.\n✅ - Can produce outputs tailored to specific - Simpler architecture and easier to\nAdvantages tasks or user inputs. implement.\n- More interpretable generation process. - Requires less labeled data.\n\n--- Page 16 ---\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\n- Capable of learning diverse patter",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 39,
      "content": "t.\n- More interpretable generation process. - Requires less labeled data.\n\n--- Page 16 ---\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\n- Capable of learning diverse patterns\nfrom large, unstructured datasets.\n- Requires labeled data or conditioning\n- Lacks control over generated content.\n✅ inputs, which may not always be available.\n- May produce irrelevant or ambiguous\nLimitations - More complex architecture and higher\noutputs when diverse patterns overlap.\ncomputational cost.\nDDIM (DENOISING DIFFUSION IMPLICIT MODELS)\nDDIM (Denoising Diffusion Implicit Models) is an improvement over standard diffusion\nmodels like DDPM (Denoising Diffusion Probabilistic Models). It introduces a new sampling\nmethod that allows generating high-quality samples with significantly fewer steps, while still\nretaining diversity and structure in the outputs.\n✅ Why DDIM was introduced\n1.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 40,
      "content": "introduces a new sampling\nmethod that allows generating high-quality samples with significantly fewer steps, while still\nretaining diversity and structure in the outputs.\n✅ Why DDIM was introduced\n1. Reduce Sampling Time\no Traditional diffusion models like DDPM require hundreds or thousands of\nsteps during sampling, which makes them computationally expensive and slow\nfor practical applications.\n2. Maintain Quality and Diversity\no Simply reducing steps in DDPM leads to degraded or less diverse outputs.\no DDIM proposes a deterministic or pseudo-deterministic approach that\nmaintains high sample fidelity even with fewer steps.\n✅ How DDIM works\n1. Implicit Sampling\no Instead of following the stochastic reverse process of DDPM, DDIM defines a\ndeterministic mapping between noise and data, reducing randomness during\nsampling.\no The model avoids resampling at each step, making it faster and more stable.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 41,
      "content": "erse process of DDPM, DDIM defines a\ndeterministic mapping between noise and data, reducing randomness during\nsampling.\no The model avoids resampling at each step, making it faster and more stable.\n2. Non-Markovian Transitions\no Unlike DDPM where each step depends only on the previous one (Markov\nproperty), DDIM relaxes this assumption by allowing steps that depend on\nearlier states.\no This enables more flexible transitions and faster sampling while preserving\nsample quality.\n3. Controlled Interpolation\no DDIM allows interpolation between different noise levels and samples, which\ncan be used for creative applications like style mixing or smooth transitions.\n\n--- Page 17 ---\n✅ Key Differences from DDPM\nFeature DDPM DDIM\nStochastic, follows Markov chain with Deterministic or pseudo-deterministic,\nSampling process\nrandom transitions with fewer steps\nComputational\nHigh due to many sampling steps Much lower with accelerated sampling\ncost\nCan explore a wide range of outputs due Maintains div",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 42,
      "content": "stic,\nSampling process\nrandom transitions with fewer steps\nComputational\nHigh due to many sampling steps Much lower with accelerated sampling\ncost\nCan explore a wide range of outputs due Maintains diversity but with controlled\nDiversity\nto randomness noise patterns\nSuitable for tasks needing rich Better for fast generation and interactive\nUse case\nexploration applications\n✅ Mathematical Insight\nIn DDPM, the reverse process is modeled as a probabilistic sampling from p(x ∣x), where\nt−1 t\nrandomness is inherent at each step.\nIn DDIM, a deterministic transition is defined:\nHere:\n• α t defines how much signal is preserved at each step.\n• ϵ θ (x t ,t) is the model’s learned noise prediction.\nThis formulation allows skipping intermediate steps while still approximating the\nreverse trajectory.\n✅ Applications of DDIM\n1. Image Generation\no Produces high-resolution images quickly without compromising on details.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 43,
      "content": "s skipping intermediate steps while still approximating the\nreverse trajectory.\n✅ Applications of DDIM\n1. Image Generation\no Produces high-resolution images quickly without compromising on details.\n2. Video and Audio Synthesis\no Enables faster generation for time-sensitive applications like animation or\nsound design.\n3. Style Transfer & Interpolation\no Smoothly blends between samples by manipulating latent noise patterns\ndeterministically.\n4. Interactive Tools\no Supports real-time editing and creative workflows where speed and control are\ncritical.\n\n--- Page 18 ---\n✅ Advantages of DDIM\n✔ Faster sampling with fewer steps\n✔ Stable and high-quality outputs\n✔ Supports interpolation and controlled generation\n✔ Reduces computational cost without major trade-offs in realism\n✅ Limitations of DDIM\n❗ May lose some diversity due to reduced randomness\n❗ Requires careful tuning of schedules and noise levels\n❗ Still dependent on well-trained models to perform effectively\n✅ Conclusion\nDDIM is a power",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpfh78omy3_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 44,
      "content": "❗ May lose some diversity due to reduced randomness\n❗ Requires careful tuning of schedules and noise levels\n❗ Still dependent on well-trained models to perform effectively\n✅ Conclusion\nDDIM is a powerful extension of diffusion models that addresses one of their biggest\nlimitations—slow sampling—by introducing deterministic or semi-deterministic transitions.\nIt enables faster generation while maintaining sample fidelity and diversity, making it highly\nsuitable for real-world applications like image synthesis, animation, and interactive creative\ntools.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nDIFFUSION MODELS\nDiffusion models are a type of generative AI that create new data like images, audio or even\nvideo by starting with random noise and gradually turning it into something meaningful. They\nwork by simulating a diffusion process where data is slowly corrupted by noise during\ntraining and then learning to reverse this process step by step. By doing so the model learns\nhow to generate high quality samples from scratch.\nUnderstanding Diffusion Models\n• Diffusion models are generative models that learn to reverse a diffusion process to\ngenerate data. The diffusion process involves gradually adding noise to data until it\nbecomes pure noise.\n• Through this process a simple distribution is transformed into a complex data distribution\nin a series of small incremental steps.\n• Essentially these models operate as a reverse diffusion phenomenon where noise is\nintroduced to the data in a forward manner and removed in a reverse manner to generate\nnew data samples.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 1,
      "content": "ntal steps.\n• Essentially these models operate as a reverse diffusion phenomenon where noise is\nintroduced to the data in a forward manner and removed in a reverse manner to generate\nnew data samples.\n• By learning to reverse this process diffusion models start from noise and gradually\ndenoise it to produce data that closely resembles the training examples.\nKey Components\n1. Forward Diffusion Process: This process involves adding noise to the data in a series of\nsmall steps. Each step slightly increases the noise, making the data progressively more\nrandom until it resembles pure noise.\n2. Reverse Diffusion Process: The model learns to reverse the noise-adding steps. Starting\nfrom pure noise, the model iteratively removes the noise, generating data that matches\nthe training distribution.\n3. Score Function: This function estimates the gradient of the data distribution concerning\nthe noise. It helps guide the reverse diffusion process to produce realistic samples.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 2,
      "content": "training distribution.\n3. Score Function: This function estimates the gradient of the data distribution concerning\nthe noise. It helps guide the reverse diffusion process to produce realistic samples.\n\n--- Page 2 ---\nArchitecture of Diffusion Models\nThe architecture of diffusion models typically involves two main components:\n1. Forward Diffusion Process\n2. Reverse Diffusion Process\n1. Forward Diffusion Process\nIn this process noise is incrementally added to the data over a series of steps. This is akin to\na Markov chain where each step slightly degrades the data by adding Gaussian noise.\nForward Diffusion P\nMathematically, this can be represented as:\nwhere,\n• xt is the noisy data at step t\n• αt controls the amount of noise added.\n2. Reverse Diffusion Process\nThe reverse process aims to reconstruct the original data by denoising the noisy data in a\nseries of steps reversing the forward diffusion.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 3,
      "content": "rols the amount of noise added.\n2. Reverse Diffusion Process\nThe reverse process aims to reconstruct the original data by denoising the noisy data in a\nseries of steps reversing the forward diffusion.\nReverse Diffusion Process\nThis is typically modelled using a neural network that predicts the noise added at each step:\nwhere,\n• μθ and σθ are learned parameters.\nWorking Principle of Diffusion Models\nDuring training the model learns to predict the noise added at each step of the forward\nprocess. This is done by minimizing a loss function that measures the difference between the\npredicted and actual noise.\nForward Process (Diffusion)\n• The forward process involves gradually corrupting the data x0 with Gaussian noise over\na sequence of time steps\n• Let xt represent the noisy data at time step t. The process is defined as:\n• where βt is the noise schedule that controls the amount of noise added at each step and ϵ is\nis Gaussian noise.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 4,
      "content": "ime steps\n• Let xt represent the noisy data at time step t. The process is defined as:\n• where βt is the noise schedule that controls the amount of noise added at each step and ϵ is\nis Gaussian noise.\n\n--- Page 3 ---\n• As t increases, xt becomes more noisy until it approximates a Gaussian distribution.\nReverse Process (Denoising)\n• The reverse process aims to reconstruct the original data x0x0 from the noisy data xT at\nthe final time step T.\n• This process is modelled using a neural network to approximate the conditional\nprobability pθ(xt−1∣xt).\n• The reverse process can be formulated as:\n• where ϵθ is a neural network parameterized by θ that predicts the noise.\nTraining Diffusion Models\n• The training objective for diffusion models involves minimizing the difference between\nthe true noise ϵ added in the forward process and the noise predicted by the neural\nnetwork ϵθ.\n• The score function which estimates the gradient of the data distribution concerning the\nnoise plays an important rol",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 5,
      "content": "ϵ added in the forward process and the noise predicted by the neural\nnetwork ϵθ.\n• The score function which estimates the gradient of the data distribution concerning the\nnoise plays an important role in guiding the reverse process.\n• The loss function is typically the mean squared error (MSE) between these two quantities:\n• This encourages the model to accurately predict the noise and, consequently, to denoise\neffectively during the reverse process.\nIn diffusion models, both the forward and backward processes are modeled as a sequence of\nsmall incremental steps rather than a single transformation. This sequential approach is\ncrucial because:\n1. Gradual Learning – By breaking the process into many steps, the model learns how\nto handle slight changes at each stage, making it easier to reverse the noise addition. If\nit tried to denoise from a fully noisy image in one step, it would struggle to map the\nrandom noise back to structured data.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 6,
      "content": "hanges at each stage, making it easier to reverse the noise addition. If\nit tried to denoise from a fully noisy image in one step, it would struggle to map the\nrandom noise back to structured data.\n2. Stability in Training – Learning through small denoising steps prevents abrupt\ntransitions, reducing the chances of errors or divergence during training. It ensures\nthat the model refines its predictions slowly, stabilizing gradients and allowing\nconsistent improvements.\n3. Better Control Over Generation – The step-wise nature allows the model to be\nsampled at different stages, offering control over how much noise to remove or retain.\nThis is especially useful in VR environments, where designers might want to balance\nrealism with creativity.\n4. Avoiding Catastrophic Forgetting – Incremental denoising reinforces the learning at\nevery step, ensuring that earlier patterns are not forgotten as the model progresses\ntoward generating complex outputs.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 7,
      "content": "iding Catastrophic Forgetting – Incremental denoising reinforces the learning at\nevery step, ensuring that earlier patterns are not forgotten as the model progresses\ntoward generating complex outputs.\n\n--- Page 4 ---\nThus, modeling the forward and backward processes as a sequence of steps ensures that\nlearning is smooth, robust, and interpretable, ultimately allowing the system to produce high-\nquality, stable, and realistic images from rough sketches.\nNoise plays a central role in the diffusion process, and carefully adjusting it can significantly\ninfluence the outcomes:\n1. Higher Noise Levels\no Encourages diverse outputs because the model explores a wider range of\npossibilities when starting from more random data.\no Useful for generating creative or artistic VR landscapes where uniqueness is\ndesired.\no However, if the noise is too high, the generated images may lose structure or\ncoherence, reducing realism.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 8,
      "content": "o Useful for generating creative or artistic VR landscapes where uniqueness is\ndesired.\no However, if the noise is too high, the generated images may lose structure or\ncoherence, reducing realism.\n2. Lower Noise Levels\no Helps maintain realism and fidelity because the model starts closer to\nstructured patterns, making it easier to produce clear and consistent images.\no Best suited for VR environments where accuracy, recognizable objects, and\nrealistic textures are essential.\no It may, however, limit creativity and diversity since the outputs are\nconstrained to follow the training data closely.\n3. Noise Scheduling\no Adjusting how noise is added or removed across steps (e.g., linear,\nexponential, cosine schedules) allows fine-tuning between exploration and\nrefinement.\no Designers can control whether the model produces subtle variations or\nradically different landscapes.\n4. Application in VR Systems\no For immersive experiences, higher noise levels at early steps can generate\nunpredictabl",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 9,
      "content": "l whether the model produces subtle variations or\nradically different landscapes.\n4. Application in VR Systems\no For immersive experiences, higher noise levels at early steps can generate\nunpredictable and novel environments, while later steps can be fine-tuned with\nlower noise to ensure realistic details.\no This balance allows users to start with abstract sketches and transform them\ninto believable virtual worlds that retain creativity without sacrificing\ncoherence.\n\n--- Page 5 ---\nDENOISING DIFFUSION PROBABILISTIC MODEL (DDPM)\nWhat are DDPMs?\nThey are a class of generative models that work by iteratively adding noise to an input signal\n(like an image, text, or audio) and then learning to denoise from the noisy signal to generate\nnew samples.\nGenerative models\nAre a type of model that can generate new data instances. Previously, machine learning models\nhave done a good job of learning differences in data and then making predictions or\nclassification tasks.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 10,
      "content": "Are a type of model that can generate new data instances. Previously, machine learning models\nhave done a good job of learning differences in data and then making predictions or\nclassification tasks. For example, a model trained on a digits dataset like MNIST can recognize\na 0 from a 1. Generative models, on the other hand, learn the distribution of digits and can create\na “fake digit” which closely resembles a real digit.\nA Denoising Diffusion Probabilistic Model (DDPM) is a type of generative model that\ncreates realistic images by learning how to progressively refine noisy data. It works in two\nphases:\n1. Forward Process (Noise Addition) – The model gradually adds random noise to a\nclean image over many steps until the image becomes indistinguishable from noise.\n2. Backward Process (Denoising) – The model learns to reverse this process by\npredicting how to remove noise at each step, eventually reconstructing a high-quality\nimage from random noise or a rough input.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 11,
      "content": "ckward Process (Denoising) – The model learns to reverse this process by\npredicting how to remove noise at each step, eventually reconstructing a high-quality\nimage from random noise or a rough input.\nThe model is called probabilistic because it doesn’t rely on a single deterministic\ntransformation but instead learns the distribution of possible images at each stage of noise\nand denoising. This approach allows it to generate diverse, high-fidelity images by sampling\nfrom the learned distribution.\n\n--- Page 6 ---\nKey Features of DDPM:\n• Iterative Refinement – Instead of transforming an image in one step, it uses many\nsmall steps, making it easier to model complex patterns.\n• Noise-Based Learning – By learning how images degrade with noise, the model\nunderstands how to reverse this degradation to recreate details.\n• Probabilistic Nature – It generates a range of plausible outputs rather than a single\nfixed result, which is useful in creative tasks like animation.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 12,
      "content": "to reverse this degradation to recreate details.\n• Probabilistic Nature – It generates a range of plausible outputs rather than a single\nfixed result, which is useful in creative tasks like animation.\n• Flexibility – DDPMs can be applied to various tasks such as image synthesis, super-\nresolution, and in your case, converting rough sketches into fully rendered scenes.\nForward and Backward Diffusion Process\nThe forward diffusion process is the initial phase in a DDPM where noise is incrementally\nadded to clean data over many steps. The purpose is to teach the model how data transitions\nfrom structured and detailed forms into randomness.\nKey steps involved:\n1. Starting with clean data – At the beginning, the model takes real data such as an\nimage or signal that contains structured information like shapes, textures, and\npatterns.\n2. Adding noise at each step – Gaussian noise is added to the data in small amounts\nover a sequence of steps. The noise schedule (linear, cosine, etc.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 13,
      "content": "information like shapes, textures, and\npatterns.\n2. Adding noise at each step – Gaussian noise is added to the data in small amounts\nover a sequence of steps. The noise schedule (linear, cosine, etc.) controls how much\nnoise is added at each step.\n3. Progressive degradation – The data becomes increasingly noisy at every step.\nInitially, the patterns are still recognizable, but as the process continues, the structure\ndisappears, and the data looks like random noise.\n4. Mathematical formulation – At step t, the noisy data x is derived from the previous\nt\nstep x by sampling from a normal distribution:\nt−1\nwhere α controls the amount of retained information and ϵ is sampled from a normal\nt\ndistribution.\nWhy this step is essential:\n• It exposes the model to how real data deteriorates with noise.\n• It creates a learning path for the model to understand the inverse operation—\nrecovering the data from noisy versions.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 14,
      "content": "is essential:\n• It exposes the model to how real data deteriorates with noise.\n• It creates a learning path for the model to understand the inverse operation—\nrecovering the data from noisy versions.\n• It ensures that the model can generalize to varying noise levels and recover details\nfrom incomplete or corrupted data.\n\n--- Page 7 ---\nRole of the Markov Chain in the Forward Diffusion Process of a DDPM\nIn a Denoising Diffusion Probabilistic Model (DDPM), the forward diffusion process\ninvolves gradually adding noise to clean data over multiple steps. This process is modeled as\na Markov chain, which plays a crucial role in structuring how noise is added.\nA Markov chain is a mathematical system that transitions from one state to another, where\nthe next state depends only on the current state and not on the entire history of past states. In\nthe context of DDPM’s forward diffusion process, this means:\n1.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 15,
      "content": "tions from one state to another, where\nthe next state depends only on the current state and not on the entire history of past states. In\nthe context of DDPM’s forward diffusion process, this means:\n1. Stepwise progression\no At each time step ttt, noise is added based only on the data at that step\n(xt−1x_{t-1}xt−1), not on earlier steps. This simplifies the process and\nensures that each step depends only on the immediately preceding one.\n2. Controlled noise addition\no The amount of noise added at each step is determined by a known noise\nschedule, ensuring that the transition from structured data to noise is smooth\nand gradual.\n3. Mathematical tractability\no By assuming that each step depends only on the previous step, the forward\nprocess becomes easier to analyze, simulate, and invert during training.\nHow does it help structure the noise addition steps?\n1. Simplifies modeling\no The Markov assumption allows the model to focus on learning local\ntransitions rather than global dependencies,",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 16,
      "content": "g training.\nHow does it help structure the noise addition steps?\n1. Simplifies modeling\no The Markov assumption allows the model to focus on learning local\ntransitions rather than global dependencies, making the noise addition process\ncomputationally feasible.\n2. Ensures gradual degradation\no The structured, stepwise approach ensures that noise is added progressively,\npreserving information early on and fully randomizing the data at later steps.\n3. Supports efficient training\no The Markov property allows the use of recursive formulations where each\nnoisy sample can be derived from the previous one using simple equations,\nfacilitating optimization and gradient computation.\n4. Enables inversion during sampling\no Since each step only depends on the previous one, the backward process\n(denoising) can also be structured in the same stepwise manner, allowing the\nmodel to learn how to reverse the process reliably.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 17,
      "content": "Since each step only depends on the previous one, the backward process\n(denoising) can also be structured in the same stepwise manner, allowing the\nmodel to learn how to reverse the process reliably.\nThe backward diffusion process is where the model learns to reverse the noise addition and\nreconstruct the original or new data from noisy inputs.\nKey aspects:\n1. Predicting the noise – At each step, the model is trained to estimate the noise that\nwas added in the forward process. It learns how the noisy data differs from its clean\nversion and tries to correct it.\n\n--- Page 8 ---\n2. Iterative refinement – Starting from pure noise, the model removes noise\nprogressively by applying its learned knowledge of patterns at each step. Over time,\nthe image or data becomes clearer and more structured.\n3. Learning objective – The model is optimized to minimize the difference between the\npredicted noise and the actual noise added during training.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 18,
      "content": "the image or data becomes clearer and more structured.\n3. Learning objective – The model is optimized to minimize the difference between the\npredicted noise and the actual noise added during training. This is typically done\nusing a loss function like Mean Squared Error (MSE).\n4. Sampling during generation – Once trained, the model can start from random noise\nand iteratively apply the backward process to generate new, realistic data samples.\nWhy this process is critical:\n• It allows the model to reconstruct missing or noisy details.\n• It ensures that the output is consistent with real-world data distributions.\n• It provides control over the generation process by using learned probabilities rather\nthan rigid rules.\nThe probabilistic nature of DDPM plays a central role in its ability to generate both diverse\nand high-quality outputs.\nWhy probabilistic modeling is useful?\n1. Learning distributions rather than fixed mappings\no Instead of learning a direct transformation from input to output",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 19,
      "content": "ate both diverse\nand high-quality outputs.\nWhy probabilistic modeling is useful?\n1. Learning distributions rather than fixed mappings\no Instead of learning a direct transformation from input to output, the model\nlearns the underlying distribution of possible clean data conditioned on noisy\ninputs.\no This enables the model to handle uncertainty and variations present in real\ndata.\n2. Sampling from distributions\no During generation, the model samples noise from a distribution at each step.\nEven with the same input, different random samples produce varied outputs,\npromoting creativity and diversity.\n3. Capturing subtle patterns\no Probabilistic modeling allows the model to learn nuanced relationships in the\ndata such as textures, lighting patterns, or variations in shape that are hard to\ncapture with deterministic methods.\n4. Balancing realism and exploration\no By controlling the noise level and how it’s modeled, the system can explore\nnew possibilities while staying within the realm of re",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 20,
      "content": "re with deterministic methods.\n4. Balancing realism and exploration\no By controlling the noise level and how it’s modeled, the system can explore\nnew possibilities while staying within the realm of realistic outputs. This is\ncrucial for applications like design, simulation, and data augmentation.\nChallenges:\n1. High computational cost\no Because the process involves many steps (often hundreds or thousands),\ngenerating data can be slow and resource-intensive.\n2. Latency issues in real-time applications\n\n--- Page 9 ---\no The iterative nature makes it difficult to apply DDPMs in interactive or real-\ntime environments where fast feedback is essential.\n3. Difficulty in controlling outputs\no Without proper conditioning or guidance, the model might produce outputs\nthat are inconsistent with user expectations or desired styles.\n4. Data requirements\no Training DDPMs effectively requires large and diverse datasets to accurately\nlearn noise patterns and recover fine details.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 21,
      "content": "nconsistent with user expectations or desired styles.\n4. Data requirements\no Training DDPMs effectively requires large and diverse datasets to accurately\nlearn noise patterns and recover fine details.\nENERGY-BASED MODELS(EBMs)\nEnergy-Based Models (EBMs) are a class of probabilistic models that define relationships\nbetween variables using an energy function. Rather than explicitly modeling probability\ndistributions, EBMs assign an “energy” value to each possible configuration of variables,\nwhere lower energy indicates more likely or desirable configurations, and higher energy\ncorresponds to less likely ones.\nEBMs are widely used in machine learning for tasks such as representation learning,\nstructured prediction, anomaly detection, and reinforcement learning, where capturing\nrelationships and constraints between variables is more important than explicitly computing\nprobabilities.\n2. The Concept of Energy in EBMs\n• An energy function E(x)maps an input x to a scalar energy value.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 22,
      "content": "onships and constraints between variables is more important than explicitly computing\nprobabilities.\n2. The Concept of Energy in EBMs\n• An energy function E(x)maps an input x to a scalar energy value.\n• The lower the energy, the more plausible or preferred the data point is according to\nthe model.\n• The probability distribution p(x)is related to the energy via the Boltzmann\ndistribution:\nwhere Z is the partition function:\n• The partition function Z is often intractable, making it difficult to directly compute\nprobabilities, but not necessary for learning.\n\n--- Page 10 ---\n3. Architecture and Working\nCore Components:\n1. Energy Function\no The energy function is typically parameterized by neural networks or other\ndifferentiable models.\no It scores different data configurations to indicate how well they conform to the\ndesired patterns.\n2. Learning Objective\no EBMs learn by comparing the energies of positive (correct) and negative\n(incorrect or unlikely) samples.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 23,
      "content": "nfigurations to indicate how well they conform to the\ndesired patterns.\n2. Learning Objective\no EBMs learn by comparing the energies of positive (correct) and negative\n(incorrect or unlikely) samples.\no The goal is to assign lower energy to real data and higher energy to unlikely\ndata.\n3. Training Approaches\no Contrastive Divergence (CD) – Optimizes the model by comparing energy\ndifferences between observed and model-generated samples.\no Score Matching – Matches the gradient of the energy function rather than the\nenergy itself.\no Noise Contrastive Estimation (NCE) – Uses noise samples to help\napproximate the partition function during learning.\n4. Markov Random Fields (MRFs) and Conditional EBMs\n• EBMs are closely related to Markov Random Fields (MRFs), which model\ndependencies between variables using graph structures.\n• Conditional EBMs extend the energy framework to tasks where the output depends\non input features (e.g., image classification, structured output prediction).\n5.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 24,
      "content": "ween variables using graph structures.\n• Conditional EBMs extend the energy framework to tasks where the output depends\non input features (e.g., image classification, structured output prediction).\n5. Applications of EBMs\n1. Unsupervised Learning\no Modeling complex relationships in high-dimensional data such as images,\nspeech, or text.\n2. Anomaly Detection\no Identifying outliers by assigning higher energy to rare or unlikely\nconfigurations.\n3. Reinforcement Learning (RL)\no Estimating value functions where actions with lower energy correspond to\nmore rewarding behaviors.\n4. Generative Modeling\no Generating samples by searching for configurations with low energy, often\nusing sampling algorithms like Langevin dynamics.\n5. Structured Prediction\no Solving problems like image segmentation or sequence labeling where\nrelationships between output variables are important.\n\n--- Page 11 ---\n6. Advantages of EBMs\n• Flexibility – Can model arbitrary dependencies without requiring explicit probabilit",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 25,
      "content": "uence labeling where\nrelationships between output variables are important.\n\n--- Page 11 ---\n6. Advantages of EBMs\n• Flexibility – Can model arbitrary dependencies without requiring explicit probability\ndistributions.\n• Interpretability – The energy function directly encodes preferences or constraints.\n• Applicability – Useful in domains where structured relationships and constraints\ndominate over simple classification.\n7. Challenges and Limitations\n1. Intractable Partition Function\no Computing ZZZ is often impossible in practice, requiring approximation\ntechniques that can be unstable.\n2. Training Instability\no Optimization methods like contrastive divergence rely on sampling, which can\nlead to slow convergence or poor performance.\n3. Sampling Complexity\no Generating samples requires iterative methods such as Markov Chain Monte\nCarlo (MCMC), which can be computationally expensive.\n4. Scalability Issues\no Handling high-dimensional data with complex energy landscapes is\nchallenging.\n8.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 26,
      "content": "rative methods such as Markov Chain Monte\nCarlo (MCMC), which can be computationally expensive.\n4. Scalability Issues\no Handling high-dimensional data with complex energy landscapes is\nchallenging.\n8. Recent Advances\n• Neural EBMs – Combining deep learning with energy functions to model high-\ndimensional and structured data more effectively.\n• Score-based Generative Models – Learning the gradient of the energy function to\navoid directly computing the partition function.\n• Applications in Contrastive Learning – EBMs form the backbone of contrastive\napproaches where relationships between samples are emphasized.\n\n--- Page 12 ---\nCOMPARE EBMS VS VAES\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Defined by an energy function\nthat assigns a scalar “energy” to\n- Composed of two main parts: an\neach configuration of inputs (and\nencoder and a decoder.\noptionally outputs).\n- The encoder maps input data to a\n- No explicit probability\nlatent space distribution (typically\ndist",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 27,
      "content": "two main parts: an\neach configuration of inputs (and\nencoder and a decoder.\noptionally outputs).\n- The encoder maps input data to a\n- No explicit probability\nlatent space distribution (typically\ndistribution; the model learns to\nGaussian).\nassign lower energy to desired\n- The decoder reconstructs data\n✅ Architecture samples and higher energy to\nfrom samples drawn from the latent\nundesired ones.\nspace.\n- Often optimized using contrastive\n- Uses variational inference to\ndivergence or score matching.\napproximate intractable posteriors.\n- The architecture focuses on\n- The architecture explicitly models\nrelationships between data points\ndata generation.\nrather than reconstructing or\ngenerating them directly.\n- Maximize the Evidence Lower\n- Learn an energy landscape where\nBound (ELBO) which balances\ncorrect data points are assigned\nreconstruction accuracy and\nlower energy.\n✅ Objective regularization of the latent space.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 28,
      "content": "Evidence Lower\n- Learn an energy landscape where\nBound (ELBO) which balances\ncorrect data points are assigned\nreconstruction accuracy and\nlower energy.\n✅ Objective regularization of the latent space.\n- Optimization is based on\n- Encourages latent space structure\ndistinguishing good samples from\nfor efficient sampling and\nbad ones.\ninterpolation.\n- Indirect; energy defines the\nlikelihood up to a normalization - Explicit probabilistic framework\nconstant (partition function), which with tractable priors and\n✅ Probabilistic\nis often intractable. approximate posteriors.\nInterpretation\n- Focuses on learning relationships - Can directly sample from the latent\nand constraints rather than full space and model uncertainty.\ndensity estimation.\n- Uses sampling-based methods\nlike Markov Chain Monte Carlo - Uses backpropagation with\n(MCMC), contrastive divergence, reparameterization trick for efficient\n✅ Training\nor score matching. gradient estimation.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 29,
      "content": "mpling-based methods\nlike Markov Chain Monte Carlo - Uses backpropagation with\n(MCMC), contrastive divergence, reparameterization trick for efficient\n✅ Training\nor score matching. gradient estimation.\nMethods\n- Training can be unstable due to - More stable and easier to train\nreliance on sampling and gradient with large datasets.\nestimation.\n- Modeling complex dependencies\nin structured data. - Image and speech generation, data\n- Used in tasks like anomaly compression, anomaly detection,\ndetection, reinforcement learning, and semi-supervised learning.\n✅ Applications\nand unsupervised learning. - Used where interpretable latent\n- Applicable where relationships representations and smooth\nand constraints are more important generation paths are required.\nthan explicit reconstruction.\n\n--- Page 13 ---\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Flexibility in modeling\n- Well-suited for generating new\nrelationships without requiring\ndata samples.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 30,
      "content": "onstruction.\n\n--- Page 13 ---\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Flexibility in modeling\n- Well-suited for generating new\nrelationships without requiring\ndata samples.\n✅ Strengths explicit likelihood functions.\n- Provides interpretable latent spaces\n- Can incorporate constraints and\nuseful for downstream tasks.\ndomain knowledge easily.\n- May suffer from blurry\n- Training is computationally\nreconstructions or mode collapse.\nexpensive and less scalable. -\n✅ Limitations - Latent space structure depends\nNormalization constant estimation\nheavily on choice of priors and\nis intractable in many cases.\narchitectures.\nINTRODUCTION TO NOISE SCHEDULERS IN DIFFUSION MODELS\nIn diffusion models, noise plays a central role in transforming structured data into random noise\nduring training and then reconstructing it during sampling. However, how much noise is added\nor removed at each step is not arbitrary—it must be carefully controlled to ensure that the model\nlearns me",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 31,
      "content": "during training and then reconstructing it during sampling. However, how much noise is added\nor removed at each step is not arbitrary—it must be carefully controlled to ensure that the model\nlearns meaningful patterns and can effectively generate high-quality data.\nThis is where noise schedulers come into play.\nA noise scheduler defines the schedule or strategy by which noise is added to data in the\nforward diffusion process and removed in the backward process. It determines the magnitude\nof noise at each step, shaping how the model degrades and refines information over time.\nThe design of the noise schedule affects several critical aspects:\n• Learning efficiency – Too much noise can obscure important details, while too little\nmay prevent the model from learning to handle uncertainty.\n• Sample diversity and quality – The progression of noise influences how creative or\nrealistic the generated outputs are.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 32,
      "content": "s, while too little\nmay prevent the model from learning to handle uncertainty.\n• Sample diversity and quality – The progression of noise influences how creative or\nrealistic the generated outputs are.\n• Training stability – Gradual noise addition helps avoid erratic learning and ensures\nthat the model can generalize from noisy inputs.\nCommon schedules include linear, cosine, and exponential noise schedules, each offering\ndifferent trade-offs between smoothness, speed, and complexity.\nSignificance of Noise Schedulers in Diffusion Models\nIn diffusion models, noise schedulers determine how noise is added (in the forward process)\nor removed (in the backward process) at each step. They play a critical role in controlling the\nquality, stability, and efficiency of the model during both training and sampling.\nWhy are noise schedulers important?\n1. Control over noise injection\no A noise scheduler defines how much noise is added at each step, influencing\nhow quickly the data degrades from its or",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 33,
      "content": "nd sampling.\nWhy are noise schedulers important?\n1. Control over noise injection\no A noise scheduler defines how much noise is added at each step, influencing\nhow quickly the data degrades from its original form to pure noise.\n\n--- Page 14 ---\no A carefully designed schedule ensures that the model learns meaningful\ntransformations at each step rather than abrupt or overly noisy transitions.\n2. Balance between learning and randomness\no If noise is added too aggressively, the model may struggle to learn how to\nrecover the data because too much information is lost early.\no If noise is too weak, the model may not generalize well and could overfit to\nspecific patterns without learning how to handle uncertainty.\n3. Smooth transitions\no Gradual noise addition allows the model to capture complex patterns and fine\ndetails at different noise levels, helping the backward process refine the data\neffectively.\n4.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 34,
      "content": "ty.\n3. Smooth transitions\no Gradual noise addition allows the model to capture complex patterns and fine\ndetails at different noise levels, helping the backward process refine the data\neffectively.\n4. Influences sample quality and diversity\no The noise schedule affects the kinds of outputs the model generates. For\ninstance, a slower noise increase might produce high-fidelity samples, while a\nfaster schedule might encourage more diverse and creative outputs.\n5. Stabilizes training\no Appropriate noise scheduling prevents extreme gradients or erratic learning\nbehavior, enabling stable and efficient training across large datasets.\n✅ Example of a commonly used noise scheduler: Linear noise schedule\nOne widely used noise scheduler is the linear noise schedule, where the noise level increases\nat a constant rate across steps.\n• The noise added at each step t is computed as:\nwhere:\no β start is the initial noise amount,\no β end is the final noise amount,\no T is the total number of steps.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 35,
      "content": "ses\nat a constant rate across steps.\n• The noise added at each step t is computed as:\nwhere:\no β start is the initial noise amount,\no β end is the final noise amount,\no T is the total number of steps.\nWhy it's used:\n• Simplicity – easy to implement and analyze.\n• Gradual degradation – ensures smooth transitions from structured data to noise.\n• Works well in practice for a variety of tasks without requiring complex tuning.\n✅ Other common noise schedules\n• Cosine schedule – Uses a cosine curve to control noise increments, adding noise\nmore smoothly at the beginning and end.\n\n--- Page 15 ---\n• Exponential schedule – Adds noise in a way that accelerates or decelerates across\nsteps, providing more control over learning phases.\nComparison between Class-Conditional Diffusion Models and Unconditional Diffusion\nModels\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\nDiffusion models where the generation\nDiffusion models that generate data\nprocess is guided by class label",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 36,
      "content": "nal Diffusion\nModels\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\nDiffusion models where the generation\nDiffusion models that generate data\nprocess is guided by class labels or\npurely based on learned distributions\nadditional conditioning information (e.g.,\n✅ Definition without any conditioning information.\ntext, attributes). The model learns how the\nThe model only depends on noise and\ndata distribution changes for different\nthe learned data distribution.\nclasses.\n- Incorporates class labels or auxiliary\ninputs into the noise prediction network.\n- Contains only the noise prediction\n- Conditioning is usually done by\nnetwork without any external inputs.\nconcatenating labels or through\n✅ - Learns the general structure and\nembeddings that influence intermediate\nArchitecture distribution of the entire dataset.\nlayers.\n- Generates samples based on noise\n- The model learns separate modes of the\nwithout class-specific guidance.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 37,
      "content": "ddings that influence intermediate\nArchitecture distribution of the entire dataset.\nlayers.\n- Generates samples based on noise\n- The model learns separate modes of the\nwithout class-specific guidance.\ndata distribution for each class or\ncondition.\n- Learn how to denoise while respecting - Learn to denoise without any guidance\nclass information. other than the underlying data\n✅ Training - The model minimizes the reconstruction distribution.\nObjective loss while conditioning on the class, - The model focuses on general patterns\nensuring generated samples match the and statistical relationships in the\ntarget category. dataset.\n- During generation, class labels guide the\n- Generates samples from noise without\nsampling process, allowing control over\ncontrol over attributes or categories.\n✅ Sampling what kind of sample is generated (e.g., a\n- Produces diverse outputs but without\ncat vs. a dog image).\nspecific guidance.\n- Can produce targeted, structured outputs.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 38,
      "content": "tributes or categories.\n✅ Sampling what kind of sample is generated (e.g., a\n- Produces diverse outputs but without\ncat vs. a dog image).\nspecific guidance.\n- Can produce targeted, structured outputs.\n- Image synthesis conditioned on class\nlabels (e.g., generating specific objects or - General image, audio, or video\nfaces). generation where control is not\n✅ - Text-to-image generation, style transfer, necessary.\nApplications or scenarios requiring targeted outputs. - Data augmentation, unsupervised\n- Semi-supervised learning where learning, and exploratory creative\nadditional information improves generation generation.\nquality.\n- Greater control over generated samples.\n✅ - Can produce outputs tailored to specific - Simpler architecture and easier to\nAdvantages tasks or user inputs. implement.\n- More interpretable generation process. - Requires less labeled data.\n\n--- Page 16 ---\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\n- Capable of learning diverse patter",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 39,
      "content": "t.\n- More interpretable generation process. - Requires less labeled data.\n\n--- Page 16 ---\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\n- Capable of learning diverse patterns\nfrom large, unstructured datasets.\n- Requires labeled data or conditioning\n- Lacks control over generated content.\n✅ inputs, which may not always be available.\n- May produce irrelevant or ambiguous\nLimitations - More complex architecture and higher\noutputs when diverse patterns overlap.\ncomputational cost.\nDDIM (DENOISING DIFFUSION IMPLICIT MODELS)\nDDIM (Denoising Diffusion Implicit Models) is an improvement over standard diffusion\nmodels like DDPM (Denoising Diffusion Probabilistic Models). It introduces a new sampling\nmethod that allows generating high-quality samples with significantly fewer steps, while still\nretaining diversity and structure in the outputs.\n✅ Why DDIM was introduced\n1.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 40,
      "content": "introduces a new sampling\nmethod that allows generating high-quality samples with significantly fewer steps, while still\nretaining diversity and structure in the outputs.\n✅ Why DDIM was introduced\n1. Reduce Sampling Time\no Traditional diffusion models like DDPM require hundreds or thousands of\nsteps during sampling, which makes them computationally expensive and slow\nfor practical applications.\n2. Maintain Quality and Diversity\no Simply reducing steps in DDPM leads to degraded or less diverse outputs.\no DDIM proposes a deterministic or pseudo-deterministic approach that\nmaintains high sample fidelity even with fewer steps.\n✅ How DDIM works\n1. Implicit Sampling\no Instead of following the stochastic reverse process of DDPM, DDIM defines a\ndeterministic mapping between noise and data, reducing randomness during\nsampling.\no The model avoids resampling at each step, making it faster and more stable.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 41,
      "content": "erse process of DDPM, DDIM defines a\ndeterministic mapping between noise and data, reducing randomness during\nsampling.\no The model avoids resampling at each step, making it faster and more stable.\n2. Non-Markovian Transitions\no Unlike DDPM where each step depends only on the previous one (Markov\nproperty), DDIM relaxes this assumption by allowing steps that depend on\nearlier states.\no This enables more flexible transitions and faster sampling while preserving\nsample quality.\n3. Controlled Interpolation\no DDIM allows interpolation between different noise levels and samples, which\ncan be used for creative applications like style mixing or smooth transitions.\n\n--- Page 17 ---\n✅ Key Differences from DDPM\nFeature DDPM DDIM\nStochastic, follows Markov chain with Deterministic or pseudo-deterministic,\nSampling process\nrandom transitions with fewer steps\nComputational\nHigh due to many sampling steps Much lower with accelerated sampling\ncost\nCan explore a wide range of outputs due Maintains div",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 42,
      "content": "stic,\nSampling process\nrandom transitions with fewer steps\nComputational\nHigh due to many sampling steps Much lower with accelerated sampling\ncost\nCan explore a wide range of outputs due Maintains diversity but with controlled\nDiversity\nto randomness noise patterns\nSuitable for tasks needing rich Better for fast generation and interactive\nUse case\nexploration applications\n✅ Mathematical Insight\nIn DDPM, the reverse process is modeled as a probabilistic sampling from p(x ∣x), where\nt−1 t\nrandomness is inherent at each step.\nIn DDIM, a deterministic transition is defined:\nHere:\n• α t defines how much signal is preserved at each step.\n• ϵ θ (x t ,t) is the model’s learned noise prediction.\nThis formulation allows skipping intermediate steps while still approximating the\nreverse trajectory.\n✅ Applications of DDIM\n1. Image Generation\no Produces high-resolution images quickly without compromising on details.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 43,
      "content": "s skipping intermediate steps while still approximating the\nreverse trajectory.\n✅ Applications of DDIM\n1. Image Generation\no Produces high-resolution images quickly without compromising on details.\n2. Video and Audio Synthesis\no Enables faster generation for time-sensitive applications like animation or\nsound design.\n3. Style Transfer & Interpolation\no Smoothly blends between samples by manipulating latent noise patterns\ndeterministically.\n4. Interactive Tools\no Supports real-time editing and creative workflows where speed and control are\ncritical.\n\n--- Page 18 ---\n✅ Advantages of DDIM\n✔ Faster sampling with fewer steps\n✔ Stable and high-quality outputs\n✔ Supports interpolation and controlled generation\n✔ Reduces computational cost without major trade-offs in realism\n✅ Limitations of DDIM\n❗ May lose some diversity due to reduced randomness\n❗ Requires careful tuning of schedules and noise levels\n❗ Still dependent on well-trained models to perform effectively\n✅ Conclusion\nDDIM is a power",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "42eab934-cfce-450b-888d-ea7b1bf868df_UNIT I - GCV NOTES.pdf_a0a003d3",
      "chunk_index": 44,
      "content": "❗ May lose some diversity due to reduced randomness\n❗ Requires careful tuning of schedules and noise levels\n❗ Still dependent on well-trained models to perform effectively\n✅ Conclusion\nDDIM is a powerful extension of diffusion models that addresses one of their biggest\nlimitations—slow sampling—by introducing deterministic or semi-deterministic transitions.\nIt enables faster generation while maintaining sample fidelity and diversity, making it highly\nsuitable for real-world applications like image synthesis, animation, and interactive creative\ntools.",
      "filename": "UNIT I - GCV NOTES.pdf"
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nUnit II\nCLIP (Contrastive Language–Image Pretraining)\nCLIP (Contrastive Language–Image Pretraining) learns a joint text–image embedding\nspace by using contrastive learning to bring matching image–text pairs close and push\nnon-matching pairs apart.\nKey points & justifications:\n1. Dual encoders (text & image) mapped to a shared space.\nJustification: Mapping both modalities into the same vector space makes direct\nsimilarity computations (cosine similarity) possible. This design simplifies\ndownstream tasks (retrieval, zero-shot classification) because the model does\nnot have to learn task-specific cross-modal projections every time — the shared\nspace is a reusable interface.\n2. Contrastive (InfoNCE) loss pulls positives and pushes negatives.\nJustification: InfoNCE directly optimizes relative similarity: maximizing similarity\nof correct pairs while minimizing similarity of incorrect pairs.",
      "filename": "UNIT II - GCV.pdf",
      "page": 1
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 1,
      "content": "nfoNCE) loss pulls positives and pushes negatives.\nJustification: InfoNCE directly optimizes relative similarity: maximizing similarity\nof correct pairs while minimizing similarity of incorrect pairs. This encourages\nembeddings to capture semantics that distinguish correct captions from\ndistractors, which is precisely what cross-modal tasks require.\n3. Large batch / many negatives improve representation quality.\nJustification: More negatives increase the difficulty of the contrastive task,\nforcing embeddings to capture fine-grained distinctions. Empirically large\neffective batch sizes (or memory banks) create stronger supervision signals,\nproducing richer semantic structure.\n4. Enables zero-shot transfer and robust retrieval.\nJustification: Because CLIP learns general alignment between text concepts and\nvisual features, it can map a new text label into the same space and retrieve\nrelevant images without task-specific retraining — the learned semantic\ngeometry generalizes.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 2,
      "content": "nt between text concepts and\nvisual features, it can map a new text label into the same space and retrieve\nrelevant images without task-specific retraining — the learned semantic\ngeometry generalizes.\nExample:\nImage: “a red bicycle on a rainy street.” CLIP will place the image embedding near\ncaptions describing bicycles/rain, and far from unrelated captions (e.g., “a dog in a\npark”).\nApplications & justification:\n• Zero-shot classification: No fine-tuning needed because class names can be\nembedded and compared to images.\nJustification: The shared semantic space means class semantics are already\nencoded.\n\n--- Page 2 ---\n• Text-guided retrieval and generation: CLIP scores can rank generated images or\nguide generative models.\nJustification: Direct similarity metrics allow automatic evaluation and steering.\nText embeddings in multimodal diffusion models\nText embeddings convert a prompt into a dense vector that conditions diffusion models,\nguiding stochastic denoising toward images that mat",
      "filename": "UNIT II - GCV.pdf",
      "page": 2
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 3,
      "content": "and steering.\nText embeddings in multimodal diffusion models\nText embeddings convert a prompt into a dense vector that conditions diffusion models,\nguiding stochastic denoising toward images that match the text.\nKey points & justifications:\n1. Serve as conditioning signal during denoising.\nDiffusion models generate by reversing noise; conditioning vectors are injected\n(via concatenation, cross-attention, or FiLM) so each denoising step has\nsemantic context. Without conditioning, the model has no way to steer\ngeneration toward the desired semantics.\n2. Capture both object and style attributes.\nModern text encoders (Transformers) represent not just nouns but adjectives,\nrelations, and style descriptors. Embeddings therefore allow the generator to\nsynthesize content (objects) and aesthetic (style) simultaneously.\n3. Enable fine controls (compositional prompts, modifiers).\nVector arithmetic and attention let the model weight different subcomponents\nof the prompt; e.g.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 4,
      "content": "ects) and aesthetic (style) simultaneously.\n3. Enable fine controls (compositional prompts, modifiers).\nVector arithmetic and attention let the model weight different subcomponents\nof the prompt; e.g., “photorealistic” vs “oil painting” map to different embedding\ndirections, producing controlled stylistic outcomes.\n4. Facilitate semantic consistency across steps.\nConditioning every denoising step (rather than only at start) ensures semantic\ninformation persists through the stochastic sampling, preventing drift to\nirrelevant modes.\nExample:\nPrompt: “A small wooden cabin at sunset, misty atmosphere.” The embedding encodes\nobject (“cabin”), material (“wooden”), time (“sunset”), and mood (“misty”) so the\ndiffusion model composes these attributes coherently.\nApplications & justification:\n• Text-to-image (Stable Diffusion): Embeddings let a single model produce\ndiverse outputs from many prompts.\nA single learned forward/backward process can be reused with different\ncondition vectors.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 5,
      "content": ":\n• Text-to-image (Stable Diffusion): Embeddings let a single model produce\ndiverse outputs from many prompts.\nA single learned forward/backward process can be reused with different\ncondition vectors.\n\n--- Page 3 ---\n• Prompt interpolation and editing: Embeddings allow latent manipulations\n(e.g., amplify “sunset”) to edit outputs.\nContinuous embeddings provide smooth control that discrete labels cannot.\nCritical insight / limitation\nIf embeddings lack domain knowledge or are ambiguous, generation will be\nsemantically weak. Therefore, high-quality text encoders and, when needed, domain-\nspecific embedding fine-tuning are essential.\nCommon evaluation metrics for text–image alignment\nEvaluating multimodal generation requires metrics that measure both visual quality and\nsemantic alignment between text and image.\nMetrics & justifications:\n1. CLIPScore (cosine similarity of CLIP embeddings).\nWhat it measures: Semantic alignment between generated image and\nprompt.",
      "filename": "UNIT II - GCV.pdf",
      "page": 3
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 6,
      "content": "y and\nsemantic alignment between text and image.\nMetrics & justifications:\n1. CLIPScore (cosine similarity of CLIP embeddings).\nWhat it measures: Semantic alignment between generated image and\nprompt.\nCLIP is trained to align modalities; its cosine similarity is a direct proxy for how\nwell image content matches textual semantics. It’s automatic and correlates\nreasonably with human judgments for many prompts.\n2. FID (Fréchet Inception Distance).\nWhat it measures: Distributional similarity between generated images and\nreal images.\nFID captures both quality and diversity by comparing feature statistics (means,\ncovariances). Lower FID implies generated images occupy similar manifold to\nreal images.\n3. Inception Score (IS).\nWhat it measures: Distinctiveness and confidence of generated images (via\nan Inception classifier).\nIS rewards samples that are recognizable and varied; however it doesn’t\nmeasure prompt alignment.\n4. Human evaluation (relevance, fidelity, preference).",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 7,
      "content": "generated images (via\nan Inception classifier).\nIS rewards samples that are recognizable and varied; however it doesn’t\nmeasure prompt alignment.\n4. Human evaluation (relevance, fidelity, preference).\nWhat it measures: Subjective semantic correctness and visual appeal.\nAutomated metrics are imperfect, so human judgment remains the gold\nstandard, especially for nuanced or creative prompts.\n5. Task-specific metrics (precision/recall on objects, detection mAP).\nWhen prompts require specific objects or relations, applying object detectors\nand measuring precision/recall quantifies functional correctness.\n\n--- Page 4 ---\nCombining metrics — justification:\nNo single metric captures all aspects. CLIPScore checks alignment but not realism; FID\nchecks realism but not prompt adherence. Combining metrics plus human checks\nproduces more reliable evaluation.\nLimitations :\nCLIPScore can be gamed (adversarially optimized); FID is sensitive to dataset choice\nand model used for features.",
      "filename": "UNIT II - GCV.pdf",
      "page": 4
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 8,
      "content": ". Combining metrics plus human checks\nproduces more reliable evaluation.\nLimitations :\nCLIPScore can be gamed (adversarially optimized); FID is sensitive to dataset choice\nand model used for features. Thus metric selection should align with evaluation goals\nand be interpreted carefully.\nFine-tuning CLIP\nIntroduction:\nPretrained CLIP is broad but not deep in domain-specific semantics; fine-tuning adapts\nit to specialized vocabularies, visual cues, and biases of a target domain.\nKey points & justifications:\n1. Bridging domain vocabulary gaps.\nCLIP’s internet training may underrepresent domain terms (medical labels,\nindustrial parts). Fine-tuning with domain captions teaches the text encoder\ndomain semantics and aligns them to visual cues in that field.\n2. Improving visual feature sensitivity to domain specifics.\nFine-tuning the image encoder helps it attend to subtle diagnostic visual features\n(e.g., microcalcifications) that general models may deem irrelevant.\n3.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 9,
      "content": "sual feature sensitivity to domain specifics.\nFine-tuning the image encoder helps it attend to subtle diagnostic visual features\n(e.g., microcalcifications) that general models may deem irrelevant.\n3. Reducing harmful biases and spurious correlations.\nDomain curation can balance datasets and remove stereotypes present in\ninternet data, improving fairness and factual accuracy in sensitive contexts.\n4. Better downstream task performance (retrieval, VQA, diagnostics).\nFine-tuned embeddings yield higher retrieval precision and more accurate VQA\nanswers because they encode task-relevant features.\nPractical methods & justifications:\n• Full fine-tuning: update all weights — best for abundant labels.\nAllows maximal adaptation but risks catastrophic forgetting and needs data/GPU\nresources.\n• Adapter modules / LoRA / prompt tuning: lightweight adjustments.\nPreserve pretrained knowledge while cheaply adapting to domain; less risk of\nforgetting and cheaper to train.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 10,
      "content": "eds data/GPU\nresources.\n• Adapter modules / LoRA / prompt tuning: lightweight adjustments.\nPreserve pretrained knowledge while cheaply adapting to domain; less risk of\nforgetting and cheaper to train.\n\n--- Page 5 ---\n• Continual learning / regularization: e.g., Elastic Weight Consolidation to\nprevent forgetting.\nMaintains general CLIP capabilities while learning domain specifics.\nExample:\nFine-tuning CLIP on annotated chest X-rays (labels, radiologist captions) yields\nimproved retrieval and VQA performance for radiology tasks because the model learns\nto associate radiographic patterns with domain terms.\nFine-tuning requires curated, representative, and labeled domain data; otherwise you\nrisk overfitting or preserving harmful biases. Validation and human oversight are\nessential.\nArchitecture of CLIP and joint learning\nIntroduction:\nCLIP uses separate encoders for images and text, projection heads to a common\nembedding space, and contrastive training to jointly learn aligned representati",
      "filename": "UNIT II - GCV.pdf",
      "page": 5
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 11,
      "content": "e of CLIP and joint learning\nIntroduction:\nCLIP uses separate encoders for images and text, projection heads to a common\nembedding space, and contrastive training to jointly learn aligned representations.\nArchitecture components & justifications:\n1. Image encoder (ViT or ResNet).\nCNNs (ResNet) capture local textures; ViTs capture long-range interactions.\n\n--- Page 6 ---\nChoice depends on tradeoffs (compute vs performance). Both produce rich\nvisual features for projection.\n2. Text encoder (Transformer).\nTransformers model sequential and contextual language semantics effectively,\nenabling capture of compositional meaning (modifiers, relations).\n3. Projection heads (linear layers) mapping to shared space.\nSeparate high-dim features are projected to a common dimensionality so cosine\nsimilarity is meaningful; projection can also adapt modality-specific statistics.\n4. Contrastive (InfoNCE) training with large effective batch size.\nMany negatives help the model learn fine distinctions.",
      "filename": "UNIT II - GCV.pdf",
      "page": 6
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 12,
      "content": "ilarity is meaningful; projection can also adapt modality-specific statistics.\n4. Contrastive (InfoNCE) training with large effective batch size.\nMany negatives help the model learn fine distinctions. Training with symmetric\nloss (image→text and text→image) strengthens bidirectional retrieval capability.\n5. Temperature scaling in contrastive loss.\nTemperature controls concentration of similarity distribution; tuning it balances\nsensitivity between positive/negative pairs.\nWhy this design works?\n• Separate encoders let each modality use architectures tailored to its inductive\nbiases, yet the projection + contrastive loss forces semantic alignment without\nmerging architectures (which would be less flexible).\n• Large paired datasets provide diverse supervision so the embedding geometry\ngeneralizes across many concepts.\nExample:\nDuring training a batch of image-caption pairs, each image’s closest embedding should\nbe its caption’s embedding.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 13,
      "content": "verse supervision so the embedding geometry\ngeneralizes across many concepts.\nExample:\nDuring training a batch of image-caption pairs, each image’s closest embedding should\nbe its caption’s embedding. The symmetric contrastive loss enforces this across all\nbatch pairs, producing a globally consistent embedding geometry.\nTradeoffs:\n• Heavy compute and data requirements are justified by strong zero-shot\nperformance.\n• Model complexity makes fine-tuning expensive; adapter techniques can mitigate\ncosts.\nCLIP can be integrated with diffusion models for text-to-image generation\nIntroduction:\nCLIP can guide diffusion models either by providing conditioning embeddings or by\nacting as an external scorer to encourage semantic alignment during sampling.\n\n--- Page 7 ---\nIntegration mechanisms & justifications:\n1. Embedding conditioning (direct): feed CLIP text embeddings into diffusion\nmodel (via cross-attention or concatenation).",
      "filename": "UNIT II - GCV.pdf",
      "page": 7
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 14,
      "content": "ent during sampling.\n\n--- Page 7 ---\nIntegration mechanisms & justifications:\n1. Embedding conditioning (direct): feed CLIP text embeddings into diffusion\nmodel (via cross-attention or concatenation).\nDirect conditioning uses the semantic vector as part of the generative process,\nenabling the model to learn to map embeddings to visual features during training\n— the cleanest, learned integration.\n2. CLIP guidance (external scorer / gradient guidance): compute CLIP similarity\nof intermediate samples to the prompt and backpropagate gradients to\nnudge samples.\nThis allows a pretrained diffusion model (without conditioning) to be steered at\nsampling time; useful when retraining is expensive. It leverages CLIP’s semantic\nsignal as an online objective.\n3. Classifier-free guidance vs CLIP scoring: classifier-free guidance blends\nunconditional and conditional denoising; CLIP guidance explicitly optimizes\nsemantic similarity.",
      "filename": "UNIT II - GCV.pdf",
      "page": 7
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 15,
      "content": "al as an online objective.\n3. Classifier-free guidance vs CLIP scoring: classifier-free guidance blends\nunconditional and conditional denoising; CLIP guidance explicitly optimizes\nsemantic similarity.\nClassifier-free guidance is learned and often efficient; CLIP guidance can\nimprove semantic alignment but is computationally heavier and sometimes\nunstable, so practitioners choose based on constraints.\n4. Hybrid approaches (fine-tune diffusion with CLIP): fine-tune a conditional\ndiffusion model where conditioning is CLIP embeddings.\nThis produces the most coherent integration: the generator learns to use\nembeddings during training, reducing the need for costly gradient-based steering\nat sampling time.\nExample workflow (gradient guidance):\nAt each sampling step, generate image x_t, compute CLIP similarity s = cosine(clip_text,\nclip_image(x_t)), compute ∇_{x_t} s and adjust x_t in direction that increases similarity,\nthen proceed to next denoising step.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 16,
      "content": "step, generate image x_t, compute CLIP similarity s = cosine(clip_text,\nclip_image(x_t)), compute ∇_{x_t} s and adjust x_t in direction that increases similarity,\nthen proceed to next denoising step.\nTradeoffs:\n• Pros: CLIP guidance improves semantic fidelity and allows reusing pretrained\ndiffusion models.\n• Cons: Extra compute (CLIP forward + gradient) and potential for adversarial\nartifacts if optimized too aggressively — justification for careful step size and\nregularization.\nQ7 — Compare CLIP-guided generation vs GAN-based text-to-image methods\n\n--- Page 8 ---\nComparison points & justifications:\n1. Semantic alignment: CLIP-guided diffusion > GANs.\nJustification: CLIP provides explicit semantic supervision via\nembeddings/scores; GANs rely on discriminator signals that emphasize\nrealism rather than semantic correctness.\n2. Visual sharpness / texture realism: GANs often produce sharper textures.",
      "filename": "UNIT II - GCV.pdf",
      "page": 8
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 17,
      "content": "pervision via\nembeddings/scores; GANs rely on discriminator signals that emphasize\nrealism rather than semantic correctness.\n2. Visual sharpness / texture realism: GANs often produce sharper textures.\nJustification: GAN adversarial loss explicitly forces photorealistic textures;\ndiffusion models historically produced blurrier outputs (though modern\ntechniques narrowed the gap).\n3. Training stability: Diffusion (with CLIP) tends to be more stable than GAN\ntraining.\nJustification: GANs suffer from mode collapse and training instability due to\nadversarial dynamics; diffusion is likelihood-based and often converges\nmore predictably.\n4. Sampling speed / compute: GANs typically faster at inference; CLIP-guided\ndiffusion is slower.\nJustification: GANs generate in one forward pass; diffusion models require\nmany denoising steps; CLIP guidance adds more compute for\nscoring/gradients.\n5. Controllability & editing: CLIP-guided diffusion offers finer control (text,\nprompt editing).",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 18,
      "content": "; diffusion models require\nmany denoising steps; CLIP guidance adds more compute for\nscoring/gradients.\n5. Controllability & editing: CLIP-guided diffusion offers finer control (text,\nprompt editing).\nJustification: Conditioning and CLIP feedback directly influence semantics\nacross steps; GANs can be controlled via latent manipulations but mapping\nbetween latent and semantics is less direct.\n6. Robustness to prompts: CLIP-guided methods generalize better to open-\nended prompts.\nJustification: CLIP’s pretraining on broad captions provides strong semantic\ngrounding; GANs trained on limited paired data often struggle with out-of-\ndistribution prompts.\nUse-case recommendations (justified):\n• For high-speed production of photoreal textures, GANs may be preferable.\nJustification: Fast single-pass generation with high fidelity.\n• For semantic, creative, and controllable generation, CLIP-guided diffusion is\npreferable despite slower sampling.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 19,
      "content": "Ns may be preferable.\nJustification: Fast single-pass generation with high fidelity.\n• For semantic, creative, and controllable generation, CLIP-guided diffusion is\npreferable despite slower sampling.\nJustification: Better alignment to textual intent and flexibility.\n\n--- Page 9 ---\nLimitation of CLIP and a detailed solution (with justifications)\nLimitation chosen: Bias and spurious correlations inherited from large web-scale\ntraining data.\n• CLIP’s embeddings reflect the distribution of its training corpus; societal\nstereotypes and underrepresentation produce associations that can harm\ndownstream use (e.g., biased retrieval or discriminatory generative outputs). In\ncritical domains (hiring, law, medicine) these errors are unacceptable.\nProposed multi-pronged solution:\n1. Domain-aware fine-tuning with curated datasets.\nCurated, annotated domain data corrects label distributions and teaches the\nmodel correct associations relevant to the domain (e.g., medical labels).",
      "filename": "UNIT II - GCV.pdf",
      "page": 9
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 20,
      "content": "1. Domain-aware fine-tuning with curated datasets.\nCurated, annotated domain data corrects label distributions and teaches the\nmodel correct associations relevant to the domain (e.g., medical labels). It\nreduces reliance on noisy web labels.\n2. Bias mitigation during training (reweighting / adversarial debiasing).\nReweighting or adversarial objectives discourage encoding of protected\nattributes (e.g., gender) when they’re not relevant. These methods directly\npenalize the emergence of undesirable correlations.\n3. Counterfactual data augmentation.\nGenerating or collecting balanced examples that swap sensitive attributes (e.g.,\nsame profession across genders/ethnicities) reduces statistical shortcuts and\nforces the model to focus on relevant visual cues.\n4. Evaluation & continuous monitoring (human-in-the-loop).\nAutomated checks (fairness metrics) plus human audits detect remaining bias.\nContinuous monitoring post-deployment catches distribution shifts and\nemergent problems.\n5.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 21,
      "content": "monitoring (human-in-the-loop).\nAutomated checks (fairness metrics) plus human audits detect remaining bias.\nContinuous monitoring post-deployment catches distribution shifts and\nemergent problems.\n5. Model explanations and transparency.\nSaliency maps or retrieval-based explanations help users understand why the\nmodel associated certain text and images, enabling corrective action.\nExample application:\nDeploying an e-commerce visual search: before deployment, augment training with\ndiverse product images across demographics, apply reweighting, and run fairness tests\nto ensure the model does not systematically underrepresent particular groups.\n\n--- Page 10 ---\n2. CLIP AND JOINT EMBEDDINGS\nIntroduction\nGenerative AI has transformed the way text and visual data can be integrated to create\nnew forms of digital content. Among the leading approaches are Contrastive Language–\nImage Pretraining (CLIP) and diffusion models, which together form a powerful pipeline\nfor text-to-image synthesis.",
      "filename": "UNIT II - GCV.pdf",
      "page": 10
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 22,
      "content": "new forms of digital content. Among the leading approaches are Contrastive Language–\nImage Pretraining (CLIP) and diffusion models, which together form a powerful pipeline\nfor text-to-image synthesis.\nCLIP aligns language and visual modalities through joint embeddings, while diffusion\nmodels use probabilistic denoising processes to synthesize realistic and semantically\naligned images.\nThis integration is significant across domains like education, design, healthcare,\nentertainment, and scientific communication, where the ability to convert descriptions\ninto visuals saves time, enhances creativity, and improves accessibility. However,\nensuring reliability, accuracy, and fairness requires deeper understanding of the\nmechanisms, limitations, and solutions of such systems.\n(a) CLIP and Joint Embeddings – Mechanism and Benefits\n1. Core Concept\no CLIP consists of two encoders:\n▪ A Text Encoder (Transformer-based) processes natural language\nprompts.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 23,
      "content": "utions of such systems.\n(a) CLIP and Joint Embeddings – Mechanism and Benefits\n1. Core Concept\no CLIP consists of two encoders:\n▪ A Text Encoder (Transformer-based) processes natural language\nprompts.\n▪ An Image Encoder (ResNet or Vision Transformer) processes image\ndata.\no Both outputs are projected into a shared embedding space, enabling\ncomparisons.\n2. Contrastive Learning\no During training, CLIP is presented with a batch of image–text pairs.\no The correct image–caption pair should have a high cosine similarity, while\nincorrect pairs should score low.\no InfoNCE loss optimizes this by pulling true pairs closer and pushing false\npairs apart.\n3. Why This Matters for Generation\no When combined with diffusion models, the shared space ensures the\ngenerated image faithfully represents the meaning of the text.\n\n--- Page 11 ---\no Unlike traditional vision models limited to classification, CLIP’s\nembeddings generalize across unseen categories and abstract prompts.\n4.",
      "filename": "UNIT II - GCV.pdf",
      "page": 11
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 24,
      "content": "hfully represents the meaning of the text.\n\n--- Page 11 ---\no Unlike traditional vision models limited to classification, CLIP’s\nembeddings generalize across unseen categories and abstract prompts.\n4. Example\no Prompt: “A panda wearing sunglasses playing guitar.”\no CLIP embeddings capture not only the object (“panda”) but also\nattributes (“wearing sunglasses”) and context (“playing guitar”).\no The diffusion model uses these embeddings to guide generation, ensuring\nall described elements appear.\n5. Justification\no This approach solves the problem of semantic drift, where generated\nimages deviate from text.\no It also enables zero-shot transfer, where the model works on new\nconcepts without retraining.\n(b) Noise Scheduling and Diffusion Process – Stability and Quality\n1. Forward Diffusion (Training Stage)\no The model learns by gradually adding Gaussian noise to real images over\nmany steps until they become indistinguishable from random noise.",
      "filename": "UNIT II - GCV.pdf",
      "page": 11
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 25,
      "content": "Stability and Quality\n1. Forward Diffusion (Training Stage)\no The model learns by gradually adding Gaussian noise to real images over\nmany steps until they become indistinguishable from random noise.\no This corruption process teaches the system how data can be “destroyed”\nin a controlled manner.\n2. Backward Diffusion (Generation Stage)\no The generative model reverses the process, progressively denoising\nrandom noise step by step to reconstruct a meaningful image.\no Conditioning on text embeddings ensures that the denoising follows the\nsemantic structure encoded in the prompt.\n3. Noise Schedulers\no Decide the rate and distribution of noise addition/removal across\ntimesteps.\no Common schedulers: linear, cosine, exponential decay.\no The choice affects image clarity, diversity, and fidelity.\n4. Why It Matters\n\n--- Page 12 ---\no Too much noise at early steps → unstable generations.\no Too little → lack of diversity.",
      "filename": "UNIT II - GCV.pdf",
      "page": 12
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 26,
      "content": "nential decay.\no The choice affects image clarity, diversity, and fidelity.\n4. Why It Matters\n\n--- Page 12 ---\no Too much noise at early steps → unstable generations.\no Too little → lack of diversity.\no A well-designed scheduler balances exploration and accuracy, leading to\nimages that are high-quality, sharp, and semantically consistent.\n5. Example\no A poorly tuned scheduler may generate a “blurred car” for the prompt “a\nred sports car on a racetrack.”\no With proper scheduling, details like color, motion blur, and track\nbackground are preserved.\n6. Justification\no Diffusion + noise scheduling ensures outputs remain reliable and artifact-\nfree, addressing weaknesses of earlier GAN-based methods which often\nsuffered from mode collapse.\n(c) Ensuring Accuracy with Fine-Tuning – Overcoming Hallucinations\n1. The Challenge\no Generative models, when trained on generic internet data, may produce\nimages that are visually appealing but scientifically or contextually\ninaccurate.",
      "filename": "UNIT II - GCV.pdf",
      "page": 12
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 27,
      "content": "g – Overcoming Hallucinations\n1. The Challenge\no Generative models, when trained on generic internet data, may produce\nimages that are visually appealing but scientifically or contextually\ninaccurate.\no Risk of “hallucination” (adding irrelevant objects) or oversimplification.\n2. Role of Fine-Tuning\no Fine-tuning adapts pretrained models to specific domains using curated\ndatasets.\no Adjusts weights so the model captures domain-specific semantics and\navoids irrelevant associations.\n3. Methods\no Full fine-tuning: Retrain on specialized datasets (e.g., radiology images,\nengineering diagrams).\no Adapter/LoRA tuning: Lightweight layers added for efficient adaptation.\no Prompt-tuning: Adding domain-specific tokens or context.\n4. Example\no Generic model → “DNA double helix” may produce artistic swirls.\n\n--- Page 13 ---\no Fine-tuned model on biology diagrams → generates precise base pairs and\nmolecular structure.\n5. Justification\no Fine-tuning improves factual accuracy.",
      "filename": "UNIT II - GCV.pdf",
      "page": 13
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 28,
      "content": "” may produce artistic swirls.\n\n--- Page 13 ---\no Fine-tuned model on biology diagrams → generates precise base pairs and\nmolecular structure.\n5. Justification\no Fine-tuning improves factual accuracy.\no Reduces domain mismatch, making outputs trustworthy in professional\nor academic settings.\no Supports applications where error tolerance is low (e.g., medicine,\nengineering, education).\n(d) Limitations of CLIP and Solutions\n1. Limitations\no Bias and Fairness: CLIP inherits social and cultural biases from web data.\no Ambiguity Handling: Struggles when prompts are vague (“a beautiful\nscene”) or multi-layered.\no Domain Gaps: Lacks accuracy in highly technical or specialized areas.\no Computational Cost: Joint text-image training and inference are resource-\nintensive.\n2. Possible Solutions\no Bias Mitigation: Curate balanced datasets, use fairness-aware training,\nand adversarial debiasing.\no Prompt Engineering: Rephrase prompts to be specific, reducing\nambiguity.",
      "filename": "UNIT II - GCV.pdf",
      "page": 13
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 29,
      "content": "e.\n2. Possible Solutions\no Bias Mitigation: Curate balanced datasets, use fairness-aware training,\nand adversarial debiasing.\no Prompt Engineering: Rephrase prompts to be specific, reducing\nambiguity.\no Domain Adaptation: Use fine-tuning, adapters, or hybrid models for niche\ntasks.\no Human-in-the-Loop Evaluation: Incorporate expert feedback to validate\noutputs.\n3. Example\no Prompt: “A doctor” may disproportionately generate male figures due to\nbiased training data.\no Mitigation: Fine-tuning with balanced datasets ensures diverse\nrepresentations.\n4. Justification\n\n--- Page 14 ---\no Without addressing these issues, the trustworthiness and adoption of\nCLIP-based systems may be limited.\no Solutions ensure outputs remain inclusive, accurate, and ethically\ndeployable.\nThe integration of CLIP and diffusion models represents a paradigm shift in multimodal\nAI, enabling systems to understand and generate complex visual representations from\nnatural language.",
      "filename": "UNIT II - GCV.pdf",
      "page": 14
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 30,
      "content": "deployable.\nThe integration of CLIP and diffusion models represents a paradigm shift in multimodal\nAI, enabling systems to understand and generate complex visual representations from\nnatural language.\nCLIP ensures semantic alignment through joint embeddings, while diffusion models\nguarantee stability and quality via noise scheduling and denoising processes.\nFine-tuning resolves the issue of accuracy and domain specificity, while awareness of\nCLIP’s limitations (biases, ambiguity, domain gaps) and corrective solutions ensures\ntrustworthy deployment. In essence, the synergy between CLIP and diffusion models\nforms a robust, flexible, and scalable framework for multimodal content creation,\ncapable of serving both general and highly specialized applications.\n3. CLIP with diffusion models\nIntroduction\nText-to-image generation has become one of the most exciting advancements in\nartificial intelligence.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 31,
      "content": "rving both general and highly specialized applications.\n3. CLIP with diffusion models\nIntroduction\nText-to-image generation has become one of the most exciting advancements in\nartificial intelligence. By combining CLIP (Contrastive Language–Image Pretraining)\nwith diffusion models, systems can generate images that accurately reflect user\ndescriptions. CLIP provides a bridge between language and vision, aligning text prompts\nwith visual features, while diffusion models create high-quality, coherent outputs\nthrough a noise-to-image process. Together, they enable applications ranging from\ncreative design and education to healthcare and entertainment.\n(a) Architecture of CLIP – Connecting Text and Visuals\n1. Dual Encoder System\no CLIP consists of a text encoder (Transformer-based) and an image\nencoder (Vision Transformer or CNN).\no Both map their inputs into feature vectors.\n2. Shared Semantic Space\no Text and image embeddings are projected into a joint latent space where\nsimilarity is mea",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 32,
      "content": "encoder (Vision Transformer or CNN).\no Both map their inputs into feature vectors.\n2. Shared Semantic Space\no Text and image embeddings are projected into a joint latent space where\nsimilarity is measured.\no Training uses contrastive learning: matching text–image pairs are pulled\ncloser, mismatched ones pushed apart.\n\n--- Page 15 ---\n3. Outcome\no This allows CLIP to capture not just objects but also attributes, context,\nand relationships.\no For example, the phrase “bright red car on a snowy road” aligns with\nimages showing both the car and the setting.\n4. Significance\no These joint embeddings are crucial for guiding generative models so that\noutputs remain semantically aligned with textual descriptions.\n(b) Text-Guided Stable Diffusion – The Generation Process\n1. Forward Diffusion\no Real images are progressively noised until they become indistinguishable\nrandom noise.\n2. Backward Diffusion (Denoising)\no The model learns to reverse this process: starting from noise, it generates\nan ima",
      "filename": "UNIT II - GCV.pdf",
      "page": 15
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 33,
      "content": "images are progressively noised until they become indistinguishable\nrandom noise.\n2. Backward Diffusion (Denoising)\no The model learns to reverse this process: starting from noise, it generates\nan image step by step.\n3. Conditioning with CLIP\no The embeddings from CLIP are injected into the backward process as\nguidance signals.\no This ensures that the generated image reflects the semantic meaning of\nthe text prompt.\n4. Noise Scheduling\no Proper noise scheduling regulates how much detail is added at each step,\npreventing artifacts and improving stability.\n5. Why It Works\no Diffusion models combined with CLIP generate stable, realistic, and\nprompt-aligned visuals, outperforming earlier GAN-based approaches\nthat often struggled with fine details.\n(c) Fine-Tuning for Domain-Specific Applications\n1. Need for Fine-Tuning\no Base CLIP and diffusion models are trained on broad internet data, which\nmay not cover specialized domains well.\n\n--- Page 16 ---\n2.",
      "filename": "UNIT II - GCV.pdf",
      "page": 16
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 34,
      "content": "e-Tuning for Domain-Specific Applications\n1. Need for Fine-Tuning\no Base CLIP and diffusion models are trained on broad internet data, which\nmay not cover specialized domains well.\n\n--- Page 16 ---\n2. Process\no Fine-tuning involves training or adapting the model with domain-specific\nprompts or datasets.\no Example: In medicine, fine-tuning ensures that a description like “X-ray\nshowing lung opacity” produces medically accurate images.\n3. Benefits\no Enhances accuracy (outputs match technical details).\no Improves aesthetic or contextual relevance (outputs suit the domain\nstyle).\no Reduces biases and errors from general-purpose training.\n4. Justification\no Without fine-tuning, models may produce outputs that are visually\nplausible but factually incorrect. Domain adaptation ensures trustworthy\nand useful results.\n(d) Evaluation Metrics for Text–Image Alignment\n1. Quantitative Metrics\no CLIPScore: Measures similarity between generated image embeddings\nand prompt embeddings.",
      "filename": "UNIT II - GCV.pdf",
      "page": 16
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 35,
      "content": "sures trustworthy\nand useful results.\n(d) Evaluation Metrics for Text–Image Alignment\n1. Quantitative Metrics\no CLIPScore: Measures similarity between generated image embeddings\nand prompt embeddings.\no FID (Fréchet Inception Distance): Evaluates image quality by comparing\ngenerated and real data distributions.\no IS (Inception Score): Measures diversity and realism of generated\nimages.\n2. Qualitative Metrics\no Human evaluation: Users judge whether images align with descriptions.\no Task-based evaluation: Checking how well generated outputs support\ndownstream tasks (e.g., retrieval, classification).\n3. Balanced Evaluation\no A mix of automated and human assessments ensures both objective\naccuracy and subjective quality are measured.\n4. Significance\n\n--- Page 17 ---\no Robust evaluation is critical to confirm that the system produces outputs\nthat are reliable, meaningful, and user-aligned.\nConclusion\nBy integrating CLIP embeddings with diffusion-based generation, AI systems achieve\naccurate",
      "filename": "UNIT II - GCV.pdf",
      "page": 17
    },
    {
      "doc_id": "tmpws6vz554_UNIT II - GCV.pdf_1d6f9513",
      "chunk_index": 36,
      "content": "ical to confirm that the system produces outputs\nthat are reliable, meaningful, and user-aligned.\nConclusion\nBy integrating CLIP embeddings with diffusion-based generation, AI systems achieve\naccurate text-to-image synthesis. CLIP ensures semantic alignment, diffusion\nguarantees high visual fidelity, fine-tuning adapts models to specialized domains, and\nevaluation metrics confirm performance. This synergy represents a powerful paradigm\nfor multimodal AI, enabling diverse applications where reliable translation of language\ninto images is essential.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nUnit II\nCLIP (Contrastive Language–Image Pretraining)\nCLIP (Contrastive Language–Image Pretraining) learns a joint text–image embedding\nspace by using contrastive learning to bring matching image–text pairs close and push\nnon-matching pairs apart.\nKey points & justifications:\n1. Dual encoders (text & image) mapped to a shared space.\nJustification: Mapping both modalities into the same vector space makes direct\nsimilarity computations (cosine similarity) possible. This design simplifies\ndownstream tasks (retrieval, zero-shot classification) because the model does\nnot have to learn task-specific cross-modal projections every time — the shared\nspace is a reusable interface.\n2. Contrastive (InfoNCE) loss pulls positives and pushes negatives.\nJustification: InfoNCE directly optimizes relative similarity: maximizing similarity\nof correct pairs while minimizing similarity of incorrect pairs.",
      "filename": "UNIT II - GCV.pdf",
      "page": 1
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 1,
      "content": "nfoNCE) loss pulls positives and pushes negatives.\nJustification: InfoNCE directly optimizes relative similarity: maximizing similarity\nof correct pairs while minimizing similarity of incorrect pairs. This encourages\nembeddings to capture semantics that distinguish correct captions from\ndistractors, which is precisely what cross-modal tasks require.\n3. Large batch / many negatives improve representation quality.\nJustification: More negatives increase the difficulty of the contrastive task,\nforcing embeddings to capture fine-grained distinctions. Empirically large\neffective batch sizes (or memory banks) create stronger supervision signals,\nproducing richer semantic structure.\n4. Enables zero-shot transfer and robust retrieval.\nJustification: Because CLIP learns general alignment between text concepts and\nvisual features, it can map a new text label into the same space and retrieve\nrelevant images without task-specific retraining — the learned semantic\ngeometry generalizes.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 2,
      "content": "nt between text concepts and\nvisual features, it can map a new text label into the same space and retrieve\nrelevant images without task-specific retraining — the learned semantic\ngeometry generalizes.\nExample:\nImage: “a red bicycle on a rainy street.” CLIP will place the image embedding near\ncaptions describing bicycles/rain, and far from unrelated captions (e.g., “a dog in a\npark”).\nApplications & justification:\n• Zero-shot classification: No fine-tuning needed because class names can be\nembedded and compared to images.\nJustification: The shared semantic space means class semantics are already\nencoded.\n\n--- Page 2 ---\n• Text-guided retrieval and generation: CLIP scores can rank generated images or\nguide generative models.\nJustification: Direct similarity metrics allow automatic evaluation and steering.\nText embeddings in multimodal diffusion models\nText embeddings convert a prompt into a dense vector that conditions diffusion models,\nguiding stochastic denoising toward images that mat",
      "filename": "UNIT II - GCV.pdf",
      "page": 2
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 3,
      "content": "and steering.\nText embeddings in multimodal diffusion models\nText embeddings convert a prompt into a dense vector that conditions diffusion models,\nguiding stochastic denoising toward images that match the text.\nKey points & justifications:\n1. Serve as conditioning signal during denoising.\nDiffusion models generate by reversing noise; conditioning vectors are injected\n(via concatenation, cross-attention, or FiLM) so each denoising step has\nsemantic context. Without conditioning, the model has no way to steer\ngeneration toward the desired semantics.\n2. Capture both object and style attributes.\nModern text encoders (Transformers) represent not just nouns but adjectives,\nrelations, and style descriptors. Embeddings therefore allow the generator to\nsynthesize content (objects) and aesthetic (style) simultaneously.\n3. Enable fine controls (compositional prompts, modifiers).\nVector arithmetic and attention let the model weight different subcomponents\nof the prompt; e.g.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 4,
      "content": "ects) and aesthetic (style) simultaneously.\n3. Enable fine controls (compositional prompts, modifiers).\nVector arithmetic and attention let the model weight different subcomponents\nof the prompt; e.g., “photorealistic” vs “oil painting” map to different embedding\ndirections, producing controlled stylistic outcomes.\n4. Facilitate semantic consistency across steps.\nConditioning every denoising step (rather than only at start) ensures semantic\ninformation persists through the stochastic sampling, preventing drift to\nirrelevant modes.\nExample:\nPrompt: “A small wooden cabin at sunset, misty atmosphere.” The embedding encodes\nobject (“cabin”), material (“wooden”), time (“sunset”), and mood (“misty”) so the\ndiffusion model composes these attributes coherently.\nApplications & justification:\n• Text-to-image (Stable Diffusion): Embeddings let a single model produce\ndiverse outputs from many prompts.\nA single learned forward/backward process can be reused with different\ncondition vectors.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 5,
      "content": ":\n• Text-to-image (Stable Diffusion): Embeddings let a single model produce\ndiverse outputs from many prompts.\nA single learned forward/backward process can be reused with different\ncondition vectors.\n\n--- Page 3 ---\n• Prompt interpolation and editing: Embeddings allow latent manipulations\n(e.g., amplify “sunset”) to edit outputs.\nContinuous embeddings provide smooth control that discrete labels cannot.\nCritical insight / limitation\nIf embeddings lack domain knowledge or are ambiguous, generation will be\nsemantically weak. Therefore, high-quality text encoders and, when needed, domain-\nspecific embedding fine-tuning are essential.\nCommon evaluation metrics for text–image alignment\nEvaluating multimodal generation requires metrics that measure both visual quality and\nsemantic alignment between text and image.\nMetrics & justifications:\n1. CLIPScore (cosine similarity of CLIP embeddings).\nWhat it measures: Semantic alignment between generated image and\nprompt.",
      "filename": "UNIT II - GCV.pdf",
      "page": 3
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 6,
      "content": "y and\nsemantic alignment between text and image.\nMetrics & justifications:\n1. CLIPScore (cosine similarity of CLIP embeddings).\nWhat it measures: Semantic alignment between generated image and\nprompt.\nCLIP is trained to align modalities; its cosine similarity is a direct proxy for how\nwell image content matches textual semantics. It’s automatic and correlates\nreasonably with human judgments for many prompts.\n2. FID (Fréchet Inception Distance).\nWhat it measures: Distributional similarity between generated images and\nreal images.\nFID captures both quality and diversity by comparing feature statistics (means,\ncovariances). Lower FID implies generated images occupy similar manifold to\nreal images.\n3. Inception Score (IS).\nWhat it measures: Distinctiveness and confidence of generated images (via\nan Inception classifier).\nIS rewards samples that are recognizable and varied; however it doesn’t\nmeasure prompt alignment.\n4. Human evaluation (relevance, fidelity, preference).",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 7,
      "content": "generated images (via\nan Inception classifier).\nIS rewards samples that are recognizable and varied; however it doesn’t\nmeasure prompt alignment.\n4. Human evaluation (relevance, fidelity, preference).\nWhat it measures: Subjective semantic correctness and visual appeal.\nAutomated metrics are imperfect, so human judgment remains the gold\nstandard, especially for nuanced or creative prompts.\n5. Task-specific metrics (precision/recall on objects, detection mAP).\nWhen prompts require specific objects or relations, applying object detectors\nand measuring precision/recall quantifies functional correctness.\n\n--- Page 4 ---\nCombining metrics — justification:\nNo single metric captures all aspects. CLIPScore checks alignment but not realism; FID\nchecks realism but not prompt adherence. Combining metrics plus human checks\nproduces more reliable evaluation.\nLimitations :\nCLIPScore can be gamed (adversarially optimized); FID is sensitive to dataset choice\nand model used for features.",
      "filename": "UNIT II - GCV.pdf",
      "page": 4
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 8,
      "content": ". Combining metrics plus human checks\nproduces more reliable evaluation.\nLimitations :\nCLIPScore can be gamed (adversarially optimized); FID is sensitive to dataset choice\nand model used for features. Thus metric selection should align with evaluation goals\nand be interpreted carefully.\nFine-tuning CLIP\nIntroduction:\nPretrained CLIP is broad but not deep in domain-specific semantics; fine-tuning adapts\nit to specialized vocabularies, visual cues, and biases of a target domain.\nKey points & justifications:\n1. Bridging domain vocabulary gaps.\nCLIP’s internet training may underrepresent domain terms (medical labels,\nindustrial parts). Fine-tuning with domain captions teaches the text encoder\ndomain semantics and aligns them to visual cues in that field.\n2. Improving visual feature sensitivity to domain specifics.\nFine-tuning the image encoder helps it attend to subtle diagnostic visual features\n(e.g., microcalcifications) that general models may deem irrelevant.\n3.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 9,
      "content": "sual feature sensitivity to domain specifics.\nFine-tuning the image encoder helps it attend to subtle diagnostic visual features\n(e.g., microcalcifications) that general models may deem irrelevant.\n3. Reducing harmful biases and spurious correlations.\nDomain curation can balance datasets and remove stereotypes present in\ninternet data, improving fairness and factual accuracy in sensitive contexts.\n4. Better downstream task performance (retrieval, VQA, diagnostics).\nFine-tuned embeddings yield higher retrieval precision and more accurate VQA\nanswers because they encode task-relevant features.\nPractical methods & justifications:\n• Full fine-tuning: update all weights — best for abundant labels.\nAllows maximal adaptation but risks catastrophic forgetting and needs data/GPU\nresources.\n• Adapter modules / LoRA / prompt tuning: lightweight adjustments.\nPreserve pretrained knowledge while cheaply adapting to domain; less risk of\nforgetting and cheaper to train.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 10,
      "content": "eds data/GPU\nresources.\n• Adapter modules / LoRA / prompt tuning: lightweight adjustments.\nPreserve pretrained knowledge while cheaply adapting to domain; less risk of\nforgetting and cheaper to train.\n\n--- Page 5 ---\n• Continual learning / regularization: e.g., Elastic Weight Consolidation to\nprevent forgetting.\nMaintains general CLIP capabilities while learning domain specifics.\nExample:\nFine-tuning CLIP on annotated chest X-rays (labels, radiologist captions) yields\nimproved retrieval and VQA performance for radiology tasks because the model learns\nto associate radiographic patterns with domain terms.\nFine-tuning requires curated, representative, and labeled domain data; otherwise you\nrisk overfitting or preserving harmful biases. Validation and human oversight are\nessential.\nArchitecture of CLIP and joint learning\nIntroduction:\nCLIP uses separate encoders for images and text, projection heads to a common\nembedding space, and contrastive training to jointly learn aligned representati",
      "filename": "UNIT II - GCV.pdf",
      "page": 5
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 11,
      "content": "e of CLIP and joint learning\nIntroduction:\nCLIP uses separate encoders for images and text, projection heads to a common\nembedding space, and contrastive training to jointly learn aligned representations.\nArchitecture components & justifications:\n1. Image encoder (ViT or ResNet).\nCNNs (ResNet) capture local textures; ViTs capture long-range interactions.\n\n--- Page 6 ---\nChoice depends on tradeoffs (compute vs performance). Both produce rich\nvisual features for projection.\n2. Text encoder (Transformer).\nTransformers model sequential and contextual language semantics effectively,\nenabling capture of compositional meaning (modifiers, relations).\n3. Projection heads (linear layers) mapping to shared space.\nSeparate high-dim features are projected to a common dimensionality so cosine\nsimilarity is meaningful; projection can also adapt modality-specific statistics.\n4. Contrastive (InfoNCE) training with large effective batch size.\nMany negatives help the model learn fine distinctions.",
      "filename": "UNIT II - GCV.pdf",
      "page": 6
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 12,
      "content": "ilarity is meaningful; projection can also adapt modality-specific statistics.\n4. Contrastive (InfoNCE) training with large effective batch size.\nMany negatives help the model learn fine distinctions. Training with symmetric\nloss (image→text and text→image) strengthens bidirectional retrieval capability.\n5. Temperature scaling in contrastive loss.\nTemperature controls concentration of similarity distribution; tuning it balances\nsensitivity between positive/negative pairs.\nWhy this design works?\n• Separate encoders let each modality use architectures tailored to its inductive\nbiases, yet the projection + contrastive loss forces semantic alignment without\nmerging architectures (which would be less flexible).\n• Large paired datasets provide diverse supervision so the embedding geometry\ngeneralizes across many concepts.\nExample:\nDuring training a batch of image-caption pairs, each image’s closest embedding should\nbe its caption’s embedding.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 13,
      "content": "verse supervision so the embedding geometry\ngeneralizes across many concepts.\nExample:\nDuring training a batch of image-caption pairs, each image’s closest embedding should\nbe its caption’s embedding. The symmetric contrastive loss enforces this across all\nbatch pairs, producing a globally consistent embedding geometry.\nTradeoffs:\n• Heavy compute and data requirements are justified by strong zero-shot\nperformance.\n• Model complexity makes fine-tuning expensive; adapter techniques can mitigate\ncosts.\nCLIP can be integrated with diffusion models for text-to-image generation\nIntroduction:\nCLIP can guide diffusion models either by providing conditioning embeddings or by\nacting as an external scorer to encourage semantic alignment during sampling.\n\n--- Page 7 ---\nIntegration mechanisms & justifications:\n1. Embedding conditioning (direct): feed CLIP text embeddings into diffusion\nmodel (via cross-attention or concatenation).",
      "filename": "UNIT II - GCV.pdf",
      "page": 7
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 14,
      "content": "ent during sampling.\n\n--- Page 7 ---\nIntegration mechanisms & justifications:\n1. Embedding conditioning (direct): feed CLIP text embeddings into diffusion\nmodel (via cross-attention or concatenation).\nDirect conditioning uses the semantic vector as part of the generative process,\nenabling the model to learn to map embeddings to visual features during training\n— the cleanest, learned integration.\n2. CLIP guidance (external scorer / gradient guidance): compute CLIP similarity\nof intermediate samples to the prompt and backpropagate gradients to\nnudge samples.\nThis allows a pretrained diffusion model (without conditioning) to be steered at\nsampling time; useful when retraining is expensive. It leverages CLIP’s semantic\nsignal as an online objective.\n3. Classifier-free guidance vs CLIP scoring: classifier-free guidance blends\nunconditional and conditional denoising; CLIP guidance explicitly optimizes\nsemantic similarity.",
      "filename": "UNIT II - GCV.pdf",
      "page": 7
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 15,
      "content": "al as an online objective.\n3. Classifier-free guidance vs CLIP scoring: classifier-free guidance blends\nunconditional and conditional denoising; CLIP guidance explicitly optimizes\nsemantic similarity.\nClassifier-free guidance is learned and often efficient; CLIP guidance can\nimprove semantic alignment but is computationally heavier and sometimes\nunstable, so practitioners choose based on constraints.\n4. Hybrid approaches (fine-tune diffusion with CLIP): fine-tune a conditional\ndiffusion model where conditioning is CLIP embeddings.\nThis produces the most coherent integration: the generator learns to use\nembeddings during training, reducing the need for costly gradient-based steering\nat sampling time.\nExample workflow (gradient guidance):\nAt each sampling step, generate image x_t, compute CLIP similarity s = cosine(clip_text,\nclip_image(x_t)), compute ∇_{x_t} s and adjust x_t in direction that increases similarity,\nthen proceed to next denoising step.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 16,
      "content": "step, generate image x_t, compute CLIP similarity s = cosine(clip_text,\nclip_image(x_t)), compute ∇_{x_t} s and adjust x_t in direction that increases similarity,\nthen proceed to next denoising step.\nTradeoffs:\n• Pros: CLIP guidance improves semantic fidelity and allows reusing pretrained\ndiffusion models.\n• Cons: Extra compute (CLIP forward + gradient) and potential for adversarial\nartifacts if optimized too aggressively — justification for careful step size and\nregularization.\nQ7 — Compare CLIP-guided generation vs GAN-based text-to-image methods\n\n--- Page 8 ---\nComparison points & justifications:\n1. Semantic alignment: CLIP-guided diffusion > GANs.\nJustification: CLIP provides explicit semantic supervision via\nembeddings/scores; GANs rely on discriminator signals that emphasize\nrealism rather than semantic correctness.\n2. Visual sharpness / texture realism: GANs often produce sharper textures.",
      "filename": "UNIT II - GCV.pdf",
      "page": 8
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 17,
      "content": "pervision via\nembeddings/scores; GANs rely on discriminator signals that emphasize\nrealism rather than semantic correctness.\n2. Visual sharpness / texture realism: GANs often produce sharper textures.\nJustification: GAN adversarial loss explicitly forces photorealistic textures;\ndiffusion models historically produced blurrier outputs (though modern\ntechniques narrowed the gap).\n3. Training stability: Diffusion (with CLIP) tends to be more stable than GAN\ntraining.\nJustification: GANs suffer from mode collapse and training instability due to\nadversarial dynamics; diffusion is likelihood-based and often converges\nmore predictably.\n4. Sampling speed / compute: GANs typically faster at inference; CLIP-guided\ndiffusion is slower.\nJustification: GANs generate in one forward pass; diffusion models require\nmany denoising steps; CLIP guidance adds more compute for\nscoring/gradients.\n5. Controllability & editing: CLIP-guided diffusion offers finer control (text,\nprompt editing).",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 18,
      "content": "; diffusion models require\nmany denoising steps; CLIP guidance adds more compute for\nscoring/gradients.\n5. Controllability & editing: CLIP-guided diffusion offers finer control (text,\nprompt editing).\nJustification: Conditioning and CLIP feedback directly influence semantics\nacross steps; GANs can be controlled via latent manipulations but mapping\nbetween latent and semantics is less direct.\n6. Robustness to prompts: CLIP-guided methods generalize better to open-\nended prompts.\nJustification: CLIP’s pretraining on broad captions provides strong semantic\ngrounding; GANs trained on limited paired data often struggle with out-of-\ndistribution prompts.\nUse-case recommendations (justified):\n• For high-speed production of photoreal textures, GANs may be preferable.\nJustification: Fast single-pass generation with high fidelity.\n• For semantic, creative, and controllable generation, CLIP-guided diffusion is\npreferable despite slower sampling.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 19,
      "content": "Ns may be preferable.\nJustification: Fast single-pass generation with high fidelity.\n• For semantic, creative, and controllable generation, CLIP-guided diffusion is\npreferable despite slower sampling.\nJustification: Better alignment to textual intent and flexibility.\n\n--- Page 9 ---\nLimitation of CLIP and a detailed solution (with justifications)\nLimitation chosen: Bias and spurious correlations inherited from large web-scale\ntraining data.\n• CLIP’s embeddings reflect the distribution of its training corpus; societal\nstereotypes and underrepresentation produce associations that can harm\ndownstream use (e.g., biased retrieval or discriminatory generative outputs). In\ncritical domains (hiring, law, medicine) these errors are unacceptable.\nProposed multi-pronged solution:\n1. Domain-aware fine-tuning with curated datasets.\nCurated, annotated domain data corrects label distributions and teaches the\nmodel correct associations relevant to the domain (e.g., medical labels).",
      "filename": "UNIT II - GCV.pdf",
      "page": 9
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 20,
      "content": "1. Domain-aware fine-tuning with curated datasets.\nCurated, annotated domain data corrects label distributions and teaches the\nmodel correct associations relevant to the domain (e.g., medical labels). It\nreduces reliance on noisy web labels.\n2. Bias mitigation during training (reweighting / adversarial debiasing).\nReweighting or adversarial objectives discourage encoding of protected\nattributes (e.g., gender) when they’re not relevant. These methods directly\npenalize the emergence of undesirable correlations.\n3. Counterfactual data augmentation.\nGenerating or collecting balanced examples that swap sensitive attributes (e.g.,\nsame profession across genders/ethnicities) reduces statistical shortcuts and\nforces the model to focus on relevant visual cues.\n4. Evaluation & continuous monitoring (human-in-the-loop).\nAutomated checks (fairness metrics) plus human audits detect remaining bias.\nContinuous monitoring post-deployment catches distribution shifts and\nemergent problems.\n5.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 21,
      "content": "monitoring (human-in-the-loop).\nAutomated checks (fairness metrics) plus human audits detect remaining bias.\nContinuous monitoring post-deployment catches distribution shifts and\nemergent problems.\n5. Model explanations and transparency.\nSaliency maps or retrieval-based explanations help users understand why the\nmodel associated certain text and images, enabling corrective action.\nExample application:\nDeploying an e-commerce visual search: before deployment, augment training with\ndiverse product images across demographics, apply reweighting, and run fairness tests\nto ensure the model does not systematically underrepresent particular groups.\n\n--- Page 10 ---\n2. CLIP AND JOINT EMBEDDINGS\nIntroduction\nGenerative AI has transformed the way text and visual data can be integrated to create\nnew forms of digital content. Among the leading approaches are Contrastive Language–\nImage Pretraining (CLIP) and diffusion models, which together form a powerful pipeline\nfor text-to-image synthesis.",
      "filename": "UNIT II - GCV.pdf",
      "page": 10
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 22,
      "content": "new forms of digital content. Among the leading approaches are Contrastive Language–\nImage Pretraining (CLIP) and diffusion models, which together form a powerful pipeline\nfor text-to-image synthesis.\nCLIP aligns language and visual modalities through joint embeddings, while diffusion\nmodels use probabilistic denoising processes to synthesize realistic and semantically\naligned images.\nThis integration is significant across domains like education, design, healthcare,\nentertainment, and scientific communication, where the ability to convert descriptions\ninto visuals saves time, enhances creativity, and improves accessibility. However,\nensuring reliability, accuracy, and fairness requires deeper understanding of the\nmechanisms, limitations, and solutions of such systems.\n(a) CLIP and Joint Embeddings – Mechanism and Benefits\n1. Core Concept\no CLIP consists of two encoders:\n▪ A Text Encoder (Transformer-based) processes natural language\nprompts.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 23,
      "content": "utions of such systems.\n(a) CLIP and Joint Embeddings – Mechanism and Benefits\n1. Core Concept\no CLIP consists of two encoders:\n▪ A Text Encoder (Transformer-based) processes natural language\nprompts.\n▪ An Image Encoder (ResNet or Vision Transformer) processes image\ndata.\no Both outputs are projected into a shared embedding space, enabling\ncomparisons.\n2. Contrastive Learning\no During training, CLIP is presented with a batch of image–text pairs.\no The correct image–caption pair should have a high cosine similarity, while\nincorrect pairs should score low.\no InfoNCE loss optimizes this by pulling true pairs closer and pushing false\npairs apart.\n3. Why This Matters for Generation\no When combined with diffusion models, the shared space ensures the\ngenerated image faithfully represents the meaning of the text.\n\n--- Page 11 ---\no Unlike traditional vision models limited to classification, CLIP’s\nembeddings generalize across unseen categories and abstract prompts.\n4.",
      "filename": "UNIT II - GCV.pdf",
      "page": 11
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 24,
      "content": "hfully represents the meaning of the text.\n\n--- Page 11 ---\no Unlike traditional vision models limited to classification, CLIP’s\nembeddings generalize across unseen categories and abstract prompts.\n4. Example\no Prompt: “A panda wearing sunglasses playing guitar.”\no CLIP embeddings capture not only the object (“panda”) but also\nattributes (“wearing sunglasses”) and context (“playing guitar”).\no The diffusion model uses these embeddings to guide generation, ensuring\nall described elements appear.\n5. Justification\no This approach solves the problem of semantic drift, where generated\nimages deviate from text.\no It also enables zero-shot transfer, where the model works on new\nconcepts without retraining.\n(b) Noise Scheduling and Diffusion Process – Stability and Quality\n1. Forward Diffusion (Training Stage)\no The model learns by gradually adding Gaussian noise to real images over\nmany steps until they become indistinguishable from random noise.",
      "filename": "UNIT II - GCV.pdf",
      "page": 11
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 25,
      "content": "Stability and Quality\n1. Forward Diffusion (Training Stage)\no The model learns by gradually adding Gaussian noise to real images over\nmany steps until they become indistinguishable from random noise.\no This corruption process teaches the system how data can be “destroyed”\nin a controlled manner.\n2. Backward Diffusion (Generation Stage)\no The generative model reverses the process, progressively denoising\nrandom noise step by step to reconstruct a meaningful image.\no Conditioning on text embeddings ensures that the denoising follows the\nsemantic structure encoded in the prompt.\n3. Noise Schedulers\no Decide the rate and distribution of noise addition/removal across\ntimesteps.\no Common schedulers: linear, cosine, exponential decay.\no The choice affects image clarity, diversity, and fidelity.\n4. Why It Matters\n\n--- Page 12 ---\no Too much noise at early steps → unstable generations.\no Too little → lack of diversity.",
      "filename": "UNIT II - GCV.pdf",
      "page": 12
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 26,
      "content": "nential decay.\no The choice affects image clarity, diversity, and fidelity.\n4. Why It Matters\n\n--- Page 12 ---\no Too much noise at early steps → unstable generations.\no Too little → lack of diversity.\no A well-designed scheduler balances exploration and accuracy, leading to\nimages that are high-quality, sharp, and semantically consistent.\n5. Example\no A poorly tuned scheduler may generate a “blurred car” for the prompt “a\nred sports car on a racetrack.”\no With proper scheduling, details like color, motion blur, and track\nbackground are preserved.\n6. Justification\no Diffusion + noise scheduling ensures outputs remain reliable and artifact-\nfree, addressing weaknesses of earlier GAN-based methods which often\nsuffered from mode collapse.\n(c) Ensuring Accuracy with Fine-Tuning – Overcoming Hallucinations\n1. The Challenge\no Generative models, when trained on generic internet data, may produce\nimages that are visually appealing but scientifically or contextually\ninaccurate.",
      "filename": "UNIT II - GCV.pdf",
      "page": 12
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 27,
      "content": "g – Overcoming Hallucinations\n1. The Challenge\no Generative models, when trained on generic internet data, may produce\nimages that are visually appealing but scientifically or contextually\ninaccurate.\no Risk of “hallucination” (adding irrelevant objects) or oversimplification.\n2. Role of Fine-Tuning\no Fine-tuning adapts pretrained models to specific domains using curated\ndatasets.\no Adjusts weights so the model captures domain-specific semantics and\navoids irrelevant associations.\n3. Methods\no Full fine-tuning: Retrain on specialized datasets (e.g., radiology images,\nengineering diagrams).\no Adapter/LoRA tuning: Lightweight layers added for efficient adaptation.\no Prompt-tuning: Adding domain-specific tokens or context.\n4. Example\no Generic model → “DNA double helix” may produce artistic swirls.\n\n--- Page 13 ---\no Fine-tuned model on biology diagrams → generates precise base pairs and\nmolecular structure.\n5. Justification\no Fine-tuning improves factual accuracy.",
      "filename": "UNIT II - GCV.pdf",
      "page": 13
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 28,
      "content": "” may produce artistic swirls.\n\n--- Page 13 ---\no Fine-tuned model on biology diagrams → generates precise base pairs and\nmolecular structure.\n5. Justification\no Fine-tuning improves factual accuracy.\no Reduces domain mismatch, making outputs trustworthy in professional\nor academic settings.\no Supports applications where error tolerance is low (e.g., medicine,\nengineering, education).\n(d) Limitations of CLIP and Solutions\n1. Limitations\no Bias and Fairness: CLIP inherits social and cultural biases from web data.\no Ambiguity Handling: Struggles when prompts are vague (“a beautiful\nscene”) or multi-layered.\no Domain Gaps: Lacks accuracy in highly technical or specialized areas.\no Computational Cost: Joint text-image training and inference are resource-\nintensive.\n2. Possible Solutions\no Bias Mitigation: Curate balanced datasets, use fairness-aware training,\nand adversarial debiasing.\no Prompt Engineering: Rephrase prompts to be specific, reducing\nambiguity.",
      "filename": "UNIT II - GCV.pdf",
      "page": 13
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 29,
      "content": "e.\n2. Possible Solutions\no Bias Mitigation: Curate balanced datasets, use fairness-aware training,\nand adversarial debiasing.\no Prompt Engineering: Rephrase prompts to be specific, reducing\nambiguity.\no Domain Adaptation: Use fine-tuning, adapters, or hybrid models for niche\ntasks.\no Human-in-the-Loop Evaluation: Incorporate expert feedback to validate\noutputs.\n3. Example\no Prompt: “A doctor” may disproportionately generate male figures due to\nbiased training data.\no Mitigation: Fine-tuning with balanced datasets ensures diverse\nrepresentations.\n4. Justification\n\n--- Page 14 ---\no Without addressing these issues, the trustworthiness and adoption of\nCLIP-based systems may be limited.\no Solutions ensure outputs remain inclusive, accurate, and ethically\ndeployable.\nThe integration of CLIP and diffusion models represents a paradigm shift in multimodal\nAI, enabling systems to understand and generate complex visual representations from\nnatural language.",
      "filename": "UNIT II - GCV.pdf",
      "page": 14
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 30,
      "content": "deployable.\nThe integration of CLIP and diffusion models represents a paradigm shift in multimodal\nAI, enabling systems to understand and generate complex visual representations from\nnatural language.\nCLIP ensures semantic alignment through joint embeddings, while diffusion models\nguarantee stability and quality via noise scheduling and denoising processes.\nFine-tuning resolves the issue of accuracy and domain specificity, while awareness of\nCLIP’s limitations (biases, ambiguity, domain gaps) and corrective solutions ensures\ntrustworthy deployment. In essence, the synergy between CLIP and diffusion models\nforms a robust, flexible, and scalable framework for multimodal content creation,\ncapable of serving both general and highly specialized applications.\n3. CLIP with diffusion models\nIntroduction\nText-to-image generation has become one of the most exciting advancements in\nartificial intelligence.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 31,
      "content": "rving both general and highly specialized applications.\n3. CLIP with diffusion models\nIntroduction\nText-to-image generation has become one of the most exciting advancements in\nartificial intelligence. By combining CLIP (Contrastive Language–Image Pretraining)\nwith diffusion models, systems can generate images that accurately reflect user\ndescriptions. CLIP provides a bridge between language and vision, aligning text prompts\nwith visual features, while diffusion models create high-quality, coherent outputs\nthrough a noise-to-image process. Together, they enable applications ranging from\ncreative design and education to healthcare and entertainment.\n(a) Architecture of CLIP – Connecting Text and Visuals\n1. Dual Encoder System\no CLIP consists of a text encoder (Transformer-based) and an image\nencoder (Vision Transformer or CNN).\no Both map their inputs into feature vectors.\n2. Shared Semantic Space\no Text and image embeddings are projected into a joint latent space where\nsimilarity is mea",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 32,
      "content": "encoder (Vision Transformer or CNN).\no Both map their inputs into feature vectors.\n2. Shared Semantic Space\no Text and image embeddings are projected into a joint latent space where\nsimilarity is measured.\no Training uses contrastive learning: matching text–image pairs are pulled\ncloser, mismatched ones pushed apart.\n\n--- Page 15 ---\n3. Outcome\no This allows CLIP to capture not just objects but also attributes, context,\nand relationships.\no For example, the phrase “bright red car on a snowy road” aligns with\nimages showing both the car and the setting.\n4. Significance\no These joint embeddings are crucial for guiding generative models so that\noutputs remain semantically aligned with textual descriptions.\n(b) Text-Guided Stable Diffusion – The Generation Process\n1. Forward Diffusion\no Real images are progressively noised until they become indistinguishable\nrandom noise.\n2. Backward Diffusion (Denoising)\no The model learns to reverse this process: starting from noise, it generates\nan ima",
      "filename": "UNIT II - GCV.pdf",
      "page": 15
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 33,
      "content": "images are progressively noised until they become indistinguishable\nrandom noise.\n2. Backward Diffusion (Denoising)\no The model learns to reverse this process: starting from noise, it generates\nan image step by step.\n3. Conditioning with CLIP\no The embeddings from CLIP are injected into the backward process as\nguidance signals.\no This ensures that the generated image reflects the semantic meaning of\nthe text prompt.\n4. Noise Scheduling\no Proper noise scheduling regulates how much detail is added at each step,\npreventing artifacts and improving stability.\n5. Why It Works\no Diffusion models combined with CLIP generate stable, realistic, and\nprompt-aligned visuals, outperforming earlier GAN-based approaches\nthat often struggled with fine details.\n(c) Fine-Tuning for Domain-Specific Applications\n1. Need for Fine-Tuning\no Base CLIP and diffusion models are trained on broad internet data, which\nmay not cover specialized domains well.\n\n--- Page 16 ---\n2.",
      "filename": "UNIT II - GCV.pdf",
      "page": 16
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 34,
      "content": "e-Tuning for Domain-Specific Applications\n1. Need for Fine-Tuning\no Base CLIP and diffusion models are trained on broad internet data, which\nmay not cover specialized domains well.\n\n--- Page 16 ---\n2. Process\no Fine-tuning involves training or adapting the model with domain-specific\nprompts or datasets.\no Example: In medicine, fine-tuning ensures that a description like “X-ray\nshowing lung opacity” produces medically accurate images.\n3. Benefits\no Enhances accuracy (outputs match technical details).\no Improves aesthetic or contextual relevance (outputs suit the domain\nstyle).\no Reduces biases and errors from general-purpose training.\n4. Justification\no Without fine-tuning, models may produce outputs that are visually\nplausible but factually incorrect. Domain adaptation ensures trustworthy\nand useful results.\n(d) Evaluation Metrics for Text–Image Alignment\n1. Quantitative Metrics\no CLIPScore: Measures similarity between generated image embeddings\nand prompt embeddings.",
      "filename": "UNIT II - GCV.pdf",
      "page": 16
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 35,
      "content": "sures trustworthy\nand useful results.\n(d) Evaluation Metrics for Text–Image Alignment\n1. Quantitative Metrics\no CLIPScore: Measures similarity between generated image embeddings\nand prompt embeddings.\no FID (Fréchet Inception Distance): Evaluates image quality by comparing\ngenerated and real data distributions.\no IS (Inception Score): Measures diversity and realism of generated\nimages.\n2. Qualitative Metrics\no Human evaluation: Users judge whether images align with descriptions.\no Task-based evaluation: Checking how well generated outputs support\ndownstream tasks (e.g., retrieval, classification).\n3. Balanced Evaluation\no A mix of automated and human assessments ensures both objective\naccuracy and subjective quality are measured.\n4. Significance\n\n--- Page 17 ---\no Robust evaluation is critical to confirm that the system produces outputs\nthat are reliable, meaningful, and user-aligned.\nConclusion\nBy integrating CLIP embeddings with diffusion-based generation, AI systems achieve\naccurate",
      "filename": "UNIT II - GCV.pdf",
      "page": 17
    },
    {
      "doc_id": "tmpq6fgzwr7_UNIT II - GCV.pdf_1d6f9513_fd7c60bc",
      "chunk_index": 36,
      "content": "ical to confirm that the system produces outputs\nthat are reliable, meaningful, and user-aligned.\nConclusion\nBy integrating CLIP embeddings with diffusion-based generation, AI systems achieve\naccurate text-to-image synthesis. CLIP ensures semantic alignment, diffusion\nguarantees high visual fidelity, fine-tuning adapts models to specialized domains, and\nevaluation metrics confirm performance. This synergy represents a powerful paradigm\nfor multimodal AI, enabling diverse applications where reliable translation of language\ninto images is essential.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmp8fzwuted_Restitution Devices in AR.pdf_bb87f86e_fc012117",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nRestitution Devices in AR/VR\n\n--- Page 2 ---\n• Introduction\n• In Augmented Reality (AR) and Virtual Reality (VR) systems,\nrestitution devices (also called output devices) are responsible for\npresenting or “restituting” the processed virtual or augmented\ninformation back to the user through different senses.\nThey convert the system’s digital data into sensory outputs such as\nvisuals, sound, or tactile feedback, enabling an immersive experience.\n\n--- Page 3 ---\nDefinition\n• Restitution devices: Hardware components that output sensory\nfeedback (visual, auditory, haptic) to the user, making interaction\nwith virtual or augmented content possible.\n\n--- Page 4 ---\nCategories of Restitution Devices\n• (A) Visual Restitution Devices\n• Used to present virtual or augmented images to the user.\n• Head-Mounted Displays (HMDs):\n• Worn on the head; display virtual worlds in VR or overlay graphics in AR.\n• Example: Oculus Quest, Microsoft HoloLens.",
      "filename": "Restitution Devices in AR.pdf",
      "page": 1
    },
    {
      "doc_id": "tmp8fzwuted_Restitution Devices in AR.pdf_bb87f86e_fc012117",
      "chunk_index": 1,
      "content": "resent virtual or augmented images to the user.\n• Head-Mounted Displays (HMDs):\n• Worn on the head; display virtual worlds in VR or overlay graphics in AR.\n• Example: Oculus Quest, Microsoft HoloLens.\n• Smart Glasses:\n• Lightweight wearable displays for AR.\n• Example: Google Glass, Magic Leap.\n\n--- Page 5 ---\n(A) Visual Restitution Devices\nCAVE (Cave Automatic Virtual Environment):\nRoom-sized projection system for immersive VR.\n∙ Projection Systems:\nProject AR overlays directly onto physical surfaces\n\n--- Page 6 ---\n(B) Auditory Restitution Devices\n• Provide sound cues for immersion and spatial awareness.\n• Headphones / Earphones:\n• Deliver 3D spatial audio for realistic sound positioning.\n• Example: Bose AR audio glasses.\n• Surround Sound Systems:\n• Multi-speaker setups for CAVE environments.\n• Bone-Conduction Devices:\n• Transmit sound through bones of the skull, leaving ears open to ambient\nsounds.",
      "filename": "Restitution Devices in AR.pdf",
      "page": 5
    },
    {
      "doc_id": "tmp8fzwuted_Restitution Devices in AR.pdf_bb87f86e_fc012117",
      "chunk_index": 2,
      "content": "e AR audio glasses.\n• Surround Sound Systems:\n• Multi-speaker setups for CAVE environments.\n• Bone-Conduction Devices:\n• Transmit sound through bones of the skull, leaving ears open to ambient\nsounds.\n\n--- Page 7 ---\n(C) Haptic Restitution Devices\n• Provide tactile feedback to simulate touch or interaction.\n• Haptic Gloves:\n• Detect hand motion and give touch sensation through vibration or\nresistance.\n• Example: HaptX Gloves.\n• Force Feedback Devices:\n• Apply resistance to simulate weight or texture.\n• Example: Steering wheels in VR driving simulators.\n• Vibration Modules:\n• Used in controllers to enhance feedback during interaction.\n• Example: PlayStation VR controllers.\n\n--- Page 8 ---\n(D) Other Sensory Restitution Devices\n• Olfactory Devices: Emit scents to match virtual environments.\n• Example: Feelreal VR Mask.\n• Gustatory Devices: Rare, simulate taste sensations (experimental).\n• Motion Platforms: Move user’s seat/platform to simulate motion in\nVR rides.\n\n--- Page 9 ---\n4.",
      "filename": "Restitution Devices in AR.pdf",
      "page": 7
    },
    {
      "doc_id": "tmp8fzwuted_Restitution Devices in AR.pdf_bb87f86e_fc012117",
      "chunk_index": 3,
      "content": "ents.\n• Example: Feelreal VR Mask.\n• Gustatory Devices: Rare, simulate taste sensations (experimental).\n• Motion Platforms: Move user’s seat/platform to simulate motion in\nVR rides.\n\n--- Page 9 ---\n4. Role in AR/VR\n• Deliver real-time, multi-sensory feedback.\n• Increase user immersion and realism.\n• Support interaction by engaging more senses.\n• Reduce the cognitive gap between virtual and physical worlds.\n\n--- Page 10 ---\nAdvantages\n• Enhanced realism and user engagement.\n• Supports training and skill development (e.g., surgical VR).\n• Multi-sensory feedback improves spatial understanding.\n\n--- Page 11 ---\n6. Limitations\n•High cost for advanced devices.\n∙ Physical discomfort if worn for long periods.\n∙ Some devices require powerful computing hardware\n\n--- Page 12 ---\n7. Applications\n∙ Gaming: VR headsets + haptic controllers for immersive play.\n∙ Medical Training: Haptic gloves for surgical simulations.\n∙ Education: AR smart glasses for interactive learning.",
      "filename": "Restitution Devices in AR.pdf",
      "page": 9
    },
    {
      "doc_id": "tmp8fzwuted_Restitution Devices in AR.pdf_bb87f86e_fc012117",
      "chunk_index": 4,
      "content": "2 ---\n7. Applications\n∙ Gaming: VR headsets + haptic controllers for immersive play.\n∙ Medical Training: Haptic gloves for surgical simulations.\n∙ Education: AR smart glasses for interactive learning.\n∙ Industrial Training: Motion platforms for vehicle simulators\n\n--- Page 13 ---\n8. Conclusion\n• Restitution devices are a crucial part of AR/VR systems, translating\ndigital content into sensory experiences. With advancements in\ndisplay, sound, and haptic technologies, these devices continue to\npush the boundaries of immersion in entertainment, education,\nhealthcare, and industry.",
      "filename": "Restitution Devices in AR.pdf",
      "page": 13
    },
    {
      "doc_id": "tmp_teku8x2_Tutorial4_Banking_Laws_Comparison.pdf_da86a0f3_13072223",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nTutorial 4: Comparison of National and\nInternational Banking Laws\nThis tutorial provides a comparative overview of international and national banking laws, focusing\non the Basel framework and its implementation across the US, EU, and India. It explores capital\nadequacy, liquidity, leverage, stress testing, resolution regimes, and supervisory structures,\nfollowed by case studies that illustrate lessons from regulatory failures.\n1. International Baseline: The Basel Framework\nThe Basel Committee on Banking Supervision (BCBS) sets global prudential standards through\nBasel I, II, and III. Key components include capital adequacy (Pillar 1), supervisory review (Pillar 2),\nand disclosure (Pillar 3). Basel III introduced Liquidity Coverage Ratio (LCR), Net Stable Funding\nRatio (NSFR), and the leverage ratio.\n2. National Implementations\nUnited States (Dodd-Frank, Fed, OCC, FDIC): Implements Basel but adds stricter stress tests\n(CCAR), living wills, the Volcker Rule, and Orderly Li",
      "filename": "Tutorial4_Banking_Laws_Comparison.pdf",
      "page": 1
    },
    {
      "doc_id": "tmp_teku8x2_Tutorial4_Banking_Laws_Comparison.pdf_da86a0f3_13072223",
      "chunk_index": 1,
      "content": ", and the leverage ratio.\n2. National Implementations\nUnited States (Dodd-Frank, Fed, OCC, FDIC): Implements Basel but adds stricter stress tests\n(CCAR), living wills, the Volcker Rule, and Orderly Liquidation Authority.\nEuropean Union (CRD/CRR, SSM, SRM): Basel rules via Capital Requirements\nDirective/Regulation; ECB supervises significant banks, with Bank Recovery & Resolution Directive\n(BRRD) for resolution.\nIndia (RBI): Adopts Basel standards with local adjustments. Uses Prompt Corrective Action (PCA)\nframework, liquidity ratios (SLR/CRR), and case-based resolutions (e.g., Yes Bank in 2020).\n3. Comparative Risk Analytics\nCredit Risk: Basel allows standardized or internal ratings-based approaches. The US and EU\napply stricter controls on models. India primarily uses standardized approaches.\nMarket Risk: Post-2008 reforms emphasize stressed Value-at-Risk (VaR) and model governance.\nOperational Risk: Basel reforms simplified approaches; national regulators require strong controls\nand",
      "filename": "Tutorial4_Banking_Laws_Comparison.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_teku8x2_Tutorial4_Banking_Laws_Comparison.pdf_da86a0f3_13072223",
      "chunk_index": 2,
      "content": "hes.\nMarket Risk: Post-2008 reforms emphasize stressed Value-at-Risk (VaR) and model governance.\nOperational Risk: Basel reforms simplified approaches; national regulators require strong controls\nand fraud monitoring.\nStress Testing: Basel issues principles, but US (CCAR/DFAST), EU (EBA/ECB), and India (RBI\nscenarios) conduct binding exercises.\n4. Resolution Regimes\nInternational: Basel promotes Total Loss Absorbing Capacity (TLAC).\nUS: Dodd-Frank Title II enables Orderly Liquidation and mandates living wills.\nEU: BRRD and the Single Resolution Mechanism (SRM) apply.\nIndia: RBI manages resolutions (Yes Bank 2020, PNB fraud responses) with amalgamation and\ncapital support.\n5. Case Studies and Lessons\nLehman Brothers (2008): Exposed weaknesses in capital and liquidity, motivating Basel III and\nDodd-Frank.\nLIBOR Scandal (Barclays, others): Led to benchmark reforms and stricter conduct oversight.",
      "filename": "Tutorial4_Banking_Laws_Comparison.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_teku8x2_Tutorial4_Banking_Laws_Comparison.pdf_da86a0f3_13072223",
      "chunk_index": 3,
      "content": "ons\nLehman Brothers (2008): Exposed weaknesses in capital and liquidity, motivating Basel III and\nDodd-Frank.\nLIBOR Scandal (Barclays, others): Led to benchmark reforms and stricter conduct oversight.\nJPMorgan “London Whale”: Highlighted model risk and the need for governance in market risk\nmanagement.\nYes Bank (India, 2020): RBI-led resolution showed importance of governance and rapid\nintervention in emerging markets.\n6. Key Takeaways\n- Basel provides the global framework; countries adapt with local enforcement.\n- US adds stress testing and resolution planning; EU emphasizes centralized supervision; India\nuses PCA and ad hoc resolution tools.\n- Major crises and scandals demonstrate the importance of capital adequacy, liquidity, governance,\nand transparent benchmarks.\n\n--- Page 2 ---\n- Despite harmonization, regulatory divergence can create challenges in cross-border banking\nsupervision and resolution.",
      "filename": "Tutorial4_Banking_Laws_Comparison.pdf",
      "page": 2
    },
    {
      "doc_id": "tmp_teku8x2_Tutorial4_Banking_Laws_Comparison.pdf_da86a0f3_13072223",
      "chunk_index": 4,
      "content": "al adequacy, liquidity, governance,\nand transparent benchmarks.\n\n--- Page 2 ---\n- Despite harmonization, regulatory divergence can create challenges in cross-border banking\nsupervision and resolution.\nConclusion:\nComparing international and national banking laws reveals convergence around Basel principles\nbut divergence in implementation. Case studies highlight why robust risk analytics, stress testing,\nand resolution regimes are critical for financial stability.",
      "filename": "Tutorial4_Banking_Laws_Comparison.pdf",
      "page": 2
    },
    {
      "doc_id": "tmpy_gzq1e__VR-AR for industrial renewal.pdf_8ebec43a_18d419b8",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nVR-AR for industrial renewal\n\n--- Page 2 ---\n• The integration of Virtual Reality (VR) and Augmented Reality (AR) into industrial processes is driving a\nsignificant renewal across sectors, from manufacturing and healthcare to energy and defense.\n• These technologies enhance productivity, reduce costs, and improve safety by enabling immersive training,\nreal-time data visualization, and remote collaboration. Below is a detailed analysis of how VR/AR is\nrevolutionizing industrial renewal\nKey Applications of VR/AR in Industrial Renewal\nA. Workforce Training & Skill Development\nVR/AR is transforming employee training by providing immersive, risk-free simulations that improve retention\nand performance.\n•Medical & Surgical Training: Platforms like Osso VR reduce surgical training time by two-thirds while\nimproving precision\n•Manufacturing & Safety: Companies like Siemens report 13% higher certification pass rates after adopting VR\nsafety training\n•Utility & Emergency Response:",
      "filename": "VR-AR for industrial renewal.pdf",
      "page": 1
    },
    {
      "doc_id": "tmpy_gzq1e__VR-AR for industrial renewal.pdf_8ebec43a_18d419b8",
      "chunk_index": 1,
      "content": "ime by two-thirds while\nimproving precision\n•Manufacturing & Safety: Companies like Siemens report 13% higher certification pass rates after adopting VR\nsafety training\n•Utility & Emergency Response: VR trains workers on electrical grid maintenance and disaster response in\ncontrolled environments\n\n--- Page 3 ---\n• Virtual Reality (VR) and Augmented Reality (AR) are transformative technologies reshaping industrial sectors.\nVR creates a fully immersive digital environment.\n∙\nAR overlays digital content onto the physical world through devices like smart glasses or mobile phones.\n∙\n• These technologies are driving industrial renewal by enhancing productivity, safety, and innovation across\nmanufacturing, engineering, maintenance, and training\n• Role in Industrial Renewal\n•VR and AR enable modernization of traditional industries by:\nDigital Transformation: Replacing manual operations with virtual simulations and digital overlays.",
      "filename": "VR-AR for industrial renewal.pdf",
      "page": 3
    },
    {
      "doc_id": "tmpy_gzq1e__VR-AR for industrial renewal.pdf_8ebec43a_18d419b8",
      "chunk_index": 2,
      "content": "d training\n• Role in Industrial Renewal\n•VR and AR enable modernization of traditional industries by:\nDigital Transformation: Replacing manual operations with virtual simulations and digital overlays.\n∙\nImproved Decision-Making: Real-time visualization of data supports smarter operational choices.\n∙\nProcess Optimization: Virtual modeling and simulation improve design and production efficiency.\n∙\n• Customization & Flexibility: AR-driven interfaces allow on-demand information access and task guidance\n\n--- Page 4 ---\nApplications in Industry\nDesign & Prototyping:\n∙\nVR allows engineers to test and visualize 3D models before physical production.\no\nTraining & Skill Development:\n∙\nVR simulates real-world scenarios for safe, effective training (e.g., for machine operators, welders).\no\nAR provides step-by-step guides directly in the worker's view.\no\nMaintenance & Repairs:\n∙\nAR overlays instructions for machine servicing, reducing downtime.",
      "filename": "VR-AR for industrial renewal.pdf",
      "page": 4
    },
    {
      "doc_id": "tmpy_gzq1e__VR-AR for industrial renewal.pdf_8ebec43a_18d419b8",
      "chunk_index": 3,
      "content": "g (e.g., for machine operators, welders).\no\nAR provides step-by-step guides directly in the worker's view.\no\nMaintenance & Repairs:\n∙\nAR overlays instructions for machine servicing, reducing downtime.\no\nRemote Assistance:\n∙\nExperts can guide on-site workers virtually using AR glasses.\no\nManufacturing & Assembly:\n∙\n• AR aids in precision assembly by showing virtual markers and guides\n\n--- Page 5 ---\nAdvantages\nEnhanced Efficiency: Reduces time for training, troubleshooting, and assembly.\n∙\nSafety Improvements: Dangerous tasks can be simulated virtually, lowering risks.\n∙\nCost Savings: Cuts down prototyping, travel, and downtime costs.\n∙\n• Better Quality Control: Real-time monitoring and diagnostics enhance output quality\n\n--- Page 6 ---\n• Maintenance & Remote Assistance\n•AR overlays real-time instructions onto machinery, reducing errors and downtime.\n•Boeing uses AR glasses to project wiring diagrams, cutting assembly errors by 25% 5.",
      "filename": "VR-AR for industrial renewal.pdf",
      "page": 5
    },
    {
      "doc_id": "tmpy_gzq1e__VR-AR for industrial renewal.pdf_8ebec43a_18d419b8",
      "chunk_index": 4,
      "content": "Maintenance & Remote Assistance\n•AR overlays real-time instructions onto machinery, reducing errors and downtime.\n•Boeing uses AR glasses to project wiring diagrams, cutting assembly errors by 25% 5.\n•Predictive Maintenance: AI-powered AR identifies equipment failures before they occur, minimizing disruptions\n• Digital Twins & Design Optimization\n• 5G-powered digital twins allow engineers to simulate factory layouts, reducing design time by 10% and construction\ntime by 7% 4\n• Automotive & Aerospace: VR prototypes streamline testing, saving millions in physical model cost\nDefense & Industrial Collaboration\n• Meta and Anduril are developing AR/VR military systems, such as EagleEye, which enhances soldiers' vision and hearing\n• Remote Expert Guidance: Technicians receive live AR annotations from specialists, reducing travel costs\n\n--- Page 7 ---\nMarket Trends & Growth Drivers:\n•Enterprise Adoption: Over 88% of medium-sized companies use AR, with healthcare and\nmanufacturing leading adopt",
      "filename": "VR-AR for industrial renewal.pdf",
      "page": 7
    },
    {
      "doc_id": "tmpy_gzq1e__VR-AR for industrial renewal.pdf_8ebec43a_18d419b8",
      "chunk_index": 5,
      "content": "from specialists, reducing travel costs\n\n--- Page 7 ---\nMarket Trends & Growth Drivers:\n•Enterprise Adoption: Over 88% of medium-sized companies use AR, with healthcare and\nmanufacturing leading adoption .\n•5G & Edge Computing: Enable low-latency AR streaming, critical for real-time industrial applications\n•AI Integration: AI automates 3D environment generation and enhances object recognition in AR\nworkflows\n•Cost Savings: VR training is 4x faster than traditional methods, reducing onboarding expense\n\n--- Page 8 ---\nChallenges and Limitations\nHigh Initial Costs: Devices and development of content are expensive.\n∙\nIntegration Issues: Compatibility with existing industrial systems can be complex.\n∙\nSkill Gap: Requires training to operate VR/AR systems.\n∙\n• Connectivity Needs: High-speed networks (e.g., 5G) often required for smooth functionality",
      "filename": "VR-AR for industrial renewal.pdf",
      "page": 7
    },
    {
      "doc_id": "tmpy_gzq1e__VR-AR for industrial renewal.pdf_8ebec43a_18d419b8",
      "chunk_index": 6,
      "content": "orks (e.g., 5G) often required for smooth functionality",
      "filename": "VR-AR for industrial renewal.pdf",
      "page": null
    },
    {
      "doc_id": "e69a2cb3-36e0-44d2-b1ae-2a5b48c16a02_docA.txt_125a1826_d5c09805",
      "chunk_index": 0,
      "content": "DocA intro. This is only about alpha topic.\n--- Page 1 ---\nAlpha improves X by 10%.",
      "filename": "docA.txt",
      "page": 1
    },
    {
      "doc_id": "2eb8b721-ddce-4bbd-ac02-4a47277965fe_docB.txt_b3f2c7e0_e19edc39",
      "chunk_index": 0,
      "content": "DocB overview. This is only about beta topic.\n--- Page 2 ---\nBeta reduces Y by 20%.",
      "filename": "docB.txt",
      "page": 2
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nUnit II\nCLIP (Contrastive Language–Image Pretraining)\nCLIP (Contrastive Language–Image Pretraining) learns a joint text–image embedding\nspace by using contrastive learning to bring matching image–text pairs close and push\nnon-matching pairs apart.\nKey points & justifications:\n1. Dual encoders (text & image) mapped to a shared space.\nJustification: Mapping both modalities into the same vector space makes direct\nsimilarity computations (cosine similarity) possible. This design simplifies\ndownstream tasks (retrieval, zero-shot classification) because the model does\nnot have to learn task-specific cross-modal projections every time — the shared\nspace is a reusable interface.\n2. Contrastive (InfoNCE) loss pulls positives and pushes negatives.\nJustification: InfoNCE directly optimizes relative similarity: maximizing similarity\nof correct pairs while minimizing similarity of incorrect pairs.",
      "filename": "UNIT II - GCV.pdf",
      "page": 1
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 1,
      "content": "nfoNCE) loss pulls positives and pushes negatives.\nJustification: InfoNCE directly optimizes relative similarity: maximizing similarity\nof correct pairs while minimizing similarity of incorrect pairs. This encourages\nembeddings to capture semantics that distinguish correct captions from\ndistractors, which is precisely what cross-modal tasks require.\n3. Large batch / many negatives improve representation quality.\nJustification: More negatives increase the difficulty of the contrastive task,\nforcing embeddings to capture fine-grained distinctions. Empirically large\neffective batch sizes (or memory banks) create stronger supervision signals,\nproducing richer semantic structure.\n4. Enables zero-shot transfer and robust retrieval.\nJustification: Because CLIP learns general alignment between text concepts and\nvisual features, it can map a new text label into the same space and retrieve\nrelevant images without task-specific retraining — the learned semantic\ngeometry generalizes.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 2,
      "content": "nt between text concepts and\nvisual features, it can map a new text label into the same space and retrieve\nrelevant images without task-specific retraining — the learned semantic\ngeometry generalizes.\nExample:\nImage: “a red bicycle on a rainy street.” CLIP will place the image embedding near\ncaptions describing bicycles/rain, and far from unrelated captions (e.g., “a dog in a\npark”).\nApplications & justification:\n• Zero-shot classification: No fine-tuning needed because class names can be\nembedded and compared to images.\nJustification: The shared semantic space means class semantics are already\nencoded.\n\n--- Page 2 ---\n• Text-guided retrieval and generation: CLIP scores can rank generated images or\nguide generative models.\nJustification: Direct similarity metrics allow automatic evaluation and steering.\nText embeddings in multimodal diffusion models\nText embeddings convert a prompt into a dense vector that conditions diffusion models,\nguiding stochastic denoising toward images that mat",
      "filename": "UNIT II - GCV.pdf",
      "page": 2
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 3,
      "content": "and steering.\nText embeddings in multimodal diffusion models\nText embeddings convert a prompt into a dense vector that conditions diffusion models,\nguiding stochastic denoising toward images that match the text.\nKey points & justifications:\n1. Serve as conditioning signal during denoising.\nDiffusion models generate by reversing noise; conditioning vectors are injected\n(via concatenation, cross-attention, or FiLM) so each denoising step has\nsemantic context. Without conditioning, the model has no way to steer\ngeneration toward the desired semantics.\n2. Capture both object and style attributes.\nModern text encoders (Transformers) represent not just nouns but adjectives,\nrelations, and style descriptors. Embeddings therefore allow the generator to\nsynthesize content (objects) and aesthetic (style) simultaneously.\n3. Enable fine controls (compositional prompts, modifiers).\nVector arithmetic and attention let the model weight different subcomponents\nof the prompt; e.g.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 4,
      "content": "ects) and aesthetic (style) simultaneously.\n3. Enable fine controls (compositional prompts, modifiers).\nVector arithmetic and attention let the model weight different subcomponents\nof the prompt; e.g., “photorealistic” vs “oil painting” map to different embedding\ndirections, producing controlled stylistic outcomes.\n4. Facilitate semantic consistency across steps.\nConditioning every denoising step (rather than only at start) ensures semantic\ninformation persists through the stochastic sampling, preventing drift to\nirrelevant modes.\nExample:\nPrompt: “A small wooden cabin at sunset, misty atmosphere.” The embedding encodes\nobject (“cabin”), material (“wooden”), time (“sunset”), and mood (“misty”) so the\ndiffusion model composes these attributes coherently.\nApplications & justification:\n• Text-to-image (Stable Diffusion): Embeddings let a single model produce\ndiverse outputs from many prompts.\nA single learned forward/backward process can be reused with different\ncondition vectors.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 5,
      "content": ":\n• Text-to-image (Stable Diffusion): Embeddings let a single model produce\ndiverse outputs from many prompts.\nA single learned forward/backward process can be reused with different\ncondition vectors.\n\n--- Page 3 ---\n• Prompt interpolation and editing: Embeddings allow latent manipulations\n(e.g., amplify “sunset”) to edit outputs.\nContinuous embeddings provide smooth control that discrete labels cannot.\nCritical insight / limitation\nIf embeddings lack domain knowledge or are ambiguous, generation will be\nsemantically weak. Therefore, high-quality text encoders and, when needed, domain-\nspecific embedding fine-tuning are essential.\nCommon evaluation metrics for text–image alignment\nEvaluating multimodal generation requires metrics that measure both visual quality and\nsemantic alignment between text and image.\nMetrics & justifications:\n1. CLIPScore (cosine similarity of CLIP embeddings).\nWhat it measures: Semantic alignment between generated image and\nprompt.",
      "filename": "UNIT II - GCV.pdf",
      "page": 3
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 6,
      "content": "y and\nsemantic alignment between text and image.\nMetrics & justifications:\n1. CLIPScore (cosine similarity of CLIP embeddings).\nWhat it measures: Semantic alignment between generated image and\nprompt.\nCLIP is trained to align modalities; its cosine similarity is a direct proxy for how\nwell image content matches textual semantics. It’s automatic and correlates\nreasonably with human judgments for many prompts.\n2. FID (Fréchet Inception Distance).\nWhat it measures: Distributional similarity between generated images and\nreal images.\nFID captures both quality and diversity by comparing feature statistics (means,\ncovariances). Lower FID implies generated images occupy similar manifold to\nreal images.\n3. Inception Score (IS).\nWhat it measures: Distinctiveness and confidence of generated images (via\nan Inception classifier).\nIS rewards samples that are recognizable and varied; however it doesn’t\nmeasure prompt alignment.\n4. Human evaluation (relevance, fidelity, preference).",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 7,
      "content": "generated images (via\nan Inception classifier).\nIS rewards samples that are recognizable and varied; however it doesn’t\nmeasure prompt alignment.\n4. Human evaluation (relevance, fidelity, preference).\nWhat it measures: Subjective semantic correctness and visual appeal.\nAutomated metrics are imperfect, so human judgment remains the gold\nstandard, especially for nuanced or creative prompts.\n5. Task-specific metrics (precision/recall on objects, detection mAP).\nWhen prompts require specific objects or relations, applying object detectors\nand measuring precision/recall quantifies functional correctness.\n\n--- Page 4 ---\nCombining metrics — justification:\nNo single metric captures all aspects. CLIPScore checks alignment but not realism; FID\nchecks realism but not prompt adherence. Combining metrics plus human checks\nproduces more reliable evaluation.\nLimitations :\nCLIPScore can be gamed (adversarially optimized); FID is sensitive to dataset choice\nand model used for features.",
      "filename": "UNIT II - GCV.pdf",
      "page": 4
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 8,
      "content": ". Combining metrics plus human checks\nproduces more reliable evaluation.\nLimitations :\nCLIPScore can be gamed (adversarially optimized); FID is sensitive to dataset choice\nand model used for features. Thus metric selection should align with evaluation goals\nand be interpreted carefully.\nFine-tuning CLIP\nIntroduction:\nPretrained CLIP is broad but not deep in domain-specific semantics; fine-tuning adapts\nit to specialized vocabularies, visual cues, and biases of a target domain.\nKey points & justifications:\n1. Bridging domain vocabulary gaps.\nCLIP’s internet training may underrepresent domain terms (medical labels,\nindustrial parts). Fine-tuning with domain captions teaches the text encoder\ndomain semantics and aligns them to visual cues in that field.\n2. Improving visual feature sensitivity to domain specifics.\nFine-tuning the image encoder helps it attend to subtle diagnostic visual features\n(e.g., microcalcifications) that general models may deem irrelevant.\n3.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 9,
      "content": "sual feature sensitivity to domain specifics.\nFine-tuning the image encoder helps it attend to subtle diagnostic visual features\n(e.g., microcalcifications) that general models may deem irrelevant.\n3. Reducing harmful biases and spurious correlations.\nDomain curation can balance datasets and remove stereotypes present in\ninternet data, improving fairness and factual accuracy in sensitive contexts.\n4. Better downstream task performance (retrieval, VQA, diagnostics).\nFine-tuned embeddings yield higher retrieval precision and more accurate VQA\nanswers because they encode task-relevant features.\nPractical methods & justifications:\n• Full fine-tuning: update all weights — best for abundant labels.\nAllows maximal adaptation but risks catastrophic forgetting and needs data/GPU\nresources.\n• Adapter modules / LoRA / prompt tuning: lightweight adjustments.\nPreserve pretrained knowledge while cheaply adapting to domain; less risk of\nforgetting and cheaper to train.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 10,
      "content": "eds data/GPU\nresources.\n• Adapter modules / LoRA / prompt tuning: lightweight adjustments.\nPreserve pretrained knowledge while cheaply adapting to domain; less risk of\nforgetting and cheaper to train.\n\n--- Page 5 ---\n• Continual learning / regularization: e.g., Elastic Weight Consolidation to\nprevent forgetting.\nMaintains general CLIP capabilities while learning domain specifics.\nExample:\nFine-tuning CLIP on annotated chest X-rays (labels, radiologist captions) yields\nimproved retrieval and VQA performance for radiology tasks because the model learns\nto associate radiographic patterns with domain terms.\nFine-tuning requires curated, representative, and labeled domain data; otherwise you\nrisk overfitting or preserving harmful biases. Validation and human oversight are\nessential.\nArchitecture of CLIP and joint learning\nIntroduction:\nCLIP uses separate encoders for images and text, projection heads to a common\nembedding space, and contrastive training to jointly learn aligned representati",
      "filename": "UNIT II - GCV.pdf",
      "page": 5
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 11,
      "content": "e of CLIP and joint learning\nIntroduction:\nCLIP uses separate encoders for images and text, projection heads to a common\nembedding space, and contrastive training to jointly learn aligned representations.\nArchitecture components & justifications:\n1. Image encoder (ViT or ResNet).\nCNNs (ResNet) capture local textures; ViTs capture long-range interactions.\n\n--- Page 6 ---\nChoice depends on tradeoffs (compute vs performance). Both produce rich\nvisual features for projection.\n2. Text encoder (Transformer).\nTransformers model sequential and contextual language semantics effectively,\nenabling capture of compositional meaning (modifiers, relations).\n3. Projection heads (linear layers) mapping to shared space.\nSeparate high-dim features are projected to a common dimensionality so cosine\nsimilarity is meaningful; projection can also adapt modality-specific statistics.\n4. Contrastive (InfoNCE) training with large effective batch size.\nMany negatives help the model learn fine distinctions.",
      "filename": "UNIT II - GCV.pdf",
      "page": 6
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 12,
      "content": "ilarity is meaningful; projection can also adapt modality-specific statistics.\n4. Contrastive (InfoNCE) training with large effective batch size.\nMany negatives help the model learn fine distinctions. Training with symmetric\nloss (image→text and text→image) strengthens bidirectional retrieval capability.\n5. Temperature scaling in contrastive loss.\nTemperature controls concentration of similarity distribution; tuning it balances\nsensitivity between positive/negative pairs.\nWhy this design works?\n• Separate encoders let each modality use architectures tailored to its inductive\nbiases, yet the projection + contrastive loss forces semantic alignment without\nmerging architectures (which would be less flexible).\n• Large paired datasets provide diverse supervision so the embedding geometry\ngeneralizes across many concepts.\nExample:\nDuring training a batch of image-caption pairs, each image’s closest embedding should\nbe its caption’s embedding.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 13,
      "content": "verse supervision so the embedding geometry\ngeneralizes across many concepts.\nExample:\nDuring training a batch of image-caption pairs, each image’s closest embedding should\nbe its caption’s embedding. The symmetric contrastive loss enforces this across all\nbatch pairs, producing a globally consistent embedding geometry.\nTradeoffs:\n• Heavy compute and data requirements are justified by strong zero-shot\nperformance.\n• Model complexity makes fine-tuning expensive; adapter techniques can mitigate\ncosts.\nCLIP can be integrated with diffusion models for text-to-image generation\nIntroduction:\nCLIP can guide diffusion models either by providing conditioning embeddings or by\nacting as an external scorer to encourage semantic alignment during sampling.\n\n--- Page 7 ---\nIntegration mechanisms & justifications:\n1. Embedding conditioning (direct): feed CLIP text embeddings into diffusion\nmodel (via cross-attention or concatenation).",
      "filename": "UNIT II - GCV.pdf",
      "page": 7
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 14,
      "content": "ent during sampling.\n\n--- Page 7 ---\nIntegration mechanisms & justifications:\n1. Embedding conditioning (direct): feed CLIP text embeddings into diffusion\nmodel (via cross-attention or concatenation).\nDirect conditioning uses the semantic vector as part of the generative process,\nenabling the model to learn to map embeddings to visual features during training\n— the cleanest, learned integration.\n2. CLIP guidance (external scorer / gradient guidance): compute CLIP similarity\nof intermediate samples to the prompt and backpropagate gradients to\nnudge samples.\nThis allows a pretrained diffusion model (without conditioning) to be steered at\nsampling time; useful when retraining is expensive. It leverages CLIP’s semantic\nsignal as an online objective.\n3. Classifier-free guidance vs CLIP scoring: classifier-free guidance blends\nunconditional and conditional denoising; CLIP guidance explicitly optimizes\nsemantic similarity.",
      "filename": "UNIT II - GCV.pdf",
      "page": 7
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 15,
      "content": "al as an online objective.\n3. Classifier-free guidance vs CLIP scoring: classifier-free guidance blends\nunconditional and conditional denoising; CLIP guidance explicitly optimizes\nsemantic similarity.\nClassifier-free guidance is learned and often efficient; CLIP guidance can\nimprove semantic alignment but is computationally heavier and sometimes\nunstable, so practitioners choose based on constraints.\n4. Hybrid approaches (fine-tune diffusion with CLIP): fine-tune a conditional\ndiffusion model where conditioning is CLIP embeddings.\nThis produces the most coherent integration: the generator learns to use\nembeddings during training, reducing the need for costly gradient-based steering\nat sampling time.\nExample workflow (gradient guidance):\nAt each sampling step, generate image x_t, compute CLIP similarity s = cosine(clip_text,\nclip_image(x_t)), compute ∇_{x_t} s and adjust x_t in direction that increases similarity,\nthen proceed to next denoising step.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 16,
      "content": "step, generate image x_t, compute CLIP similarity s = cosine(clip_text,\nclip_image(x_t)), compute ∇_{x_t} s and adjust x_t in direction that increases similarity,\nthen proceed to next denoising step.\nTradeoffs:\n• Pros: CLIP guidance improves semantic fidelity and allows reusing pretrained\ndiffusion models.\n• Cons: Extra compute (CLIP forward + gradient) and potential for adversarial\nartifacts if optimized too aggressively — justification for careful step size and\nregularization.\nQ7 — Compare CLIP-guided generation vs GAN-based text-to-image methods\n\n--- Page 8 ---\nComparison points & justifications:\n1. Semantic alignment: CLIP-guided diffusion > GANs.\nJustification: CLIP provides explicit semantic supervision via\nembeddings/scores; GANs rely on discriminator signals that emphasize\nrealism rather than semantic correctness.\n2. Visual sharpness / texture realism: GANs often produce sharper textures.",
      "filename": "UNIT II - GCV.pdf",
      "page": 8
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 17,
      "content": "pervision via\nembeddings/scores; GANs rely on discriminator signals that emphasize\nrealism rather than semantic correctness.\n2. Visual sharpness / texture realism: GANs often produce sharper textures.\nJustification: GAN adversarial loss explicitly forces photorealistic textures;\ndiffusion models historically produced blurrier outputs (though modern\ntechniques narrowed the gap).\n3. Training stability: Diffusion (with CLIP) tends to be more stable than GAN\ntraining.\nJustification: GANs suffer from mode collapse and training instability due to\nadversarial dynamics; diffusion is likelihood-based and often converges\nmore predictably.\n4. Sampling speed / compute: GANs typically faster at inference; CLIP-guided\ndiffusion is slower.\nJustification: GANs generate in one forward pass; diffusion models require\nmany denoising steps; CLIP guidance adds more compute for\nscoring/gradients.\n5. Controllability & editing: CLIP-guided diffusion offers finer control (text,\nprompt editing).",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 18,
      "content": "; diffusion models require\nmany denoising steps; CLIP guidance adds more compute for\nscoring/gradients.\n5. Controllability & editing: CLIP-guided diffusion offers finer control (text,\nprompt editing).\nJustification: Conditioning and CLIP feedback directly influence semantics\nacross steps; GANs can be controlled via latent manipulations but mapping\nbetween latent and semantics is less direct.\n6. Robustness to prompts: CLIP-guided methods generalize better to open-\nended prompts.\nJustification: CLIP’s pretraining on broad captions provides strong semantic\ngrounding; GANs trained on limited paired data often struggle with out-of-\ndistribution prompts.\nUse-case recommendations (justified):\n• For high-speed production of photoreal textures, GANs may be preferable.\nJustification: Fast single-pass generation with high fidelity.\n• For semantic, creative, and controllable generation, CLIP-guided diffusion is\npreferable despite slower sampling.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 19,
      "content": "Ns may be preferable.\nJustification: Fast single-pass generation with high fidelity.\n• For semantic, creative, and controllable generation, CLIP-guided diffusion is\npreferable despite slower sampling.\nJustification: Better alignment to textual intent and flexibility.\n\n--- Page 9 ---\nLimitation of CLIP and a detailed solution (with justifications)\nLimitation chosen: Bias and spurious correlations inherited from large web-scale\ntraining data.\n• CLIP’s embeddings reflect the distribution of its training corpus; societal\nstereotypes and underrepresentation produce associations that can harm\ndownstream use (e.g., biased retrieval or discriminatory generative outputs). In\ncritical domains (hiring, law, medicine) these errors are unacceptable.\nProposed multi-pronged solution:\n1. Domain-aware fine-tuning with curated datasets.\nCurated, annotated domain data corrects label distributions and teaches the\nmodel correct associations relevant to the domain (e.g., medical labels).",
      "filename": "UNIT II - GCV.pdf",
      "page": 9
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 20,
      "content": "1. Domain-aware fine-tuning with curated datasets.\nCurated, annotated domain data corrects label distributions and teaches the\nmodel correct associations relevant to the domain (e.g., medical labels). It\nreduces reliance on noisy web labels.\n2. Bias mitigation during training (reweighting / adversarial debiasing).\nReweighting or adversarial objectives discourage encoding of protected\nattributes (e.g., gender) when they’re not relevant. These methods directly\npenalize the emergence of undesirable correlations.\n3. Counterfactual data augmentation.\nGenerating or collecting balanced examples that swap sensitive attributes (e.g.,\nsame profession across genders/ethnicities) reduces statistical shortcuts and\nforces the model to focus on relevant visual cues.\n4. Evaluation & continuous monitoring (human-in-the-loop).\nAutomated checks (fairness metrics) plus human audits detect remaining bias.\nContinuous monitoring post-deployment catches distribution shifts and\nemergent problems.\n5.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 21,
      "content": "monitoring (human-in-the-loop).\nAutomated checks (fairness metrics) plus human audits detect remaining bias.\nContinuous monitoring post-deployment catches distribution shifts and\nemergent problems.\n5. Model explanations and transparency.\nSaliency maps or retrieval-based explanations help users understand why the\nmodel associated certain text and images, enabling corrective action.\nExample application:\nDeploying an e-commerce visual search: before deployment, augment training with\ndiverse product images across demographics, apply reweighting, and run fairness tests\nto ensure the model does not systematically underrepresent particular groups.\n\n--- Page 10 ---\n2. CLIP AND JOINT EMBEDDINGS\nIntroduction\nGenerative AI has transformed the way text and visual data can be integrated to create\nnew forms of digital content. Among the leading approaches are Contrastive Language–\nImage Pretraining (CLIP) and diffusion models, which together form a powerful pipeline\nfor text-to-image synthesis.",
      "filename": "UNIT II - GCV.pdf",
      "page": 10
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 22,
      "content": "new forms of digital content. Among the leading approaches are Contrastive Language–\nImage Pretraining (CLIP) and diffusion models, which together form a powerful pipeline\nfor text-to-image synthesis.\nCLIP aligns language and visual modalities through joint embeddings, while diffusion\nmodels use probabilistic denoising processes to synthesize realistic and semantically\naligned images.\nThis integration is significant across domains like education, design, healthcare,\nentertainment, and scientific communication, where the ability to convert descriptions\ninto visuals saves time, enhances creativity, and improves accessibility. However,\nensuring reliability, accuracy, and fairness requires deeper understanding of the\nmechanisms, limitations, and solutions of such systems.\n(a) CLIP and Joint Embeddings – Mechanism and Benefits\n1. Core Concept\no CLIP consists of two encoders:\n▪ A Text Encoder (Transformer-based) processes natural language\nprompts.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 23,
      "content": "utions of such systems.\n(a) CLIP and Joint Embeddings – Mechanism and Benefits\n1. Core Concept\no CLIP consists of two encoders:\n▪ A Text Encoder (Transformer-based) processes natural language\nprompts.\n▪ An Image Encoder (ResNet or Vision Transformer) processes image\ndata.\no Both outputs are projected into a shared embedding space, enabling\ncomparisons.\n2. Contrastive Learning\no During training, CLIP is presented with a batch of image–text pairs.\no The correct image–caption pair should have a high cosine similarity, while\nincorrect pairs should score low.\no InfoNCE loss optimizes this by pulling true pairs closer and pushing false\npairs apart.\n3. Why This Matters for Generation\no When combined with diffusion models, the shared space ensures the\ngenerated image faithfully represents the meaning of the text.\n\n--- Page 11 ---\no Unlike traditional vision models limited to classification, CLIP’s\nembeddings generalize across unseen categories and abstract prompts.\n4.",
      "filename": "UNIT II - GCV.pdf",
      "page": 11
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 24,
      "content": "hfully represents the meaning of the text.\n\n--- Page 11 ---\no Unlike traditional vision models limited to classification, CLIP’s\nembeddings generalize across unseen categories and abstract prompts.\n4. Example\no Prompt: “A panda wearing sunglasses playing guitar.”\no CLIP embeddings capture not only the object (“panda”) but also\nattributes (“wearing sunglasses”) and context (“playing guitar”).\no The diffusion model uses these embeddings to guide generation, ensuring\nall described elements appear.\n5. Justification\no This approach solves the problem of semantic drift, where generated\nimages deviate from text.\no It also enables zero-shot transfer, where the model works on new\nconcepts without retraining.\n(b) Noise Scheduling and Diffusion Process – Stability and Quality\n1. Forward Diffusion (Training Stage)\no The model learns by gradually adding Gaussian noise to real images over\nmany steps until they become indistinguishable from random noise.",
      "filename": "UNIT II - GCV.pdf",
      "page": 11
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 25,
      "content": "Stability and Quality\n1. Forward Diffusion (Training Stage)\no The model learns by gradually adding Gaussian noise to real images over\nmany steps until they become indistinguishable from random noise.\no This corruption process teaches the system how data can be “destroyed”\nin a controlled manner.\n2. Backward Diffusion (Generation Stage)\no The generative model reverses the process, progressively denoising\nrandom noise step by step to reconstruct a meaningful image.\no Conditioning on text embeddings ensures that the denoising follows the\nsemantic structure encoded in the prompt.\n3. Noise Schedulers\no Decide the rate and distribution of noise addition/removal across\ntimesteps.\no Common schedulers: linear, cosine, exponential decay.\no The choice affects image clarity, diversity, and fidelity.\n4. Why It Matters\n\n--- Page 12 ---\no Too much noise at early steps → unstable generations.\no Too little → lack of diversity.",
      "filename": "UNIT II - GCV.pdf",
      "page": 12
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 26,
      "content": "nential decay.\no The choice affects image clarity, diversity, and fidelity.\n4. Why It Matters\n\n--- Page 12 ---\no Too much noise at early steps → unstable generations.\no Too little → lack of diversity.\no A well-designed scheduler balances exploration and accuracy, leading to\nimages that are high-quality, sharp, and semantically consistent.\n5. Example\no A poorly tuned scheduler may generate a “blurred car” for the prompt “a\nred sports car on a racetrack.”\no With proper scheduling, details like color, motion blur, and track\nbackground are preserved.\n6. Justification\no Diffusion + noise scheduling ensures outputs remain reliable and artifact-\nfree, addressing weaknesses of earlier GAN-based methods which often\nsuffered from mode collapse.\n(c) Ensuring Accuracy with Fine-Tuning – Overcoming Hallucinations\n1. The Challenge\no Generative models, when trained on generic internet data, may produce\nimages that are visually appealing but scientifically or contextually\ninaccurate.",
      "filename": "UNIT II - GCV.pdf",
      "page": 12
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 27,
      "content": "g – Overcoming Hallucinations\n1. The Challenge\no Generative models, when trained on generic internet data, may produce\nimages that are visually appealing but scientifically or contextually\ninaccurate.\no Risk of “hallucination” (adding irrelevant objects) or oversimplification.\n2. Role of Fine-Tuning\no Fine-tuning adapts pretrained models to specific domains using curated\ndatasets.\no Adjusts weights so the model captures domain-specific semantics and\navoids irrelevant associations.\n3. Methods\no Full fine-tuning: Retrain on specialized datasets (e.g., radiology images,\nengineering diagrams).\no Adapter/LoRA tuning: Lightweight layers added for efficient adaptation.\no Prompt-tuning: Adding domain-specific tokens or context.\n4. Example\no Generic model → “DNA double helix” may produce artistic swirls.\n\n--- Page 13 ---\no Fine-tuned model on biology diagrams → generates precise base pairs and\nmolecular structure.\n5. Justification\no Fine-tuning improves factual accuracy.",
      "filename": "UNIT II - GCV.pdf",
      "page": 13
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 28,
      "content": "” may produce artistic swirls.\n\n--- Page 13 ---\no Fine-tuned model on biology diagrams → generates precise base pairs and\nmolecular structure.\n5. Justification\no Fine-tuning improves factual accuracy.\no Reduces domain mismatch, making outputs trustworthy in professional\nor academic settings.\no Supports applications where error tolerance is low (e.g., medicine,\nengineering, education).\n(d) Limitations of CLIP and Solutions\n1. Limitations\no Bias and Fairness: CLIP inherits social and cultural biases from web data.\no Ambiguity Handling: Struggles when prompts are vague (“a beautiful\nscene”) or multi-layered.\no Domain Gaps: Lacks accuracy in highly technical or specialized areas.\no Computational Cost: Joint text-image training and inference are resource-\nintensive.\n2. Possible Solutions\no Bias Mitigation: Curate balanced datasets, use fairness-aware training,\nand adversarial debiasing.\no Prompt Engineering: Rephrase prompts to be specific, reducing\nambiguity.",
      "filename": "UNIT II - GCV.pdf",
      "page": 13
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 29,
      "content": "e.\n2. Possible Solutions\no Bias Mitigation: Curate balanced datasets, use fairness-aware training,\nand adversarial debiasing.\no Prompt Engineering: Rephrase prompts to be specific, reducing\nambiguity.\no Domain Adaptation: Use fine-tuning, adapters, or hybrid models for niche\ntasks.\no Human-in-the-Loop Evaluation: Incorporate expert feedback to validate\noutputs.\n3. Example\no Prompt: “A doctor” may disproportionately generate male figures due to\nbiased training data.\no Mitigation: Fine-tuning with balanced datasets ensures diverse\nrepresentations.\n4. Justification\n\n--- Page 14 ---\no Without addressing these issues, the trustworthiness and adoption of\nCLIP-based systems may be limited.\no Solutions ensure outputs remain inclusive, accurate, and ethically\ndeployable.\nThe integration of CLIP and diffusion models represents a paradigm shift in multimodal\nAI, enabling systems to understand and generate complex visual representations from\nnatural language.",
      "filename": "UNIT II - GCV.pdf",
      "page": 14
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 30,
      "content": "deployable.\nThe integration of CLIP and diffusion models represents a paradigm shift in multimodal\nAI, enabling systems to understand and generate complex visual representations from\nnatural language.\nCLIP ensures semantic alignment through joint embeddings, while diffusion models\nguarantee stability and quality via noise scheduling and denoising processes.\nFine-tuning resolves the issue of accuracy and domain specificity, while awareness of\nCLIP’s limitations (biases, ambiguity, domain gaps) and corrective solutions ensures\ntrustworthy deployment. In essence, the synergy between CLIP and diffusion models\nforms a robust, flexible, and scalable framework for multimodal content creation,\ncapable of serving both general and highly specialized applications.\n3. CLIP with diffusion models\nIntroduction\nText-to-image generation has become one of the most exciting advancements in\nartificial intelligence.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 31,
      "content": "rving both general and highly specialized applications.\n3. CLIP with diffusion models\nIntroduction\nText-to-image generation has become one of the most exciting advancements in\nartificial intelligence. By combining CLIP (Contrastive Language–Image Pretraining)\nwith diffusion models, systems can generate images that accurately reflect user\ndescriptions. CLIP provides a bridge between language and vision, aligning text prompts\nwith visual features, while diffusion models create high-quality, coherent outputs\nthrough a noise-to-image process. Together, they enable applications ranging from\ncreative design and education to healthcare and entertainment.\n(a) Architecture of CLIP – Connecting Text and Visuals\n1. Dual Encoder System\no CLIP consists of a text encoder (Transformer-based) and an image\nencoder (Vision Transformer or CNN).\no Both map their inputs into feature vectors.\n2. Shared Semantic Space\no Text and image embeddings are projected into a joint latent space where\nsimilarity is mea",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 32,
      "content": "encoder (Vision Transformer or CNN).\no Both map their inputs into feature vectors.\n2. Shared Semantic Space\no Text and image embeddings are projected into a joint latent space where\nsimilarity is measured.\no Training uses contrastive learning: matching text–image pairs are pulled\ncloser, mismatched ones pushed apart.\n\n--- Page 15 ---\n3. Outcome\no This allows CLIP to capture not just objects but also attributes, context,\nand relationships.\no For example, the phrase “bright red car on a snowy road” aligns with\nimages showing both the car and the setting.\n4. Significance\no These joint embeddings are crucial for guiding generative models so that\noutputs remain semantically aligned with textual descriptions.\n(b) Text-Guided Stable Diffusion – The Generation Process\n1. Forward Diffusion\no Real images are progressively noised until they become indistinguishable\nrandom noise.\n2. Backward Diffusion (Denoising)\no The model learns to reverse this process: starting from noise, it generates\nan ima",
      "filename": "UNIT II - GCV.pdf",
      "page": 15
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 33,
      "content": "images are progressively noised until they become indistinguishable\nrandom noise.\n2. Backward Diffusion (Denoising)\no The model learns to reverse this process: starting from noise, it generates\nan image step by step.\n3. Conditioning with CLIP\no The embeddings from CLIP are injected into the backward process as\nguidance signals.\no This ensures that the generated image reflects the semantic meaning of\nthe text prompt.\n4. Noise Scheduling\no Proper noise scheduling regulates how much detail is added at each step,\npreventing artifacts and improving stability.\n5. Why It Works\no Diffusion models combined with CLIP generate stable, realistic, and\nprompt-aligned visuals, outperforming earlier GAN-based approaches\nthat often struggled with fine details.\n(c) Fine-Tuning for Domain-Specific Applications\n1. Need for Fine-Tuning\no Base CLIP and diffusion models are trained on broad internet data, which\nmay not cover specialized domains well.\n\n--- Page 16 ---\n2.",
      "filename": "UNIT II - GCV.pdf",
      "page": 16
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 34,
      "content": "e-Tuning for Domain-Specific Applications\n1. Need for Fine-Tuning\no Base CLIP and diffusion models are trained on broad internet data, which\nmay not cover specialized domains well.\n\n--- Page 16 ---\n2. Process\no Fine-tuning involves training or adapting the model with domain-specific\nprompts or datasets.\no Example: In medicine, fine-tuning ensures that a description like “X-ray\nshowing lung opacity” produces medically accurate images.\n3. Benefits\no Enhances accuracy (outputs match technical details).\no Improves aesthetic or contextual relevance (outputs suit the domain\nstyle).\no Reduces biases and errors from general-purpose training.\n4. Justification\no Without fine-tuning, models may produce outputs that are visually\nplausible but factually incorrect. Domain adaptation ensures trustworthy\nand useful results.\n(d) Evaluation Metrics for Text–Image Alignment\n1. Quantitative Metrics\no CLIPScore: Measures similarity between generated image embeddings\nand prompt embeddings.",
      "filename": "UNIT II - GCV.pdf",
      "page": 16
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 35,
      "content": "sures trustworthy\nand useful results.\n(d) Evaluation Metrics for Text–Image Alignment\n1. Quantitative Metrics\no CLIPScore: Measures similarity between generated image embeddings\nand prompt embeddings.\no FID (Fréchet Inception Distance): Evaluates image quality by comparing\ngenerated and real data distributions.\no IS (Inception Score): Measures diversity and realism of generated\nimages.\n2. Qualitative Metrics\no Human evaluation: Users judge whether images align with descriptions.\no Task-based evaluation: Checking how well generated outputs support\ndownstream tasks (e.g., retrieval, classification).\n3. Balanced Evaluation\no A mix of automated and human assessments ensures both objective\naccuracy and subjective quality are measured.\n4. Significance\n\n--- Page 17 ---\no Robust evaluation is critical to confirm that the system produces outputs\nthat are reliable, meaningful, and user-aligned.\nConclusion\nBy integrating CLIP embeddings with diffusion-based generation, AI systems achieve\naccurate",
      "filename": "UNIT II - GCV.pdf",
      "page": 17
    },
    {
      "doc_id": "tmpi1f70h19_UNIT II - GCV.pdf_1d6f9513_b1016398",
      "chunk_index": 36,
      "content": "ical to confirm that the system produces outputs\nthat are reliable, meaningful, and user-aligned.\nConclusion\nBy integrating CLIP embeddings with diffusion-based generation, AI systems achieve\naccurate text-to-image synthesis. CLIP ensures semantic alignment, diffusion\nguarantees high visual fidelity, fine-tuning adapts models to specialized domains, and\nevaluation metrics confirm performance. This synergy represents a powerful paradigm\nfor multimodal AI, enabling diverse applications where reliable translation of language\ninto images is essential.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nUnit II\nCLIP (Contrastive Language–Image Pretraining)\nCLIP (Contrastive Language–Image Pretraining) learns a joint text–image embedding\nspace by using contrastive learning to bring matching image–text pairs close and push\nnon-matching pairs apart.\nKey points & justifications:\n1. Dual encoders (text & image) mapped to a shared space.\nJustification: Mapping both modalities into the same vector space makes direct\nsimilarity computations (cosine similarity) possible. This design simplifies\ndownstream tasks (retrieval, zero-shot classification) because the model does\nnot have to learn task-specific cross-modal projections every time — the shared\nspace is a reusable interface.\n2. Contrastive (InfoNCE) loss pulls positives and pushes negatives.\nJustification: InfoNCE directly optimizes relative similarity: maximizing similarity\nof correct pairs while minimizing similarity of incorrect pairs.",
      "filename": "UNIT II - GCV.pdf",
      "page": 1
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 1,
      "content": "nfoNCE) loss pulls positives and pushes negatives.\nJustification: InfoNCE directly optimizes relative similarity: maximizing similarity\nof correct pairs while minimizing similarity of incorrect pairs. This encourages\nembeddings to capture semantics that distinguish correct captions from\ndistractors, which is precisely what cross-modal tasks require.\n3. Large batch / many negatives improve representation quality.\nJustification: More negatives increase the difficulty of the contrastive task,\nforcing embeddings to capture fine-grained distinctions. Empirically large\neffective batch sizes (or memory banks) create stronger supervision signals,\nproducing richer semantic structure.\n4. Enables zero-shot transfer and robust retrieval.\nJustification: Because CLIP learns general alignment between text concepts and\nvisual features, it can map a new text label into the same space and retrieve\nrelevant images without task-specific retraining — the learned semantic\ngeometry generalizes.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 2,
      "content": "nt between text concepts and\nvisual features, it can map a new text label into the same space and retrieve\nrelevant images without task-specific retraining — the learned semantic\ngeometry generalizes.\nExample:\nImage: “a red bicycle on a rainy street.” CLIP will place the image embedding near\ncaptions describing bicycles/rain, and far from unrelated captions (e.g., “a dog in a\npark”).\nApplications & justification:\n• Zero-shot classification: No fine-tuning needed because class names can be\nembedded and compared to images.\nJustification: The shared semantic space means class semantics are already\nencoded.\n\n--- Page 2 ---\n• Text-guided retrieval and generation: CLIP scores can rank generated images or\nguide generative models.\nJustification: Direct similarity metrics allow automatic evaluation and steering.\nText embeddings in multimodal diffusion models\nText embeddings convert a prompt into a dense vector that conditions diffusion models,\nguiding stochastic denoising toward images that mat",
      "filename": "UNIT II - GCV.pdf",
      "page": 2
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 3,
      "content": "and steering.\nText embeddings in multimodal diffusion models\nText embeddings convert a prompt into a dense vector that conditions diffusion models,\nguiding stochastic denoising toward images that match the text.\nKey points & justifications:\n1. Serve as conditioning signal during denoising.\nDiffusion models generate by reversing noise; conditioning vectors are injected\n(via concatenation, cross-attention, or FiLM) so each denoising step has\nsemantic context. Without conditioning, the model has no way to steer\ngeneration toward the desired semantics.\n2. Capture both object and style attributes.\nModern text encoders (Transformers) represent not just nouns but adjectives,\nrelations, and style descriptors. Embeddings therefore allow the generator to\nsynthesize content (objects) and aesthetic (style) simultaneously.\n3. Enable fine controls (compositional prompts, modifiers).\nVector arithmetic and attention let the model weight different subcomponents\nof the prompt; e.g.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 4,
      "content": "ects) and aesthetic (style) simultaneously.\n3. Enable fine controls (compositional prompts, modifiers).\nVector arithmetic and attention let the model weight different subcomponents\nof the prompt; e.g., “photorealistic” vs “oil painting” map to different embedding\ndirections, producing controlled stylistic outcomes.\n4. Facilitate semantic consistency across steps.\nConditioning every denoising step (rather than only at start) ensures semantic\ninformation persists through the stochastic sampling, preventing drift to\nirrelevant modes.\nExample:\nPrompt: “A small wooden cabin at sunset, misty atmosphere.” The embedding encodes\nobject (“cabin”), material (“wooden”), time (“sunset”), and mood (“misty”) so the\ndiffusion model composes these attributes coherently.\nApplications & justification:\n• Text-to-image (Stable Diffusion): Embeddings let a single model produce\ndiverse outputs from many prompts.\nA single learned forward/backward process can be reused with different\ncondition vectors.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 5,
      "content": ":\n• Text-to-image (Stable Diffusion): Embeddings let a single model produce\ndiverse outputs from many prompts.\nA single learned forward/backward process can be reused with different\ncondition vectors.\n\n--- Page 3 ---\n• Prompt interpolation and editing: Embeddings allow latent manipulations\n(e.g., amplify “sunset”) to edit outputs.\nContinuous embeddings provide smooth control that discrete labels cannot.\nCritical insight / limitation\nIf embeddings lack domain knowledge or are ambiguous, generation will be\nsemantically weak. Therefore, high-quality text encoders and, when needed, domain-\nspecific embedding fine-tuning are essential.\nCommon evaluation metrics for text–image alignment\nEvaluating multimodal generation requires metrics that measure both visual quality and\nsemantic alignment between text and image.\nMetrics & justifications:\n1. CLIPScore (cosine similarity of CLIP embeddings).\nWhat it measures: Semantic alignment between generated image and\nprompt.",
      "filename": "UNIT II - GCV.pdf",
      "page": 3
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 6,
      "content": "y and\nsemantic alignment between text and image.\nMetrics & justifications:\n1. CLIPScore (cosine similarity of CLIP embeddings).\nWhat it measures: Semantic alignment between generated image and\nprompt.\nCLIP is trained to align modalities; its cosine similarity is a direct proxy for how\nwell image content matches textual semantics. It’s automatic and correlates\nreasonably with human judgments for many prompts.\n2. FID (Fréchet Inception Distance).\nWhat it measures: Distributional similarity between generated images and\nreal images.\nFID captures both quality and diversity by comparing feature statistics (means,\ncovariances). Lower FID implies generated images occupy similar manifold to\nreal images.\n3. Inception Score (IS).\nWhat it measures: Distinctiveness and confidence of generated images (via\nan Inception classifier).\nIS rewards samples that are recognizable and varied; however it doesn’t\nmeasure prompt alignment.\n4. Human evaluation (relevance, fidelity, preference).",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 7,
      "content": "generated images (via\nan Inception classifier).\nIS rewards samples that are recognizable and varied; however it doesn’t\nmeasure prompt alignment.\n4. Human evaluation (relevance, fidelity, preference).\nWhat it measures: Subjective semantic correctness and visual appeal.\nAutomated metrics are imperfect, so human judgment remains the gold\nstandard, especially for nuanced or creative prompts.\n5. Task-specific metrics (precision/recall on objects, detection mAP).\nWhen prompts require specific objects or relations, applying object detectors\nand measuring precision/recall quantifies functional correctness.\n\n--- Page 4 ---\nCombining metrics — justification:\nNo single metric captures all aspects. CLIPScore checks alignment but not realism; FID\nchecks realism but not prompt adherence. Combining metrics plus human checks\nproduces more reliable evaluation.\nLimitations :\nCLIPScore can be gamed (adversarially optimized); FID is sensitive to dataset choice\nand model used for features.",
      "filename": "UNIT II - GCV.pdf",
      "page": 4
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 8,
      "content": ". Combining metrics plus human checks\nproduces more reliable evaluation.\nLimitations :\nCLIPScore can be gamed (adversarially optimized); FID is sensitive to dataset choice\nand model used for features. Thus metric selection should align with evaluation goals\nand be interpreted carefully.\nFine-tuning CLIP\nIntroduction:\nPretrained CLIP is broad but not deep in domain-specific semantics; fine-tuning adapts\nit to specialized vocabularies, visual cues, and biases of a target domain.\nKey points & justifications:\n1. Bridging domain vocabulary gaps.\nCLIP’s internet training may underrepresent domain terms (medical labels,\nindustrial parts). Fine-tuning with domain captions teaches the text encoder\ndomain semantics and aligns them to visual cues in that field.\n2. Improving visual feature sensitivity to domain specifics.\nFine-tuning the image encoder helps it attend to subtle diagnostic visual features\n(e.g., microcalcifications) that general models may deem irrelevant.\n3.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 9,
      "content": "sual feature sensitivity to domain specifics.\nFine-tuning the image encoder helps it attend to subtle diagnostic visual features\n(e.g., microcalcifications) that general models may deem irrelevant.\n3. Reducing harmful biases and spurious correlations.\nDomain curation can balance datasets and remove stereotypes present in\ninternet data, improving fairness and factual accuracy in sensitive contexts.\n4. Better downstream task performance (retrieval, VQA, diagnostics).\nFine-tuned embeddings yield higher retrieval precision and more accurate VQA\nanswers because they encode task-relevant features.\nPractical methods & justifications:\n• Full fine-tuning: update all weights — best for abundant labels.\nAllows maximal adaptation but risks catastrophic forgetting and needs data/GPU\nresources.\n• Adapter modules / LoRA / prompt tuning: lightweight adjustments.\nPreserve pretrained knowledge while cheaply adapting to domain; less risk of\nforgetting and cheaper to train.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 10,
      "content": "eds data/GPU\nresources.\n• Adapter modules / LoRA / prompt tuning: lightweight adjustments.\nPreserve pretrained knowledge while cheaply adapting to domain; less risk of\nforgetting and cheaper to train.\n\n--- Page 5 ---\n• Continual learning / regularization: e.g., Elastic Weight Consolidation to\nprevent forgetting.\nMaintains general CLIP capabilities while learning domain specifics.\nExample:\nFine-tuning CLIP on annotated chest X-rays (labels, radiologist captions) yields\nimproved retrieval and VQA performance for radiology tasks because the model learns\nto associate radiographic patterns with domain terms.\nFine-tuning requires curated, representative, and labeled domain data; otherwise you\nrisk overfitting or preserving harmful biases. Validation and human oversight are\nessential.\nArchitecture of CLIP and joint learning\nIntroduction:\nCLIP uses separate encoders for images and text, projection heads to a common\nembedding space, and contrastive training to jointly learn aligned representati",
      "filename": "UNIT II - GCV.pdf",
      "page": 5
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 11,
      "content": "e of CLIP and joint learning\nIntroduction:\nCLIP uses separate encoders for images and text, projection heads to a common\nembedding space, and contrastive training to jointly learn aligned representations.\nArchitecture components & justifications:\n1. Image encoder (ViT or ResNet).\nCNNs (ResNet) capture local textures; ViTs capture long-range interactions.\n\n--- Page 6 ---\nChoice depends on tradeoffs (compute vs performance). Both produce rich\nvisual features for projection.\n2. Text encoder (Transformer).\nTransformers model sequential and contextual language semantics effectively,\nenabling capture of compositional meaning (modifiers, relations).\n3. Projection heads (linear layers) mapping to shared space.\nSeparate high-dim features are projected to a common dimensionality so cosine\nsimilarity is meaningful; projection can also adapt modality-specific statistics.\n4. Contrastive (InfoNCE) training with large effective batch size.\nMany negatives help the model learn fine distinctions.",
      "filename": "UNIT II - GCV.pdf",
      "page": 6
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 12,
      "content": "ilarity is meaningful; projection can also adapt modality-specific statistics.\n4. Contrastive (InfoNCE) training with large effective batch size.\nMany negatives help the model learn fine distinctions. Training with symmetric\nloss (image→text and text→image) strengthens bidirectional retrieval capability.\n5. Temperature scaling in contrastive loss.\nTemperature controls concentration of similarity distribution; tuning it balances\nsensitivity between positive/negative pairs.\nWhy this design works?\n• Separate encoders let each modality use architectures tailored to its inductive\nbiases, yet the projection + contrastive loss forces semantic alignment without\nmerging architectures (which would be less flexible).\n• Large paired datasets provide diverse supervision so the embedding geometry\ngeneralizes across many concepts.\nExample:\nDuring training a batch of image-caption pairs, each image’s closest embedding should\nbe its caption’s embedding.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 13,
      "content": "verse supervision so the embedding geometry\ngeneralizes across many concepts.\nExample:\nDuring training a batch of image-caption pairs, each image’s closest embedding should\nbe its caption’s embedding. The symmetric contrastive loss enforces this across all\nbatch pairs, producing a globally consistent embedding geometry.\nTradeoffs:\n• Heavy compute and data requirements are justified by strong zero-shot\nperformance.\n• Model complexity makes fine-tuning expensive; adapter techniques can mitigate\ncosts.\nCLIP can be integrated with diffusion models for text-to-image generation\nIntroduction:\nCLIP can guide diffusion models either by providing conditioning embeddings or by\nacting as an external scorer to encourage semantic alignment during sampling.\n\n--- Page 7 ---\nIntegration mechanisms & justifications:\n1. Embedding conditioning (direct): feed CLIP text embeddings into diffusion\nmodel (via cross-attention or concatenation).",
      "filename": "UNIT II - GCV.pdf",
      "page": 7
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 14,
      "content": "ent during sampling.\n\n--- Page 7 ---\nIntegration mechanisms & justifications:\n1. Embedding conditioning (direct): feed CLIP text embeddings into diffusion\nmodel (via cross-attention or concatenation).\nDirect conditioning uses the semantic vector as part of the generative process,\nenabling the model to learn to map embeddings to visual features during training\n— the cleanest, learned integration.\n2. CLIP guidance (external scorer / gradient guidance): compute CLIP similarity\nof intermediate samples to the prompt and backpropagate gradients to\nnudge samples.\nThis allows a pretrained diffusion model (without conditioning) to be steered at\nsampling time; useful when retraining is expensive. It leverages CLIP’s semantic\nsignal as an online objective.\n3. Classifier-free guidance vs CLIP scoring: classifier-free guidance blends\nunconditional and conditional denoising; CLIP guidance explicitly optimizes\nsemantic similarity.",
      "filename": "UNIT II - GCV.pdf",
      "page": 7
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 15,
      "content": "al as an online objective.\n3. Classifier-free guidance vs CLIP scoring: classifier-free guidance blends\nunconditional and conditional denoising; CLIP guidance explicitly optimizes\nsemantic similarity.\nClassifier-free guidance is learned and often efficient; CLIP guidance can\nimprove semantic alignment but is computationally heavier and sometimes\nunstable, so practitioners choose based on constraints.\n4. Hybrid approaches (fine-tune diffusion with CLIP): fine-tune a conditional\ndiffusion model where conditioning is CLIP embeddings.\nThis produces the most coherent integration: the generator learns to use\nembeddings during training, reducing the need for costly gradient-based steering\nat sampling time.\nExample workflow (gradient guidance):\nAt each sampling step, generate image x_t, compute CLIP similarity s = cosine(clip_text,\nclip_image(x_t)), compute ∇_{x_t} s and adjust x_t in direction that increases similarity,\nthen proceed to next denoising step.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 16,
      "content": "step, generate image x_t, compute CLIP similarity s = cosine(clip_text,\nclip_image(x_t)), compute ∇_{x_t} s and adjust x_t in direction that increases similarity,\nthen proceed to next denoising step.\nTradeoffs:\n• Pros: CLIP guidance improves semantic fidelity and allows reusing pretrained\ndiffusion models.\n• Cons: Extra compute (CLIP forward + gradient) and potential for adversarial\nartifacts if optimized too aggressively — justification for careful step size and\nregularization.\nQ7 — Compare CLIP-guided generation vs GAN-based text-to-image methods\n\n--- Page 8 ---\nComparison points & justifications:\n1. Semantic alignment: CLIP-guided diffusion > GANs.\nJustification: CLIP provides explicit semantic supervision via\nembeddings/scores; GANs rely on discriminator signals that emphasize\nrealism rather than semantic correctness.\n2. Visual sharpness / texture realism: GANs often produce sharper textures.",
      "filename": "UNIT II - GCV.pdf",
      "page": 8
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 17,
      "content": "pervision via\nembeddings/scores; GANs rely on discriminator signals that emphasize\nrealism rather than semantic correctness.\n2. Visual sharpness / texture realism: GANs often produce sharper textures.\nJustification: GAN adversarial loss explicitly forces photorealistic textures;\ndiffusion models historically produced blurrier outputs (though modern\ntechniques narrowed the gap).\n3. Training stability: Diffusion (with CLIP) tends to be more stable than GAN\ntraining.\nJustification: GANs suffer from mode collapse and training instability due to\nadversarial dynamics; diffusion is likelihood-based and often converges\nmore predictably.\n4. Sampling speed / compute: GANs typically faster at inference; CLIP-guided\ndiffusion is slower.\nJustification: GANs generate in one forward pass; diffusion models require\nmany denoising steps; CLIP guidance adds more compute for\nscoring/gradients.\n5. Controllability & editing: CLIP-guided diffusion offers finer control (text,\nprompt editing).",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 18,
      "content": "; diffusion models require\nmany denoising steps; CLIP guidance adds more compute for\nscoring/gradients.\n5. Controllability & editing: CLIP-guided diffusion offers finer control (text,\nprompt editing).\nJustification: Conditioning and CLIP feedback directly influence semantics\nacross steps; GANs can be controlled via latent manipulations but mapping\nbetween latent and semantics is less direct.\n6. Robustness to prompts: CLIP-guided methods generalize better to open-\nended prompts.\nJustification: CLIP’s pretraining on broad captions provides strong semantic\ngrounding; GANs trained on limited paired data often struggle with out-of-\ndistribution prompts.\nUse-case recommendations (justified):\n• For high-speed production of photoreal textures, GANs may be preferable.\nJustification: Fast single-pass generation with high fidelity.\n• For semantic, creative, and controllable generation, CLIP-guided diffusion is\npreferable despite slower sampling.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 19,
      "content": "Ns may be preferable.\nJustification: Fast single-pass generation with high fidelity.\n• For semantic, creative, and controllable generation, CLIP-guided diffusion is\npreferable despite slower sampling.\nJustification: Better alignment to textual intent and flexibility.\n\n--- Page 9 ---\nLimitation of CLIP and a detailed solution (with justifications)\nLimitation chosen: Bias and spurious correlations inherited from large web-scale\ntraining data.\n• CLIP’s embeddings reflect the distribution of its training corpus; societal\nstereotypes and underrepresentation produce associations that can harm\ndownstream use (e.g., biased retrieval or discriminatory generative outputs). In\ncritical domains (hiring, law, medicine) these errors are unacceptable.\nProposed multi-pronged solution:\n1. Domain-aware fine-tuning with curated datasets.\nCurated, annotated domain data corrects label distributions and teaches the\nmodel correct associations relevant to the domain (e.g., medical labels).",
      "filename": "UNIT II - GCV.pdf",
      "page": 9
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 20,
      "content": "1. Domain-aware fine-tuning with curated datasets.\nCurated, annotated domain data corrects label distributions and teaches the\nmodel correct associations relevant to the domain (e.g., medical labels). It\nreduces reliance on noisy web labels.\n2. Bias mitigation during training (reweighting / adversarial debiasing).\nReweighting or adversarial objectives discourage encoding of protected\nattributes (e.g., gender) when they’re not relevant. These methods directly\npenalize the emergence of undesirable correlations.\n3. Counterfactual data augmentation.\nGenerating or collecting balanced examples that swap sensitive attributes (e.g.,\nsame profession across genders/ethnicities) reduces statistical shortcuts and\nforces the model to focus on relevant visual cues.\n4. Evaluation & continuous monitoring (human-in-the-loop).\nAutomated checks (fairness metrics) plus human audits detect remaining bias.\nContinuous monitoring post-deployment catches distribution shifts and\nemergent problems.\n5.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 21,
      "content": "monitoring (human-in-the-loop).\nAutomated checks (fairness metrics) plus human audits detect remaining bias.\nContinuous monitoring post-deployment catches distribution shifts and\nemergent problems.\n5. Model explanations and transparency.\nSaliency maps or retrieval-based explanations help users understand why the\nmodel associated certain text and images, enabling corrective action.\nExample application:\nDeploying an e-commerce visual search: before deployment, augment training with\ndiverse product images across demographics, apply reweighting, and run fairness tests\nto ensure the model does not systematically underrepresent particular groups.\n\n--- Page 10 ---\n2. CLIP AND JOINT EMBEDDINGS\nIntroduction\nGenerative AI has transformed the way text and visual data can be integrated to create\nnew forms of digital content. Among the leading approaches are Contrastive Language–\nImage Pretraining (CLIP) and diffusion models, which together form a powerful pipeline\nfor text-to-image synthesis.",
      "filename": "UNIT II - GCV.pdf",
      "page": 10
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 22,
      "content": "new forms of digital content. Among the leading approaches are Contrastive Language–\nImage Pretraining (CLIP) and diffusion models, which together form a powerful pipeline\nfor text-to-image synthesis.\nCLIP aligns language and visual modalities through joint embeddings, while diffusion\nmodels use probabilistic denoising processes to synthesize realistic and semantically\naligned images.\nThis integration is significant across domains like education, design, healthcare,\nentertainment, and scientific communication, where the ability to convert descriptions\ninto visuals saves time, enhances creativity, and improves accessibility. However,\nensuring reliability, accuracy, and fairness requires deeper understanding of the\nmechanisms, limitations, and solutions of such systems.\n(a) CLIP and Joint Embeddings – Mechanism and Benefits\n1. Core Concept\no CLIP consists of two encoders:\n▪ A Text Encoder (Transformer-based) processes natural language\nprompts.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 23,
      "content": "utions of such systems.\n(a) CLIP and Joint Embeddings – Mechanism and Benefits\n1. Core Concept\no CLIP consists of two encoders:\n▪ A Text Encoder (Transformer-based) processes natural language\nprompts.\n▪ An Image Encoder (ResNet or Vision Transformer) processes image\ndata.\no Both outputs are projected into a shared embedding space, enabling\ncomparisons.\n2. Contrastive Learning\no During training, CLIP is presented with a batch of image–text pairs.\no The correct image–caption pair should have a high cosine similarity, while\nincorrect pairs should score low.\no InfoNCE loss optimizes this by pulling true pairs closer and pushing false\npairs apart.\n3. Why This Matters for Generation\no When combined with diffusion models, the shared space ensures the\ngenerated image faithfully represents the meaning of the text.\n\n--- Page 11 ---\no Unlike traditional vision models limited to classification, CLIP’s\nembeddings generalize across unseen categories and abstract prompts.\n4.",
      "filename": "UNIT II - GCV.pdf",
      "page": 11
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 24,
      "content": "hfully represents the meaning of the text.\n\n--- Page 11 ---\no Unlike traditional vision models limited to classification, CLIP’s\nembeddings generalize across unseen categories and abstract prompts.\n4. Example\no Prompt: “A panda wearing sunglasses playing guitar.”\no CLIP embeddings capture not only the object (“panda”) but also\nattributes (“wearing sunglasses”) and context (“playing guitar”).\no The diffusion model uses these embeddings to guide generation, ensuring\nall described elements appear.\n5. Justification\no This approach solves the problem of semantic drift, where generated\nimages deviate from text.\no It also enables zero-shot transfer, where the model works on new\nconcepts without retraining.\n(b) Noise Scheduling and Diffusion Process – Stability and Quality\n1. Forward Diffusion (Training Stage)\no The model learns by gradually adding Gaussian noise to real images over\nmany steps until they become indistinguishable from random noise.",
      "filename": "UNIT II - GCV.pdf",
      "page": 11
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 25,
      "content": "Stability and Quality\n1. Forward Diffusion (Training Stage)\no The model learns by gradually adding Gaussian noise to real images over\nmany steps until they become indistinguishable from random noise.\no This corruption process teaches the system how data can be “destroyed”\nin a controlled manner.\n2. Backward Diffusion (Generation Stage)\no The generative model reverses the process, progressively denoising\nrandom noise step by step to reconstruct a meaningful image.\no Conditioning on text embeddings ensures that the denoising follows the\nsemantic structure encoded in the prompt.\n3. Noise Schedulers\no Decide the rate and distribution of noise addition/removal across\ntimesteps.\no Common schedulers: linear, cosine, exponential decay.\no The choice affects image clarity, diversity, and fidelity.\n4. Why It Matters\n\n--- Page 12 ---\no Too much noise at early steps → unstable generations.\no Too little → lack of diversity.",
      "filename": "UNIT II - GCV.pdf",
      "page": 12
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 26,
      "content": "nential decay.\no The choice affects image clarity, diversity, and fidelity.\n4. Why It Matters\n\n--- Page 12 ---\no Too much noise at early steps → unstable generations.\no Too little → lack of diversity.\no A well-designed scheduler balances exploration and accuracy, leading to\nimages that are high-quality, sharp, and semantically consistent.\n5. Example\no A poorly tuned scheduler may generate a “blurred car” for the prompt “a\nred sports car on a racetrack.”\no With proper scheduling, details like color, motion blur, and track\nbackground are preserved.\n6. Justification\no Diffusion + noise scheduling ensures outputs remain reliable and artifact-\nfree, addressing weaknesses of earlier GAN-based methods which often\nsuffered from mode collapse.\n(c) Ensuring Accuracy with Fine-Tuning – Overcoming Hallucinations\n1. The Challenge\no Generative models, when trained on generic internet data, may produce\nimages that are visually appealing but scientifically or contextually\ninaccurate.",
      "filename": "UNIT II - GCV.pdf",
      "page": 12
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 27,
      "content": "g – Overcoming Hallucinations\n1. The Challenge\no Generative models, when trained on generic internet data, may produce\nimages that are visually appealing but scientifically or contextually\ninaccurate.\no Risk of “hallucination” (adding irrelevant objects) or oversimplification.\n2. Role of Fine-Tuning\no Fine-tuning adapts pretrained models to specific domains using curated\ndatasets.\no Adjusts weights so the model captures domain-specific semantics and\navoids irrelevant associations.\n3. Methods\no Full fine-tuning: Retrain on specialized datasets (e.g., radiology images,\nengineering diagrams).\no Adapter/LoRA tuning: Lightweight layers added for efficient adaptation.\no Prompt-tuning: Adding domain-specific tokens or context.\n4. Example\no Generic model → “DNA double helix” may produce artistic swirls.\n\n--- Page 13 ---\no Fine-tuned model on biology diagrams → generates precise base pairs and\nmolecular structure.\n5. Justification\no Fine-tuning improves factual accuracy.",
      "filename": "UNIT II - GCV.pdf",
      "page": 13
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 28,
      "content": "” may produce artistic swirls.\n\n--- Page 13 ---\no Fine-tuned model on biology diagrams → generates precise base pairs and\nmolecular structure.\n5. Justification\no Fine-tuning improves factual accuracy.\no Reduces domain mismatch, making outputs trustworthy in professional\nor academic settings.\no Supports applications where error tolerance is low (e.g., medicine,\nengineering, education).\n(d) Limitations of CLIP and Solutions\n1. Limitations\no Bias and Fairness: CLIP inherits social and cultural biases from web data.\no Ambiguity Handling: Struggles when prompts are vague (“a beautiful\nscene”) or multi-layered.\no Domain Gaps: Lacks accuracy in highly technical or specialized areas.\no Computational Cost: Joint text-image training and inference are resource-\nintensive.\n2. Possible Solutions\no Bias Mitigation: Curate balanced datasets, use fairness-aware training,\nand adversarial debiasing.\no Prompt Engineering: Rephrase prompts to be specific, reducing\nambiguity.",
      "filename": "UNIT II - GCV.pdf",
      "page": 13
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 29,
      "content": "e.\n2. Possible Solutions\no Bias Mitigation: Curate balanced datasets, use fairness-aware training,\nand adversarial debiasing.\no Prompt Engineering: Rephrase prompts to be specific, reducing\nambiguity.\no Domain Adaptation: Use fine-tuning, adapters, or hybrid models for niche\ntasks.\no Human-in-the-Loop Evaluation: Incorporate expert feedback to validate\noutputs.\n3. Example\no Prompt: “A doctor” may disproportionately generate male figures due to\nbiased training data.\no Mitigation: Fine-tuning with balanced datasets ensures diverse\nrepresentations.\n4. Justification\n\n--- Page 14 ---\no Without addressing these issues, the trustworthiness and adoption of\nCLIP-based systems may be limited.\no Solutions ensure outputs remain inclusive, accurate, and ethically\ndeployable.\nThe integration of CLIP and diffusion models represents a paradigm shift in multimodal\nAI, enabling systems to understand and generate complex visual representations from\nnatural language.",
      "filename": "UNIT II - GCV.pdf",
      "page": 14
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 30,
      "content": "deployable.\nThe integration of CLIP and diffusion models represents a paradigm shift in multimodal\nAI, enabling systems to understand and generate complex visual representations from\nnatural language.\nCLIP ensures semantic alignment through joint embeddings, while diffusion models\nguarantee stability and quality via noise scheduling and denoising processes.\nFine-tuning resolves the issue of accuracy and domain specificity, while awareness of\nCLIP’s limitations (biases, ambiguity, domain gaps) and corrective solutions ensures\ntrustworthy deployment. In essence, the synergy between CLIP and diffusion models\nforms a robust, flexible, and scalable framework for multimodal content creation,\ncapable of serving both general and highly specialized applications.\n3. CLIP with diffusion models\nIntroduction\nText-to-image generation has become one of the most exciting advancements in\nartificial intelligence.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 31,
      "content": "rving both general and highly specialized applications.\n3. CLIP with diffusion models\nIntroduction\nText-to-image generation has become one of the most exciting advancements in\nartificial intelligence. By combining CLIP (Contrastive Language–Image Pretraining)\nwith diffusion models, systems can generate images that accurately reflect user\ndescriptions. CLIP provides a bridge between language and vision, aligning text prompts\nwith visual features, while diffusion models create high-quality, coherent outputs\nthrough a noise-to-image process. Together, they enable applications ranging from\ncreative design and education to healthcare and entertainment.\n(a) Architecture of CLIP – Connecting Text and Visuals\n1. Dual Encoder System\no CLIP consists of a text encoder (Transformer-based) and an image\nencoder (Vision Transformer or CNN).\no Both map their inputs into feature vectors.\n2. Shared Semantic Space\no Text and image embeddings are projected into a joint latent space where\nsimilarity is mea",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 32,
      "content": "encoder (Vision Transformer or CNN).\no Both map their inputs into feature vectors.\n2. Shared Semantic Space\no Text and image embeddings are projected into a joint latent space where\nsimilarity is measured.\no Training uses contrastive learning: matching text–image pairs are pulled\ncloser, mismatched ones pushed apart.\n\n--- Page 15 ---\n3. Outcome\no This allows CLIP to capture not just objects but also attributes, context,\nand relationships.\no For example, the phrase “bright red car on a snowy road” aligns with\nimages showing both the car and the setting.\n4. Significance\no These joint embeddings are crucial for guiding generative models so that\noutputs remain semantically aligned with textual descriptions.\n(b) Text-Guided Stable Diffusion – The Generation Process\n1. Forward Diffusion\no Real images are progressively noised until they become indistinguishable\nrandom noise.\n2. Backward Diffusion (Denoising)\no The model learns to reverse this process: starting from noise, it generates\nan ima",
      "filename": "UNIT II - GCV.pdf",
      "page": 15
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 33,
      "content": "images are progressively noised until they become indistinguishable\nrandom noise.\n2. Backward Diffusion (Denoising)\no The model learns to reverse this process: starting from noise, it generates\nan image step by step.\n3. Conditioning with CLIP\no The embeddings from CLIP are injected into the backward process as\nguidance signals.\no This ensures that the generated image reflects the semantic meaning of\nthe text prompt.\n4. Noise Scheduling\no Proper noise scheduling regulates how much detail is added at each step,\npreventing artifacts and improving stability.\n5. Why It Works\no Diffusion models combined with CLIP generate stable, realistic, and\nprompt-aligned visuals, outperforming earlier GAN-based approaches\nthat often struggled with fine details.\n(c) Fine-Tuning for Domain-Specific Applications\n1. Need for Fine-Tuning\no Base CLIP and diffusion models are trained on broad internet data, which\nmay not cover specialized domains well.\n\n--- Page 16 ---\n2.",
      "filename": "UNIT II - GCV.pdf",
      "page": 16
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 34,
      "content": "e-Tuning for Domain-Specific Applications\n1. Need for Fine-Tuning\no Base CLIP and diffusion models are trained on broad internet data, which\nmay not cover specialized domains well.\n\n--- Page 16 ---\n2. Process\no Fine-tuning involves training or adapting the model with domain-specific\nprompts or datasets.\no Example: In medicine, fine-tuning ensures that a description like “X-ray\nshowing lung opacity” produces medically accurate images.\n3. Benefits\no Enhances accuracy (outputs match technical details).\no Improves aesthetic or contextual relevance (outputs suit the domain\nstyle).\no Reduces biases and errors from general-purpose training.\n4. Justification\no Without fine-tuning, models may produce outputs that are visually\nplausible but factually incorrect. Domain adaptation ensures trustworthy\nand useful results.\n(d) Evaluation Metrics for Text–Image Alignment\n1. Quantitative Metrics\no CLIPScore: Measures similarity between generated image embeddings\nand prompt embeddings.",
      "filename": "UNIT II - GCV.pdf",
      "page": 16
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 35,
      "content": "sures trustworthy\nand useful results.\n(d) Evaluation Metrics for Text–Image Alignment\n1. Quantitative Metrics\no CLIPScore: Measures similarity between generated image embeddings\nand prompt embeddings.\no FID (Fréchet Inception Distance): Evaluates image quality by comparing\ngenerated and real data distributions.\no IS (Inception Score): Measures diversity and realism of generated\nimages.\n2. Qualitative Metrics\no Human evaluation: Users judge whether images align with descriptions.\no Task-based evaluation: Checking how well generated outputs support\ndownstream tasks (e.g., retrieval, classification).\n3. Balanced Evaluation\no A mix of automated and human assessments ensures both objective\naccuracy and subjective quality are measured.\n4. Significance\n\n--- Page 17 ---\no Robust evaluation is critical to confirm that the system produces outputs\nthat are reliable, meaningful, and user-aligned.\nConclusion\nBy integrating CLIP embeddings with diffusion-based generation, AI systems achieve\naccurate",
      "filename": "UNIT II - GCV.pdf",
      "page": 17
    },
    {
      "doc_id": "tmp9lufgen8_UNIT II - GCV.pdf_1d6f9513_9d3e85dd",
      "chunk_index": 36,
      "content": "ical to confirm that the system produces outputs\nthat are reliable, meaningful, and user-aligned.\nConclusion\nBy integrating CLIP embeddings with diffusion-based generation, AI systems achieve\naccurate text-to-image synthesis. CLIP ensures semantic alignment, diffusion\nguarantees high visual fidelity, fine-tuning adapts models to specialized domains, and\nevaluation metrics confirm performance. This synergy represents a powerful paradigm\nfor multimodal AI, enabling diverse applications where reliable translation of language\ninto images is essential.",
      "filename": "UNIT II - GCV.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nDIFFUSION MODELS\nDiffusion models are a type of generative AI that create new data like images, audio or even\nvideo by starting with random noise and gradually turning it into something meaningful. They\nwork by simulating a diffusion process where data is slowly corrupted by noise during\ntraining and then learning to reverse this process step by step. By doing so the model learns\nhow to generate high quality samples from scratch.\nUnderstanding Diffusion Models\n• Diffusion models are generative models that learn to reverse a diffusion process to\ngenerate data. The diffusion process involves gradually adding noise to data until it\nbecomes pure noise.\n• Through this process a simple distribution is transformed into a complex data distribution\nin a series of small incremental steps.\n• Essentially these models operate as a reverse diffusion phenomenon where noise is\nintroduced to the data in a forward manner and removed in a reverse manner to generate\nnew data samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 1
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 1,
      "content": "ntal steps.\n• Essentially these models operate as a reverse diffusion phenomenon where noise is\nintroduced to the data in a forward manner and removed in a reverse manner to generate\nnew data samples.\n• By learning to reverse this process diffusion models start from noise and gradually\ndenoise it to produce data that closely resembles the training examples.\nKey Components\n1. Forward Diffusion Process: This process involves adding noise to the data in a series of\nsmall steps. Each step slightly increases the noise, making the data progressively more\nrandom until it resembles pure noise.\n2. Reverse Diffusion Process: The model learns to reverse the noise-adding steps. Starting\nfrom pure noise, the model iteratively removes the noise, generating data that matches\nthe training distribution.\n3. Score Function: This function estimates the gradient of the data distribution concerning\nthe noise. It helps guide the reverse diffusion process to produce realistic samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 2,
      "content": "training distribution.\n3. Score Function: This function estimates the gradient of the data distribution concerning\nthe noise. It helps guide the reverse diffusion process to produce realistic samples.\n\n--- Page 2 ---\nArchitecture of Diffusion Models\nThe architecture of diffusion models typically involves two main components:\n1. Forward Diffusion Process\n2. Reverse Diffusion Process\n1. Forward Diffusion Process\nIn this process noise is incrementally added to the data over a series of steps. This is akin to\na Markov chain where each step slightly degrades the data by adding Gaussian noise.\nForward Diffusion P\nMathematically, this can be represented as:\nwhere,\n• xt is the noisy data at step t\n• αt controls the amount of noise added.\n2. Reverse Diffusion Process\nThe reverse process aims to reconstruct the original data by denoising the noisy data in a\nseries of steps reversing the forward diffusion.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 2
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 3,
      "content": "rols the amount of noise added.\n2. Reverse Diffusion Process\nThe reverse process aims to reconstruct the original data by denoising the noisy data in a\nseries of steps reversing the forward diffusion.\nReverse Diffusion Process\nThis is typically modelled using a neural network that predicts the noise added at each step:\nwhere,\n• μθ and σθ are learned parameters.\nWorking Principle of Diffusion Models\nDuring training the model learns to predict the noise added at each step of the forward\nprocess. This is done by minimizing a loss function that measures the difference between the\npredicted and actual noise.\nForward Process (Diffusion)\n• The forward process involves gradually corrupting the data x0 with Gaussian noise over\na sequence of time steps\n• Let xt represent the noisy data at time step t. The process is defined as:\n• where βt is the noise schedule that controls the amount of noise added at each step and ϵ is\nis Gaussian noise.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 4,
      "content": "ime steps\n• Let xt represent the noisy data at time step t. The process is defined as:\n• where βt is the noise schedule that controls the amount of noise added at each step and ϵ is\nis Gaussian noise.\n\n--- Page 3 ---\n• As t increases, xt becomes more noisy until it approximates a Gaussian distribution.\nReverse Process (Denoising)\n• The reverse process aims to reconstruct the original data x0x0 from the noisy data xT at\nthe final time step T.\n• This process is modelled using a neural network to approximate the conditional\nprobability pθ(xt−1∣xt).\n• The reverse process can be formulated as:\n• where ϵθ is a neural network parameterized by θ that predicts the noise.\nTraining Diffusion Models\n• The training objective for diffusion models involves minimizing the difference between\nthe true noise ϵ added in the forward process and the noise predicted by the neural\nnetwork ϵθ.\n• The score function which estimates the gradient of the data distribution concerning the\nnoise plays an important rol",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 3
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 5,
      "content": "ϵ added in the forward process and the noise predicted by the neural\nnetwork ϵθ.\n• The score function which estimates the gradient of the data distribution concerning the\nnoise plays an important role in guiding the reverse process.\n• The loss function is typically the mean squared error (MSE) between these two quantities:\n• This encourages the model to accurately predict the noise and, consequently, to denoise\neffectively during the reverse process.\nIn diffusion models, both the forward and backward processes are modeled as a sequence of\nsmall incremental steps rather than a single transformation. This sequential approach is\ncrucial because:\n1. Gradual Learning – By breaking the process into many steps, the model learns how\nto handle slight changes at each stage, making it easier to reverse the noise addition. If\nit tried to denoise from a fully noisy image in one step, it would struggle to map the\nrandom noise back to structured data.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 6,
      "content": "hanges at each stage, making it easier to reverse the noise addition. If\nit tried to denoise from a fully noisy image in one step, it would struggle to map the\nrandom noise back to structured data.\n2. Stability in Training – Learning through small denoising steps prevents abrupt\ntransitions, reducing the chances of errors or divergence during training. It ensures\nthat the model refines its predictions slowly, stabilizing gradients and allowing\nconsistent improvements.\n3. Better Control Over Generation – The step-wise nature allows the model to be\nsampled at different stages, offering control over how much noise to remove or retain.\nThis is especially useful in VR environments, where designers might want to balance\nrealism with creativity.\n4. Avoiding Catastrophic Forgetting – Incremental denoising reinforces the learning at\nevery step, ensuring that earlier patterns are not forgotten as the model progresses\ntoward generating complex outputs.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 7,
      "content": "iding Catastrophic Forgetting – Incremental denoising reinforces the learning at\nevery step, ensuring that earlier patterns are not forgotten as the model progresses\ntoward generating complex outputs.\n\n--- Page 4 ---\nThus, modeling the forward and backward processes as a sequence of steps ensures that\nlearning is smooth, robust, and interpretable, ultimately allowing the system to produce high-\nquality, stable, and realistic images from rough sketches.\nNoise plays a central role in the diffusion process, and carefully adjusting it can significantly\ninfluence the outcomes:\n1. Higher Noise Levels\no Encourages diverse outputs because the model explores a wider range of\npossibilities when starting from more random data.\no Useful for generating creative or artistic VR landscapes where uniqueness is\ndesired.\no However, if the noise is too high, the generated images may lose structure or\ncoherence, reducing realism.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 4
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 8,
      "content": "o Useful for generating creative or artistic VR landscapes where uniqueness is\ndesired.\no However, if the noise is too high, the generated images may lose structure or\ncoherence, reducing realism.\n2. Lower Noise Levels\no Helps maintain realism and fidelity because the model starts closer to\nstructured patterns, making it easier to produce clear and consistent images.\no Best suited for VR environments where accuracy, recognizable objects, and\nrealistic textures are essential.\no It may, however, limit creativity and diversity since the outputs are\nconstrained to follow the training data closely.\n3. Noise Scheduling\no Adjusting how noise is added or removed across steps (e.g., linear,\nexponential, cosine schedules) allows fine-tuning between exploration and\nrefinement.\no Designers can control whether the model produces subtle variations or\nradically different landscapes.\n4. Application in VR Systems\no For immersive experiences, higher noise levels at early steps can generate\nunpredictabl",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 9,
      "content": "l whether the model produces subtle variations or\nradically different landscapes.\n4. Application in VR Systems\no For immersive experiences, higher noise levels at early steps can generate\nunpredictable and novel environments, while later steps can be fine-tuned with\nlower noise to ensure realistic details.\no This balance allows users to start with abstract sketches and transform them\ninto believable virtual worlds that retain creativity without sacrificing\ncoherence.\n\n--- Page 5 ---\nDENOISING DIFFUSION PROBABILISTIC MODEL (DDPM)\nWhat are DDPMs?\nThey are a class of generative models that work by iteratively adding noise to an input signal\n(like an image, text, or audio) and then learning to denoise from the noisy signal to generate\nnew samples.\nGenerative models\nAre a type of model that can generate new data instances. Previously, machine learning models\nhave done a good job of learning differences in data and then making predictions or\nclassification tasks.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 5
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 10,
      "content": "Are a type of model that can generate new data instances. Previously, machine learning models\nhave done a good job of learning differences in data and then making predictions or\nclassification tasks. For example, a model trained on a digits dataset like MNIST can recognize\na 0 from a 1. Generative models, on the other hand, learn the distribution of digits and can create\na “fake digit” which closely resembles a real digit.\nA Denoising Diffusion Probabilistic Model (DDPM) is a type of generative model that\ncreates realistic images by learning how to progressively refine noisy data. It works in two\nphases:\n1. Forward Process (Noise Addition) – The model gradually adds random noise to a\nclean image over many steps until the image becomes indistinguishable from noise.\n2. Backward Process (Denoising) – The model learns to reverse this process by\npredicting how to remove noise at each step, eventually reconstructing a high-quality\nimage from random noise or a rough input.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 11,
      "content": "ckward Process (Denoising) – The model learns to reverse this process by\npredicting how to remove noise at each step, eventually reconstructing a high-quality\nimage from random noise or a rough input.\nThe model is called probabilistic because it doesn’t rely on a single deterministic\ntransformation but instead learns the distribution of possible images at each stage of noise\nand denoising. This approach allows it to generate diverse, high-fidelity images by sampling\nfrom the learned distribution.\n\n--- Page 6 ---\nKey Features of DDPM:\n• Iterative Refinement – Instead of transforming an image in one step, it uses many\nsmall steps, making it easier to model complex patterns.\n• Noise-Based Learning – By learning how images degrade with noise, the model\nunderstands how to reverse this degradation to recreate details.\n• Probabilistic Nature – It generates a range of plausible outputs rather than a single\nfixed result, which is useful in creative tasks like animation.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 6
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 12,
      "content": "to reverse this degradation to recreate details.\n• Probabilistic Nature – It generates a range of plausible outputs rather than a single\nfixed result, which is useful in creative tasks like animation.\n• Flexibility – DDPMs can be applied to various tasks such as image synthesis, super-\nresolution, and in your case, converting rough sketches into fully rendered scenes.\nForward and Backward Diffusion Process\nThe forward diffusion process is the initial phase in a DDPM where noise is incrementally\nadded to clean data over many steps. The purpose is to teach the model how data transitions\nfrom structured and detailed forms into randomness.\nKey steps involved:\n1. Starting with clean data – At the beginning, the model takes real data such as an\nimage or signal that contains structured information like shapes, textures, and\npatterns.\n2. Adding noise at each step – Gaussian noise is added to the data in small amounts\nover a sequence of steps. The noise schedule (linear, cosine, etc.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 13,
      "content": "information like shapes, textures, and\npatterns.\n2. Adding noise at each step – Gaussian noise is added to the data in small amounts\nover a sequence of steps. The noise schedule (linear, cosine, etc.) controls how much\nnoise is added at each step.\n3. Progressive degradation – The data becomes increasingly noisy at every step.\nInitially, the patterns are still recognizable, but as the process continues, the structure\ndisappears, and the data looks like random noise.\n4. Mathematical formulation – At step t, the noisy data x is derived from the previous\nt\nstep x by sampling from a normal distribution:\nt−1\nwhere α controls the amount of retained information and ϵ is sampled from a normal\nt\ndistribution.\nWhy this step is essential:\n• It exposes the model to how real data deteriorates with noise.\n• It creates a learning path for the model to understand the inverse operation—\nrecovering the data from noisy versions.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 14,
      "content": "is essential:\n• It exposes the model to how real data deteriorates with noise.\n• It creates a learning path for the model to understand the inverse operation—\nrecovering the data from noisy versions.\n• It ensures that the model can generalize to varying noise levels and recover details\nfrom incomplete or corrupted data.\n\n--- Page 7 ---\nRole of the Markov Chain in the Forward Diffusion Process of a DDPM\nIn a Denoising Diffusion Probabilistic Model (DDPM), the forward diffusion process\ninvolves gradually adding noise to clean data over multiple steps. This process is modeled as\na Markov chain, which plays a crucial role in structuring how noise is added.\nA Markov chain is a mathematical system that transitions from one state to another, where\nthe next state depends only on the current state and not on the entire history of past states. In\nthe context of DDPM’s forward diffusion process, this means:\n1.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 7
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 15,
      "content": "tions from one state to another, where\nthe next state depends only on the current state and not on the entire history of past states. In\nthe context of DDPM’s forward diffusion process, this means:\n1. Stepwise progression\no At each time step ttt, noise is added based only on the data at that step\n(xt−1x_{t-1}xt−1), not on earlier steps. This simplifies the process and\nensures that each step depends only on the immediately preceding one.\n2. Controlled noise addition\no The amount of noise added at each step is determined by a known noise\nschedule, ensuring that the transition from structured data to noise is smooth\nand gradual.\n3. Mathematical tractability\no By assuming that each step depends only on the previous step, the forward\nprocess becomes easier to analyze, simulate, and invert during training.\nHow does it help structure the noise addition steps?\n1. Simplifies modeling\no The Markov assumption allows the model to focus on learning local\ntransitions rather than global dependencies,",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 16,
      "content": "g training.\nHow does it help structure the noise addition steps?\n1. Simplifies modeling\no The Markov assumption allows the model to focus on learning local\ntransitions rather than global dependencies, making the noise addition process\ncomputationally feasible.\n2. Ensures gradual degradation\no The structured, stepwise approach ensures that noise is added progressively,\npreserving information early on and fully randomizing the data at later steps.\n3. Supports efficient training\no The Markov property allows the use of recursive formulations where each\nnoisy sample can be derived from the previous one using simple equations,\nfacilitating optimization and gradient computation.\n4. Enables inversion during sampling\no Since each step only depends on the previous one, the backward process\n(denoising) can also be structured in the same stepwise manner, allowing the\nmodel to learn how to reverse the process reliably.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 17,
      "content": "Since each step only depends on the previous one, the backward process\n(denoising) can also be structured in the same stepwise manner, allowing the\nmodel to learn how to reverse the process reliably.\nThe backward diffusion process is where the model learns to reverse the noise addition and\nreconstruct the original or new data from noisy inputs.\nKey aspects:\n1. Predicting the noise – At each step, the model is trained to estimate the noise that\nwas added in the forward process. It learns how the noisy data differs from its clean\nversion and tries to correct it.\n\n--- Page 8 ---\n2. Iterative refinement – Starting from pure noise, the model removes noise\nprogressively by applying its learned knowledge of patterns at each step. Over time,\nthe image or data becomes clearer and more structured.\n3. Learning objective – The model is optimized to minimize the difference between the\npredicted noise and the actual noise added during training.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 8
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 18,
      "content": "the image or data becomes clearer and more structured.\n3. Learning objective – The model is optimized to minimize the difference between the\npredicted noise and the actual noise added during training. This is typically done\nusing a loss function like Mean Squared Error (MSE).\n4. Sampling during generation – Once trained, the model can start from random noise\nand iteratively apply the backward process to generate new, realistic data samples.\nWhy this process is critical:\n• It allows the model to reconstruct missing or noisy details.\n• It ensures that the output is consistent with real-world data distributions.\n• It provides control over the generation process by using learned probabilities rather\nthan rigid rules.\nThe probabilistic nature of DDPM plays a central role in its ability to generate both diverse\nand high-quality outputs.\nWhy probabilistic modeling is useful?\n1. Learning distributions rather than fixed mappings\no Instead of learning a direct transformation from input to output",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 19,
      "content": "ate both diverse\nand high-quality outputs.\nWhy probabilistic modeling is useful?\n1. Learning distributions rather than fixed mappings\no Instead of learning a direct transformation from input to output, the model\nlearns the underlying distribution of possible clean data conditioned on noisy\ninputs.\no This enables the model to handle uncertainty and variations present in real\ndata.\n2. Sampling from distributions\no During generation, the model samples noise from a distribution at each step.\nEven with the same input, different random samples produce varied outputs,\npromoting creativity and diversity.\n3. Capturing subtle patterns\no Probabilistic modeling allows the model to learn nuanced relationships in the\ndata such as textures, lighting patterns, or variations in shape that are hard to\ncapture with deterministic methods.\n4. Balancing realism and exploration\no By controlling the noise level and how it’s modeled, the system can explore\nnew possibilities while staying within the realm of re",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 20,
      "content": "re with deterministic methods.\n4. Balancing realism and exploration\no By controlling the noise level and how it’s modeled, the system can explore\nnew possibilities while staying within the realm of realistic outputs. This is\ncrucial for applications like design, simulation, and data augmentation.\nChallenges:\n1. High computational cost\no Because the process involves many steps (often hundreds or thousands),\ngenerating data can be slow and resource-intensive.\n2. Latency issues in real-time applications\n\n--- Page 9 ---\no The iterative nature makes it difficult to apply DDPMs in interactive or real-\ntime environments where fast feedback is essential.\n3. Difficulty in controlling outputs\no Without proper conditioning or guidance, the model might produce outputs\nthat are inconsistent with user expectations or desired styles.\n4. Data requirements\no Training DDPMs effectively requires large and diverse datasets to accurately\nlearn noise patterns and recover fine details.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 9
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 21,
      "content": "nconsistent with user expectations or desired styles.\n4. Data requirements\no Training DDPMs effectively requires large and diverse datasets to accurately\nlearn noise patterns and recover fine details.\nENERGY-BASED MODELS(EBMs)\nEnergy-Based Models (EBMs) are a class of probabilistic models that define relationships\nbetween variables using an energy function. Rather than explicitly modeling probability\ndistributions, EBMs assign an “energy” value to each possible configuration of variables,\nwhere lower energy indicates more likely or desirable configurations, and higher energy\ncorresponds to less likely ones.\nEBMs are widely used in machine learning for tasks such as representation learning,\nstructured prediction, anomaly detection, and reinforcement learning, where capturing\nrelationships and constraints between variables is more important than explicitly computing\nprobabilities.\n2. The Concept of Energy in EBMs\n• An energy function E(x)maps an input x to a scalar energy value.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 22,
      "content": "onships and constraints between variables is more important than explicitly computing\nprobabilities.\n2. The Concept of Energy in EBMs\n• An energy function E(x)maps an input x to a scalar energy value.\n• The lower the energy, the more plausible or preferred the data point is according to\nthe model.\n• The probability distribution p(x)is related to the energy via the Boltzmann\ndistribution:\nwhere Z is the partition function:\n• The partition function Z is often intractable, making it difficult to directly compute\nprobabilities, but not necessary for learning.\n\n--- Page 10 ---\n3. Architecture and Working\nCore Components:\n1. Energy Function\no The energy function is typically parameterized by neural networks or other\ndifferentiable models.\no It scores different data configurations to indicate how well they conform to the\ndesired patterns.\n2. Learning Objective\no EBMs learn by comparing the energies of positive (correct) and negative\n(incorrect or unlikely) samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 10
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 23,
      "content": "nfigurations to indicate how well they conform to the\ndesired patterns.\n2. Learning Objective\no EBMs learn by comparing the energies of positive (correct) and negative\n(incorrect or unlikely) samples.\no The goal is to assign lower energy to real data and higher energy to unlikely\ndata.\n3. Training Approaches\no Contrastive Divergence (CD) – Optimizes the model by comparing energy\ndifferences between observed and model-generated samples.\no Score Matching – Matches the gradient of the energy function rather than the\nenergy itself.\no Noise Contrastive Estimation (NCE) – Uses noise samples to help\napproximate the partition function during learning.\n4. Markov Random Fields (MRFs) and Conditional EBMs\n• EBMs are closely related to Markov Random Fields (MRFs), which model\ndependencies between variables using graph structures.\n• Conditional EBMs extend the energy framework to tasks where the output depends\non input features (e.g., image classification, structured output prediction).\n5.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 24,
      "content": "ween variables using graph structures.\n• Conditional EBMs extend the energy framework to tasks where the output depends\non input features (e.g., image classification, structured output prediction).\n5. Applications of EBMs\n1. Unsupervised Learning\no Modeling complex relationships in high-dimensional data such as images,\nspeech, or text.\n2. Anomaly Detection\no Identifying outliers by assigning higher energy to rare or unlikely\nconfigurations.\n3. Reinforcement Learning (RL)\no Estimating value functions where actions with lower energy correspond to\nmore rewarding behaviors.\n4. Generative Modeling\no Generating samples by searching for configurations with low energy, often\nusing sampling algorithms like Langevin dynamics.\n5. Structured Prediction\no Solving problems like image segmentation or sequence labeling where\nrelationships between output variables are important.\n\n--- Page 11 ---\n6. Advantages of EBMs\n• Flexibility – Can model arbitrary dependencies without requiring explicit probabilit",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 11
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 25,
      "content": "uence labeling where\nrelationships between output variables are important.\n\n--- Page 11 ---\n6. Advantages of EBMs\n• Flexibility – Can model arbitrary dependencies without requiring explicit probability\ndistributions.\n• Interpretability – The energy function directly encodes preferences or constraints.\n• Applicability – Useful in domains where structured relationships and constraints\ndominate over simple classification.\n7. Challenges and Limitations\n1. Intractable Partition Function\no Computing ZZZ is often impossible in practice, requiring approximation\ntechniques that can be unstable.\n2. Training Instability\no Optimization methods like contrastive divergence rely on sampling, which can\nlead to slow convergence or poor performance.\n3. Sampling Complexity\no Generating samples requires iterative methods such as Markov Chain Monte\nCarlo (MCMC), which can be computationally expensive.\n4. Scalability Issues\no Handling high-dimensional data with complex energy landscapes is\nchallenging.\n8.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 11
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 26,
      "content": "rative methods such as Markov Chain Monte\nCarlo (MCMC), which can be computationally expensive.\n4. Scalability Issues\no Handling high-dimensional data with complex energy landscapes is\nchallenging.\n8. Recent Advances\n• Neural EBMs – Combining deep learning with energy functions to model high-\ndimensional and structured data more effectively.\n• Score-based Generative Models – Learning the gradient of the energy function to\navoid directly computing the partition function.\n• Applications in Contrastive Learning – EBMs form the backbone of contrastive\napproaches where relationships between samples are emphasized.\n\n--- Page 12 ---\nCOMPARE EBMS VS VAES\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Defined by an energy function\nthat assigns a scalar “energy” to\n- Composed of two main parts: an\neach configuration of inputs (and\nencoder and a decoder.\noptionally outputs).\n- The encoder maps input data to a\n- No explicit probability\nlatent space distribution (typically\ndist",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 12
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 27,
      "content": "two main parts: an\neach configuration of inputs (and\nencoder and a decoder.\noptionally outputs).\n- The encoder maps input data to a\n- No explicit probability\nlatent space distribution (typically\ndistribution; the model learns to\nGaussian).\nassign lower energy to desired\n- The decoder reconstructs data\n✅ Architecture samples and higher energy to\nfrom samples drawn from the latent\nundesired ones.\nspace.\n- Often optimized using contrastive\n- Uses variational inference to\ndivergence or score matching.\napproximate intractable posteriors.\n- The architecture focuses on\n- The architecture explicitly models\nrelationships between data points\ndata generation.\nrather than reconstructing or\ngenerating them directly.\n- Maximize the Evidence Lower\n- Learn an energy landscape where\nBound (ELBO) which balances\ncorrect data points are assigned\nreconstruction accuracy and\nlower energy.\n✅ Objective regularization of the latent space.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 28,
      "content": "Evidence Lower\n- Learn an energy landscape where\nBound (ELBO) which balances\ncorrect data points are assigned\nreconstruction accuracy and\nlower energy.\n✅ Objective regularization of the latent space.\n- Optimization is based on\n- Encourages latent space structure\ndistinguishing good samples from\nfor efficient sampling and\nbad ones.\ninterpolation.\n- Indirect; energy defines the\nlikelihood up to a normalization - Explicit probabilistic framework\nconstant (partition function), which with tractable priors and\n✅ Probabilistic\nis often intractable. approximate posteriors.\nInterpretation\n- Focuses on learning relationships - Can directly sample from the latent\nand constraints rather than full space and model uncertainty.\ndensity estimation.\n- Uses sampling-based methods\nlike Markov Chain Monte Carlo - Uses backpropagation with\n(MCMC), contrastive divergence, reparameterization trick for efficient\n✅ Training\nor score matching. gradient estimation.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 29,
      "content": "mpling-based methods\nlike Markov Chain Monte Carlo - Uses backpropagation with\n(MCMC), contrastive divergence, reparameterization trick for efficient\n✅ Training\nor score matching. gradient estimation.\nMethods\n- Training can be unstable due to - More stable and easier to train\nreliance on sampling and gradient with large datasets.\nestimation.\n- Modeling complex dependencies\nin structured data. - Image and speech generation, data\n- Used in tasks like anomaly compression, anomaly detection,\ndetection, reinforcement learning, and semi-supervised learning.\n✅ Applications\nand unsupervised learning. - Used where interpretable latent\n- Applicable where relationships representations and smooth\nand constraints are more important generation paths are required.\nthan explicit reconstruction.\n\n--- Page 13 ---\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Flexibility in modeling\n- Well-suited for generating new\nrelationships without requiring\ndata samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 13
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 30,
      "content": "onstruction.\n\n--- Page 13 ---\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Flexibility in modeling\n- Well-suited for generating new\nrelationships without requiring\ndata samples.\n✅ Strengths explicit likelihood functions.\n- Provides interpretable latent spaces\n- Can incorporate constraints and\nuseful for downstream tasks.\ndomain knowledge easily.\n- May suffer from blurry\n- Training is computationally\nreconstructions or mode collapse.\nexpensive and less scalable. -\n✅ Limitations - Latent space structure depends\nNormalization constant estimation\nheavily on choice of priors and\nis intractable in many cases.\narchitectures.\nINTRODUCTION TO NOISE SCHEDULERS IN DIFFUSION MODELS\nIn diffusion models, noise plays a central role in transforming structured data into random noise\nduring training and then reconstructing it during sampling. However, how much noise is added\nor removed at each step is not arbitrary—it must be carefully controlled to ensure that the model\nlearns me",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 13
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 31,
      "content": "during training and then reconstructing it during sampling. However, how much noise is added\nor removed at each step is not arbitrary—it must be carefully controlled to ensure that the model\nlearns meaningful patterns and can effectively generate high-quality data.\nThis is where noise schedulers come into play.\nA noise scheduler defines the schedule or strategy by which noise is added to data in the\nforward diffusion process and removed in the backward process. It determines the magnitude\nof noise at each step, shaping how the model degrades and refines information over time.\nThe design of the noise schedule affects several critical aspects:\n• Learning efficiency – Too much noise can obscure important details, while too little\nmay prevent the model from learning to handle uncertainty.\n• Sample diversity and quality – The progression of noise influences how creative or\nrealistic the generated outputs are.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 32,
      "content": "s, while too little\nmay prevent the model from learning to handle uncertainty.\n• Sample diversity and quality – The progression of noise influences how creative or\nrealistic the generated outputs are.\n• Training stability – Gradual noise addition helps avoid erratic learning and ensures\nthat the model can generalize from noisy inputs.\nCommon schedules include linear, cosine, and exponential noise schedules, each offering\ndifferent trade-offs between smoothness, speed, and complexity.\nSignificance of Noise Schedulers in Diffusion Models\nIn diffusion models, noise schedulers determine how noise is added (in the forward process)\nor removed (in the backward process) at each step. They play a critical role in controlling the\nquality, stability, and efficiency of the model during both training and sampling.\nWhy are noise schedulers important?\n1. Control over noise injection\no A noise scheduler defines how much noise is added at each step, influencing\nhow quickly the data degrades from its or",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 33,
      "content": "nd sampling.\nWhy are noise schedulers important?\n1. Control over noise injection\no A noise scheduler defines how much noise is added at each step, influencing\nhow quickly the data degrades from its original form to pure noise.\n\n--- Page 14 ---\no A carefully designed schedule ensures that the model learns meaningful\ntransformations at each step rather than abrupt or overly noisy transitions.\n2. Balance between learning and randomness\no If noise is added too aggressively, the model may struggle to learn how to\nrecover the data because too much information is lost early.\no If noise is too weak, the model may not generalize well and could overfit to\nspecific patterns without learning how to handle uncertainty.\n3. Smooth transitions\no Gradual noise addition allows the model to capture complex patterns and fine\ndetails at different noise levels, helping the backward process refine the data\neffectively.\n4.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 14
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 34,
      "content": "ty.\n3. Smooth transitions\no Gradual noise addition allows the model to capture complex patterns and fine\ndetails at different noise levels, helping the backward process refine the data\neffectively.\n4. Influences sample quality and diversity\no The noise schedule affects the kinds of outputs the model generates. For\ninstance, a slower noise increase might produce high-fidelity samples, while a\nfaster schedule might encourage more diverse and creative outputs.\n5. Stabilizes training\no Appropriate noise scheduling prevents extreme gradients or erratic learning\nbehavior, enabling stable and efficient training across large datasets.\n✅ Example of a commonly used noise scheduler: Linear noise schedule\nOne widely used noise scheduler is the linear noise schedule, where the noise level increases\nat a constant rate across steps.\n• The noise added at each step t is computed as:\nwhere:\no β start is the initial noise amount,\no β end is the final noise amount,\no T is the total number of steps.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 35,
      "content": "ses\nat a constant rate across steps.\n• The noise added at each step t is computed as:\nwhere:\no β start is the initial noise amount,\no β end is the final noise amount,\no T is the total number of steps.\nWhy it's used:\n• Simplicity – easy to implement and analyze.\n• Gradual degradation – ensures smooth transitions from structured data to noise.\n• Works well in practice for a variety of tasks without requiring complex tuning.\n✅ Other common noise schedules\n• Cosine schedule – Uses a cosine curve to control noise increments, adding noise\nmore smoothly at the beginning and end.\n\n--- Page 15 ---\n• Exponential schedule – Adds noise in a way that accelerates or decelerates across\nsteps, providing more control over learning phases.\nComparison between Class-Conditional Diffusion Models and Unconditional Diffusion\nModels\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\nDiffusion models where the generation\nDiffusion models that generate data\nprocess is guided by class label",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 15
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 36,
      "content": "nal Diffusion\nModels\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\nDiffusion models where the generation\nDiffusion models that generate data\nprocess is guided by class labels or\npurely based on learned distributions\nadditional conditioning information (e.g.,\n✅ Definition without any conditioning information.\ntext, attributes). The model learns how the\nThe model only depends on noise and\ndata distribution changes for different\nthe learned data distribution.\nclasses.\n- Incorporates class labels or auxiliary\ninputs into the noise prediction network.\n- Contains only the noise prediction\n- Conditioning is usually done by\nnetwork without any external inputs.\nconcatenating labels or through\n✅ - Learns the general structure and\nembeddings that influence intermediate\nArchitecture distribution of the entire dataset.\nlayers.\n- Generates samples based on noise\n- The model learns separate modes of the\nwithout class-specific guidance.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 37,
      "content": "ddings that influence intermediate\nArchitecture distribution of the entire dataset.\nlayers.\n- Generates samples based on noise\n- The model learns separate modes of the\nwithout class-specific guidance.\ndata distribution for each class or\ncondition.\n- Learn how to denoise while respecting - Learn to denoise without any guidance\nclass information. other than the underlying data\n✅ Training - The model minimizes the reconstruction distribution.\nObjective loss while conditioning on the class, - The model focuses on general patterns\nensuring generated samples match the and statistical relationships in the\ntarget category. dataset.\n- During generation, class labels guide the\n- Generates samples from noise without\nsampling process, allowing control over\ncontrol over attributes or categories.\n✅ Sampling what kind of sample is generated (e.g., a\n- Produces diverse outputs but without\ncat vs. a dog image).\nspecific guidance.\n- Can produce targeted, structured outputs.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 38,
      "content": "tributes or categories.\n✅ Sampling what kind of sample is generated (e.g., a\n- Produces diverse outputs but without\ncat vs. a dog image).\nspecific guidance.\n- Can produce targeted, structured outputs.\n- Image synthesis conditioned on class\nlabels (e.g., generating specific objects or - General image, audio, or video\nfaces). generation where control is not\n✅ - Text-to-image generation, style transfer, necessary.\nApplications or scenarios requiring targeted outputs. - Data augmentation, unsupervised\n- Semi-supervised learning where learning, and exploratory creative\nadditional information improves generation generation.\nquality.\n- Greater control over generated samples.\n✅ - Can produce outputs tailored to specific - Simpler architecture and easier to\nAdvantages tasks or user inputs. implement.\n- More interpretable generation process. - Requires less labeled data.\n\n--- Page 16 ---\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\n- Capable of learning diverse patter",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 16
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 39,
      "content": "t.\n- More interpretable generation process. - Requires less labeled data.\n\n--- Page 16 ---\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\n- Capable of learning diverse patterns\nfrom large, unstructured datasets.\n- Requires labeled data or conditioning\n- Lacks control over generated content.\n✅ inputs, which may not always be available.\n- May produce irrelevant or ambiguous\nLimitations - More complex architecture and higher\noutputs when diverse patterns overlap.\ncomputational cost.\nDDIM (DENOISING DIFFUSION IMPLICIT MODELS)\nDDIM (Denoising Diffusion Implicit Models) is an improvement over standard diffusion\nmodels like DDPM (Denoising Diffusion Probabilistic Models). It introduces a new sampling\nmethod that allows generating high-quality samples with significantly fewer steps, while still\nretaining diversity and structure in the outputs.\n✅ Why DDIM was introduced\n1.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 16
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 40,
      "content": "introduces a new sampling\nmethod that allows generating high-quality samples with significantly fewer steps, while still\nretaining diversity and structure in the outputs.\n✅ Why DDIM was introduced\n1. Reduce Sampling Time\no Traditional diffusion models like DDPM require hundreds or thousands of\nsteps during sampling, which makes them computationally expensive and slow\nfor practical applications.\n2. Maintain Quality and Diversity\no Simply reducing steps in DDPM leads to degraded or less diverse outputs.\no DDIM proposes a deterministic or pseudo-deterministic approach that\nmaintains high sample fidelity even with fewer steps.\n✅ How DDIM works\n1. Implicit Sampling\no Instead of following the stochastic reverse process of DDPM, DDIM defines a\ndeterministic mapping between noise and data, reducing randomness during\nsampling.\no The model avoids resampling at each step, making it faster and more stable.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 41,
      "content": "erse process of DDPM, DDIM defines a\ndeterministic mapping between noise and data, reducing randomness during\nsampling.\no The model avoids resampling at each step, making it faster and more stable.\n2. Non-Markovian Transitions\no Unlike DDPM where each step depends only on the previous one (Markov\nproperty), DDIM relaxes this assumption by allowing steps that depend on\nearlier states.\no This enables more flexible transitions and faster sampling while preserving\nsample quality.\n3. Controlled Interpolation\no DDIM allows interpolation between different noise levels and samples, which\ncan be used for creative applications like style mixing or smooth transitions.\n\n--- Page 17 ---\n✅ Key Differences from DDPM\nFeature DDPM DDIM\nStochastic, follows Markov chain with Deterministic or pseudo-deterministic,\nSampling process\nrandom transitions with fewer steps\nComputational\nHigh due to many sampling steps Much lower with accelerated sampling\ncost\nCan explore a wide range of outputs due Maintains div",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 17
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 42,
      "content": "stic,\nSampling process\nrandom transitions with fewer steps\nComputational\nHigh due to many sampling steps Much lower with accelerated sampling\ncost\nCan explore a wide range of outputs due Maintains diversity but with controlled\nDiversity\nto randomness noise patterns\nSuitable for tasks needing rich Better for fast generation and interactive\nUse case\nexploration applications\n✅ Mathematical Insight\nIn DDPM, the reverse process is modeled as a probabilistic sampling from p(x ∣x), where\nt−1 t\nrandomness is inherent at each step.\nIn DDIM, a deterministic transition is defined:\nHere:\n• α t defines how much signal is preserved at each step.\n• ϵ θ (x t ,t) is the model’s learned noise prediction.\nThis formulation allows skipping intermediate steps while still approximating the\nreverse trajectory.\n✅ Applications of DDIM\n1. Image Generation\no Produces high-resolution images quickly without compromising on details.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 43,
      "content": "s skipping intermediate steps while still approximating the\nreverse trajectory.\n✅ Applications of DDIM\n1. Image Generation\no Produces high-resolution images quickly without compromising on details.\n2. Video and Audio Synthesis\no Enables faster generation for time-sensitive applications like animation or\nsound design.\n3. Style Transfer & Interpolation\no Smoothly blends between samples by manipulating latent noise patterns\ndeterministically.\n4. Interactive Tools\no Supports real-time editing and creative workflows where speed and control are\ncritical.\n\n--- Page 18 ---\n✅ Advantages of DDIM\n✔ Faster sampling with fewer steps\n✔ Stable and high-quality outputs\n✔ Supports interpolation and controlled generation\n✔ Reduces computational cost without major trade-offs in realism\n✅ Limitations of DDIM\n❗ May lose some diversity due to reduced randomness\n❗ Requires careful tuning of schedules and noise levels\n❗ Still dependent on well-trained models to perform effectively\n✅ Conclusion\nDDIM is a power",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 18
    },
    {
      "doc_id": "tmp_m_71n3r_UNIT I - GCV NOTES.pdf_a0a003d3_a6e42865",
      "chunk_index": 44,
      "content": "❗ May lose some diversity due to reduced randomness\n❗ Requires careful tuning of schedules and noise levels\n❗ Still dependent on well-trained models to perform effectively\n✅ Conclusion\nDDIM is a powerful extension of diffusion models that addresses one of their biggest\nlimitations—slow sampling—by introducing deterministic or semi-deterministic transitions.\nIt enables faster generation while maintaining sample fidelity and diversity, making it highly\nsuitable for real-world applications like image synthesis, animation, and interactive creative\ntools.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nDIFFUSION MODELS\nDiffusion models are a type of generative AI that create new data like images, audio or even\nvideo by starting with random noise and gradually turning it into something meaningful. They\nwork by simulating a diffusion process where data is slowly corrupted by noise during\ntraining and then learning to reverse this process step by step. By doing so the model learns\nhow to generate high quality samples from scratch.\nUnderstanding Diffusion Models\n• Diffusion models are generative models that learn to reverse a diffusion process to\ngenerate data. The diffusion process involves gradually adding noise to data until it\nbecomes pure noise.\n• Through this process a simple distribution is transformed into a complex data distribution\nin a series of small incremental steps.\n• Essentially these models operate as a reverse diffusion phenomenon where noise is\nintroduced to the data in a forward manner and removed in a reverse manner to generate\nnew data samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 1
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 1,
      "content": "ntal steps.\n• Essentially these models operate as a reverse diffusion phenomenon where noise is\nintroduced to the data in a forward manner and removed in a reverse manner to generate\nnew data samples.\n• By learning to reverse this process diffusion models start from noise and gradually\ndenoise it to produce data that closely resembles the training examples.\nKey Components\n1. Forward Diffusion Process: This process involves adding noise to the data in a series of\nsmall steps. Each step slightly increases the noise, making the data progressively more\nrandom until it resembles pure noise.\n2. Reverse Diffusion Process: The model learns to reverse the noise-adding steps. Starting\nfrom pure noise, the model iteratively removes the noise, generating data that matches\nthe training distribution.\n3. Score Function: This function estimates the gradient of the data distribution concerning\nthe noise. It helps guide the reverse diffusion process to produce realistic samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 2,
      "content": "training distribution.\n3. Score Function: This function estimates the gradient of the data distribution concerning\nthe noise. It helps guide the reverse diffusion process to produce realistic samples.\n\n--- Page 2 ---\nArchitecture of Diffusion Models\nThe architecture of diffusion models typically involves two main components:\n1. Forward Diffusion Process\n2. Reverse Diffusion Process\n1. Forward Diffusion Process\nIn this process noise is incrementally added to the data over a series of steps. This is akin to\na Markov chain where each step slightly degrades the data by adding Gaussian noise.\nForward Diffusion P\nMathematically, this can be represented as:\nwhere,\n• xt is the noisy data at step t\n• αt controls the amount of noise added.\n2. Reverse Diffusion Process\nThe reverse process aims to reconstruct the original data by denoising the noisy data in a\nseries of steps reversing the forward diffusion.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 2
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 3,
      "content": "rols the amount of noise added.\n2. Reverse Diffusion Process\nThe reverse process aims to reconstruct the original data by denoising the noisy data in a\nseries of steps reversing the forward diffusion.\nReverse Diffusion Process\nThis is typically modelled using a neural network that predicts the noise added at each step:\nwhere,\n• μθ and σθ are learned parameters.\nWorking Principle of Diffusion Models\nDuring training the model learns to predict the noise added at each step of the forward\nprocess. This is done by minimizing a loss function that measures the difference between the\npredicted and actual noise.\nForward Process (Diffusion)\n• The forward process involves gradually corrupting the data x0 with Gaussian noise over\na sequence of time steps\n• Let xt represent the noisy data at time step t. The process is defined as:\n• where βt is the noise schedule that controls the amount of noise added at each step and ϵ is\nis Gaussian noise.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 4,
      "content": "ime steps\n• Let xt represent the noisy data at time step t. The process is defined as:\n• where βt is the noise schedule that controls the amount of noise added at each step and ϵ is\nis Gaussian noise.\n\n--- Page 3 ---\n• As t increases, xt becomes more noisy until it approximates a Gaussian distribution.\nReverse Process (Denoising)\n• The reverse process aims to reconstruct the original data x0x0 from the noisy data xT at\nthe final time step T.\n• This process is modelled using a neural network to approximate the conditional\nprobability pθ(xt−1∣xt).\n• The reverse process can be formulated as:\n• where ϵθ is a neural network parameterized by θ that predicts the noise.\nTraining Diffusion Models\n• The training objective for diffusion models involves minimizing the difference between\nthe true noise ϵ added in the forward process and the noise predicted by the neural\nnetwork ϵθ.\n• The score function which estimates the gradient of the data distribution concerning the\nnoise plays an important rol",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 3
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 5,
      "content": "ϵ added in the forward process and the noise predicted by the neural\nnetwork ϵθ.\n• The score function which estimates the gradient of the data distribution concerning the\nnoise plays an important role in guiding the reverse process.\n• The loss function is typically the mean squared error (MSE) between these two quantities:\n• This encourages the model to accurately predict the noise and, consequently, to denoise\neffectively during the reverse process.\nIn diffusion models, both the forward and backward processes are modeled as a sequence of\nsmall incremental steps rather than a single transformation. This sequential approach is\ncrucial because:\n1. Gradual Learning – By breaking the process into many steps, the model learns how\nto handle slight changes at each stage, making it easier to reverse the noise addition. If\nit tried to denoise from a fully noisy image in one step, it would struggle to map the\nrandom noise back to structured data.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 6,
      "content": "hanges at each stage, making it easier to reverse the noise addition. If\nit tried to denoise from a fully noisy image in one step, it would struggle to map the\nrandom noise back to structured data.\n2. Stability in Training – Learning through small denoising steps prevents abrupt\ntransitions, reducing the chances of errors or divergence during training. It ensures\nthat the model refines its predictions slowly, stabilizing gradients and allowing\nconsistent improvements.\n3. Better Control Over Generation – The step-wise nature allows the model to be\nsampled at different stages, offering control over how much noise to remove or retain.\nThis is especially useful in VR environments, where designers might want to balance\nrealism with creativity.\n4. Avoiding Catastrophic Forgetting – Incremental denoising reinforces the learning at\nevery step, ensuring that earlier patterns are not forgotten as the model progresses\ntoward generating complex outputs.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 7,
      "content": "iding Catastrophic Forgetting – Incremental denoising reinforces the learning at\nevery step, ensuring that earlier patterns are not forgotten as the model progresses\ntoward generating complex outputs.\n\n--- Page 4 ---\nThus, modeling the forward and backward processes as a sequence of steps ensures that\nlearning is smooth, robust, and interpretable, ultimately allowing the system to produce high-\nquality, stable, and realistic images from rough sketches.\nNoise plays a central role in the diffusion process, and carefully adjusting it can significantly\ninfluence the outcomes:\n1. Higher Noise Levels\no Encourages diverse outputs because the model explores a wider range of\npossibilities when starting from more random data.\no Useful for generating creative or artistic VR landscapes where uniqueness is\ndesired.\no However, if the noise is too high, the generated images may lose structure or\ncoherence, reducing realism.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 4
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 8,
      "content": "o Useful for generating creative or artistic VR landscapes where uniqueness is\ndesired.\no However, if the noise is too high, the generated images may lose structure or\ncoherence, reducing realism.\n2. Lower Noise Levels\no Helps maintain realism and fidelity because the model starts closer to\nstructured patterns, making it easier to produce clear and consistent images.\no Best suited for VR environments where accuracy, recognizable objects, and\nrealistic textures are essential.\no It may, however, limit creativity and diversity since the outputs are\nconstrained to follow the training data closely.\n3. Noise Scheduling\no Adjusting how noise is added or removed across steps (e.g., linear,\nexponential, cosine schedules) allows fine-tuning between exploration and\nrefinement.\no Designers can control whether the model produces subtle variations or\nradically different landscapes.\n4. Application in VR Systems\no For immersive experiences, higher noise levels at early steps can generate\nunpredictabl",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 9,
      "content": "l whether the model produces subtle variations or\nradically different landscapes.\n4. Application in VR Systems\no For immersive experiences, higher noise levels at early steps can generate\nunpredictable and novel environments, while later steps can be fine-tuned with\nlower noise to ensure realistic details.\no This balance allows users to start with abstract sketches and transform them\ninto believable virtual worlds that retain creativity without sacrificing\ncoherence.\n\n--- Page 5 ---\nDENOISING DIFFUSION PROBABILISTIC MODEL (DDPM)\nWhat are DDPMs?\nThey are a class of generative models that work by iteratively adding noise to an input signal\n(like an image, text, or audio) and then learning to denoise from the noisy signal to generate\nnew samples.\nGenerative models\nAre a type of model that can generate new data instances. Previously, machine learning models\nhave done a good job of learning differences in data and then making predictions or\nclassification tasks.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 5
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 10,
      "content": "Are a type of model that can generate new data instances. Previously, machine learning models\nhave done a good job of learning differences in data and then making predictions or\nclassification tasks. For example, a model trained on a digits dataset like MNIST can recognize\na 0 from a 1. Generative models, on the other hand, learn the distribution of digits and can create\na “fake digit” which closely resembles a real digit.\nA Denoising Diffusion Probabilistic Model (DDPM) is a type of generative model that\ncreates realistic images by learning how to progressively refine noisy data. It works in two\nphases:\n1. Forward Process (Noise Addition) – The model gradually adds random noise to a\nclean image over many steps until the image becomes indistinguishable from noise.\n2. Backward Process (Denoising) – The model learns to reverse this process by\npredicting how to remove noise at each step, eventually reconstructing a high-quality\nimage from random noise or a rough input.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 11,
      "content": "ckward Process (Denoising) – The model learns to reverse this process by\npredicting how to remove noise at each step, eventually reconstructing a high-quality\nimage from random noise or a rough input.\nThe model is called probabilistic because it doesn’t rely on a single deterministic\ntransformation but instead learns the distribution of possible images at each stage of noise\nand denoising. This approach allows it to generate diverse, high-fidelity images by sampling\nfrom the learned distribution.\n\n--- Page 6 ---\nKey Features of DDPM:\n• Iterative Refinement – Instead of transforming an image in one step, it uses many\nsmall steps, making it easier to model complex patterns.\n• Noise-Based Learning – By learning how images degrade with noise, the model\nunderstands how to reverse this degradation to recreate details.\n• Probabilistic Nature – It generates a range of plausible outputs rather than a single\nfixed result, which is useful in creative tasks like animation.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 6
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 12,
      "content": "to reverse this degradation to recreate details.\n• Probabilistic Nature – It generates a range of plausible outputs rather than a single\nfixed result, which is useful in creative tasks like animation.\n• Flexibility – DDPMs can be applied to various tasks such as image synthesis, super-\nresolution, and in your case, converting rough sketches into fully rendered scenes.\nForward and Backward Diffusion Process\nThe forward diffusion process is the initial phase in a DDPM where noise is incrementally\nadded to clean data over many steps. The purpose is to teach the model how data transitions\nfrom structured and detailed forms into randomness.\nKey steps involved:\n1. Starting with clean data – At the beginning, the model takes real data such as an\nimage or signal that contains structured information like shapes, textures, and\npatterns.\n2. Adding noise at each step – Gaussian noise is added to the data in small amounts\nover a sequence of steps. The noise schedule (linear, cosine, etc.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 13,
      "content": "information like shapes, textures, and\npatterns.\n2. Adding noise at each step – Gaussian noise is added to the data in small amounts\nover a sequence of steps. The noise schedule (linear, cosine, etc.) controls how much\nnoise is added at each step.\n3. Progressive degradation – The data becomes increasingly noisy at every step.\nInitially, the patterns are still recognizable, but as the process continues, the structure\ndisappears, and the data looks like random noise.\n4. Mathematical formulation – At step t, the noisy data x is derived from the previous\nt\nstep x by sampling from a normal distribution:\nt−1\nwhere α controls the amount of retained information and ϵ is sampled from a normal\nt\ndistribution.\nWhy this step is essential:\n• It exposes the model to how real data deteriorates with noise.\n• It creates a learning path for the model to understand the inverse operation—\nrecovering the data from noisy versions.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 14,
      "content": "is essential:\n• It exposes the model to how real data deteriorates with noise.\n• It creates a learning path for the model to understand the inverse operation—\nrecovering the data from noisy versions.\n• It ensures that the model can generalize to varying noise levels and recover details\nfrom incomplete or corrupted data.\n\n--- Page 7 ---\nRole of the Markov Chain in the Forward Diffusion Process of a DDPM\nIn a Denoising Diffusion Probabilistic Model (DDPM), the forward diffusion process\ninvolves gradually adding noise to clean data over multiple steps. This process is modeled as\na Markov chain, which plays a crucial role in structuring how noise is added.\nA Markov chain is a mathematical system that transitions from one state to another, where\nthe next state depends only on the current state and not on the entire history of past states. In\nthe context of DDPM’s forward diffusion process, this means:\n1.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 7
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 15,
      "content": "tions from one state to another, where\nthe next state depends only on the current state and not on the entire history of past states. In\nthe context of DDPM’s forward diffusion process, this means:\n1. Stepwise progression\no At each time step ttt, noise is added based only on the data at that step\n(xt−1x_{t-1}xt−1), not on earlier steps. This simplifies the process and\nensures that each step depends only on the immediately preceding one.\n2. Controlled noise addition\no The amount of noise added at each step is determined by a known noise\nschedule, ensuring that the transition from structured data to noise is smooth\nand gradual.\n3. Mathematical tractability\no By assuming that each step depends only on the previous step, the forward\nprocess becomes easier to analyze, simulate, and invert during training.\nHow does it help structure the noise addition steps?\n1. Simplifies modeling\no The Markov assumption allows the model to focus on learning local\ntransitions rather than global dependencies,",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 16,
      "content": "g training.\nHow does it help structure the noise addition steps?\n1. Simplifies modeling\no The Markov assumption allows the model to focus on learning local\ntransitions rather than global dependencies, making the noise addition process\ncomputationally feasible.\n2. Ensures gradual degradation\no The structured, stepwise approach ensures that noise is added progressively,\npreserving information early on and fully randomizing the data at later steps.\n3. Supports efficient training\no The Markov property allows the use of recursive formulations where each\nnoisy sample can be derived from the previous one using simple equations,\nfacilitating optimization and gradient computation.\n4. Enables inversion during sampling\no Since each step only depends on the previous one, the backward process\n(denoising) can also be structured in the same stepwise manner, allowing the\nmodel to learn how to reverse the process reliably.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 17,
      "content": "Since each step only depends on the previous one, the backward process\n(denoising) can also be structured in the same stepwise manner, allowing the\nmodel to learn how to reverse the process reliably.\nThe backward diffusion process is where the model learns to reverse the noise addition and\nreconstruct the original or new data from noisy inputs.\nKey aspects:\n1. Predicting the noise – At each step, the model is trained to estimate the noise that\nwas added in the forward process. It learns how the noisy data differs from its clean\nversion and tries to correct it.\n\n--- Page 8 ---\n2. Iterative refinement – Starting from pure noise, the model removes noise\nprogressively by applying its learned knowledge of patterns at each step. Over time,\nthe image or data becomes clearer and more structured.\n3. Learning objective – The model is optimized to minimize the difference between the\npredicted noise and the actual noise added during training.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 8
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 18,
      "content": "the image or data becomes clearer and more structured.\n3. Learning objective – The model is optimized to minimize the difference between the\npredicted noise and the actual noise added during training. This is typically done\nusing a loss function like Mean Squared Error (MSE).\n4. Sampling during generation – Once trained, the model can start from random noise\nand iteratively apply the backward process to generate new, realistic data samples.\nWhy this process is critical:\n• It allows the model to reconstruct missing or noisy details.\n• It ensures that the output is consistent with real-world data distributions.\n• It provides control over the generation process by using learned probabilities rather\nthan rigid rules.\nThe probabilistic nature of DDPM plays a central role in its ability to generate both diverse\nand high-quality outputs.\nWhy probabilistic modeling is useful?\n1. Learning distributions rather than fixed mappings\no Instead of learning a direct transformation from input to output",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 19,
      "content": "ate both diverse\nand high-quality outputs.\nWhy probabilistic modeling is useful?\n1. Learning distributions rather than fixed mappings\no Instead of learning a direct transformation from input to output, the model\nlearns the underlying distribution of possible clean data conditioned on noisy\ninputs.\no This enables the model to handle uncertainty and variations present in real\ndata.\n2. Sampling from distributions\no During generation, the model samples noise from a distribution at each step.\nEven with the same input, different random samples produce varied outputs,\npromoting creativity and diversity.\n3. Capturing subtle patterns\no Probabilistic modeling allows the model to learn nuanced relationships in the\ndata such as textures, lighting patterns, or variations in shape that are hard to\ncapture with deterministic methods.\n4. Balancing realism and exploration\no By controlling the noise level and how it’s modeled, the system can explore\nnew possibilities while staying within the realm of re",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 20,
      "content": "re with deterministic methods.\n4. Balancing realism and exploration\no By controlling the noise level and how it’s modeled, the system can explore\nnew possibilities while staying within the realm of realistic outputs. This is\ncrucial for applications like design, simulation, and data augmentation.\nChallenges:\n1. High computational cost\no Because the process involves many steps (often hundreds or thousands),\ngenerating data can be slow and resource-intensive.\n2. Latency issues in real-time applications\n\n--- Page 9 ---\no The iterative nature makes it difficult to apply DDPMs in interactive or real-\ntime environments where fast feedback is essential.\n3. Difficulty in controlling outputs\no Without proper conditioning or guidance, the model might produce outputs\nthat are inconsistent with user expectations or desired styles.\n4. Data requirements\no Training DDPMs effectively requires large and diverse datasets to accurately\nlearn noise patterns and recover fine details.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 9
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 21,
      "content": "nconsistent with user expectations or desired styles.\n4. Data requirements\no Training DDPMs effectively requires large and diverse datasets to accurately\nlearn noise patterns and recover fine details.\nENERGY-BASED MODELS(EBMs)\nEnergy-Based Models (EBMs) are a class of probabilistic models that define relationships\nbetween variables using an energy function. Rather than explicitly modeling probability\ndistributions, EBMs assign an “energy” value to each possible configuration of variables,\nwhere lower energy indicates more likely or desirable configurations, and higher energy\ncorresponds to less likely ones.\nEBMs are widely used in machine learning for tasks such as representation learning,\nstructured prediction, anomaly detection, and reinforcement learning, where capturing\nrelationships and constraints between variables is more important than explicitly computing\nprobabilities.\n2. The Concept of Energy in EBMs\n• An energy function E(x)maps an input x to a scalar energy value.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 22,
      "content": "onships and constraints between variables is more important than explicitly computing\nprobabilities.\n2. The Concept of Energy in EBMs\n• An energy function E(x)maps an input x to a scalar energy value.\n• The lower the energy, the more plausible or preferred the data point is according to\nthe model.\n• The probability distribution p(x)is related to the energy via the Boltzmann\ndistribution:\nwhere Z is the partition function:\n• The partition function Z is often intractable, making it difficult to directly compute\nprobabilities, but not necessary for learning.\n\n--- Page 10 ---\n3. Architecture and Working\nCore Components:\n1. Energy Function\no The energy function is typically parameterized by neural networks or other\ndifferentiable models.\no It scores different data configurations to indicate how well they conform to the\ndesired patterns.\n2. Learning Objective\no EBMs learn by comparing the energies of positive (correct) and negative\n(incorrect or unlikely) samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 10
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 23,
      "content": "nfigurations to indicate how well they conform to the\ndesired patterns.\n2. Learning Objective\no EBMs learn by comparing the energies of positive (correct) and negative\n(incorrect or unlikely) samples.\no The goal is to assign lower energy to real data and higher energy to unlikely\ndata.\n3. Training Approaches\no Contrastive Divergence (CD) – Optimizes the model by comparing energy\ndifferences between observed and model-generated samples.\no Score Matching – Matches the gradient of the energy function rather than the\nenergy itself.\no Noise Contrastive Estimation (NCE) – Uses noise samples to help\napproximate the partition function during learning.\n4. Markov Random Fields (MRFs) and Conditional EBMs\n• EBMs are closely related to Markov Random Fields (MRFs), which model\ndependencies between variables using graph structures.\n• Conditional EBMs extend the energy framework to tasks where the output depends\non input features (e.g., image classification, structured output prediction).\n5.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 24,
      "content": "ween variables using graph structures.\n• Conditional EBMs extend the energy framework to tasks where the output depends\non input features (e.g., image classification, structured output prediction).\n5. Applications of EBMs\n1. Unsupervised Learning\no Modeling complex relationships in high-dimensional data such as images,\nspeech, or text.\n2. Anomaly Detection\no Identifying outliers by assigning higher energy to rare or unlikely\nconfigurations.\n3. Reinforcement Learning (RL)\no Estimating value functions where actions with lower energy correspond to\nmore rewarding behaviors.\n4. Generative Modeling\no Generating samples by searching for configurations with low energy, often\nusing sampling algorithms like Langevin dynamics.\n5. Structured Prediction\no Solving problems like image segmentation or sequence labeling where\nrelationships between output variables are important.\n\n--- Page 11 ---\n6. Advantages of EBMs\n• Flexibility – Can model arbitrary dependencies without requiring explicit probabilit",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 11
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 25,
      "content": "uence labeling where\nrelationships between output variables are important.\n\n--- Page 11 ---\n6. Advantages of EBMs\n• Flexibility – Can model arbitrary dependencies without requiring explicit probability\ndistributions.\n• Interpretability – The energy function directly encodes preferences or constraints.\n• Applicability – Useful in domains where structured relationships and constraints\ndominate over simple classification.\n7. Challenges and Limitations\n1. Intractable Partition Function\no Computing ZZZ is often impossible in practice, requiring approximation\ntechniques that can be unstable.\n2. Training Instability\no Optimization methods like contrastive divergence rely on sampling, which can\nlead to slow convergence or poor performance.\n3. Sampling Complexity\no Generating samples requires iterative methods such as Markov Chain Monte\nCarlo (MCMC), which can be computationally expensive.\n4. Scalability Issues\no Handling high-dimensional data with complex energy landscapes is\nchallenging.\n8.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 11
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 26,
      "content": "rative methods such as Markov Chain Monte\nCarlo (MCMC), which can be computationally expensive.\n4. Scalability Issues\no Handling high-dimensional data with complex energy landscapes is\nchallenging.\n8. Recent Advances\n• Neural EBMs – Combining deep learning with energy functions to model high-\ndimensional and structured data more effectively.\n• Score-based Generative Models – Learning the gradient of the energy function to\navoid directly computing the partition function.\n• Applications in Contrastive Learning – EBMs form the backbone of contrastive\napproaches where relationships between samples are emphasized.\n\n--- Page 12 ---\nCOMPARE EBMS VS VAES\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Defined by an energy function\nthat assigns a scalar “energy” to\n- Composed of two main parts: an\neach configuration of inputs (and\nencoder and a decoder.\noptionally outputs).\n- The encoder maps input data to a\n- No explicit probability\nlatent space distribution (typically\ndist",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 12
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 27,
      "content": "two main parts: an\neach configuration of inputs (and\nencoder and a decoder.\noptionally outputs).\n- The encoder maps input data to a\n- No explicit probability\nlatent space distribution (typically\ndistribution; the model learns to\nGaussian).\nassign lower energy to desired\n- The decoder reconstructs data\n✅ Architecture samples and higher energy to\nfrom samples drawn from the latent\nundesired ones.\nspace.\n- Often optimized using contrastive\n- Uses variational inference to\ndivergence or score matching.\napproximate intractable posteriors.\n- The architecture focuses on\n- The architecture explicitly models\nrelationships between data points\ndata generation.\nrather than reconstructing or\ngenerating them directly.\n- Maximize the Evidence Lower\n- Learn an energy landscape where\nBound (ELBO) which balances\ncorrect data points are assigned\nreconstruction accuracy and\nlower energy.\n✅ Objective regularization of the latent space.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 28,
      "content": "Evidence Lower\n- Learn an energy landscape where\nBound (ELBO) which balances\ncorrect data points are assigned\nreconstruction accuracy and\nlower energy.\n✅ Objective regularization of the latent space.\n- Optimization is based on\n- Encourages latent space structure\ndistinguishing good samples from\nfor efficient sampling and\nbad ones.\ninterpolation.\n- Indirect; energy defines the\nlikelihood up to a normalization - Explicit probabilistic framework\nconstant (partition function), which with tractable priors and\n✅ Probabilistic\nis often intractable. approximate posteriors.\nInterpretation\n- Focuses on learning relationships - Can directly sample from the latent\nand constraints rather than full space and model uncertainty.\ndensity estimation.\n- Uses sampling-based methods\nlike Markov Chain Monte Carlo - Uses backpropagation with\n(MCMC), contrastive divergence, reparameterization trick for efficient\n✅ Training\nor score matching. gradient estimation.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 29,
      "content": "mpling-based methods\nlike Markov Chain Monte Carlo - Uses backpropagation with\n(MCMC), contrastive divergence, reparameterization trick for efficient\n✅ Training\nor score matching. gradient estimation.\nMethods\n- Training can be unstable due to - More stable and easier to train\nreliance on sampling and gradient with large datasets.\nestimation.\n- Modeling complex dependencies\nin structured data. - Image and speech generation, data\n- Used in tasks like anomaly compression, anomaly detection,\ndetection, reinforcement learning, and semi-supervised learning.\n✅ Applications\nand unsupervised learning. - Used where interpretable latent\n- Applicable where relationships representations and smooth\nand constraints are more important generation paths are required.\nthan explicit reconstruction.\n\n--- Page 13 ---\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Flexibility in modeling\n- Well-suited for generating new\nrelationships without requiring\ndata samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 13
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 30,
      "content": "onstruction.\n\n--- Page 13 ---\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Flexibility in modeling\n- Well-suited for generating new\nrelationships without requiring\ndata samples.\n✅ Strengths explicit likelihood functions.\n- Provides interpretable latent spaces\n- Can incorporate constraints and\nuseful for downstream tasks.\ndomain knowledge easily.\n- May suffer from blurry\n- Training is computationally\nreconstructions or mode collapse.\nexpensive and less scalable. -\n✅ Limitations - Latent space structure depends\nNormalization constant estimation\nheavily on choice of priors and\nis intractable in many cases.\narchitectures.\nINTRODUCTION TO NOISE SCHEDULERS IN DIFFUSION MODELS\nIn diffusion models, noise plays a central role in transforming structured data into random noise\nduring training and then reconstructing it during sampling. However, how much noise is added\nor removed at each step is not arbitrary—it must be carefully controlled to ensure that the model\nlearns me",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 13
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 31,
      "content": "during training and then reconstructing it during sampling. However, how much noise is added\nor removed at each step is not arbitrary—it must be carefully controlled to ensure that the model\nlearns meaningful patterns and can effectively generate high-quality data.\nThis is where noise schedulers come into play.\nA noise scheduler defines the schedule or strategy by which noise is added to data in the\nforward diffusion process and removed in the backward process. It determines the magnitude\nof noise at each step, shaping how the model degrades and refines information over time.\nThe design of the noise schedule affects several critical aspects:\n• Learning efficiency – Too much noise can obscure important details, while too little\nmay prevent the model from learning to handle uncertainty.\n• Sample diversity and quality – The progression of noise influences how creative or\nrealistic the generated outputs are.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 32,
      "content": "s, while too little\nmay prevent the model from learning to handle uncertainty.\n• Sample diversity and quality – The progression of noise influences how creative or\nrealistic the generated outputs are.\n• Training stability – Gradual noise addition helps avoid erratic learning and ensures\nthat the model can generalize from noisy inputs.\nCommon schedules include linear, cosine, and exponential noise schedules, each offering\ndifferent trade-offs between smoothness, speed, and complexity.\nSignificance of Noise Schedulers in Diffusion Models\nIn diffusion models, noise schedulers determine how noise is added (in the forward process)\nor removed (in the backward process) at each step. They play a critical role in controlling the\nquality, stability, and efficiency of the model during both training and sampling.\nWhy are noise schedulers important?\n1. Control over noise injection\no A noise scheduler defines how much noise is added at each step, influencing\nhow quickly the data degrades from its or",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 33,
      "content": "nd sampling.\nWhy are noise schedulers important?\n1. Control over noise injection\no A noise scheduler defines how much noise is added at each step, influencing\nhow quickly the data degrades from its original form to pure noise.\n\n--- Page 14 ---\no A carefully designed schedule ensures that the model learns meaningful\ntransformations at each step rather than abrupt or overly noisy transitions.\n2. Balance between learning and randomness\no If noise is added too aggressively, the model may struggle to learn how to\nrecover the data because too much information is lost early.\no If noise is too weak, the model may not generalize well and could overfit to\nspecific patterns without learning how to handle uncertainty.\n3. Smooth transitions\no Gradual noise addition allows the model to capture complex patterns and fine\ndetails at different noise levels, helping the backward process refine the data\neffectively.\n4.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 14
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 34,
      "content": "ty.\n3. Smooth transitions\no Gradual noise addition allows the model to capture complex patterns and fine\ndetails at different noise levels, helping the backward process refine the data\neffectively.\n4. Influences sample quality and diversity\no The noise schedule affects the kinds of outputs the model generates. For\ninstance, a slower noise increase might produce high-fidelity samples, while a\nfaster schedule might encourage more diverse and creative outputs.\n5. Stabilizes training\no Appropriate noise scheduling prevents extreme gradients or erratic learning\nbehavior, enabling stable and efficient training across large datasets.\n✅ Example of a commonly used noise scheduler: Linear noise schedule\nOne widely used noise scheduler is the linear noise schedule, where the noise level increases\nat a constant rate across steps.\n• The noise added at each step t is computed as:\nwhere:\no β start is the initial noise amount,\no β end is the final noise amount,\no T is the total number of steps.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 35,
      "content": "ses\nat a constant rate across steps.\n• The noise added at each step t is computed as:\nwhere:\no β start is the initial noise amount,\no β end is the final noise amount,\no T is the total number of steps.\nWhy it's used:\n• Simplicity – easy to implement and analyze.\n• Gradual degradation – ensures smooth transitions from structured data to noise.\n• Works well in practice for a variety of tasks without requiring complex tuning.\n✅ Other common noise schedules\n• Cosine schedule – Uses a cosine curve to control noise increments, adding noise\nmore smoothly at the beginning and end.\n\n--- Page 15 ---\n• Exponential schedule – Adds noise in a way that accelerates or decelerates across\nsteps, providing more control over learning phases.\nComparison between Class-Conditional Diffusion Models and Unconditional Diffusion\nModels\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\nDiffusion models where the generation\nDiffusion models that generate data\nprocess is guided by class label",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 15
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 36,
      "content": "nal Diffusion\nModels\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\nDiffusion models where the generation\nDiffusion models that generate data\nprocess is guided by class labels or\npurely based on learned distributions\nadditional conditioning information (e.g.,\n✅ Definition without any conditioning information.\ntext, attributes). The model learns how the\nThe model only depends on noise and\ndata distribution changes for different\nthe learned data distribution.\nclasses.\n- Incorporates class labels or auxiliary\ninputs into the noise prediction network.\n- Contains only the noise prediction\n- Conditioning is usually done by\nnetwork without any external inputs.\nconcatenating labels or through\n✅ - Learns the general structure and\nembeddings that influence intermediate\nArchitecture distribution of the entire dataset.\nlayers.\n- Generates samples based on noise\n- The model learns separate modes of the\nwithout class-specific guidance.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 37,
      "content": "ddings that influence intermediate\nArchitecture distribution of the entire dataset.\nlayers.\n- Generates samples based on noise\n- The model learns separate modes of the\nwithout class-specific guidance.\ndata distribution for each class or\ncondition.\n- Learn how to denoise while respecting - Learn to denoise without any guidance\nclass information. other than the underlying data\n✅ Training - The model minimizes the reconstruction distribution.\nObjective loss while conditioning on the class, - The model focuses on general patterns\nensuring generated samples match the and statistical relationships in the\ntarget category. dataset.\n- During generation, class labels guide the\n- Generates samples from noise without\nsampling process, allowing control over\ncontrol over attributes or categories.\n✅ Sampling what kind of sample is generated (e.g., a\n- Produces diverse outputs but without\ncat vs. a dog image).\nspecific guidance.\n- Can produce targeted, structured outputs.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 38,
      "content": "tributes or categories.\n✅ Sampling what kind of sample is generated (e.g., a\n- Produces diverse outputs but without\ncat vs. a dog image).\nspecific guidance.\n- Can produce targeted, structured outputs.\n- Image synthesis conditioned on class\nlabels (e.g., generating specific objects or - General image, audio, or video\nfaces). generation where control is not\n✅ - Text-to-image generation, style transfer, necessary.\nApplications or scenarios requiring targeted outputs. - Data augmentation, unsupervised\n- Semi-supervised learning where learning, and exploratory creative\nadditional information improves generation generation.\nquality.\n- Greater control over generated samples.\n✅ - Can produce outputs tailored to specific - Simpler architecture and easier to\nAdvantages tasks or user inputs. implement.\n- More interpretable generation process. - Requires less labeled data.\n\n--- Page 16 ---\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\n- Capable of learning diverse patter",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 16
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 39,
      "content": "t.\n- More interpretable generation process. - Requires less labeled data.\n\n--- Page 16 ---\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\n- Capable of learning diverse patterns\nfrom large, unstructured datasets.\n- Requires labeled data or conditioning\n- Lacks control over generated content.\n✅ inputs, which may not always be available.\n- May produce irrelevant or ambiguous\nLimitations - More complex architecture and higher\noutputs when diverse patterns overlap.\ncomputational cost.\nDDIM (DENOISING DIFFUSION IMPLICIT MODELS)\nDDIM (Denoising Diffusion Implicit Models) is an improvement over standard diffusion\nmodels like DDPM (Denoising Diffusion Probabilistic Models). It introduces a new sampling\nmethod that allows generating high-quality samples with significantly fewer steps, while still\nretaining diversity and structure in the outputs.\n✅ Why DDIM was introduced\n1.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 16
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 40,
      "content": "introduces a new sampling\nmethod that allows generating high-quality samples with significantly fewer steps, while still\nretaining diversity and structure in the outputs.\n✅ Why DDIM was introduced\n1. Reduce Sampling Time\no Traditional diffusion models like DDPM require hundreds or thousands of\nsteps during sampling, which makes them computationally expensive and slow\nfor practical applications.\n2. Maintain Quality and Diversity\no Simply reducing steps in DDPM leads to degraded or less diverse outputs.\no DDIM proposes a deterministic or pseudo-deterministic approach that\nmaintains high sample fidelity even with fewer steps.\n✅ How DDIM works\n1. Implicit Sampling\no Instead of following the stochastic reverse process of DDPM, DDIM defines a\ndeterministic mapping between noise and data, reducing randomness during\nsampling.\no The model avoids resampling at each step, making it faster and more stable.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 41,
      "content": "erse process of DDPM, DDIM defines a\ndeterministic mapping between noise and data, reducing randomness during\nsampling.\no The model avoids resampling at each step, making it faster and more stable.\n2. Non-Markovian Transitions\no Unlike DDPM where each step depends only on the previous one (Markov\nproperty), DDIM relaxes this assumption by allowing steps that depend on\nearlier states.\no This enables more flexible transitions and faster sampling while preserving\nsample quality.\n3. Controlled Interpolation\no DDIM allows interpolation between different noise levels and samples, which\ncan be used for creative applications like style mixing or smooth transitions.\n\n--- Page 17 ---\n✅ Key Differences from DDPM\nFeature DDPM DDIM\nStochastic, follows Markov chain with Deterministic or pseudo-deterministic,\nSampling process\nrandom transitions with fewer steps\nComputational\nHigh due to many sampling steps Much lower with accelerated sampling\ncost\nCan explore a wide range of outputs due Maintains div",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 17
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 42,
      "content": "stic,\nSampling process\nrandom transitions with fewer steps\nComputational\nHigh due to many sampling steps Much lower with accelerated sampling\ncost\nCan explore a wide range of outputs due Maintains diversity but with controlled\nDiversity\nto randomness noise patterns\nSuitable for tasks needing rich Better for fast generation and interactive\nUse case\nexploration applications\n✅ Mathematical Insight\nIn DDPM, the reverse process is modeled as a probabilistic sampling from p(x ∣x), where\nt−1 t\nrandomness is inherent at each step.\nIn DDIM, a deterministic transition is defined:\nHere:\n• α t defines how much signal is preserved at each step.\n• ϵ θ (x t ,t) is the model’s learned noise prediction.\nThis formulation allows skipping intermediate steps while still approximating the\nreverse trajectory.\n✅ Applications of DDIM\n1. Image Generation\no Produces high-resolution images quickly without compromising on details.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 43,
      "content": "s skipping intermediate steps while still approximating the\nreverse trajectory.\n✅ Applications of DDIM\n1. Image Generation\no Produces high-resolution images quickly without compromising on details.\n2. Video and Audio Synthesis\no Enables faster generation for time-sensitive applications like animation or\nsound design.\n3. Style Transfer & Interpolation\no Smoothly blends between samples by manipulating latent noise patterns\ndeterministically.\n4. Interactive Tools\no Supports real-time editing and creative workflows where speed and control are\ncritical.\n\n--- Page 18 ---\n✅ Advantages of DDIM\n✔ Faster sampling with fewer steps\n✔ Stable and high-quality outputs\n✔ Supports interpolation and controlled generation\n✔ Reduces computational cost without major trade-offs in realism\n✅ Limitations of DDIM\n❗ May lose some diversity due to reduced randomness\n❗ Requires careful tuning of schedules and noise levels\n❗ Still dependent on well-trained models to perform effectively\n✅ Conclusion\nDDIM is a power",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 18
    },
    {
      "doc_id": "tmp_d45enbk_UNIT I - GCV NOTES.pdf_a0a003d3_753b5f78",
      "chunk_index": 44,
      "content": "❗ May lose some diversity due to reduced randomness\n❗ Requires careful tuning of schedules and noise levels\n❗ Still dependent on well-trained models to perform effectively\n✅ Conclusion\nDDIM is a powerful extension of diffusion models that addresses one of their biggest\nlimitations—slow sampling—by introducing deterministic or semi-deterministic transitions.\nIt enables faster generation while maintaining sample fidelity and diversity, making it highly\nsuitable for real-world applications like image synthesis, animation, and interactive creative\ntools.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "7983b982-fce7-40aa-9820-783d0b476c8f_test_ai_document.txt_74ec5939_56ed54d4",
      "chunk_index": 0,
      "content": "Artificial Intelligence (AI) is a branch of computer science that focuses on creating intelligent machines that can perform tasks typically requiring human intelligence. AI systems use machine learning algorithms to analyze data, recognize patterns, and make decisions. Modern AI applications include natural language processing, computer vision, robotics, and autonomous systems. Deep learning, a subset of machine learning, uses neural networks with multiple layers to process complex data.",
      "filename": "test_ai_document.txt",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nDIFFUSION MODELS\nDiffusion models are a type of generative AI that create new data like images, audio or even\nvideo by starting with random noise and gradually turning it into something meaningful. They\nwork by simulating a diffusion process where data is slowly corrupted by noise during\ntraining and then learning to reverse this process step by step. By doing so the model learns\nhow to generate high quality samples from scratch.\nUnderstanding Diffusion Models\n• Diffusion models are generative models that learn to reverse a diffusion process to\ngenerate data. The diffusion process involves gradually adding noise to data until it\nbecomes pure noise.\n• Through this process a simple distribution is transformed into a complex data distribution\nin a series of small incremental steps.\n• Essentially these models operate as a reverse diffusion phenomenon where noise is\nintroduced to the data in a forward manner and removed in a reverse manner to generate\nnew data samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 1
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 1,
      "content": "ntal steps.\n• Essentially these models operate as a reverse diffusion phenomenon where noise is\nintroduced to the data in a forward manner and removed in a reverse manner to generate\nnew data samples.\n• By learning to reverse this process diffusion models start from noise and gradually\ndenoise it to produce data that closely resembles the training examples.\nKey Components\n1. Forward Diffusion Process: This process involves adding noise to the data in a series of\nsmall steps. Each step slightly increases the noise, making the data progressively more\nrandom until it resembles pure noise.\n2. Reverse Diffusion Process: The model learns to reverse the noise-adding steps. Starting\nfrom pure noise, the model iteratively removes the noise, generating data that matches\nthe training distribution.\n3. Score Function: This function estimates the gradient of the data distribution concerning\nthe noise. It helps guide the reverse diffusion process to produce realistic samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 2,
      "content": "training distribution.\n3. Score Function: This function estimates the gradient of the data distribution concerning\nthe noise. It helps guide the reverse diffusion process to produce realistic samples.\n\n--- Page 2 ---\nArchitecture of Diffusion Models\nThe architecture of diffusion models typically involves two main components:\n1. Forward Diffusion Process\n2. Reverse Diffusion Process\n1. Forward Diffusion Process\nIn this process noise is incrementally added to the data over a series of steps. This is akin to\na Markov chain where each step slightly degrades the data by adding Gaussian noise.\nForward Diffusion P\nMathematically, this can be represented as:\nwhere,\n• xt is the noisy data at step t\n• αt controls the amount of noise added.\n2. Reverse Diffusion Process\nThe reverse process aims to reconstruct the original data by denoising the noisy data in a\nseries of steps reversing the forward diffusion.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 2
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 3,
      "content": "rols the amount of noise added.\n2. Reverse Diffusion Process\nThe reverse process aims to reconstruct the original data by denoising the noisy data in a\nseries of steps reversing the forward diffusion.\nReverse Diffusion Process\nThis is typically modelled using a neural network that predicts the noise added at each step:\nwhere,\n• μθ and σθ are learned parameters.\nWorking Principle of Diffusion Models\nDuring training the model learns to predict the noise added at each step of the forward\nprocess. This is done by minimizing a loss function that measures the difference between the\npredicted and actual noise.\nForward Process (Diffusion)\n• The forward process involves gradually corrupting the data x0 with Gaussian noise over\na sequence of time steps\n• Let xt represent the noisy data at time step t. The process is defined as:\n• where βt is the noise schedule that controls the amount of noise added at each step and ϵ is\nis Gaussian noise.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 4,
      "content": "ime steps\n• Let xt represent the noisy data at time step t. The process is defined as:\n• where βt is the noise schedule that controls the amount of noise added at each step and ϵ is\nis Gaussian noise.\n\n--- Page 3 ---\n• As t increases, xt becomes more noisy until it approximates a Gaussian distribution.\nReverse Process (Denoising)\n• The reverse process aims to reconstruct the original data x0x0 from the noisy data xT at\nthe final time step T.\n• This process is modelled using a neural network to approximate the conditional\nprobability pθ(xt−1∣xt).\n• The reverse process can be formulated as:\n• where ϵθ is a neural network parameterized by θ that predicts the noise.\nTraining Diffusion Models\n• The training objective for diffusion models involves minimizing the difference between\nthe true noise ϵ added in the forward process and the noise predicted by the neural\nnetwork ϵθ.\n• The score function which estimates the gradient of the data distribution concerning the\nnoise plays an important rol",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 3
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 5,
      "content": "ϵ added in the forward process and the noise predicted by the neural\nnetwork ϵθ.\n• The score function which estimates the gradient of the data distribution concerning the\nnoise plays an important role in guiding the reverse process.\n• The loss function is typically the mean squared error (MSE) between these two quantities:\n• This encourages the model to accurately predict the noise and, consequently, to denoise\neffectively during the reverse process.\nIn diffusion models, both the forward and backward processes are modeled as a sequence of\nsmall incremental steps rather than a single transformation. This sequential approach is\ncrucial because:\n1. Gradual Learning – By breaking the process into many steps, the model learns how\nto handle slight changes at each stage, making it easier to reverse the noise addition. If\nit tried to denoise from a fully noisy image in one step, it would struggle to map the\nrandom noise back to structured data.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 6,
      "content": "hanges at each stage, making it easier to reverse the noise addition. If\nit tried to denoise from a fully noisy image in one step, it would struggle to map the\nrandom noise back to structured data.\n2. Stability in Training – Learning through small denoising steps prevents abrupt\ntransitions, reducing the chances of errors or divergence during training. It ensures\nthat the model refines its predictions slowly, stabilizing gradients and allowing\nconsistent improvements.\n3. Better Control Over Generation – The step-wise nature allows the model to be\nsampled at different stages, offering control over how much noise to remove or retain.\nThis is especially useful in VR environments, where designers might want to balance\nrealism with creativity.\n4. Avoiding Catastrophic Forgetting – Incremental denoising reinforces the learning at\nevery step, ensuring that earlier patterns are not forgotten as the model progresses\ntoward generating complex outputs.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 7,
      "content": "iding Catastrophic Forgetting – Incremental denoising reinforces the learning at\nevery step, ensuring that earlier patterns are not forgotten as the model progresses\ntoward generating complex outputs.\n\n--- Page 4 ---\nThus, modeling the forward and backward processes as a sequence of steps ensures that\nlearning is smooth, robust, and interpretable, ultimately allowing the system to produce high-\nquality, stable, and realistic images from rough sketches.\nNoise plays a central role in the diffusion process, and carefully adjusting it can significantly\ninfluence the outcomes:\n1. Higher Noise Levels\no Encourages diverse outputs because the model explores a wider range of\npossibilities when starting from more random data.\no Useful for generating creative or artistic VR landscapes where uniqueness is\ndesired.\no However, if the noise is too high, the generated images may lose structure or\ncoherence, reducing realism.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 4
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 8,
      "content": "o Useful for generating creative or artistic VR landscapes where uniqueness is\ndesired.\no However, if the noise is too high, the generated images may lose structure or\ncoherence, reducing realism.\n2. Lower Noise Levels\no Helps maintain realism and fidelity because the model starts closer to\nstructured patterns, making it easier to produce clear and consistent images.\no Best suited for VR environments where accuracy, recognizable objects, and\nrealistic textures are essential.\no It may, however, limit creativity and diversity since the outputs are\nconstrained to follow the training data closely.\n3. Noise Scheduling\no Adjusting how noise is added or removed across steps (e.g., linear,\nexponential, cosine schedules) allows fine-tuning between exploration and\nrefinement.\no Designers can control whether the model produces subtle variations or\nradically different landscapes.\n4. Application in VR Systems\no For immersive experiences, higher noise levels at early steps can generate\nunpredictabl",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 9,
      "content": "l whether the model produces subtle variations or\nradically different landscapes.\n4. Application in VR Systems\no For immersive experiences, higher noise levels at early steps can generate\nunpredictable and novel environments, while later steps can be fine-tuned with\nlower noise to ensure realistic details.\no This balance allows users to start with abstract sketches and transform them\ninto believable virtual worlds that retain creativity without sacrificing\ncoherence.\n\n--- Page 5 ---\nDENOISING DIFFUSION PROBABILISTIC MODEL (DDPM)\nWhat are DDPMs?\nThey are a class of generative models that work by iteratively adding noise to an input signal\n(like an image, text, or audio) and then learning to denoise from the noisy signal to generate\nnew samples.\nGenerative models\nAre a type of model that can generate new data instances. Previously, machine learning models\nhave done a good job of learning differences in data and then making predictions or\nclassification tasks.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 5
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 10,
      "content": "Are a type of model that can generate new data instances. Previously, machine learning models\nhave done a good job of learning differences in data and then making predictions or\nclassification tasks. For example, a model trained on a digits dataset like MNIST can recognize\na 0 from a 1. Generative models, on the other hand, learn the distribution of digits and can create\na “fake digit” which closely resembles a real digit.\nA Denoising Diffusion Probabilistic Model (DDPM) is a type of generative model that\ncreates realistic images by learning how to progressively refine noisy data. It works in two\nphases:\n1. Forward Process (Noise Addition) – The model gradually adds random noise to a\nclean image over many steps until the image becomes indistinguishable from noise.\n2. Backward Process (Denoising) – The model learns to reverse this process by\npredicting how to remove noise at each step, eventually reconstructing a high-quality\nimage from random noise or a rough input.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 11,
      "content": "ckward Process (Denoising) – The model learns to reverse this process by\npredicting how to remove noise at each step, eventually reconstructing a high-quality\nimage from random noise or a rough input.\nThe model is called probabilistic because it doesn’t rely on a single deterministic\ntransformation but instead learns the distribution of possible images at each stage of noise\nand denoising. This approach allows it to generate diverse, high-fidelity images by sampling\nfrom the learned distribution.\n\n--- Page 6 ---\nKey Features of DDPM:\n• Iterative Refinement – Instead of transforming an image in one step, it uses many\nsmall steps, making it easier to model complex patterns.\n• Noise-Based Learning – By learning how images degrade with noise, the model\nunderstands how to reverse this degradation to recreate details.\n• Probabilistic Nature – It generates a range of plausible outputs rather than a single\nfixed result, which is useful in creative tasks like animation.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 6
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 12,
      "content": "to reverse this degradation to recreate details.\n• Probabilistic Nature – It generates a range of plausible outputs rather than a single\nfixed result, which is useful in creative tasks like animation.\n• Flexibility – DDPMs can be applied to various tasks such as image synthesis, super-\nresolution, and in your case, converting rough sketches into fully rendered scenes.\nForward and Backward Diffusion Process\nThe forward diffusion process is the initial phase in a DDPM where noise is incrementally\nadded to clean data over many steps. The purpose is to teach the model how data transitions\nfrom structured and detailed forms into randomness.\nKey steps involved:\n1. Starting with clean data – At the beginning, the model takes real data such as an\nimage or signal that contains structured information like shapes, textures, and\npatterns.\n2. Adding noise at each step – Gaussian noise is added to the data in small amounts\nover a sequence of steps. The noise schedule (linear, cosine, etc.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 13,
      "content": "information like shapes, textures, and\npatterns.\n2. Adding noise at each step – Gaussian noise is added to the data in small amounts\nover a sequence of steps. The noise schedule (linear, cosine, etc.) controls how much\nnoise is added at each step.\n3. Progressive degradation – The data becomes increasingly noisy at every step.\nInitially, the patterns are still recognizable, but as the process continues, the structure\ndisappears, and the data looks like random noise.\n4. Mathematical formulation – At step t, the noisy data x is derived from the previous\nt\nstep x by sampling from a normal distribution:\nt−1\nwhere α controls the amount of retained information and ϵ is sampled from a normal\nt\ndistribution.\nWhy this step is essential:\n• It exposes the model to how real data deteriorates with noise.\n• It creates a learning path for the model to understand the inverse operation—\nrecovering the data from noisy versions.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 14,
      "content": "is essential:\n• It exposes the model to how real data deteriorates with noise.\n• It creates a learning path for the model to understand the inverse operation—\nrecovering the data from noisy versions.\n• It ensures that the model can generalize to varying noise levels and recover details\nfrom incomplete or corrupted data.\n\n--- Page 7 ---\nRole of the Markov Chain in the Forward Diffusion Process of a DDPM\nIn a Denoising Diffusion Probabilistic Model (DDPM), the forward diffusion process\ninvolves gradually adding noise to clean data over multiple steps. This process is modeled as\na Markov chain, which plays a crucial role in structuring how noise is added.\nA Markov chain is a mathematical system that transitions from one state to another, where\nthe next state depends only on the current state and not on the entire history of past states. In\nthe context of DDPM’s forward diffusion process, this means:\n1.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 7
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 15,
      "content": "tions from one state to another, where\nthe next state depends only on the current state and not on the entire history of past states. In\nthe context of DDPM’s forward diffusion process, this means:\n1. Stepwise progression\no At each time step ttt, noise is added based only on the data at that step\n(xt−1x_{t-1}xt−1), not on earlier steps. This simplifies the process and\nensures that each step depends only on the immediately preceding one.\n2. Controlled noise addition\no The amount of noise added at each step is determined by a known noise\nschedule, ensuring that the transition from structured data to noise is smooth\nand gradual.\n3. Mathematical tractability\no By assuming that each step depends only on the previous step, the forward\nprocess becomes easier to analyze, simulate, and invert during training.\nHow does it help structure the noise addition steps?\n1. Simplifies modeling\no The Markov assumption allows the model to focus on learning local\ntransitions rather than global dependencies,",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 16,
      "content": "g training.\nHow does it help structure the noise addition steps?\n1. Simplifies modeling\no The Markov assumption allows the model to focus on learning local\ntransitions rather than global dependencies, making the noise addition process\ncomputationally feasible.\n2. Ensures gradual degradation\no The structured, stepwise approach ensures that noise is added progressively,\npreserving information early on and fully randomizing the data at later steps.\n3. Supports efficient training\no The Markov property allows the use of recursive formulations where each\nnoisy sample can be derived from the previous one using simple equations,\nfacilitating optimization and gradient computation.\n4. Enables inversion during sampling\no Since each step only depends on the previous one, the backward process\n(denoising) can also be structured in the same stepwise manner, allowing the\nmodel to learn how to reverse the process reliably.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 17,
      "content": "Since each step only depends on the previous one, the backward process\n(denoising) can also be structured in the same stepwise manner, allowing the\nmodel to learn how to reverse the process reliably.\nThe backward diffusion process is where the model learns to reverse the noise addition and\nreconstruct the original or new data from noisy inputs.\nKey aspects:\n1. Predicting the noise – At each step, the model is trained to estimate the noise that\nwas added in the forward process. It learns how the noisy data differs from its clean\nversion and tries to correct it.\n\n--- Page 8 ---\n2. Iterative refinement – Starting from pure noise, the model removes noise\nprogressively by applying its learned knowledge of patterns at each step. Over time,\nthe image or data becomes clearer and more structured.\n3. Learning objective – The model is optimized to minimize the difference between the\npredicted noise and the actual noise added during training.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 8
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 18,
      "content": "the image or data becomes clearer and more structured.\n3. Learning objective – The model is optimized to minimize the difference between the\npredicted noise and the actual noise added during training. This is typically done\nusing a loss function like Mean Squared Error (MSE).\n4. Sampling during generation – Once trained, the model can start from random noise\nand iteratively apply the backward process to generate new, realistic data samples.\nWhy this process is critical:\n• It allows the model to reconstruct missing or noisy details.\n• It ensures that the output is consistent with real-world data distributions.\n• It provides control over the generation process by using learned probabilities rather\nthan rigid rules.\nThe probabilistic nature of DDPM plays a central role in its ability to generate both diverse\nand high-quality outputs.\nWhy probabilistic modeling is useful?\n1. Learning distributions rather than fixed mappings\no Instead of learning a direct transformation from input to output",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 19,
      "content": "ate both diverse\nand high-quality outputs.\nWhy probabilistic modeling is useful?\n1. Learning distributions rather than fixed mappings\no Instead of learning a direct transformation from input to output, the model\nlearns the underlying distribution of possible clean data conditioned on noisy\ninputs.\no This enables the model to handle uncertainty and variations present in real\ndata.\n2. Sampling from distributions\no During generation, the model samples noise from a distribution at each step.\nEven with the same input, different random samples produce varied outputs,\npromoting creativity and diversity.\n3. Capturing subtle patterns\no Probabilistic modeling allows the model to learn nuanced relationships in the\ndata such as textures, lighting patterns, or variations in shape that are hard to\ncapture with deterministic methods.\n4. Balancing realism and exploration\no By controlling the noise level and how it’s modeled, the system can explore\nnew possibilities while staying within the realm of re",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 20,
      "content": "re with deterministic methods.\n4. Balancing realism and exploration\no By controlling the noise level and how it’s modeled, the system can explore\nnew possibilities while staying within the realm of realistic outputs. This is\ncrucial for applications like design, simulation, and data augmentation.\nChallenges:\n1. High computational cost\no Because the process involves many steps (often hundreds or thousands),\ngenerating data can be slow and resource-intensive.\n2. Latency issues in real-time applications\n\n--- Page 9 ---\no The iterative nature makes it difficult to apply DDPMs in interactive or real-\ntime environments where fast feedback is essential.\n3. Difficulty in controlling outputs\no Without proper conditioning or guidance, the model might produce outputs\nthat are inconsistent with user expectations or desired styles.\n4. Data requirements\no Training DDPMs effectively requires large and diverse datasets to accurately\nlearn noise patterns and recover fine details.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 9
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 21,
      "content": "nconsistent with user expectations or desired styles.\n4. Data requirements\no Training DDPMs effectively requires large and diverse datasets to accurately\nlearn noise patterns and recover fine details.\nENERGY-BASED MODELS(EBMs)\nEnergy-Based Models (EBMs) are a class of probabilistic models that define relationships\nbetween variables using an energy function. Rather than explicitly modeling probability\ndistributions, EBMs assign an “energy” value to each possible configuration of variables,\nwhere lower energy indicates more likely or desirable configurations, and higher energy\ncorresponds to less likely ones.\nEBMs are widely used in machine learning for tasks such as representation learning,\nstructured prediction, anomaly detection, and reinforcement learning, where capturing\nrelationships and constraints between variables is more important than explicitly computing\nprobabilities.\n2. The Concept of Energy in EBMs\n• An energy function E(x)maps an input x to a scalar energy value.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 22,
      "content": "onships and constraints between variables is more important than explicitly computing\nprobabilities.\n2. The Concept of Energy in EBMs\n• An energy function E(x)maps an input x to a scalar energy value.\n• The lower the energy, the more plausible or preferred the data point is according to\nthe model.\n• The probability distribution p(x)is related to the energy via the Boltzmann\ndistribution:\nwhere Z is the partition function:\n• The partition function Z is often intractable, making it difficult to directly compute\nprobabilities, but not necessary for learning.\n\n--- Page 10 ---\n3. Architecture and Working\nCore Components:\n1. Energy Function\no The energy function is typically parameterized by neural networks or other\ndifferentiable models.\no It scores different data configurations to indicate how well they conform to the\ndesired patterns.\n2. Learning Objective\no EBMs learn by comparing the energies of positive (correct) and negative\n(incorrect or unlikely) samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 10
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 23,
      "content": "nfigurations to indicate how well they conform to the\ndesired patterns.\n2. Learning Objective\no EBMs learn by comparing the energies of positive (correct) and negative\n(incorrect or unlikely) samples.\no The goal is to assign lower energy to real data and higher energy to unlikely\ndata.\n3. Training Approaches\no Contrastive Divergence (CD) – Optimizes the model by comparing energy\ndifferences between observed and model-generated samples.\no Score Matching – Matches the gradient of the energy function rather than the\nenergy itself.\no Noise Contrastive Estimation (NCE) – Uses noise samples to help\napproximate the partition function during learning.\n4. Markov Random Fields (MRFs) and Conditional EBMs\n• EBMs are closely related to Markov Random Fields (MRFs), which model\ndependencies between variables using graph structures.\n• Conditional EBMs extend the energy framework to tasks where the output depends\non input features (e.g., image classification, structured output prediction).\n5.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 24,
      "content": "ween variables using graph structures.\n• Conditional EBMs extend the energy framework to tasks where the output depends\non input features (e.g., image classification, structured output prediction).\n5. Applications of EBMs\n1. Unsupervised Learning\no Modeling complex relationships in high-dimensional data such as images,\nspeech, or text.\n2. Anomaly Detection\no Identifying outliers by assigning higher energy to rare or unlikely\nconfigurations.\n3. Reinforcement Learning (RL)\no Estimating value functions where actions with lower energy correspond to\nmore rewarding behaviors.\n4. Generative Modeling\no Generating samples by searching for configurations with low energy, often\nusing sampling algorithms like Langevin dynamics.\n5. Structured Prediction\no Solving problems like image segmentation or sequence labeling where\nrelationships between output variables are important.\n\n--- Page 11 ---\n6. Advantages of EBMs\n• Flexibility – Can model arbitrary dependencies without requiring explicit probabilit",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 11
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 25,
      "content": "uence labeling where\nrelationships between output variables are important.\n\n--- Page 11 ---\n6. Advantages of EBMs\n• Flexibility – Can model arbitrary dependencies without requiring explicit probability\ndistributions.\n• Interpretability – The energy function directly encodes preferences or constraints.\n• Applicability – Useful in domains where structured relationships and constraints\ndominate over simple classification.\n7. Challenges and Limitations\n1. Intractable Partition Function\no Computing ZZZ is often impossible in practice, requiring approximation\ntechniques that can be unstable.\n2. Training Instability\no Optimization methods like contrastive divergence rely on sampling, which can\nlead to slow convergence or poor performance.\n3. Sampling Complexity\no Generating samples requires iterative methods such as Markov Chain Monte\nCarlo (MCMC), which can be computationally expensive.\n4. Scalability Issues\no Handling high-dimensional data with complex energy landscapes is\nchallenging.\n8.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 11
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 26,
      "content": "rative methods such as Markov Chain Monte\nCarlo (MCMC), which can be computationally expensive.\n4. Scalability Issues\no Handling high-dimensional data with complex energy landscapes is\nchallenging.\n8. Recent Advances\n• Neural EBMs – Combining deep learning with energy functions to model high-\ndimensional and structured data more effectively.\n• Score-based Generative Models – Learning the gradient of the energy function to\navoid directly computing the partition function.\n• Applications in Contrastive Learning – EBMs form the backbone of contrastive\napproaches where relationships between samples are emphasized.\n\n--- Page 12 ---\nCOMPARE EBMS VS VAES\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Defined by an energy function\nthat assigns a scalar “energy” to\n- Composed of two main parts: an\neach configuration of inputs (and\nencoder and a decoder.\noptionally outputs).\n- The encoder maps input data to a\n- No explicit probability\nlatent space distribution (typically\ndist",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 12
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 27,
      "content": "two main parts: an\neach configuration of inputs (and\nencoder and a decoder.\noptionally outputs).\n- The encoder maps input data to a\n- No explicit probability\nlatent space distribution (typically\ndistribution; the model learns to\nGaussian).\nassign lower energy to desired\n- The decoder reconstructs data\n✅ Architecture samples and higher energy to\nfrom samples drawn from the latent\nundesired ones.\nspace.\n- Often optimized using contrastive\n- Uses variational inference to\ndivergence or score matching.\napproximate intractable posteriors.\n- The architecture focuses on\n- The architecture explicitly models\nrelationships between data points\ndata generation.\nrather than reconstructing or\ngenerating them directly.\n- Maximize the Evidence Lower\n- Learn an energy landscape where\nBound (ELBO) which balances\ncorrect data points are assigned\nreconstruction accuracy and\nlower energy.\n✅ Objective regularization of the latent space.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 28,
      "content": "Evidence Lower\n- Learn an energy landscape where\nBound (ELBO) which balances\ncorrect data points are assigned\nreconstruction accuracy and\nlower energy.\n✅ Objective regularization of the latent space.\n- Optimization is based on\n- Encourages latent space structure\ndistinguishing good samples from\nfor efficient sampling and\nbad ones.\ninterpolation.\n- Indirect; energy defines the\nlikelihood up to a normalization - Explicit probabilistic framework\nconstant (partition function), which with tractable priors and\n✅ Probabilistic\nis often intractable. approximate posteriors.\nInterpretation\n- Focuses on learning relationships - Can directly sample from the latent\nand constraints rather than full space and model uncertainty.\ndensity estimation.\n- Uses sampling-based methods\nlike Markov Chain Monte Carlo - Uses backpropagation with\n(MCMC), contrastive divergence, reparameterization trick for efficient\n✅ Training\nor score matching. gradient estimation.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 29,
      "content": "mpling-based methods\nlike Markov Chain Monte Carlo - Uses backpropagation with\n(MCMC), contrastive divergence, reparameterization trick for efficient\n✅ Training\nor score matching. gradient estimation.\nMethods\n- Training can be unstable due to - More stable and easier to train\nreliance on sampling and gradient with large datasets.\nestimation.\n- Modeling complex dependencies\nin structured data. - Image and speech generation, data\n- Used in tasks like anomaly compression, anomaly detection,\ndetection, reinforcement learning, and semi-supervised learning.\n✅ Applications\nand unsupervised learning. - Used where interpretable latent\n- Applicable where relationships representations and smooth\nand constraints are more important generation paths are required.\nthan explicit reconstruction.\n\n--- Page 13 ---\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Flexibility in modeling\n- Well-suited for generating new\nrelationships without requiring\ndata samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 13
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 30,
      "content": "onstruction.\n\n--- Page 13 ---\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Flexibility in modeling\n- Well-suited for generating new\nrelationships without requiring\ndata samples.\n✅ Strengths explicit likelihood functions.\n- Provides interpretable latent spaces\n- Can incorporate constraints and\nuseful for downstream tasks.\ndomain knowledge easily.\n- May suffer from blurry\n- Training is computationally\nreconstructions or mode collapse.\nexpensive and less scalable. -\n✅ Limitations - Latent space structure depends\nNormalization constant estimation\nheavily on choice of priors and\nis intractable in many cases.\narchitectures.\nINTRODUCTION TO NOISE SCHEDULERS IN DIFFUSION MODELS\nIn diffusion models, noise plays a central role in transforming structured data into random noise\nduring training and then reconstructing it during sampling. However, how much noise is added\nor removed at each step is not arbitrary—it must be carefully controlled to ensure that the model\nlearns me",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 13
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 31,
      "content": "during training and then reconstructing it during sampling. However, how much noise is added\nor removed at each step is not arbitrary—it must be carefully controlled to ensure that the model\nlearns meaningful patterns and can effectively generate high-quality data.\nThis is where noise schedulers come into play.\nA noise scheduler defines the schedule or strategy by which noise is added to data in the\nforward diffusion process and removed in the backward process. It determines the magnitude\nof noise at each step, shaping how the model degrades and refines information over time.\nThe design of the noise schedule affects several critical aspects:\n• Learning efficiency – Too much noise can obscure important details, while too little\nmay prevent the model from learning to handle uncertainty.\n• Sample diversity and quality – The progression of noise influences how creative or\nrealistic the generated outputs are.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 32,
      "content": "s, while too little\nmay prevent the model from learning to handle uncertainty.\n• Sample diversity and quality – The progression of noise influences how creative or\nrealistic the generated outputs are.\n• Training stability – Gradual noise addition helps avoid erratic learning and ensures\nthat the model can generalize from noisy inputs.\nCommon schedules include linear, cosine, and exponential noise schedules, each offering\ndifferent trade-offs between smoothness, speed, and complexity.\nSignificance of Noise Schedulers in Diffusion Models\nIn diffusion models, noise schedulers determine how noise is added (in the forward process)\nor removed (in the backward process) at each step. They play a critical role in controlling the\nquality, stability, and efficiency of the model during both training and sampling.\nWhy are noise schedulers important?\n1. Control over noise injection\no A noise scheduler defines how much noise is added at each step, influencing\nhow quickly the data degrades from its or",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 33,
      "content": "nd sampling.\nWhy are noise schedulers important?\n1. Control over noise injection\no A noise scheduler defines how much noise is added at each step, influencing\nhow quickly the data degrades from its original form to pure noise.\n\n--- Page 14 ---\no A carefully designed schedule ensures that the model learns meaningful\ntransformations at each step rather than abrupt or overly noisy transitions.\n2. Balance between learning and randomness\no If noise is added too aggressively, the model may struggle to learn how to\nrecover the data because too much information is lost early.\no If noise is too weak, the model may not generalize well and could overfit to\nspecific patterns without learning how to handle uncertainty.\n3. Smooth transitions\no Gradual noise addition allows the model to capture complex patterns and fine\ndetails at different noise levels, helping the backward process refine the data\neffectively.\n4.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 14
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 34,
      "content": "ty.\n3. Smooth transitions\no Gradual noise addition allows the model to capture complex patterns and fine\ndetails at different noise levels, helping the backward process refine the data\neffectively.\n4. Influences sample quality and diversity\no The noise schedule affects the kinds of outputs the model generates. For\ninstance, a slower noise increase might produce high-fidelity samples, while a\nfaster schedule might encourage more diverse and creative outputs.\n5. Stabilizes training\no Appropriate noise scheduling prevents extreme gradients or erratic learning\nbehavior, enabling stable and efficient training across large datasets.\n✅ Example of a commonly used noise scheduler: Linear noise schedule\nOne widely used noise scheduler is the linear noise schedule, where the noise level increases\nat a constant rate across steps.\n• The noise added at each step t is computed as:\nwhere:\no β start is the initial noise amount,\no β end is the final noise amount,\no T is the total number of steps.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 35,
      "content": "ses\nat a constant rate across steps.\n• The noise added at each step t is computed as:\nwhere:\no β start is the initial noise amount,\no β end is the final noise amount,\no T is the total number of steps.\nWhy it's used:\n• Simplicity – easy to implement and analyze.\n• Gradual degradation – ensures smooth transitions from structured data to noise.\n• Works well in practice for a variety of tasks without requiring complex tuning.\n✅ Other common noise schedules\n• Cosine schedule – Uses a cosine curve to control noise increments, adding noise\nmore smoothly at the beginning and end.\n\n--- Page 15 ---\n• Exponential schedule – Adds noise in a way that accelerates or decelerates across\nsteps, providing more control over learning phases.\nComparison between Class-Conditional Diffusion Models and Unconditional Diffusion\nModels\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\nDiffusion models where the generation\nDiffusion models that generate data\nprocess is guided by class label",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 15
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 36,
      "content": "nal Diffusion\nModels\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\nDiffusion models where the generation\nDiffusion models that generate data\nprocess is guided by class labels or\npurely based on learned distributions\nadditional conditioning information (e.g.,\n✅ Definition without any conditioning information.\ntext, attributes). The model learns how the\nThe model only depends on noise and\ndata distribution changes for different\nthe learned data distribution.\nclasses.\n- Incorporates class labels or auxiliary\ninputs into the noise prediction network.\n- Contains only the noise prediction\n- Conditioning is usually done by\nnetwork without any external inputs.\nconcatenating labels or through\n✅ - Learns the general structure and\nembeddings that influence intermediate\nArchitecture distribution of the entire dataset.\nlayers.\n- Generates samples based on noise\n- The model learns separate modes of the\nwithout class-specific guidance.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 37,
      "content": "ddings that influence intermediate\nArchitecture distribution of the entire dataset.\nlayers.\n- Generates samples based on noise\n- The model learns separate modes of the\nwithout class-specific guidance.\ndata distribution for each class or\ncondition.\n- Learn how to denoise while respecting - Learn to denoise without any guidance\nclass information. other than the underlying data\n✅ Training - The model minimizes the reconstruction distribution.\nObjective loss while conditioning on the class, - The model focuses on general patterns\nensuring generated samples match the and statistical relationships in the\ntarget category. dataset.\n- During generation, class labels guide the\n- Generates samples from noise without\nsampling process, allowing control over\ncontrol over attributes or categories.\n✅ Sampling what kind of sample is generated (e.g., a\n- Produces diverse outputs but without\ncat vs. a dog image).\nspecific guidance.\n- Can produce targeted, structured outputs.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 38,
      "content": "tributes or categories.\n✅ Sampling what kind of sample is generated (e.g., a\n- Produces diverse outputs but without\ncat vs. a dog image).\nspecific guidance.\n- Can produce targeted, structured outputs.\n- Image synthesis conditioned on class\nlabels (e.g., generating specific objects or - General image, audio, or video\nfaces). generation where control is not\n✅ - Text-to-image generation, style transfer, necessary.\nApplications or scenarios requiring targeted outputs. - Data augmentation, unsupervised\n- Semi-supervised learning where learning, and exploratory creative\nadditional information improves generation generation.\nquality.\n- Greater control over generated samples.\n✅ - Can produce outputs tailored to specific - Simpler architecture and easier to\nAdvantages tasks or user inputs. implement.\n- More interpretable generation process. - Requires less labeled data.\n\n--- Page 16 ---\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\n- Capable of learning diverse patter",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 16
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 39,
      "content": "t.\n- More interpretable generation process. - Requires less labeled data.\n\n--- Page 16 ---\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\n- Capable of learning diverse patterns\nfrom large, unstructured datasets.\n- Requires labeled data or conditioning\n- Lacks control over generated content.\n✅ inputs, which may not always be available.\n- May produce irrelevant or ambiguous\nLimitations - More complex architecture and higher\noutputs when diverse patterns overlap.\ncomputational cost.\nDDIM (DENOISING DIFFUSION IMPLICIT MODELS)\nDDIM (Denoising Diffusion Implicit Models) is an improvement over standard diffusion\nmodels like DDPM (Denoising Diffusion Probabilistic Models). It introduces a new sampling\nmethod that allows generating high-quality samples with significantly fewer steps, while still\nretaining diversity and structure in the outputs.\n✅ Why DDIM was introduced\n1.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 16
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 40,
      "content": "introduces a new sampling\nmethod that allows generating high-quality samples with significantly fewer steps, while still\nretaining diversity and structure in the outputs.\n✅ Why DDIM was introduced\n1. Reduce Sampling Time\no Traditional diffusion models like DDPM require hundreds or thousands of\nsteps during sampling, which makes them computationally expensive and slow\nfor practical applications.\n2. Maintain Quality and Diversity\no Simply reducing steps in DDPM leads to degraded or less diverse outputs.\no DDIM proposes a deterministic or pseudo-deterministic approach that\nmaintains high sample fidelity even with fewer steps.\n✅ How DDIM works\n1. Implicit Sampling\no Instead of following the stochastic reverse process of DDPM, DDIM defines a\ndeterministic mapping between noise and data, reducing randomness during\nsampling.\no The model avoids resampling at each step, making it faster and more stable.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 41,
      "content": "erse process of DDPM, DDIM defines a\ndeterministic mapping between noise and data, reducing randomness during\nsampling.\no The model avoids resampling at each step, making it faster and more stable.\n2. Non-Markovian Transitions\no Unlike DDPM where each step depends only on the previous one (Markov\nproperty), DDIM relaxes this assumption by allowing steps that depend on\nearlier states.\no This enables more flexible transitions and faster sampling while preserving\nsample quality.\n3. Controlled Interpolation\no DDIM allows interpolation between different noise levels and samples, which\ncan be used for creative applications like style mixing or smooth transitions.\n\n--- Page 17 ---\n✅ Key Differences from DDPM\nFeature DDPM DDIM\nStochastic, follows Markov chain with Deterministic or pseudo-deterministic,\nSampling process\nrandom transitions with fewer steps\nComputational\nHigh due to many sampling steps Much lower with accelerated sampling\ncost\nCan explore a wide range of outputs due Maintains div",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 17
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 42,
      "content": "stic,\nSampling process\nrandom transitions with fewer steps\nComputational\nHigh due to many sampling steps Much lower with accelerated sampling\ncost\nCan explore a wide range of outputs due Maintains diversity but with controlled\nDiversity\nto randomness noise patterns\nSuitable for tasks needing rich Better for fast generation and interactive\nUse case\nexploration applications\n✅ Mathematical Insight\nIn DDPM, the reverse process is modeled as a probabilistic sampling from p(x ∣x), where\nt−1 t\nrandomness is inherent at each step.\nIn DDIM, a deterministic transition is defined:\nHere:\n• α t defines how much signal is preserved at each step.\n• ϵ θ (x t ,t) is the model’s learned noise prediction.\nThis formulation allows skipping intermediate steps while still approximating the\nreverse trajectory.\n✅ Applications of DDIM\n1. Image Generation\no Produces high-resolution images quickly without compromising on details.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 43,
      "content": "s skipping intermediate steps while still approximating the\nreverse trajectory.\n✅ Applications of DDIM\n1. Image Generation\no Produces high-resolution images quickly without compromising on details.\n2. Video and Audio Synthesis\no Enables faster generation for time-sensitive applications like animation or\nsound design.\n3. Style Transfer & Interpolation\no Smoothly blends between samples by manipulating latent noise patterns\ndeterministically.\n4. Interactive Tools\no Supports real-time editing and creative workflows where speed and control are\ncritical.\n\n--- Page 18 ---\n✅ Advantages of DDIM\n✔ Faster sampling with fewer steps\n✔ Stable and high-quality outputs\n✔ Supports interpolation and controlled generation\n✔ Reduces computational cost without major trade-offs in realism\n✅ Limitations of DDIM\n❗ May lose some diversity due to reduced randomness\n❗ Requires careful tuning of schedules and noise levels\n❗ Still dependent on well-trained models to perform effectively\n✅ Conclusion\nDDIM is a power",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 18
    },
    {
      "doc_id": "tmp6b5qb6dw_UNIT I - GCV NOTES.pdf_a0a003d3_2dc0361f",
      "chunk_index": 44,
      "content": "❗ May lose some diversity due to reduced randomness\n❗ Requires careful tuning of schedules and noise levels\n❗ Still dependent on well-trained models to perform effectively\n✅ Conclusion\nDDIM is a powerful extension of diffusion models that addresses one of their biggest\nlimitations—slow sampling—by introducing deterministic or semi-deterministic transitions.\nIt enables faster generation while maintaining sample fidelity and diversity, making it highly\nsuitable for real-world applications like image synthesis, animation, and interactive creative\ntools.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nDIFFUSION MODELS\nDiffusion models are a type of generative AI that create new data like images, audio or even\nvideo by starting with random noise and gradually turning it into something meaningful. They\nwork by simulating a diffusion process where data is slowly corrupted by noise during\ntraining and then learning to reverse this process step by step. By doing so the model learns\nhow to generate high quality samples from scratch.\nUnderstanding Diffusion Models\n• Diffusion models are generative models that learn to reverse a diffusion process to\ngenerate data. The diffusion process involves gradually adding noise to data until it\nbecomes pure noise.\n• Through this process a simple distribution is transformed into a complex data distribution\nin a series of small incremental steps.\n• Essentially these models operate as a reverse diffusion phenomenon where noise is\nintroduced to the data in a forward manner and removed in a reverse manner to generate\nnew data samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 1
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 1,
      "content": "ntal steps.\n• Essentially these models operate as a reverse diffusion phenomenon where noise is\nintroduced to the data in a forward manner and removed in a reverse manner to generate\nnew data samples.\n• By learning to reverse this process diffusion models start from noise and gradually\ndenoise it to produce data that closely resembles the training examples.\nKey Components\n1. Forward Diffusion Process: This process involves adding noise to the data in a series of\nsmall steps. Each step slightly increases the noise, making the data progressively more\nrandom until it resembles pure noise.\n2. Reverse Diffusion Process: The model learns to reverse the noise-adding steps. Starting\nfrom pure noise, the model iteratively removes the noise, generating data that matches\nthe training distribution.\n3. Score Function: This function estimates the gradient of the data distribution concerning\nthe noise. It helps guide the reverse diffusion process to produce realistic samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 2,
      "content": "training distribution.\n3. Score Function: This function estimates the gradient of the data distribution concerning\nthe noise. It helps guide the reverse diffusion process to produce realistic samples.\n\n--- Page 2 ---\nArchitecture of Diffusion Models\nThe architecture of diffusion models typically involves two main components:\n1. Forward Diffusion Process\n2. Reverse Diffusion Process\n1. Forward Diffusion Process\nIn this process noise is incrementally added to the data over a series of steps. This is akin to\na Markov chain where each step slightly degrades the data by adding Gaussian noise.\nForward Diffusion P\nMathematically, this can be represented as:\nwhere,\n• xt is the noisy data at step t\n• αt controls the amount of noise added.\n2. Reverse Diffusion Process\nThe reverse process aims to reconstruct the original data by denoising the noisy data in a\nseries of steps reversing the forward diffusion.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 2
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 3,
      "content": "rols the amount of noise added.\n2. Reverse Diffusion Process\nThe reverse process aims to reconstruct the original data by denoising the noisy data in a\nseries of steps reversing the forward diffusion.\nReverse Diffusion Process\nThis is typically modelled using a neural network that predicts the noise added at each step:\nwhere,\n• μθ and σθ are learned parameters.\nWorking Principle of Diffusion Models\nDuring training the model learns to predict the noise added at each step of the forward\nprocess. This is done by minimizing a loss function that measures the difference between the\npredicted and actual noise.\nForward Process (Diffusion)\n• The forward process involves gradually corrupting the data x0 with Gaussian noise over\na sequence of time steps\n• Let xt represent the noisy data at time step t. The process is defined as:\n• where βt is the noise schedule that controls the amount of noise added at each step and ϵ is\nis Gaussian noise.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 4,
      "content": "ime steps\n• Let xt represent the noisy data at time step t. The process is defined as:\n• where βt is the noise schedule that controls the amount of noise added at each step and ϵ is\nis Gaussian noise.\n\n--- Page 3 ---\n• As t increases, xt becomes more noisy until it approximates a Gaussian distribution.\nReverse Process (Denoising)\n• The reverse process aims to reconstruct the original data x0x0 from the noisy data xT at\nthe final time step T.\n• This process is modelled using a neural network to approximate the conditional\nprobability pθ(xt−1∣xt).\n• The reverse process can be formulated as:\n• where ϵθ is a neural network parameterized by θ that predicts the noise.\nTraining Diffusion Models\n• The training objective for diffusion models involves minimizing the difference between\nthe true noise ϵ added in the forward process and the noise predicted by the neural\nnetwork ϵθ.\n• The score function which estimates the gradient of the data distribution concerning the\nnoise plays an important rol",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 3
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 5,
      "content": "ϵ added in the forward process and the noise predicted by the neural\nnetwork ϵθ.\n• The score function which estimates the gradient of the data distribution concerning the\nnoise plays an important role in guiding the reverse process.\n• The loss function is typically the mean squared error (MSE) between these two quantities:\n• This encourages the model to accurately predict the noise and, consequently, to denoise\neffectively during the reverse process.\nIn diffusion models, both the forward and backward processes are modeled as a sequence of\nsmall incremental steps rather than a single transformation. This sequential approach is\ncrucial because:\n1. Gradual Learning – By breaking the process into many steps, the model learns how\nto handle slight changes at each stage, making it easier to reverse the noise addition. If\nit tried to denoise from a fully noisy image in one step, it would struggle to map the\nrandom noise back to structured data.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 6,
      "content": "hanges at each stage, making it easier to reverse the noise addition. If\nit tried to denoise from a fully noisy image in one step, it would struggle to map the\nrandom noise back to structured data.\n2. Stability in Training – Learning through small denoising steps prevents abrupt\ntransitions, reducing the chances of errors or divergence during training. It ensures\nthat the model refines its predictions slowly, stabilizing gradients and allowing\nconsistent improvements.\n3. Better Control Over Generation – The step-wise nature allows the model to be\nsampled at different stages, offering control over how much noise to remove or retain.\nThis is especially useful in VR environments, where designers might want to balance\nrealism with creativity.\n4. Avoiding Catastrophic Forgetting – Incremental denoising reinforces the learning at\nevery step, ensuring that earlier patterns are not forgotten as the model progresses\ntoward generating complex outputs.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 7,
      "content": "iding Catastrophic Forgetting – Incremental denoising reinforces the learning at\nevery step, ensuring that earlier patterns are not forgotten as the model progresses\ntoward generating complex outputs.\n\n--- Page 4 ---\nThus, modeling the forward and backward processes as a sequence of steps ensures that\nlearning is smooth, robust, and interpretable, ultimately allowing the system to produce high-\nquality, stable, and realistic images from rough sketches.\nNoise plays a central role in the diffusion process, and carefully adjusting it can significantly\ninfluence the outcomes:\n1. Higher Noise Levels\no Encourages diverse outputs because the model explores a wider range of\npossibilities when starting from more random data.\no Useful for generating creative or artistic VR landscapes where uniqueness is\ndesired.\no However, if the noise is too high, the generated images may lose structure or\ncoherence, reducing realism.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 4
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 8,
      "content": "o Useful for generating creative or artistic VR landscapes where uniqueness is\ndesired.\no However, if the noise is too high, the generated images may lose structure or\ncoherence, reducing realism.\n2. Lower Noise Levels\no Helps maintain realism and fidelity because the model starts closer to\nstructured patterns, making it easier to produce clear and consistent images.\no Best suited for VR environments where accuracy, recognizable objects, and\nrealistic textures are essential.\no It may, however, limit creativity and diversity since the outputs are\nconstrained to follow the training data closely.\n3. Noise Scheduling\no Adjusting how noise is added or removed across steps (e.g., linear,\nexponential, cosine schedules) allows fine-tuning between exploration and\nrefinement.\no Designers can control whether the model produces subtle variations or\nradically different landscapes.\n4. Application in VR Systems\no For immersive experiences, higher noise levels at early steps can generate\nunpredictabl",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 9,
      "content": "l whether the model produces subtle variations or\nradically different landscapes.\n4. Application in VR Systems\no For immersive experiences, higher noise levels at early steps can generate\nunpredictable and novel environments, while later steps can be fine-tuned with\nlower noise to ensure realistic details.\no This balance allows users to start with abstract sketches and transform them\ninto believable virtual worlds that retain creativity without sacrificing\ncoherence.\n\n--- Page 5 ---\nDENOISING DIFFUSION PROBABILISTIC MODEL (DDPM)\nWhat are DDPMs?\nThey are a class of generative models that work by iteratively adding noise to an input signal\n(like an image, text, or audio) and then learning to denoise from the noisy signal to generate\nnew samples.\nGenerative models\nAre a type of model that can generate new data instances. Previously, machine learning models\nhave done a good job of learning differences in data and then making predictions or\nclassification tasks.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 5
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 10,
      "content": "Are a type of model that can generate new data instances. Previously, machine learning models\nhave done a good job of learning differences in data and then making predictions or\nclassification tasks. For example, a model trained on a digits dataset like MNIST can recognize\na 0 from a 1. Generative models, on the other hand, learn the distribution of digits and can create\na “fake digit” which closely resembles a real digit.\nA Denoising Diffusion Probabilistic Model (DDPM) is a type of generative model that\ncreates realistic images by learning how to progressively refine noisy data. It works in two\nphases:\n1. Forward Process (Noise Addition) – The model gradually adds random noise to a\nclean image over many steps until the image becomes indistinguishable from noise.\n2. Backward Process (Denoising) – The model learns to reverse this process by\npredicting how to remove noise at each step, eventually reconstructing a high-quality\nimage from random noise or a rough input.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 11,
      "content": "ckward Process (Denoising) – The model learns to reverse this process by\npredicting how to remove noise at each step, eventually reconstructing a high-quality\nimage from random noise or a rough input.\nThe model is called probabilistic because it doesn’t rely on a single deterministic\ntransformation but instead learns the distribution of possible images at each stage of noise\nand denoising. This approach allows it to generate diverse, high-fidelity images by sampling\nfrom the learned distribution.\n\n--- Page 6 ---\nKey Features of DDPM:\n• Iterative Refinement – Instead of transforming an image in one step, it uses many\nsmall steps, making it easier to model complex patterns.\n• Noise-Based Learning – By learning how images degrade with noise, the model\nunderstands how to reverse this degradation to recreate details.\n• Probabilistic Nature – It generates a range of plausible outputs rather than a single\nfixed result, which is useful in creative tasks like animation.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 6
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 12,
      "content": "to reverse this degradation to recreate details.\n• Probabilistic Nature – It generates a range of plausible outputs rather than a single\nfixed result, which is useful in creative tasks like animation.\n• Flexibility – DDPMs can be applied to various tasks such as image synthesis, super-\nresolution, and in your case, converting rough sketches into fully rendered scenes.\nForward and Backward Diffusion Process\nThe forward diffusion process is the initial phase in a DDPM where noise is incrementally\nadded to clean data over many steps. The purpose is to teach the model how data transitions\nfrom structured and detailed forms into randomness.\nKey steps involved:\n1. Starting with clean data – At the beginning, the model takes real data such as an\nimage or signal that contains structured information like shapes, textures, and\npatterns.\n2. Adding noise at each step – Gaussian noise is added to the data in small amounts\nover a sequence of steps. The noise schedule (linear, cosine, etc.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 13,
      "content": "information like shapes, textures, and\npatterns.\n2. Adding noise at each step – Gaussian noise is added to the data in small amounts\nover a sequence of steps. The noise schedule (linear, cosine, etc.) controls how much\nnoise is added at each step.\n3. Progressive degradation – The data becomes increasingly noisy at every step.\nInitially, the patterns are still recognizable, but as the process continues, the structure\ndisappears, and the data looks like random noise.\n4. Mathematical formulation – At step t, the noisy data x is derived from the previous\nt\nstep x by sampling from a normal distribution:\nt−1\nwhere α controls the amount of retained information and ϵ is sampled from a normal\nt\ndistribution.\nWhy this step is essential:\n• It exposes the model to how real data deteriorates with noise.\n• It creates a learning path for the model to understand the inverse operation—\nrecovering the data from noisy versions.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 14,
      "content": "is essential:\n• It exposes the model to how real data deteriorates with noise.\n• It creates a learning path for the model to understand the inverse operation—\nrecovering the data from noisy versions.\n• It ensures that the model can generalize to varying noise levels and recover details\nfrom incomplete or corrupted data.\n\n--- Page 7 ---\nRole of the Markov Chain in the Forward Diffusion Process of a DDPM\nIn a Denoising Diffusion Probabilistic Model (DDPM), the forward diffusion process\ninvolves gradually adding noise to clean data over multiple steps. This process is modeled as\na Markov chain, which plays a crucial role in structuring how noise is added.\nA Markov chain is a mathematical system that transitions from one state to another, where\nthe next state depends only on the current state and not on the entire history of past states. In\nthe context of DDPM’s forward diffusion process, this means:\n1.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 7
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 15,
      "content": "tions from one state to another, where\nthe next state depends only on the current state and not on the entire history of past states. In\nthe context of DDPM’s forward diffusion process, this means:\n1. Stepwise progression\no At each time step ttt, noise is added based only on the data at that step\n(xt−1x_{t-1}xt−1), not on earlier steps. This simplifies the process and\nensures that each step depends only on the immediately preceding one.\n2. Controlled noise addition\no The amount of noise added at each step is determined by a known noise\nschedule, ensuring that the transition from structured data to noise is smooth\nand gradual.\n3. Mathematical tractability\no By assuming that each step depends only on the previous step, the forward\nprocess becomes easier to analyze, simulate, and invert during training.\nHow does it help structure the noise addition steps?\n1. Simplifies modeling\no The Markov assumption allows the model to focus on learning local\ntransitions rather than global dependencies,",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 16,
      "content": "g training.\nHow does it help structure the noise addition steps?\n1. Simplifies modeling\no The Markov assumption allows the model to focus on learning local\ntransitions rather than global dependencies, making the noise addition process\ncomputationally feasible.\n2. Ensures gradual degradation\no The structured, stepwise approach ensures that noise is added progressively,\npreserving information early on and fully randomizing the data at later steps.\n3. Supports efficient training\no The Markov property allows the use of recursive formulations where each\nnoisy sample can be derived from the previous one using simple equations,\nfacilitating optimization and gradient computation.\n4. Enables inversion during sampling\no Since each step only depends on the previous one, the backward process\n(denoising) can also be structured in the same stepwise manner, allowing the\nmodel to learn how to reverse the process reliably.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 17,
      "content": "Since each step only depends on the previous one, the backward process\n(denoising) can also be structured in the same stepwise manner, allowing the\nmodel to learn how to reverse the process reliably.\nThe backward diffusion process is where the model learns to reverse the noise addition and\nreconstruct the original or new data from noisy inputs.\nKey aspects:\n1. Predicting the noise – At each step, the model is trained to estimate the noise that\nwas added in the forward process. It learns how the noisy data differs from its clean\nversion and tries to correct it.\n\n--- Page 8 ---\n2. Iterative refinement – Starting from pure noise, the model removes noise\nprogressively by applying its learned knowledge of patterns at each step. Over time,\nthe image or data becomes clearer and more structured.\n3. Learning objective – The model is optimized to minimize the difference between the\npredicted noise and the actual noise added during training.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 8
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 18,
      "content": "the image or data becomes clearer and more structured.\n3. Learning objective – The model is optimized to minimize the difference between the\npredicted noise and the actual noise added during training. This is typically done\nusing a loss function like Mean Squared Error (MSE).\n4. Sampling during generation – Once trained, the model can start from random noise\nand iteratively apply the backward process to generate new, realistic data samples.\nWhy this process is critical:\n• It allows the model to reconstruct missing or noisy details.\n• It ensures that the output is consistent with real-world data distributions.\n• It provides control over the generation process by using learned probabilities rather\nthan rigid rules.\nThe probabilistic nature of DDPM plays a central role in its ability to generate both diverse\nand high-quality outputs.\nWhy probabilistic modeling is useful?\n1. Learning distributions rather than fixed mappings\no Instead of learning a direct transformation from input to output",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 19,
      "content": "ate both diverse\nand high-quality outputs.\nWhy probabilistic modeling is useful?\n1. Learning distributions rather than fixed mappings\no Instead of learning a direct transformation from input to output, the model\nlearns the underlying distribution of possible clean data conditioned on noisy\ninputs.\no This enables the model to handle uncertainty and variations present in real\ndata.\n2. Sampling from distributions\no During generation, the model samples noise from a distribution at each step.\nEven with the same input, different random samples produce varied outputs,\npromoting creativity and diversity.\n3. Capturing subtle patterns\no Probabilistic modeling allows the model to learn nuanced relationships in the\ndata such as textures, lighting patterns, or variations in shape that are hard to\ncapture with deterministic methods.\n4. Balancing realism and exploration\no By controlling the noise level and how it’s modeled, the system can explore\nnew possibilities while staying within the realm of re",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 20,
      "content": "re with deterministic methods.\n4. Balancing realism and exploration\no By controlling the noise level and how it’s modeled, the system can explore\nnew possibilities while staying within the realm of realistic outputs. This is\ncrucial for applications like design, simulation, and data augmentation.\nChallenges:\n1. High computational cost\no Because the process involves many steps (often hundreds or thousands),\ngenerating data can be slow and resource-intensive.\n2. Latency issues in real-time applications\n\n--- Page 9 ---\no The iterative nature makes it difficult to apply DDPMs in interactive or real-\ntime environments where fast feedback is essential.\n3. Difficulty in controlling outputs\no Without proper conditioning or guidance, the model might produce outputs\nthat are inconsistent with user expectations or desired styles.\n4. Data requirements\no Training DDPMs effectively requires large and diverse datasets to accurately\nlearn noise patterns and recover fine details.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 9
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 21,
      "content": "nconsistent with user expectations or desired styles.\n4. Data requirements\no Training DDPMs effectively requires large and diverse datasets to accurately\nlearn noise patterns and recover fine details.\nENERGY-BASED MODELS(EBMs)\nEnergy-Based Models (EBMs) are a class of probabilistic models that define relationships\nbetween variables using an energy function. Rather than explicitly modeling probability\ndistributions, EBMs assign an “energy” value to each possible configuration of variables,\nwhere lower energy indicates more likely or desirable configurations, and higher energy\ncorresponds to less likely ones.\nEBMs are widely used in machine learning for tasks such as representation learning,\nstructured prediction, anomaly detection, and reinforcement learning, where capturing\nrelationships and constraints between variables is more important than explicitly computing\nprobabilities.\n2. The Concept of Energy in EBMs\n• An energy function E(x)maps an input x to a scalar energy value.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 22,
      "content": "onships and constraints between variables is more important than explicitly computing\nprobabilities.\n2. The Concept of Energy in EBMs\n• An energy function E(x)maps an input x to a scalar energy value.\n• The lower the energy, the more plausible or preferred the data point is according to\nthe model.\n• The probability distribution p(x)is related to the energy via the Boltzmann\ndistribution:\nwhere Z is the partition function:\n• The partition function Z is often intractable, making it difficult to directly compute\nprobabilities, but not necessary for learning.\n\n--- Page 10 ---\n3. Architecture and Working\nCore Components:\n1. Energy Function\no The energy function is typically parameterized by neural networks or other\ndifferentiable models.\no It scores different data configurations to indicate how well they conform to the\ndesired patterns.\n2. Learning Objective\no EBMs learn by comparing the energies of positive (correct) and negative\n(incorrect or unlikely) samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 10
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 23,
      "content": "nfigurations to indicate how well they conform to the\ndesired patterns.\n2. Learning Objective\no EBMs learn by comparing the energies of positive (correct) and negative\n(incorrect or unlikely) samples.\no The goal is to assign lower energy to real data and higher energy to unlikely\ndata.\n3. Training Approaches\no Contrastive Divergence (CD) – Optimizes the model by comparing energy\ndifferences between observed and model-generated samples.\no Score Matching – Matches the gradient of the energy function rather than the\nenergy itself.\no Noise Contrastive Estimation (NCE) – Uses noise samples to help\napproximate the partition function during learning.\n4. Markov Random Fields (MRFs) and Conditional EBMs\n• EBMs are closely related to Markov Random Fields (MRFs), which model\ndependencies between variables using graph structures.\n• Conditional EBMs extend the energy framework to tasks where the output depends\non input features (e.g., image classification, structured output prediction).\n5.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 24,
      "content": "ween variables using graph structures.\n• Conditional EBMs extend the energy framework to tasks where the output depends\non input features (e.g., image classification, structured output prediction).\n5. Applications of EBMs\n1. Unsupervised Learning\no Modeling complex relationships in high-dimensional data such as images,\nspeech, or text.\n2. Anomaly Detection\no Identifying outliers by assigning higher energy to rare or unlikely\nconfigurations.\n3. Reinforcement Learning (RL)\no Estimating value functions where actions with lower energy correspond to\nmore rewarding behaviors.\n4. Generative Modeling\no Generating samples by searching for configurations with low energy, often\nusing sampling algorithms like Langevin dynamics.\n5. Structured Prediction\no Solving problems like image segmentation or sequence labeling where\nrelationships between output variables are important.\n\n--- Page 11 ---\n6. Advantages of EBMs\n• Flexibility – Can model arbitrary dependencies without requiring explicit probabilit",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 11
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 25,
      "content": "uence labeling where\nrelationships between output variables are important.\n\n--- Page 11 ---\n6. Advantages of EBMs\n• Flexibility – Can model arbitrary dependencies without requiring explicit probability\ndistributions.\n• Interpretability – The energy function directly encodes preferences or constraints.\n• Applicability – Useful in domains where structured relationships and constraints\ndominate over simple classification.\n7. Challenges and Limitations\n1. Intractable Partition Function\no Computing ZZZ is often impossible in practice, requiring approximation\ntechniques that can be unstable.\n2. Training Instability\no Optimization methods like contrastive divergence rely on sampling, which can\nlead to slow convergence or poor performance.\n3. Sampling Complexity\no Generating samples requires iterative methods such as Markov Chain Monte\nCarlo (MCMC), which can be computationally expensive.\n4. Scalability Issues\no Handling high-dimensional data with complex energy landscapes is\nchallenging.\n8.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 11
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 26,
      "content": "rative methods such as Markov Chain Monte\nCarlo (MCMC), which can be computationally expensive.\n4. Scalability Issues\no Handling high-dimensional data with complex energy landscapes is\nchallenging.\n8. Recent Advances\n• Neural EBMs – Combining deep learning with energy functions to model high-\ndimensional and structured data more effectively.\n• Score-based Generative Models – Learning the gradient of the energy function to\navoid directly computing the partition function.\n• Applications in Contrastive Learning – EBMs form the backbone of contrastive\napproaches where relationships between samples are emphasized.\n\n--- Page 12 ---\nCOMPARE EBMS VS VAES\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Defined by an energy function\nthat assigns a scalar “energy” to\n- Composed of two main parts: an\neach configuration of inputs (and\nencoder and a decoder.\noptionally outputs).\n- The encoder maps input data to a\n- No explicit probability\nlatent space distribution (typically\ndist",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 12
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 27,
      "content": "two main parts: an\neach configuration of inputs (and\nencoder and a decoder.\noptionally outputs).\n- The encoder maps input data to a\n- No explicit probability\nlatent space distribution (typically\ndistribution; the model learns to\nGaussian).\nassign lower energy to desired\n- The decoder reconstructs data\n✅ Architecture samples and higher energy to\nfrom samples drawn from the latent\nundesired ones.\nspace.\n- Often optimized using contrastive\n- Uses variational inference to\ndivergence or score matching.\napproximate intractable posteriors.\n- The architecture focuses on\n- The architecture explicitly models\nrelationships between data points\ndata generation.\nrather than reconstructing or\ngenerating them directly.\n- Maximize the Evidence Lower\n- Learn an energy landscape where\nBound (ELBO) which balances\ncorrect data points are assigned\nreconstruction accuracy and\nlower energy.\n✅ Objective regularization of the latent space.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 28,
      "content": "Evidence Lower\n- Learn an energy landscape where\nBound (ELBO) which balances\ncorrect data points are assigned\nreconstruction accuracy and\nlower energy.\n✅ Objective regularization of the latent space.\n- Optimization is based on\n- Encourages latent space structure\ndistinguishing good samples from\nfor efficient sampling and\nbad ones.\ninterpolation.\n- Indirect; energy defines the\nlikelihood up to a normalization - Explicit probabilistic framework\nconstant (partition function), which with tractable priors and\n✅ Probabilistic\nis often intractable. approximate posteriors.\nInterpretation\n- Focuses on learning relationships - Can directly sample from the latent\nand constraints rather than full space and model uncertainty.\ndensity estimation.\n- Uses sampling-based methods\nlike Markov Chain Monte Carlo - Uses backpropagation with\n(MCMC), contrastive divergence, reparameterization trick for efficient\n✅ Training\nor score matching. gradient estimation.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 29,
      "content": "mpling-based methods\nlike Markov Chain Monte Carlo - Uses backpropagation with\n(MCMC), contrastive divergence, reparameterization trick for efficient\n✅ Training\nor score matching. gradient estimation.\nMethods\n- Training can be unstable due to - More stable and easier to train\nreliance on sampling and gradient with large datasets.\nestimation.\n- Modeling complex dependencies\nin structured data. - Image and speech generation, data\n- Used in tasks like anomaly compression, anomaly detection,\ndetection, reinforcement learning, and semi-supervised learning.\n✅ Applications\nand unsupervised learning. - Used where interpretable latent\n- Applicable where relationships representations and smooth\nand constraints are more important generation paths are required.\nthan explicit reconstruction.\n\n--- Page 13 ---\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Flexibility in modeling\n- Well-suited for generating new\nrelationships without requiring\ndata samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 13
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 30,
      "content": "onstruction.\n\n--- Page 13 ---\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Flexibility in modeling\n- Well-suited for generating new\nrelationships without requiring\ndata samples.\n✅ Strengths explicit likelihood functions.\n- Provides interpretable latent spaces\n- Can incorporate constraints and\nuseful for downstream tasks.\ndomain knowledge easily.\n- May suffer from blurry\n- Training is computationally\nreconstructions or mode collapse.\nexpensive and less scalable. -\n✅ Limitations - Latent space structure depends\nNormalization constant estimation\nheavily on choice of priors and\nis intractable in many cases.\narchitectures.\nINTRODUCTION TO NOISE SCHEDULERS IN DIFFUSION MODELS\nIn diffusion models, noise plays a central role in transforming structured data into random noise\nduring training and then reconstructing it during sampling. However, how much noise is added\nor removed at each step is not arbitrary—it must be carefully controlled to ensure that the model\nlearns me",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 13
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 31,
      "content": "during training and then reconstructing it during sampling. However, how much noise is added\nor removed at each step is not arbitrary—it must be carefully controlled to ensure that the model\nlearns meaningful patterns and can effectively generate high-quality data.\nThis is where noise schedulers come into play.\nA noise scheduler defines the schedule or strategy by which noise is added to data in the\nforward diffusion process and removed in the backward process. It determines the magnitude\nof noise at each step, shaping how the model degrades and refines information over time.\nThe design of the noise schedule affects several critical aspects:\n• Learning efficiency – Too much noise can obscure important details, while too little\nmay prevent the model from learning to handle uncertainty.\n• Sample diversity and quality – The progression of noise influences how creative or\nrealistic the generated outputs are.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 32,
      "content": "s, while too little\nmay prevent the model from learning to handle uncertainty.\n• Sample diversity and quality – The progression of noise influences how creative or\nrealistic the generated outputs are.\n• Training stability – Gradual noise addition helps avoid erratic learning and ensures\nthat the model can generalize from noisy inputs.\nCommon schedules include linear, cosine, and exponential noise schedules, each offering\ndifferent trade-offs between smoothness, speed, and complexity.\nSignificance of Noise Schedulers in Diffusion Models\nIn diffusion models, noise schedulers determine how noise is added (in the forward process)\nor removed (in the backward process) at each step. They play a critical role in controlling the\nquality, stability, and efficiency of the model during both training and sampling.\nWhy are noise schedulers important?\n1. Control over noise injection\no A noise scheduler defines how much noise is added at each step, influencing\nhow quickly the data degrades from its or",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 33,
      "content": "nd sampling.\nWhy are noise schedulers important?\n1. Control over noise injection\no A noise scheduler defines how much noise is added at each step, influencing\nhow quickly the data degrades from its original form to pure noise.\n\n--- Page 14 ---\no A carefully designed schedule ensures that the model learns meaningful\ntransformations at each step rather than abrupt or overly noisy transitions.\n2. Balance between learning and randomness\no If noise is added too aggressively, the model may struggle to learn how to\nrecover the data because too much information is lost early.\no If noise is too weak, the model may not generalize well and could overfit to\nspecific patterns without learning how to handle uncertainty.\n3. Smooth transitions\no Gradual noise addition allows the model to capture complex patterns and fine\ndetails at different noise levels, helping the backward process refine the data\neffectively.\n4.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 14
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 34,
      "content": "ty.\n3. Smooth transitions\no Gradual noise addition allows the model to capture complex patterns and fine\ndetails at different noise levels, helping the backward process refine the data\neffectively.\n4. Influences sample quality and diversity\no The noise schedule affects the kinds of outputs the model generates. For\ninstance, a slower noise increase might produce high-fidelity samples, while a\nfaster schedule might encourage more diverse and creative outputs.\n5. Stabilizes training\no Appropriate noise scheduling prevents extreme gradients or erratic learning\nbehavior, enabling stable and efficient training across large datasets.\n✅ Example of a commonly used noise scheduler: Linear noise schedule\nOne widely used noise scheduler is the linear noise schedule, where the noise level increases\nat a constant rate across steps.\n• The noise added at each step t is computed as:\nwhere:\no β start is the initial noise amount,\no β end is the final noise amount,\no T is the total number of steps.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 35,
      "content": "ses\nat a constant rate across steps.\n• The noise added at each step t is computed as:\nwhere:\no β start is the initial noise amount,\no β end is the final noise amount,\no T is the total number of steps.\nWhy it's used:\n• Simplicity – easy to implement and analyze.\n• Gradual degradation – ensures smooth transitions from structured data to noise.\n• Works well in practice for a variety of tasks without requiring complex tuning.\n✅ Other common noise schedules\n• Cosine schedule – Uses a cosine curve to control noise increments, adding noise\nmore smoothly at the beginning and end.\n\n--- Page 15 ---\n• Exponential schedule – Adds noise in a way that accelerates or decelerates across\nsteps, providing more control over learning phases.\nComparison between Class-Conditional Diffusion Models and Unconditional Diffusion\nModels\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\nDiffusion models where the generation\nDiffusion models that generate data\nprocess is guided by class label",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 15
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 36,
      "content": "nal Diffusion\nModels\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\nDiffusion models where the generation\nDiffusion models that generate data\nprocess is guided by class labels or\npurely based on learned distributions\nadditional conditioning information (e.g.,\n✅ Definition without any conditioning information.\ntext, attributes). The model learns how the\nThe model only depends on noise and\ndata distribution changes for different\nthe learned data distribution.\nclasses.\n- Incorporates class labels or auxiliary\ninputs into the noise prediction network.\n- Contains only the noise prediction\n- Conditioning is usually done by\nnetwork without any external inputs.\nconcatenating labels or through\n✅ - Learns the general structure and\nembeddings that influence intermediate\nArchitecture distribution of the entire dataset.\nlayers.\n- Generates samples based on noise\n- The model learns separate modes of the\nwithout class-specific guidance.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 37,
      "content": "ddings that influence intermediate\nArchitecture distribution of the entire dataset.\nlayers.\n- Generates samples based on noise\n- The model learns separate modes of the\nwithout class-specific guidance.\ndata distribution for each class or\ncondition.\n- Learn how to denoise while respecting - Learn to denoise without any guidance\nclass information. other than the underlying data\n✅ Training - The model minimizes the reconstruction distribution.\nObjective loss while conditioning on the class, - The model focuses on general patterns\nensuring generated samples match the and statistical relationships in the\ntarget category. dataset.\n- During generation, class labels guide the\n- Generates samples from noise without\nsampling process, allowing control over\ncontrol over attributes or categories.\n✅ Sampling what kind of sample is generated (e.g., a\n- Produces diverse outputs but without\ncat vs. a dog image).\nspecific guidance.\n- Can produce targeted, structured outputs.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 38,
      "content": "tributes or categories.\n✅ Sampling what kind of sample is generated (e.g., a\n- Produces diverse outputs but without\ncat vs. a dog image).\nspecific guidance.\n- Can produce targeted, structured outputs.\n- Image synthesis conditioned on class\nlabels (e.g., generating specific objects or - General image, audio, or video\nfaces). generation where control is not\n✅ - Text-to-image generation, style transfer, necessary.\nApplications or scenarios requiring targeted outputs. - Data augmentation, unsupervised\n- Semi-supervised learning where learning, and exploratory creative\nadditional information improves generation generation.\nquality.\n- Greater control over generated samples.\n✅ - Can produce outputs tailored to specific - Simpler architecture and easier to\nAdvantages tasks or user inputs. implement.\n- More interpretable generation process. - Requires less labeled data.\n\n--- Page 16 ---\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\n- Capable of learning diverse patter",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 16
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 39,
      "content": "t.\n- More interpretable generation process. - Requires less labeled data.\n\n--- Page 16 ---\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\n- Capable of learning diverse patterns\nfrom large, unstructured datasets.\n- Requires labeled data or conditioning\n- Lacks control over generated content.\n✅ inputs, which may not always be available.\n- May produce irrelevant or ambiguous\nLimitations - More complex architecture and higher\noutputs when diverse patterns overlap.\ncomputational cost.\nDDIM (DENOISING DIFFUSION IMPLICIT MODELS)\nDDIM (Denoising Diffusion Implicit Models) is an improvement over standard diffusion\nmodels like DDPM (Denoising Diffusion Probabilistic Models). It introduces a new sampling\nmethod that allows generating high-quality samples with significantly fewer steps, while still\nretaining diversity and structure in the outputs.\n✅ Why DDIM was introduced\n1.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 16
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 40,
      "content": "introduces a new sampling\nmethod that allows generating high-quality samples with significantly fewer steps, while still\nretaining diversity and structure in the outputs.\n✅ Why DDIM was introduced\n1. Reduce Sampling Time\no Traditional diffusion models like DDPM require hundreds or thousands of\nsteps during sampling, which makes them computationally expensive and slow\nfor practical applications.\n2. Maintain Quality and Diversity\no Simply reducing steps in DDPM leads to degraded or less diverse outputs.\no DDIM proposes a deterministic or pseudo-deterministic approach that\nmaintains high sample fidelity even with fewer steps.\n✅ How DDIM works\n1. Implicit Sampling\no Instead of following the stochastic reverse process of DDPM, DDIM defines a\ndeterministic mapping between noise and data, reducing randomness during\nsampling.\no The model avoids resampling at each step, making it faster and more stable.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 41,
      "content": "erse process of DDPM, DDIM defines a\ndeterministic mapping between noise and data, reducing randomness during\nsampling.\no The model avoids resampling at each step, making it faster and more stable.\n2. Non-Markovian Transitions\no Unlike DDPM where each step depends only on the previous one (Markov\nproperty), DDIM relaxes this assumption by allowing steps that depend on\nearlier states.\no This enables more flexible transitions and faster sampling while preserving\nsample quality.\n3. Controlled Interpolation\no DDIM allows interpolation between different noise levels and samples, which\ncan be used for creative applications like style mixing or smooth transitions.\n\n--- Page 17 ---\n✅ Key Differences from DDPM\nFeature DDPM DDIM\nStochastic, follows Markov chain with Deterministic or pseudo-deterministic,\nSampling process\nrandom transitions with fewer steps\nComputational\nHigh due to many sampling steps Much lower with accelerated sampling\ncost\nCan explore a wide range of outputs due Maintains div",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 17
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 42,
      "content": "stic,\nSampling process\nrandom transitions with fewer steps\nComputational\nHigh due to many sampling steps Much lower with accelerated sampling\ncost\nCan explore a wide range of outputs due Maintains diversity but with controlled\nDiversity\nto randomness noise patterns\nSuitable for tasks needing rich Better for fast generation and interactive\nUse case\nexploration applications\n✅ Mathematical Insight\nIn DDPM, the reverse process is modeled as a probabilistic sampling from p(x ∣x), where\nt−1 t\nrandomness is inherent at each step.\nIn DDIM, a deterministic transition is defined:\nHere:\n• α t defines how much signal is preserved at each step.\n• ϵ θ (x t ,t) is the model’s learned noise prediction.\nThis formulation allows skipping intermediate steps while still approximating the\nreverse trajectory.\n✅ Applications of DDIM\n1. Image Generation\no Produces high-resolution images quickly without compromising on details.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 43,
      "content": "s skipping intermediate steps while still approximating the\nreverse trajectory.\n✅ Applications of DDIM\n1. Image Generation\no Produces high-resolution images quickly without compromising on details.\n2. Video and Audio Synthesis\no Enables faster generation for time-sensitive applications like animation or\nsound design.\n3. Style Transfer & Interpolation\no Smoothly blends between samples by manipulating latent noise patterns\ndeterministically.\n4. Interactive Tools\no Supports real-time editing and creative workflows where speed and control are\ncritical.\n\n--- Page 18 ---\n✅ Advantages of DDIM\n✔ Faster sampling with fewer steps\n✔ Stable and high-quality outputs\n✔ Supports interpolation and controlled generation\n✔ Reduces computational cost without major trade-offs in realism\n✅ Limitations of DDIM\n❗ May lose some diversity due to reduced randomness\n❗ Requires careful tuning of schedules and noise levels\n❗ Still dependent on well-trained models to perform effectively\n✅ Conclusion\nDDIM is a power",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 18
    },
    {
      "doc_id": "tmpm2bra9mn_UNIT I - GCV NOTES.pdf_a0a003d3_74bafc82",
      "chunk_index": 44,
      "content": "❗ May lose some diversity due to reduced randomness\n❗ Requires careful tuning of schedules and noise levels\n❗ Still dependent on well-trained models to perform effectively\n✅ Conclusion\nDDIM is a powerful extension of diffusion models that addresses one of their biggest\nlimitations—slow sampling—by introducing deterministic or semi-deterministic transitions.\nIt enables faster generation while maintaining sample fidelity and diversity, making it highly\nsuitable for real-world applications like image synthesis, animation, and interactive creative\ntools.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 0,
      "content": "--- Page 1 ---\nDIFFUSION MODELS\nDiffusion models are a type of generative AI that create new data like images, audio or even\nvideo by starting with random noise and gradually turning it into something meaningful. They\nwork by simulating a diffusion process where data is slowly corrupted by noise during\ntraining and then learning to reverse this process step by step. By doing so the model learns\nhow to generate high quality samples from scratch.\nUnderstanding Diffusion Models\n• Diffusion models are generative models that learn to reverse a diffusion process to\ngenerate data. The diffusion process involves gradually adding noise to data until it\nbecomes pure noise.\n• Through this process a simple distribution is transformed into a complex data distribution\nin a series of small incremental steps.\n• Essentially these models operate as a reverse diffusion phenomenon where noise is\nintroduced to the data in a forward manner and removed in a reverse manner to generate\nnew data samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 1
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 1,
      "content": "ntal steps.\n• Essentially these models operate as a reverse diffusion phenomenon where noise is\nintroduced to the data in a forward manner and removed in a reverse manner to generate\nnew data samples.\n• By learning to reverse this process diffusion models start from noise and gradually\ndenoise it to produce data that closely resembles the training examples.\nKey Components\n1. Forward Diffusion Process: This process involves adding noise to the data in a series of\nsmall steps. Each step slightly increases the noise, making the data progressively more\nrandom until it resembles pure noise.\n2. Reverse Diffusion Process: The model learns to reverse the noise-adding steps. Starting\nfrom pure noise, the model iteratively removes the noise, generating data that matches\nthe training distribution.\n3. Score Function: This function estimates the gradient of the data distribution concerning\nthe noise. It helps guide the reverse diffusion process to produce realistic samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 2,
      "content": "training distribution.\n3. Score Function: This function estimates the gradient of the data distribution concerning\nthe noise. It helps guide the reverse diffusion process to produce realistic samples.\n\n--- Page 2 ---\nArchitecture of Diffusion Models\nThe architecture of diffusion models typically involves two main components:\n1. Forward Diffusion Process\n2. Reverse Diffusion Process\n1. Forward Diffusion Process\nIn this process noise is incrementally added to the data over a series of steps. This is akin to\na Markov chain where each step slightly degrades the data by adding Gaussian noise.\nForward Diffusion P\nMathematically, this can be represented as:\nwhere,\n• xt is the noisy data at step t\n• αt controls the amount of noise added.\n2. Reverse Diffusion Process\nThe reverse process aims to reconstruct the original data by denoising the noisy data in a\nseries of steps reversing the forward diffusion.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 2
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 3,
      "content": "rols the amount of noise added.\n2. Reverse Diffusion Process\nThe reverse process aims to reconstruct the original data by denoising the noisy data in a\nseries of steps reversing the forward diffusion.\nReverse Diffusion Process\nThis is typically modelled using a neural network that predicts the noise added at each step:\nwhere,\n• μθ and σθ are learned parameters.\nWorking Principle of Diffusion Models\nDuring training the model learns to predict the noise added at each step of the forward\nprocess. This is done by minimizing a loss function that measures the difference between the\npredicted and actual noise.\nForward Process (Diffusion)\n• The forward process involves gradually corrupting the data x0 with Gaussian noise over\na sequence of time steps\n• Let xt represent the noisy data at time step t. The process is defined as:\n• where βt is the noise schedule that controls the amount of noise added at each step and ϵ is\nis Gaussian noise.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 4,
      "content": "ime steps\n• Let xt represent the noisy data at time step t. The process is defined as:\n• where βt is the noise schedule that controls the amount of noise added at each step and ϵ is\nis Gaussian noise.\n\n--- Page 3 ---\n• As t increases, xt becomes more noisy until it approximates a Gaussian distribution.\nReverse Process (Denoising)\n• The reverse process aims to reconstruct the original data x0x0 from the noisy data xT at\nthe final time step T.\n• This process is modelled using a neural network to approximate the conditional\nprobability pθ(xt−1∣xt).\n• The reverse process can be formulated as:\n• where ϵθ is a neural network parameterized by θ that predicts the noise.\nTraining Diffusion Models\n• The training objective for diffusion models involves minimizing the difference between\nthe true noise ϵ added in the forward process and the noise predicted by the neural\nnetwork ϵθ.\n• The score function which estimates the gradient of the data distribution concerning the\nnoise plays an important rol",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 3
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 5,
      "content": "ϵ added in the forward process and the noise predicted by the neural\nnetwork ϵθ.\n• The score function which estimates the gradient of the data distribution concerning the\nnoise plays an important role in guiding the reverse process.\n• The loss function is typically the mean squared error (MSE) between these two quantities:\n• This encourages the model to accurately predict the noise and, consequently, to denoise\neffectively during the reverse process.\nIn diffusion models, both the forward and backward processes are modeled as a sequence of\nsmall incremental steps rather than a single transformation. This sequential approach is\ncrucial because:\n1. Gradual Learning – By breaking the process into many steps, the model learns how\nto handle slight changes at each stage, making it easier to reverse the noise addition. If\nit tried to denoise from a fully noisy image in one step, it would struggle to map the\nrandom noise back to structured data.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 6,
      "content": "hanges at each stage, making it easier to reverse the noise addition. If\nit tried to denoise from a fully noisy image in one step, it would struggle to map the\nrandom noise back to structured data.\n2. Stability in Training – Learning through small denoising steps prevents abrupt\ntransitions, reducing the chances of errors or divergence during training. It ensures\nthat the model refines its predictions slowly, stabilizing gradients and allowing\nconsistent improvements.\n3. Better Control Over Generation – The step-wise nature allows the model to be\nsampled at different stages, offering control over how much noise to remove or retain.\nThis is especially useful in VR environments, where designers might want to balance\nrealism with creativity.\n4. Avoiding Catastrophic Forgetting – Incremental denoising reinforces the learning at\nevery step, ensuring that earlier patterns are not forgotten as the model progresses\ntoward generating complex outputs.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 7,
      "content": "iding Catastrophic Forgetting – Incremental denoising reinforces the learning at\nevery step, ensuring that earlier patterns are not forgotten as the model progresses\ntoward generating complex outputs.\n\n--- Page 4 ---\nThus, modeling the forward and backward processes as a sequence of steps ensures that\nlearning is smooth, robust, and interpretable, ultimately allowing the system to produce high-\nquality, stable, and realistic images from rough sketches.\nNoise plays a central role in the diffusion process, and carefully adjusting it can significantly\ninfluence the outcomes:\n1. Higher Noise Levels\no Encourages diverse outputs because the model explores a wider range of\npossibilities when starting from more random data.\no Useful for generating creative or artistic VR landscapes where uniqueness is\ndesired.\no However, if the noise is too high, the generated images may lose structure or\ncoherence, reducing realism.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 4
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 8,
      "content": "o Useful for generating creative or artistic VR landscapes where uniqueness is\ndesired.\no However, if the noise is too high, the generated images may lose structure or\ncoherence, reducing realism.\n2. Lower Noise Levels\no Helps maintain realism and fidelity because the model starts closer to\nstructured patterns, making it easier to produce clear and consistent images.\no Best suited for VR environments where accuracy, recognizable objects, and\nrealistic textures are essential.\no It may, however, limit creativity and diversity since the outputs are\nconstrained to follow the training data closely.\n3. Noise Scheduling\no Adjusting how noise is added or removed across steps (e.g., linear,\nexponential, cosine schedules) allows fine-tuning between exploration and\nrefinement.\no Designers can control whether the model produces subtle variations or\nradically different landscapes.\n4. Application in VR Systems\no For immersive experiences, higher noise levels at early steps can generate\nunpredictabl",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 9,
      "content": "l whether the model produces subtle variations or\nradically different landscapes.\n4. Application in VR Systems\no For immersive experiences, higher noise levels at early steps can generate\nunpredictable and novel environments, while later steps can be fine-tuned with\nlower noise to ensure realistic details.\no This balance allows users to start with abstract sketches and transform them\ninto believable virtual worlds that retain creativity without sacrificing\ncoherence.\n\n--- Page 5 ---\nDENOISING DIFFUSION PROBABILISTIC MODEL (DDPM)\nWhat are DDPMs?\nThey are a class of generative models that work by iteratively adding noise to an input signal\n(like an image, text, or audio) and then learning to denoise from the noisy signal to generate\nnew samples.\nGenerative models\nAre a type of model that can generate new data instances. Previously, machine learning models\nhave done a good job of learning differences in data and then making predictions or\nclassification tasks.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 5
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 10,
      "content": "Are a type of model that can generate new data instances. Previously, machine learning models\nhave done a good job of learning differences in data and then making predictions or\nclassification tasks. For example, a model trained on a digits dataset like MNIST can recognize\na 0 from a 1. Generative models, on the other hand, learn the distribution of digits and can create\na “fake digit” which closely resembles a real digit.\nA Denoising Diffusion Probabilistic Model (DDPM) is a type of generative model that\ncreates realistic images by learning how to progressively refine noisy data. It works in two\nphases:\n1. Forward Process (Noise Addition) – The model gradually adds random noise to a\nclean image over many steps until the image becomes indistinguishable from noise.\n2. Backward Process (Denoising) – The model learns to reverse this process by\npredicting how to remove noise at each step, eventually reconstructing a high-quality\nimage from random noise or a rough input.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 11,
      "content": "ckward Process (Denoising) – The model learns to reverse this process by\npredicting how to remove noise at each step, eventually reconstructing a high-quality\nimage from random noise or a rough input.\nThe model is called probabilistic because it doesn’t rely on a single deterministic\ntransformation but instead learns the distribution of possible images at each stage of noise\nand denoising. This approach allows it to generate diverse, high-fidelity images by sampling\nfrom the learned distribution.\n\n--- Page 6 ---\nKey Features of DDPM:\n• Iterative Refinement – Instead of transforming an image in one step, it uses many\nsmall steps, making it easier to model complex patterns.\n• Noise-Based Learning – By learning how images degrade with noise, the model\nunderstands how to reverse this degradation to recreate details.\n• Probabilistic Nature – It generates a range of plausible outputs rather than a single\nfixed result, which is useful in creative tasks like animation.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 6
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 12,
      "content": "to reverse this degradation to recreate details.\n• Probabilistic Nature – It generates a range of plausible outputs rather than a single\nfixed result, which is useful in creative tasks like animation.\n• Flexibility – DDPMs can be applied to various tasks such as image synthesis, super-\nresolution, and in your case, converting rough sketches into fully rendered scenes.\nForward and Backward Diffusion Process\nThe forward diffusion process is the initial phase in a DDPM where noise is incrementally\nadded to clean data over many steps. The purpose is to teach the model how data transitions\nfrom structured and detailed forms into randomness.\nKey steps involved:\n1. Starting with clean data – At the beginning, the model takes real data such as an\nimage or signal that contains structured information like shapes, textures, and\npatterns.\n2. Adding noise at each step – Gaussian noise is added to the data in small amounts\nover a sequence of steps. The noise schedule (linear, cosine, etc.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 13,
      "content": "information like shapes, textures, and\npatterns.\n2. Adding noise at each step – Gaussian noise is added to the data in small amounts\nover a sequence of steps. The noise schedule (linear, cosine, etc.) controls how much\nnoise is added at each step.\n3. Progressive degradation – The data becomes increasingly noisy at every step.\nInitially, the patterns are still recognizable, but as the process continues, the structure\ndisappears, and the data looks like random noise.\n4. Mathematical formulation – At step t, the noisy data x is derived from the previous\nt\nstep x by sampling from a normal distribution:\nt−1\nwhere α controls the amount of retained information and ϵ is sampled from a normal\nt\ndistribution.\nWhy this step is essential:\n• It exposes the model to how real data deteriorates with noise.\n• It creates a learning path for the model to understand the inverse operation—\nrecovering the data from noisy versions.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 14,
      "content": "is essential:\n• It exposes the model to how real data deteriorates with noise.\n• It creates a learning path for the model to understand the inverse operation—\nrecovering the data from noisy versions.\n• It ensures that the model can generalize to varying noise levels and recover details\nfrom incomplete or corrupted data.\n\n--- Page 7 ---\nRole of the Markov Chain in the Forward Diffusion Process of a DDPM\nIn a Denoising Diffusion Probabilistic Model (DDPM), the forward diffusion process\ninvolves gradually adding noise to clean data over multiple steps. This process is modeled as\na Markov chain, which plays a crucial role in structuring how noise is added.\nA Markov chain is a mathematical system that transitions from one state to another, where\nthe next state depends only on the current state and not on the entire history of past states. In\nthe context of DDPM’s forward diffusion process, this means:\n1.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 7
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 15,
      "content": "tions from one state to another, where\nthe next state depends only on the current state and not on the entire history of past states. In\nthe context of DDPM’s forward diffusion process, this means:\n1. Stepwise progression\no At each time step ttt, noise is added based only on the data at that step\n(xt−1x_{t-1}xt−1), not on earlier steps. This simplifies the process and\nensures that each step depends only on the immediately preceding one.\n2. Controlled noise addition\no The amount of noise added at each step is determined by a known noise\nschedule, ensuring that the transition from structured data to noise is smooth\nand gradual.\n3. Mathematical tractability\no By assuming that each step depends only on the previous step, the forward\nprocess becomes easier to analyze, simulate, and invert during training.\nHow does it help structure the noise addition steps?\n1. Simplifies modeling\no The Markov assumption allows the model to focus on learning local\ntransitions rather than global dependencies,",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 16,
      "content": "g training.\nHow does it help structure the noise addition steps?\n1. Simplifies modeling\no The Markov assumption allows the model to focus on learning local\ntransitions rather than global dependencies, making the noise addition process\ncomputationally feasible.\n2. Ensures gradual degradation\no The structured, stepwise approach ensures that noise is added progressively,\npreserving information early on and fully randomizing the data at later steps.\n3. Supports efficient training\no The Markov property allows the use of recursive formulations where each\nnoisy sample can be derived from the previous one using simple equations,\nfacilitating optimization and gradient computation.\n4. Enables inversion during sampling\no Since each step only depends on the previous one, the backward process\n(denoising) can also be structured in the same stepwise manner, allowing the\nmodel to learn how to reverse the process reliably.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 17,
      "content": "Since each step only depends on the previous one, the backward process\n(denoising) can also be structured in the same stepwise manner, allowing the\nmodel to learn how to reverse the process reliably.\nThe backward diffusion process is where the model learns to reverse the noise addition and\nreconstruct the original or new data from noisy inputs.\nKey aspects:\n1. Predicting the noise – At each step, the model is trained to estimate the noise that\nwas added in the forward process. It learns how the noisy data differs from its clean\nversion and tries to correct it.\n\n--- Page 8 ---\n2. Iterative refinement – Starting from pure noise, the model removes noise\nprogressively by applying its learned knowledge of patterns at each step. Over time,\nthe image or data becomes clearer and more structured.\n3. Learning objective – The model is optimized to minimize the difference between the\npredicted noise and the actual noise added during training.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 8
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 18,
      "content": "the image or data becomes clearer and more structured.\n3. Learning objective – The model is optimized to minimize the difference between the\npredicted noise and the actual noise added during training. This is typically done\nusing a loss function like Mean Squared Error (MSE).\n4. Sampling during generation – Once trained, the model can start from random noise\nand iteratively apply the backward process to generate new, realistic data samples.\nWhy this process is critical:\n• It allows the model to reconstruct missing or noisy details.\n• It ensures that the output is consistent with real-world data distributions.\n• It provides control over the generation process by using learned probabilities rather\nthan rigid rules.\nThe probabilistic nature of DDPM plays a central role in its ability to generate both diverse\nand high-quality outputs.\nWhy probabilistic modeling is useful?\n1. Learning distributions rather than fixed mappings\no Instead of learning a direct transformation from input to output",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 19,
      "content": "ate both diverse\nand high-quality outputs.\nWhy probabilistic modeling is useful?\n1. Learning distributions rather than fixed mappings\no Instead of learning a direct transformation from input to output, the model\nlearns the underlying distribution of possible clean data conditioned on noisy\ninputs.\no This enables the model to handle uncertainty and variations present in real\ndata.\n2. Sampling from distributions\no During generation, the model samples noise from a distribution at each step.\nEven with the same input, different random samples produce varied outputs,\npromoting creativity and diversity.\n3. Capturing subtle patterns\no Probabilistic modeling allows the model to learn nuanced relationships in the\ndata such as textures, lighting patterns, or variations in shape that are hard to\ncapture with deterministic methods.\n4. Balancing realism and exploration\no By controlling the noise level and how it’s modeled, the system can explore\nnew possibilities while staying within the realm of re",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 20,
      "content": "re with deterministic methods.\n4. Balancing realism and exploration\no By controlling the noise level and how it’s modeled, the system can explore\nnew possibilities while staying within the realm of realistic outputs. This is\ncrucial for applications like design, simulation, and data augmentation.\nChallenges:\n1. High computational cost\no Because the process involves many steps (often hundreds or thousands),\ngenerating data can be slow and resource-intensive.\n2. Latency issues in real-time applications\n\n--- Page 9 ---\no The iterative nature makes it difficult to apply DDPMs in interactive or real-\ntime environments where fast feedback is essential.\n3. Difficulty in controlling outputs\no Without proper conditioning or guidance, the model might produce outputs\nthat are inconsistent with user expectations or desired styles.\n4. Data requirements\no Training DDPMs effectively requires large and diverse datasets to accurately\nlearn noise patterns and recover fine details.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 9
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 21,
      "content": "nconsistent with user expectations or desired styles.\n4. Data requirements\no Training DDPMs effectively requires large and diverse datasets to accurately\nlearn noise patterns and recover fine details.\nENERGY-BASED MODELS(EBMs)\nEnergy-Based Models (EBMs) are a class of probabilistic models that define relationships\nbetween variables using an energy function. Rather than explicitly modeling probability\ndistributions, EBMs assign an “energy” value to each possible configuration of variables,\nwhere lower energy indicates more likely or desirable configurations, and higher energy\ncorresponds to less likely ones.\nEBMs are widely used in machine learning for tasks such as representation learning,\nstructured prediction, anomaly detection, and reinforcement learning, where capturing\nrelationships and constraints between variables is more important than explicitly computing\nprobabilities.\n2. The Concept of Energy in EBMs\n• An energy function E(x)maps an input x to a scalar energy value.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 22,
      "content": "onships and constraints between variables is more important than explicitly computing\nprobabilities.\n2. The Concept of Energy in EBMs\n• An energy function E(x)maps an input x to a scalar energy value.\n• The lower the energy, the more plausible or preferred the data point is according to\nthe model.\n• The probability distribution p(x)is related to the energy via the Boltzmann\ndistribution:\nwhere Z is the partition function:\n• The partition function Z is often intractable, making it difficult to directly compute\nprobabilities, but not necessary for learning.\n\n--- Page 10 ---\n3. Architecture and Working\nCore Components:\n1. Energy Function\no The energy function is typically parameterized by neural networks or other\ndifferentiable models.\no It scores different data configurations to indicate how well they conform to the\ndesired patterns.\n2. Learning Objective\no EBMs learn by comparing the energies of positive (correct) and negative\n(incorrect or unlikely) samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 10
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 23,
      "content": "nfigurations to indicate how well they conform to the\ndesired patterns.\n2. Learning Objective\no EBMs learn by comparing the energies of positive (correct) and negative\n(incorrect or unlikely) samples.\no The goal is to assign lower energy to real data and higher energy to unlikely\ndata.\n3. Training Approaches\no Contrastive Divergence (CD) – Optimizes the model by comparing energy\ndifferences between observed and model-generated samples.\no Score Matching – Matches the gradient of the energy function rather than the\nenergy itself.\no Noise Contrastive Estimation (NCE) – Uses noise samples to help\napproximate the partition function during learning.\n4. Markov Random Fields (MRFs) and Conditional EBMs\n• EBMs are closely related to Markov Random Fields (MRFs), which model\ndependencies between variables using graph structures.\n• Conditional EBMs extend the energy framework to tasks where the output depends\non input features (e.g., image classification, structured output prediction).\n5.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 24,
      "content": "ween variables using graph structures.\n• Conditional EBMs extend the energy framework to tasks where the output depends\non input features (e.g., image classification, structured output prediction).\n5. Applications of EBMs\n1. Unsupervised Learning\no Modeling complex relationships in high-dimensional data such as images,\nspeech, or text.\n2. Anomaly Detection\no Identifying outliers by assigning higher energy to rare or unlikely\nconfigurations.\n3. Reinforcement Learning (RL)\no Estimating value functions where actions with lower energy correspond to\nmore rewarding behaviors.\n4. Generative Modeling\no Generating samples by searching for configurations with low energy, often\nusing sampling algorithms like Langevin dynamics.\n5. Structured Prediction\no Solving problems like image segmentation or sequence labeling where\nrelationships between output variables are important.\n\n--- Page 11 ---\n6. Advantages of EBMs\n• Flexibility – Can model arbitrary dependencies without requiring explicit probabilit",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 11
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 25,
      "content": "uence labeling where\nrelationships between output variables are important.\n\n--- Page 11 ---\n6. Advantages of EBMs\n• Flexibility – Can model arbitrary dependencies without requiring explicit probability\ndistributions.\n• Interpretability – The energy function directly encodes preferences or constraints.\n• Applicability – Useful in domains where structured relationships and constraints\ndominate over simple classification.\n7. Challenges and Limitations\n1. Intractable Partition Function\no Computing ZZZ is often impossible in practice, requiring approximation\ntechniques that can be unstable.\n2. Training Instability\no Optimization methods like contrastive divergence rely on sampling, which can\nlead to slow convergence or poor performance.\n3. Sampling Complexity\no Generating samples requires iterative methods such as Markov Chain Monte\nCarlo (MCMC), which can be computationally expensive.\n4. Scalability Issues\no Handling high-dimensional data with complex energy landscapes is\nchallenging.\n8.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 11
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 26,
      "content": "rative methods such as Markov Chain Monte\nCarlo (MCMC), which can be computationally expensive.\n4. Scalability Issues\no Handling high-dimensional data with complex energy landscapes is\nchallenging.\n8. Recent Advances\n• Neural EBMs – Combining deep learning with energy functions to model high-\ndimensional and structured data more effectively.\n• Score-based Generative Models – Learning the gradient of the energy function to\navoid directly computing the partition function.\n• Applications in Contrastive Learning – EBMs form the backbone of contrastive\napproaches where relationships between samples are emphasized.\n\n--- Page 12 ---\nCOMPARE EBMS VS VAES\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Defined by an energy function\nthat assigns a scalar “energy” to\n- Composed of two main parts: an\neach configuration of inputs (and\nencoder and a decoder.\noptionally outputs).\n- The encoder maps input data to a\n- No explicit probability\nlatent space distribution (typically\ndist",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 12
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 27,
      "content": "two main parts: an\neach configuration of inputs (and\nencoder and a decoder.\noptionally outputs).\n- The encoder maps input data to a\n- No explicit probability\nlatent space distribution (typically\ndistribution; the model learns to\nGaussian).\nassign lower energy to desired\n- The decoder reconstructs data\n✅ Architecture samples and higher energy to\nfrom samples drawn from the latent\nundesired ones.\nspace.\n- Often optimized using contrastive\n- Uses variational inference to\ndivergence or score matching.\napproximate intractable posteriors.\n- The architecture focuses on\n- The architecture explicitly models\nrelationships between data points\ndata generation.\nrather than reconstructing or\ngenerating them directly.\n- Maximize the Evidence Lower\n- Learn an energy landscape where\nBound (ELBO) which balances\ncorrect data points are assigned\nreconstruction accuracy and\nlower energy.\n✅ Objective regularization of the latent space.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 28,
      "content": "Evidence Lower\n- Learn an energy landscape where\nBound (ELBO) which balances\ncorrect data points are assigned\nreconstruction accuracy and\nlower energy.\n✅ Objective regularization of the latent space.\n- Optimization is based on\n- Encourages latent space structure\ndistinguishing good samples from\nfor efficient sampling and\nbad ones.\ninterpolation.\n- Indirect; energy defines the\nlikelihood up to a normalization - Explicit probabilistic framework\nconstant (partition function), which with tractable priors and\n✅ Probabilistic\nis often intractable. approximate posteriors.\nInterpretation\n- Focuses on learning relationships - Can directly sample from the latent\nand constraints rather than full space and model uncertainty.\ndensity estimation.\n- Uses sampling-based methods\nlike Markov Chain Monte Carlo - Uses backpropagation with\n(MCMC), contrastive divergence, reparameterization trick for efficient\n✅ Training\nor score matching. gradient estimation.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 29,
      "content": "mpling-based methods\nlike Markov Chain Monte Carlo - Uses backpropagation with\n(MCMC), contrastive divergence, reparameterization trick for efficient\n✅ Training\nor score matching. gradient estimation.\nMethods\n- Training can be unstable due to - More stable and easier to train\nreliance on sampling and gradient with large datasets.\nestimation.\n- Modeling complex dependencies\nin structured data. - Image and speech generation, data\n- Used in tasks like anomaly compression, anomaly detection,\ndetection, reinforcement learning, and semi-supervised learning.\n✅ Applications\nand unsupervised learning. - Used where interpretable latent\n- Applicable where relationships representations and smooth\nand constraints are more important generation paths are required.\nthan explicit reconstruction.\n\n--- Page 13 ---\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Flexibility in modeling\n- Well-suited for generating new\nrelationships without requiring\ndata samples.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 13
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 30,
      "content": "onstruction.\n\n--- Page 13 ---\nAspect Energy-Based Models (EBMs) Variational Autoencoders (VAEs)\n- Flexibility in modeling\n- Well-suited for generating new\nrelationships without requiring\ndata samples.\n✅ Strengths explicit likelihood functions.\n- Provides interpretable latent spaces\n- Can incorporate constraints and\nuseful for downstream tasks.\ndomain knowledge easily.\n- May suffer from blurry\n- Training is computationally\nreconstructions or mode collapse.\nexpensive and less scalable. -\n✅ Limitations - Latent space structure depends\nNormalization constant estimation\nheavily on choice of priors and\nis intractable in many cases.\narchitectures.\nINTRODUCTION TO NOISE SCHEDULERS IN DIFFUSION MODELS\nIn diffusion models, noise plays a central role in transforming structured data into random noise\nduring training and then reconstructing it during sampling. However, how much noise is added\nor removed at each step is not arbitrary—it must be carefully controlled to ensure that the model\nlearns me",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 13
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 31,
      "content": "during training and then reconstructing it during sampling. However, how much noise is added\nor removed at each step is not arbitrary—it must be carefully controlled to ensure that the model\nlearns meaningful patterns and can effectively generate high-quality data.\nThis is where noise schedulers come into play.\nA noise scheduler defines the schedule or strategy by which noise is added to data in the\nforward diffusion process and removed in the backward process. It determines the magnitude\nof noise at each step, shaping how the model degrades and refines information over time.\nThe design of the noise schedule affects several critical aspects:\n• Learning efficiency – Too much noise can obscure important details, while too little\nmay prevent the model from learning to handle uncertainty.\n• Sample diversity and quality – The progression of noise influences how creative or\nrealistic the generated outputs are.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 32,
      "content": "s, while too little\nmay prevent the model from learning to handle uncertainty.\n• Sample diversity and quality – The progression of noise influences how creative or\nrealistic the generated outputs are.\n• Training stability – Gradual noise addition helps avoid erratic learning and ensures\nthat the model can generalize from noisy inputs.\nCommon schedules include linear, cosine, and exponential noise schedules, each offering\ndifferent trade-offs between smoothness, speed, and complexity.\nSignificance of Noise Schedulers in Diffusion Models\nIn diffusion models, noise schedulers determine how noise is added (in the forward process)\nor removed (in the backward process) at each step. They play a critical role in controlling the\nquality, stability, and efficiency of the model during both training and sampling.\nWhy are noise schedulers important?\n1. Control over noise injection\no A noise scheduler defines how much noise is added at each step, influencing\nhow quickly the data degrades from its or",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 33,
      "content": "nd sampling.\nWhy are noise schedulers important?\n1. Control over noise injection\no A noise scheduler defines how much noise is added at each step, influencing\nhow quickly the data degrades from its original form to pure noise.\n\n--- Page 14 ---\no A carefully designed schedule ensures that the model learns meaningful\ntransformations at each step rather than abrupt or overly noisy transitions.\n2. Balance between learning and randomness\no If noise is added too aggressively, the model may struggle to learn how to\nrecover the data because too much information is lost early.\no If noise is too weak, the model may not generalize well and could overfit to\nspecific patterns without learning how to handle uncertainty.\n3. Smooth transitions\no Gradual noise addition allows the model to capture complex patterns and fine\ndetails at different noise levels, helping the backward process refine the data\neffectively.\n4.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 14
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 34,
      "content": "ty.\n3. Smooth transitions\no Gradual noise addition allows the model to capture complex patterns and fine\ndetails at different noise levels, helping the backward process refine the data\neffectively.\n4. Influences sample quality and diversity\no The noise schedule affects the kinds of outputs the model generates. For\ninstance, a slower noise increase might produce high-fidelity samples, while a\nfaster schedule might encourage more diverse and creative outputs.\n5. Stabilizes training\no Appropriate noise scheduling prevents extreme gradients or erratic learning\nbehavior, enabling stable and efficient training across large datasets.\n✅ Example of a commonly used noise scheduler: Linear noise schedule\nOne widely used noise scheduler is the linear noise schedule, where the noise level increases\nat a constant rate across steps.\n• The noise added at each step t is computed as:\nwhere:\no β start is the initial noise amount,\no β end is the final noise amount,\no T is the total number of steps.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 35,
      "content": "ses\nat a constant rate across steps.\n• The noise added at each step t is computed as:\nwhere:\no β start is the initial noise amount,\no β end is the final noise amount,\no T is the total number of steps.\nWhy it's used:\n• Simplicity – easy to implement and analyze.\n• Gradual degradation – ensures smooth transitions from structured data to noise.\n• Works well in practice for a variety of tasks without requiring complex tuning.\n✅ Other common noise schedules\n• Cosine schedule – Uses a cosine curve to control noise increments, adding noise\nmore smoothly at the beginning and end.\n\n--- Page 15 ---\n• Exponential schedule – Adds noise in a way that accelerates or decelerates across\nsteps, providing more control over learning phases.\nComparison between Class-Conditional Diffusion Models and Unconditional Diffusion\nModels\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\nDiffusion models where the generation\nDiffusion models that generate data\nprocess is guided by class label",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 15
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 36,
      "content": "nal Diffusion\nModels\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\nDiffusion models where the generation\nDiffusion models that generate data\nprocess is guided by class labels or\npurely based on learned distributions\nadditional conditioning information (e.g.,\n✅ Definition without any conditioning information.\ntext, attributes). The model learns how the\nThe model only depends on noise and\ndata distribution changes for different\nthe learned data distribution.\nclasses.\n- Incorporates class labels or auxiliary\ninputs into the noise prediction network.\n- Contains only the noise prediction\n- Conditioning is usually done by\nnetwork without any external inputs.\nconcatenating labels or through\n✅ - Learns the general structure and\nembeddings that influence intermediate\nArchitecture distribution of the entire dataset.\nlayers.\n- Generates samples based on noise\n- The model learns separate modes of the\nwithout class-specific guidance.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 37,
      "content": "ddings that influence intermediate\nArchitecture distribution of the entire dataset.\nlayers.\n- Generates samples based on noise\n- The model learns separate modes of the\nwithout class-specific guidance.\ndata distribution for each class or\ncondition.\n- Learn how to denoise while respecting - Learn to denoise without any guidance\nclass information. other than the underlying data\n✅ Training - The model minimizes the reconstruction distribution.\nObjective loss while conditioning on the class, - The model focuses on general patterns\nensuring generated samples match the and statistical relationships in the\ntarget category. dataset.\n- During generation, class labels guide the\n- Generates samples from noise without\nsampling process, allowing control over\ncontrol over attributes or categories.\n✅ Sampling what kind of sample is generated (e.g., a\n- Produces diverse outputs but without\ncat vs. a dog image).\nspecific guidance.\n- Can produce targeted, structured outputs.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 38,
      "content": "tributes or categories.\n✅ Sampling what kind of sample is generated (e.g., a\n- Produces diverse outputs but without\ncat vs. a dog image).\nspecific guidance.\n- Can produce targeted, structured outputs.\n- Image synthesis conditioned on class\nlabels (e.g., generating specific objects or - General image, audio, or video\nfaces). generation where control is not\n✅ - Text-to-image generation, style transfer, necessary.\nApplications or scenarios requiring targeted outputs. - Data augmentation, unsupervised\n- Semi-supervised learning where learning, and exploratory creative\nadditional information improves generation generation.\nquality.\n- Greater control over generated samples.\n✅ - Can produce outputs tailored to specific - Simpler architecture and easier to\nAdvantages tasks or user inputs. implement.\n- More interpretable generation process. - Requires less labeled data.\n\n--- Page 16 ---\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\n- Capable of learning diverse patter",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 16
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 39,
      "content": "t.\n- More interpretable generation process. - Requires less labeled data.\n\n--- Page 16 ---\nAspect Class-Conditional Diffusion Models Unconditional Diffusion Models\n- Capable of learning diverse patterns\nfrom large, unstructured datasets.\n- Requires labeled data or conditioning\n- Lacks control over generated content.\n✅ inputs, which may not always be available.\n- May produce irrelevant or ambiguous\nLimitations - More complex architecture and higher\noutputs when diverse patterns overlap.\ncomputational cost.\nDDIM (DENOISING DIFFUSION IMPLICIT MODELS)\nDDIM (Denoising Diffusion Implicit Models) is an improvement over standard diffusion\nmodels like DDPM (Denoising Diffusion Probabilistic Models). It introduces a new sampling\nmethod that allows generating high-quality samples with significantly fewer steps, while still\nretaining diversity and structure in the outputs.\n✅ Why DDIM was introduced\n1.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 16
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 40,
      "content": "introduces a new sampling\nmethod that allows generating high-quality samples with significantly fewer steps, while still\nretaining diversity and structure in the outputs.\n✅ Why DDIM was introduced\n1. Reduce Sampling Time\no Traditional diffusion models like DDPM require hundreds or thousands of\nsteps during sampling, which makes them computationally expensive and slow\nfor practical applications.\n2. Maintain Quality and Diversity\no Simply reducing steps in DDPM leads to degraded or less diverse outputs.\no DDIM proposes a deterministic or pseudo-deterministic approach that\nmaintains high sample fidelity even with fewer steps.\n✅ How DDIM works\n1. Implicit Sampling\no Instead of following the stochastic reverse process of DDPM, DDIM defines a\ndeterministic mapping between noise and data, reducing randomness during\nsampling.\no The model avoids resampling at each step, making it faster and more stable.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 41,
      "content": "erse process of DDPM, DDIM defines a\ndeterministic mapping between noise and data, reducing randomness during\nsampling.\no The model avoids resampling at each step, making it faster and more stable.\n2. Non-Markovian Transitions\no Unlike DDPM where each step depends only on the previous one (Markov\nproperty), DDIM relaxes this assumption by allowing steps that depend on\nearlier states.\no This enables more flexible transitions and faster sampling while preserving\nsample quality.\n3. Controlled Interpolation\no DDIM allows interpolation between different noise levels and samples, which\ncan be used for creative applications like style mixing or smooth transitions.\n\n--- Page 17 ---\n✅ Key Differences from DDPM\nFeature DDPM DDIM\nStochastic, follows Markov chain with Deterministic or pseudo-deterministic,\nSampling process\nrandom transitions with fewer steps\nComputational\nHigh due to many sampling steps Much lower with accelerated sampling\ncost\nCan explore a wide range of outputs due Maintains div",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 17
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 42,
      "content": "stic,\nSampling process\nrandom transitions with fewer steps\nComputational\nHigh due to many sampling steps Much lower with accelerated sampling\ncost\nCan explore a wide range of outputs due Maintains diversity but with controlled\nDiversity\nto randomness noise patterns\nSuitable for tasks needing rich Better for fast generation and interactive\nUse case\nexploration applications\n✅ Mathematical Insight\nIn DDPM, the reverse process is modeled as a probabilistic sampling from p(x ∣x), where\nt−1 t\nrandomness is inherent at each step.\nIn DDIM, a deterministic transition is defined:\nHere:\n• α t defines how much signal is preserved at each step.\n• ϵ θ (x t ,t) is the model’s learned noise prediction.\nThis formulation allows skipping intermediate steps while still approximating the\nreverse trajectory.\n✅ Applications of DDIM\n1. Image Generation\no Produces high-resolution images quickly without compromising on details.\n2.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 43,
      "content": "s skipping intermediate steps while still approximating the\nreverse trajectory.\n✅ Applications of DDIM\n1. Image Generation\no Produces high-resolution images quickly without compromising on details.\n2. Video and Audio Synthesis\no Enables faster generation for time-sensitive applications like animation or\nsound design.\n3. Style Transfer & Interpolation\no Smoothly blends between samples by manipulating latent noise patterns\ndeterministically.\n4. Interactive Tools\no Supports real-time editing and creative workflows where speed and control are\ncritical.\n\n--- Page 18 ---\n✅ Advantages of DDIM\n✔ Faster sampling with fewer steps\n✔ Stable and high-quality outputs\n✔ Supports interpolation and controlled generation\n✔ Reduces computational cost without major trade-offs in realism\n✅ Limitations of DDIM\n❗ May lose some diversity due to reduced randomness\n❗ Requires careful tuning of schedules and noise levels\n❗ Still dependent on well-trained models to perform effectively\n✅ Conclusion\nDDIM is a power",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": 18
    },
    {
      "doc_id": "tmp37h9epij_UNIT I - GCV NOTES.pdf_a0a003d3_098bd210",
      "chunk_index": 44,
      "content": "❗ May lose some diversity due to reduced randomness\n❗ Requires careful tuning of schedules and noise levels\n❗ Still dependent on well-trained models to perform effectively\n✅ Conclusion\nDDIM is a powerful extension of diffusion models that addresses one of their biggest\nlimitations—slow sampling—by introducing deterministic or semi-deterministic transitions.\nIt enables faster generation while maintaining sample fidelity and diversity, making it highly\nsuitable for real-world applications like image synthesis, animation, and interactive creative\ntools.",
      "filename": "UNIT I - GCV NOTES.pdf",
      "page": null
    }
  ]
}